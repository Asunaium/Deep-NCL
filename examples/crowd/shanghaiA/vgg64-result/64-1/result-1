Log file created at: 2017/07/26 09:51:08
Running on machine: peiyong-All-Series
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0726 09:51:08.116839 27891 caffe.cpp:218] Using GPUs 1
I0726 09:51:08.137507 27891 caffe.cpp:223] GPU 1: GeForce GTX TITAN X
I0726 09:51:08.629720 27891 solver.cpp:44] Initializing solver from parameters: 
test_iter: 182
test_interval: 5400
base_lr: 1e-09
display: 5400
max_iter: 2160000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2160000
snapshot: 5400
snapshot_prefix: "examples/crowd/code/shanghaiA/model/network_vgg_1"
solver_mode: GPU
device_id: 1
net: "examples/crowd/code/shanghaiA/network_vgg_v1.prototxt"
train_state {
  level: 0
  stage: ""
}
I0726 09:51:08.634441 27891 solver.cpp:87] Creating training net from net file: examples/crowd/code/shanghaiA/network_vgg_v1.prototxt
I0726 09:51:08.635787 27891 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0726 09:51:08.635848 27891 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0726 09:51:08.635915 27891 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer avgscore
I0726 09:51:08.635958 27891 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mae
I0726 09:51:08.635998 27891 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mse
I0726 09:51:08.636739 27891 net.cpp:51] Initializing net from parameters: 
name: "crowd_counting"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/image_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/dmap_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv_score"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv_score"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    group: 64
    stride: 1
    weight_filler {
      type: "constant"
      value: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_score"
  type: "ReLU"
  bottom: "conv_score"
  top: "conv_score"
}
layer {
  name: "slicer_conv"
  type: "Slice"
  bottom: "conv_score"
  top: "score1"
  top: "score2"
  top: "score3"
  top: "score4"
  top: "score5"
  top: "score6"
  top: "score7"
  top: "score8"
  top: "score9"
  top: "score10"
  top: "score11"
  top: "score12"
  top: "score13"
  top: "score14"
  top: "score15"
  top: "score16"
  top: "score17"
  top: "score18"
  top: "score19"
  top: "score20"
  top: "score21"
  top: "score22"
  top: "score23"
  top: "score24"
  top: "score25"
  top: "score26"
  top: "score27"
  top: "score28"
  top: "score29"
  top: "score30"
  top: "score31"
  top: "score32"
  top: "score33"
  top: "score34"
  top: "score35"
  top: "score36"
  top: "score37"
  top: "score38"
  top: "score39"
  top: "score40"
  top: "score41"
  top: "score42"
  top: "score43"
  top: "score44"
  top: "score45"
  top: "score46"
  top: "score47"
  top: "score48"
  top: "score49"
  top: "score50"
  top: "score51"
  top: "score52"
  top: "score53"
  top: "score54"
  top: "score55"
  top: "score56"
  top: "score57"
  top: "score58"
  top: "score59"
  top: "score60"
  top: "score61"
  top: "score62"
  top: "score63"
  top: "score64"
  slice_param {
    axis: 1
  }
}
layer {
  name: "sumscore"
  type: "Eltwise"
  bottom: "score1"
  bottom: "score2"
  bottom: "score3"
  bottom: "score4"
  bottom: "score5"
  bottom: "score6"
  bottom: "score7"
  bottom: "score8"
  bottom: "score9"
  bottom: "score10"
  bottom: "score11"
  bottom: "score12"
  bottom: "score13"
  bottom: "score14"
  bottom: "score15"
  bottom: "score16"
  bottom: "score17"
  bottom: "score18"
  bottom: "score19"
  bottom: "score20"
  bottom: "score21"
  bottom: "score22"
  bottom: "score23"
  bottom: "score24"
  bottom: "score25"
  bottom: "score26"
  bottom: "score27"
  bottom: "score28"
  bottom: "score29"
  bottom: "score30"
  bottom: "score31"
  bottom: "score32"
  bottom: "score33"
  bottom: "score34"
  bottom: "score35"
  bottom: "score36"
  bottom: "score37"
  bottom: "score38"
  bottom: "score39"
  bottom: "score40"
  bottom: "score41"
  bottom: "score42"
  bottom: "score43"
  bottom: "score44"
  bottom: "score45"
  bottom: "score46"
  bottom: "score47"
  bottom: "score48"
  bottom: "score49"
  bottom: "score50"
  bottom: "score51"
  bottom: "score52"
  bottom: "score53"
  bottom: "score54"
  bottom: "score55"
  bottom: "score56"
  bottom: "score57"
  bottom: "score58"
  bottom: "score59"
  bottom: "score60"
  bottom: "score61"
  bottom: "score62"
  bottom: "score63"
  bottom: "score64"
  top: "sumscore"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "loss1"
  type: "NCLLoss"
  bottom: "score1"
  bottom: "label"
  bottom: "sumscore"
  top: "loss1"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss2"
  type: "NCLLoss"
  bottom: "score2"
  bottom: "label"
  bottom: "sumscore"
  top: "loss2"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss3"
  type: "NCLLoss"
  bottom: "score3"
  bottom: "label"
  bottom: "sumscore"
  top: "loss3"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss4"
  type: "NCLLoss"
  bottom: "score4"
  bottom: "label"
  bottom: "sumscore"
  top: "loss4"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss5"
  type: "NCLLoss"
  bottom: "score5"
  bottom: "label"
  bottom: "sumscore"
  top: "loss5"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss6"
  type: "NCLLoss"
  bottom: "score6"
  bottom: "label"
  bottom: "sumscore"
  top: "loss6"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss7"
  type: "NCLLoss"
  bottom: "score7"
  bottom: "label"
  bottom: "sumscore"
  top: "loss7"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss8"
  type: "NCLLoss"
  bottom: "score8"
  bottom: "label"
  bottom: "sumscore"
  top: "loss8"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss9"
  type: "NCLLoss"
  bottom: "score9"
  bottom: "label"
  bottom: "sumscore"
  top: "loss9"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss10"
  type: "NCLLoss"
  bottom: "score10"
  bottom: "label"
  bottom: "sumscore"
  top: "loss10"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss11"
  type: "NCLLoss"
  bottom: "score11"
  bottom: "label"
  bottom: "sumscore"
  top: "loss11"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss12"
  type: "NCLLoss"
  bottom: "score12"
  bottom: "label"
  bottom: "sumscore"
  top: "loss12"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss13"
  type: "NCLLoss"
  bottom: "score13"
  bottom: "label"
  bottom: "sumscore"
  top: "loss13"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss14"
  type: "NCLLoss"
  bottom: "score14"
  bottom: "label"
  bottom: "sumscore"
  top: "loss14"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss15"
  type: "NCLLoss"
  bottom: "score15"
  bottom: "label"
  bottom: "sumscore"
  top: "loss15"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss16"
  type: "NCLLoss"
  bottom: "score16"
  bottom: "label"
  bottom: "sumscore"
  top: "loss16"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss17"
  type: "NCLLoss"
  bottom: "score17"
  bottom: "label"
  bottom: "sumscore"
  top: "loss17"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss18"
  type: "NCLLoss"
  bottom: "score18"
  bottom: "label"
  bottom: "sumscore"
  top: "loss18"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss19"
  type: "NCLLoss"
  bottom: "score19"
  bottom: "label"
  bottom: "sumscore"
  top: "loss19"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss20"
  type: "NCLLoss"
  bottom: "score20"
  bottom: "label"
  bottom: "sumscore"
  top: "loss20"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss21"
  type: "NCLLoss"
  bottom: "score21"
  bottom: "label"
  bottom: "sumscore"
  top: "loss21"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss22"
  type: "NCLLoss"
  bottom: "score22"
  bottom: "label"
  bottom: "sumscore"
  top: "loss22"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss23"
  type: "NCLLoss"
  bottom: "score23"
  bottom: "label"
  bottom: "sumscore"
  top: "loss23"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss24"
  type: "NCLLoss"
  bottom: "score24"
  bottom: "label"
  bottom: "sumscore"
  top: "loss24"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss25"
  type: "NCLLoss"
  bottom: "score25"
  bottom: "label"
  bottom: "sumscore"
  top: "loss25"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss26"
  type: "NCLLoss"
  bottom: "score26"
  bottom: "label"
  bottom: "sumscore"
  top: "loss26"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss27"
  type: "NCLLoss"
  bottom: "score27"
  bottom: "label"
  bottom: "sumscore"
  top: "loss27"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss28"
  type: "NCLLoss"
  bottom: "score28"
  bottom: "label"
  bottom: "sumscore"
  top: "loss28"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss29"
  type: "NCLLoss"
  bottom: "score29"
  bottom: "label"
  bottom: "sumscore"
  top: "loss29"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss30"
  type: "NCLLoss"
  bottom: "score30"
  bottom: "label"
  bottom: "sumscore"
  top: "loss30"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss31"
  type: "NCLLoss"
  bottom: "score31"
  bottom: "label"
  bottom: "sumscore"
  top: "loss31"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss32"
  type: "NCLLoss"
  bottom: "score32"
  bottom: "label"
  bottom: "sumscore"
  top: "loss32"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss33"
  type: "NCLLoss"
  bottom: "score33"
  bottom: "label"
  bottom: "sumscore"
  top: "loss33"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss34"
  type: "NCLLoss"
  bottom: "score34"
  bottom: "label"
  bottom: "sumscore"
  top: "loss34"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss35"
  type: "NCLLoss"
  bottom: "score35"
  bottom: "label"
  bottom: "sumscore"
  top: "loss35"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss36"
  type: "NCLLoss"
  bottom: "score36"
  bottom: "label"
  bottom: "sumscore"
  top: "loss36"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss37"
  type: "NCLLoss"
  bottom: "score37"
  bottom: "label"
  bottom: "sumscore"
  top: "loss37"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss38"
  type: "NCLLoss"
  bottom: "score38"
  bottom: "label"
  bottom: "sumscore"
  top: "loss38"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss39"
  type: "NCLLoss"
  bottom: "score39"
  bottom: "label"
  bottom: "sumscore"
  top: "loss39"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss40"
  type: "NCLLoss"
  bottom: "score40"
  bottom: "label"
  bottom: "sumscore"
  top: "loss40"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss41"
  type: "NCLLoss"
  bottom: "score41"
  bottom: "label"
  bottom: "sumscore"
  top: "loss41"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss42"
  type: "NCLLoss"
  bottom: "score42"
  bottom: "label"
  bottom: "sumscore"
  top: "loss42"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss43"
  type: "NCLLoss"
  bottom: "score43"
  bottom: "label"
  bottom: "sumscore"
  top: "loss43"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss44"
  type: "NCLLoss"
  bottom: "score44"
  bottom: "label"
  bottom: "sumscore"
  top: "loss44"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss45"
  type: "NCLLoss"
  bottom: "score45"
  bottom: "label"
  bottom: "sumscore"
  top: "loss45"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss46"
  type: "NCLLoss"
  bottom: "score46"
  bottom: "label"
  bottom: "sumscore"
  top: "loss46"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss47"
  type: "NCLLoss"
  bottom: "score47"
  bottom: "label"
  bottom: "sumscore"
  top: "loss47"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss48"
  type: "NCLLoss"
  bottom: "score48"
  bottom: "label"
  bottom: "sumscore"
  top: "loss48"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss49"
  type: "NCLLoss"
  bottom: "score49"
  bottom: "label"
  bottom: "sumscore"
  top: "loss49"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss50"
  type: "NCLLoss"
  bottom: "score50"
  bottom: "label"
  bottom: "sumscore"
  top: "loss50"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss51"
  type: "NCLLoss"
  bottom: "score51"
  bottom: "label"
  bottom: "sumscore"
  top: "loss51"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss52"
  type: "NCLLoss"
  bottom: "score52"
  bottom: "label"
  bottom: "sumscore"
  top: "loss52"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss53"
  type: "NCLLoss"
  bottom: "score53"
  bottom: "label"
  bottom: "sumscore"
  top: "loss53"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss54"
  type: "NCLLoss"
  bottom: "score54"
  bottom: "label"
  bottom: "sumscore"
  top: "loss54"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss55"
  type: "NCLLoss"
  bottom: "score55"
  bottom: "label"
  bottom: "sumscore"
  top: "loss55"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss56"
  type: "NCLLoss"
  bottom: "score56"
  bottom: "label"
  bottom: "sumscore"
  top: "loss56"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss57"
  type: "NCLLoss"
  bottom: "score57"
  bottom: "label"
  bottom: "sumscore"
  top: "loss57"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss58"
  type: "NCLLoss"
  bottom: "score58"
  bottom: "label"
  bottom: "sumscore"
  top: "loss58"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss59"
  type: "NCLLoss"
  bottom: "score59"
  bottom: "label"
  bottom: "sumscore"
  top: "loss59"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss60"
  type: "NCLLoss"
  bottom: "score60"
  bottom: "label"
  bottom: "sumscore"
  top: "loss60"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss61"
  type: "NCLLoss"
  bottom: "score61"
  bottom: "label"
  bottom: "sumscore"
  top: "loss61"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss62"
  type: "NCLLoss"
  bottom: "score62"
  bottom: "label"
  bottom: "sumscore"
  top: "loss62"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss63"
  type: "NCLLoss"
  bottom: "score63"
  bottom: "label"
  bottom: "sumscore"
  top: "loss63"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
layer {
  name: "loss64"
  type: "NCLLoss"
  bottom: "score64"
  bottom: "label"
  bottom: "sumscore"
  top: "loss64"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1
    net_num: 64
  }
}
I0726 09:51:08.640043 27891 layer_factory.hpp:77] Creating layer data
I0726 09:51:08.640275 27891 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/image_lmdb
I0726 09:51:08.640326 27891 net.cpp:84] Creating Layer data
I0726 09:51:08.640338 27891 net.cpp:380] data -> data
I0726 09:51:08.641504 27891 data_layer.cpp:45] output data size: 1,3,384,512
I0726 09:51:08.648078 27891 net.cpp:122] Setting up data
I0726 09:51:08.648104 27891 net.cpp:129] Top shape: 1 3 384 512 (589824)
I0726 09:51:08.648111 27891 net.cpp:137] Memory required for data: 2359296
I0726 09:51:08.648121 27891 layer_factory.hpp:77] Creating layer label
I0726 09:51:08.648288 27891 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/dmap_lmdb
I0726 09:51:08.648321 27891 net.cpp:84] Creating Layer label
I0726 09:51:08.648331 27891 net.cpp:380] label -> label
I0726 09:51:08.648440 27891 data_layer.cpp:45] output data size: 1,1,48,64
I0726 09:51:08.649426 27891 net.cpp:122] Setting up label
I0726 09:51:08.649444 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.649451 27891 net.cpp:137] Memory required for data: 2371584
I0726 09:51:08.649457 27891 layer_factory.hpp:77] Creating layer label_label_0_split
I0726 09:51:08.649477 27891 net.cpp:84] Creating Layer label_label_0_split
I0726 09:51:08.649484 27891 net.cpp:406] label_label_0_split <- label
I0726 09:51:08.649504 27891 net.cpp:380] label_label_0_split -> label_label_0_split_0
I0726 09:51:08.649523 27891 net.cpp:380] label_label_0_split -> label_label_0_split_1
I0726 09:51:08.649538 27891 net.cpp:380] label_label_0_split -> label_label_0_split_2
I0726 09:51:08.649555 27891 net.cpp:380] label_label_0_split -> label_label_0_split_3
I0726 09:51:08.649570 27891 net.cpp:380] label_label_0_split -> label_label_0_split_4
I0726 09:51:08.649586 27891 net.cpp:380] label_label_0_split -> label_label_0_split_5
I0726 09:51:08.649602 27891 net.cpp:380] label_label_0_split -> label_label_0_split_6
I0726 09:51:08.649619 27891 net.cpp:380] label_label_0_split -> label_label_0_split_7
I0726 09:51:08.649634 27891 net.cpp:380] label_label_0_split -> label_label_0_split_8
I0726 09:51:08.649651 27891 net.cpp:380] label_label_0_split -> label_label_0_split_9
I0726 09:51:08.649665 27891 net.cpp:380] label_label_0_split -> label_label_0_split_10
I0726 09:51:08.649682 27891 net.cpp:380] label_label_0_split -> label_label_0_split_11
I0726 09:51:08.649698 27891 net.cpp:380] label_label_0_split -> label_label_0_split_12
I0726 09:51:08.649713 27891 net.cpp:380] label_label_0_split -> label_label_0_split_13
I0726 09:51:08.649729 27891 net.cpp:380] label_label_0_split -> label_label_0_split_14
I0726 09:51:08.649746 27891 net.cpp:380] label_label_0_split -> label_label_0_split_15
I0726 09:51:08.649762 27891 net.cpp:380] label_label_0_split -> label_label_0_split_16
I0726 09:51:08.649778 27891 net.cpp:380] label_label_0_split -> label_label_0_split_17
I0726 09:51:08.649794 27891 net.cpp:380] label_label_0_split -> label_label_0_split_18
I0726 09:51:08.649809 27891 net.cpp:380] label_label_0_split -> label_label_0_split_19
I0726 09:51:08.649827 27891 net.cpp:380] label_label_0_split -> label_label_0_split_20
I0726 09:51:08.649842 27891 net.cpp:380] label_label_0_split -> label_label_0_split_21
I0726 09:51:08.649857 27891 net.cpp:380] label_label_0_split -> label_label_0_split_22
I0726 09:51:08.649873 27891 net.cpp:380] label_label_0_split -> label_label_0_split_23
I0726 09:51:08.649888 27891 net.cpp:380] label_label_0_split -> label_label_0_split_24
I0726 09:51:08.649904 27891 net.cpp:380] label_label_0_split -> label_label_0_split_25
I0726 09:51:08.649920 27891 net.cpp:380] label_label_0_split -> label_label_0_split_26
I0726 09:51:08.649935 27891 net.cpp:380] label_label_0_split -> label_label_0_split_27
I0726 09:51:08.650895 27891 net.cpp:380] label_label_0_split -> label_label_0_split_28
I0726 09:51:08.650910 27891 net.cpp:380] label_label_0_split -> label_label_0_split_29
I0726 09:51:08.650923 27891 net.cpp:380] label_label_0_split -> label_label_0_split_30
I0726 09:51:08.650938 27891 net.cpp:380] label_label_0_split -> label_label_0_split_31
I0726 09:51:08.650949 27891 net.cpp:380] label_label_0_split -> label_label_0_split_32
I0726 09:51:08.650965 27891 net.cpp:380] label_label_0_split -> label_label_0_split_33
I0726 09:51:08.650981 27891 net.cpp:380] label_label_0_split -> label_label_0_split_34
I0726 09:51:08.650997 27891 net.cpp:380] label_label_0_split -> label_label_0_split_35
I0726 09:51:08.651012 27891 net.cpp:380] label_label_0_split -> label_label_0_split_36
I0726 09:51:08.651036 27891 net.cpp:380] label_label_0_split -> label_label_0_split_37
I0726 09:51:08.651052 27891 net.cpp:380] label_label_0_split -> label_label_0_split_38
I0726 09:51:08.651068 27891 net.cpp:380] label_label_0_split -> label_label_0_split_39
I0726 09:51:08.651084 27891 net.cpp:380] label_label_0_split -> label_label_0_split_40
I0726 09:51:08.651100 27891 net.cpp:380] label_label_0_split -> label_label_0_split_41
I0726 09:51:08.651115 27891 net.cpp:380] label_label_0_split -> label_label_0_split_42
I0726 09:51:08.651131 27891 net.cpp:380] label_label_0_split -> label_label_0_split_43
I0726 09:51:08.651146 27891 net.cpp:380] label_label_0_split -> label_label_0_split_44
I0726 09:51:08.651162 27891 net.cpp:380] label_label_0_split -> label_label_0_split_45
I0726 09:51:08.651178 27891 net.cpp:380] label_label_0_split -> label_label_0_split_46
I0726 09:51:08.651195 27891 net.cpp:380] label_label_0_split -> label_label_0_split_47
I0726 09:51:08.651211 27891 net.cpp:380] label_label_0_split -> label_label_0_split_48
I0726 09:51:08.651226 27891 net.cpp:380] label_label_0_split -> label_label_0_split_49
I0726 09:51:08.651242 27891 net.cpp:380] label_label_0_split -> label_label_0_split_50
I0726 09:51:08.651257 27891 net.cpp:380] label_label_0_split -> label_label_0_split_51
I0726 09:51:08.651273 27891 net.cpp:380] label_label_0_split -> label_label_0_split_52
I0726 09:51:08.651288 27891 net.cpp:380] label_label_0_split -> label_label_0_split_53
I0726 09:51:08.651304 27891 net.cpp:380] label_label_0_split -> label_label_0_split_54
I0726 09:51:08.651319 27891 net.cpp:380] label_label_0_split -> label_label_0_split_55
I0726 09:51:08.651335 27891 net.cpp:380] label_label_0_split -> label_label_0_split_56
I0726 09:51:08.651351 27891 net.cpp:380] label_label_0_split -> label_label_0_split_57
I0726 09:51:08.651366 27891 net.cpp:380] label_label_0_split -> label_label_0_split_58
I0726 09:51:08.651382 27891 net.cpp:380] label_label_0_split -> label_label_0_split_59
I0726 09:51:08.651398 27891 net.cpp:380] label_label_0_split -> label_label_0_split_60
I0726 09:51:08.651414 27891 net.cpp:380] label_label_0_split -> label_label_0_split_61
I0726 09:51:08.651430 27891 net.cpp:380] label_label_0_split -> label_label_0_split_62
I0726 09:51:08.651454 27891 net.cpp:380] label_label_0_split -> label_label_0_split_63
I0726 09:51:08.652048 27891 net.cpp:122] Setting up label_label_0_split
I0726 09:51:08.652058 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652065 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652072 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652079 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652086 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652101 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652108 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652114 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652122 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652127 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652134 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652140 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652146 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652165 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652173 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652179 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652185 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652191 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652199 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652204 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652210 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652217 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652223 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652230 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652236 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652242 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652248 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652256 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652261 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652267 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652274 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652281 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652287 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652293 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652299 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652307 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652312 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652318 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652325 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652331 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652338 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652344 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652350 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652357 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652364 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652370 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652376 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652384 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652390 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652395 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652402 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652408 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652415 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652421 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652427 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652434 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652441 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652446 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652453 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652459 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652465 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652472 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652478 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652485 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:08.652490 27891 net.cpp:137] Memory required for data: 3158016
I0726 09:51:08.652496 27891 layer_factory.hpp:77] Creating layer conv1_1
I0726 09:51:08.652514 27891 net.cpp:84] Creating Layer conv1_1
I0726 09:51:08.652520 27891 net.cpp:406] conv1_1 <- data
I0726 09:51:08.652529 27891 net.cpp:380] conv1_1 -> conv1_1
I0726 09:51:09.058389 27891 net.cpp:122] Setting up conv1_1
I0726 09:51:09.058419 27891 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0726 09:51:09.058423 27891 net.cpp:137] Memory required for data: 53489664
I0726 09:51:09.058444 27891 layer_factory.hpp:77] Creating layer relu1_1
I0726 09:51:09.058531 27891 net.cpp:84] Creating Layer relu1_1
I0726 09:51:09.058538 27891 net.cpp:406] relu1_1 <- conv1_1
I0726 09:51:09.058545 27891 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0726 09:51:09.058686 27891 net.cpp:122] Setting up relu1_1
I0726 09:51:09.058696 27891 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0726 09:51:09.058699 27891 net.cpp:137] Memory required for data: 103821312
I0726 09:51:09.058703 27891 layer_factory.hpp:77] Creating layer conv1_2
I0726 09:51:09.058714 27891 net.cpp:84] Creating Layer conv1_2
I0726 09:51:09.058718 27891 net.cpp:406] conv1_2 <- conv1_1
I0726 09:51:09.058724 27891 net.cpp:380] conv1_2 -> conv1_2
I0726 09:51:09.061512 27891 net.cpp:122] Setting up conv1_2
I0726 09:51:09.061533 27891 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0726 09:51:09.061537 27891 net.cpp:137] Memory required for data: 154152960
I0726 09:51:09.061545 27891 layer_factory.hpp:77] Creating layer relu1_2
I0726 09:51:09.061552 27891 net.cpp:84] Creating Layer relu1_2
I0726 09:51:09.061555 27891 net.cpp:406] relu1_2 <- conv1_2
I0726 09:51:09.061560 27891 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0726 09:51:09.061704 27891 net.cpp:122] Setting up relu1_2
I0726 09:51:09.061713 27891 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0726 09:51:09.061717 27891 net.cpp:137] Memory required for data: 204484608
I0726 09:51:09.061722 27891 layer_factory.hpp:77] Creating layer pool1
I0726 09:51:09.061728 27891 net.cpp:84] Creating Layer pool1
I0726 09:51:09.061733 27891 net.cpp:406] pool1 <- conv1_2
I0726 09:51:09.061739 27891 net.cpp:380] pool1 -> pool1
I0726 09:51:09.061781 27891 net.cpp:122] Setting up pool1
I0726 09:51:09.061789 27891 net.cpp:129] Top shape: 1 64 192 256 (3145728)
I0726 09:51:09.061794 27891 net.cpp:137] Memory required for data: 217067520
I0726 09:51:09.061796 27891 layer_factory.hpp:77] Creating layer conv2_1
I0726 09:51:09.061806 27891 net.cpp:84] Creating Layer conv2_1
I0726 09:51:09.061810 27891 net.cpp:406] conv2_1 <- pool1
I0726 09:51:09.061816 27891 net.cpp:380] conv2_1 -> conv2_1
I0726 09:51:09.064450 27891 net.cpp:122] Setting up conv2_1
I0726 09:51:09.064463 27891 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0726 09:51:09.064467 27891 net.cpp:137] Memory required for data: 242233344
I0726 09:51:09.064476 27891 layer_factory.hpp:77] Creating layer relu2_1
I0726 09:51:09.064481 27891 net.cpp:84] Creating Layer relu2_1
I0726 09:51:09.064486 27891 net.cpp:406] relu2_1 <- conv2_1
I0726 09:51:09.064491 27891 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0726 09:51:09.065006 27891 net.cpp:122] Setting up relu2_1
I0726 09:51:09.065016 27891 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0726 09:51:09.065021 27891 net.cpp:137] Memory required for data: 267399168
I0726 09:51:09.065024 27891 layer_factory.hpp:77] Creating layer conv2_2
I0726 09:51:09.065035 27891 net.cpp:84] Creating Layer conv2_2
I0726 09:51:09.065039 27891 net.cpp:406] conv2_2 <- conv2_1
I0726 09:51:09.065045 27891 net.cpp:380] conv2_2 -> conv2_2
I0726 09:51:09.067927 27891 net.cpp:122] Setting up conv2_2
I0726 09:51:09.067939 27891 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0726 09:51:09.067944 27891 net.cpp:137] Memory required for data: 292564992
I0726 09:51:09.067950 27891 layer_factory.hpp:77] Creating layer relu2_2
I0726 09:51:09.067956 27891 net.cpp:84] Creating Layer relu2_2
I0726 09:51:09.067960 27891 net.cpp:406] relu2_2 <- conv2_2
I0726 09:51:09.067967 27891 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0726 09:51:09.068110 27891 net.cpp:122] Setting up relu2_2
I0726 09:51:09.068120 27891 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0726 09:51:09.068122 27891 net.cpp:137] Memory required for data: 317730816
I0726 09:51:09.068126 27891 layer_factory.hpp:77] Creating layer pool2
I0726 09:51:09.068132 27891 net.cpp:84] Creating Layer pool2
I0726 09:51:09.068136 27891 net.cpp:406] pool2 <- conv2_2
I0726 09:51:09.068141 27891 net.cpp:380] pool2 -> pool2
I0726 09:51:09.068177 27891 net.cpp:122] Setting up pool2
I0726 09:51:09.068183 27891 net.cpp:129] Top shape: 1 128 96 128 (1572864)
I0726 09:51:09.068217 27891 net.cpp:137] Memory required for data: 324022272
I0726 09:51:09.068225 27891 layer_factory.hpp:77] Creating layer conv3_1
I0726 09:51:09.068238 27891 net.cpp:84] Creating Layer conv3_1
I0726 09:51:09.068243 27891 net.cpp:406] conv3_1 <- pool2
I0726 09:51:09.068248 27891 net.cpp:380] conv3_1 -> conv3_1
I0726 09:51:09.073446 27891 net.cpp:122] Setting up conv3_1
I0726 09:51:09.073465 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.073472 27891 net.cpp:137] Memory required for data: 336605184
I0726 09:51:09.073487 27891 layer_factory.hpp:77] Creating layer relu3_1
I0726 09:51:09.073495 27891 net.cpp:84] Creating Layer relu3_1
I0726 09:51:09.073503 27891 net.cpp:406] relu3_1 <- conv3_1
I0726 09:51:09.073510 27891 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0726 09:51:09.073720 27891 net.cpp:122] Setting up relu3_1
I0726 09:51:09.073732 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.073737 27891 net.cpp:137] Memory required for data: 349188096
I0726 09:51:09.073743 27891 layer_factory.hpp:77] Creating layer conv3_2
I0726 09:51:09.073757 27891 net.cpp:84] Creating Layer conv3_2
I0726 09:51:09.073763 27891 net.cpp:406] conv3_2 <- conv3_1
I0726 09:51:09.073773 27891 net.cpp:380] conv3_2 -> conv3_2
I0726 09:51:09.084496 27891 net.cpp:122] Setting up conv3_2
I0726 09:51:09.084513 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.084519 27891 net.cpp:137] Memory required for data: 361771008
I0726 09:51:09.084529 27891 layer_factory.hpp:77] Creating layer relu3_2
I0726 09:51:09.084542 27891 net.cpp:84] Creating Layer relu3_2
I0726 09:51:09.084548 27891 net.cpp:406] relu3_2 <- conv3_2
I0726 09:51:09.084556 27891 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0726 09:51:09.085227 27891 net.cpp:122] Setting up relu3_2
I0726 09:51:09.085242 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.085247 27891 net.cpp:137] Memory required for data: 374353920
I0726 09:51:09.085253 27891 layer_factory.hpp:77] Creating layer conv3_3
I0726 09:51:09.085266 27891 net.cpp:84] Creating Layer conv3_3
I0726 09:51:09.085273 27891 net.cpp:406] conv3_3 <- conv3_2
I0726 09:51:09.085281 27891 net.cpp:380] conv3_3 -> conv3_3
I0726 09:51:09.096189 27891 net.cpp:122] Setting up conv3_3
I0726 09:51:09.096220 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.096226 27891 net.cpp:137] Memory required for data: 386936832
I0726 09:51:09.096237 27891 layer_factory.hpp:77] Creating layer relu3_3
I0726 09:51:09.096249 27891 net.cpp:84] Creating Layer relu3_3
I0726 09:51:09.096256 27891 net.cpp:406] relu3_3 <- conv3_3
I0726 09:51:09.096266 27891 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0726 09:51:09.096474 27891 net.cpp:122] Setting up relu3_3
I0726 09:51:09.096487 27891 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0726 09:51:09.096491 27891 net.cpp:137] Memory required for data: 399519744
I0726 09:51:09.096498 27891 layer_factory.hpp:77] Creating layer pool3
I0726 09:51:09.096508 27891 net.cpp:84] Creating Layer pool3
I0726 09:51:09.096513 27891 net.cpp:406] pool3 <- conv3_3
I0726 09:51:09.096523 27891 net.cpp:380] pool3 -> pool3
I0726 09:51:09.096575 27891 net.cpp:122] Setting up pool3
I0726 09:51:09.096585 27891 net.cpp:129] Top shape: 1 256 48 64 (786432)
I0726 09:51:09.096590 27891 net.cpp:137] Memory required for data: 402665472
I0726 09:51:09.096596 27891 layer_factory.hpp:77] Creating layer conv4_1
I0726 09:51:09.096609 27891 net.cpp:84] Creating Layer conv4_1
I0726 09:51:09.096616 27891 net.cpp:406] conv4_1 <- pool3
I0726 09:51:09.096624 27891 net.cpp:380] conv4_1 -> conv4_1
I0726 09:51:09.116726 27891 net.cpp:122] Setting up conv4_1
I0726 09:51:09.116765 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.116771 27891 net.cpp:137] Memory required for data: 408956928
I0726 09:51:09.116782 27891 layer_factory.hpp:77] Creating layer relu4_1
I0726 09:51:09.116793 27891 net.cpp:84] Creating Layer relu4_1
I0726 09:51:09.116801 27891 net.cpp:406] relu4_1 <- conv4_1
I0726 09:51:09.116812 27891 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0726 09:51:09.117065 27891 net.cpp:122] Setting up relu4_1
I0726 09:51:09.117080 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.117087 27891 net.cpp:137] Memory required for data: 415248384
I0726 09:51:09.117094 27891 layer_factory.hpp:77] Creating layer conv4_2
I0726 09:51:09.117110 27891 net.cpp:84] Creating Layer conv4_2
I0726 09:51:09.117118 27891 net.cpp:406] conv4_2 <- conv4_1
I0726 09:51:09.117130 27891 net.cpp:380] conv4_2 -> conv4_2
I0726 09:51:09.142771 27891 net.cpp:122] Setting up conv4_2
I0726 09:51:09.142804 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.142809 27891 net.cpp:137] Memory required for data: 421539840
I0726 09:51:09.142828 27891 layer_factory.hpp:77] Creating layer relu4_2
I0726 09:51:09.142840 27891 net.cpp:84] Creating Layer relu4_2
I0726 09:51:09.142856 27891 net.cpp:406] relu4_2 <- conv4_2
I0726 09:51:09.142865 27891 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0726 09:51:09.143471 27891 net.cpp:122] Setting up relu4_2
I0726 09:51:09.143482 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.143486 27891 net.cpp:137] Memory required for data: 427831296
I0726 09:51:09.143489 27891 layer_factory.hpp:77] Creating layer conv4_3
I0726 09:51:09.143501 27891 net.cpp:84] Creating Layer conv4_3
I0726 09:51:09.143504 27891 net.cpp:406] conv4_3 <- conv4_2
I0726 09:51:09.143512 27891 net.cpp:380] conv4_3 -> conv4_3
I0726 09:51:09.165585 27891 net.cpp:122] Setting up conv4_3
I0726 09:51:09.165611 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.165614 27891 net.cpp:137] Memory required for data: 434122752
I0726 09:51:09.165623 27891 layer_factory.hpp:77] Creating layer relu4_3
I0726 09:51:09.165632 27891 net.cpp:84] Creating Layer relu4_3
I0726 09:51:09.165637 27891 net.cpp:406] relu4_3 <- conv4_3
I0726 09:51:09.165643 27891 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0726 09:51:09.165787 27891 net.cpp:122] Setting up relu4_3
I0726 09:51:09.165796 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.165799 27891 net.cpp:137] Memory required for data: 440414208
I0726 09:51:09.165802 27891 layer_factory.hpp:77] Creating layer pool4
I0726 09:51:09.165810 27891 net.cpp:84] Creating Layer pool4
I0726 09:51:09.165814 27891 net.cpp:406] pool4 <- conv4_3
I0726 09:51:09.165819 27891 net.cpp:380] pool4 -> pool4
I0726 09:51:09.165858 27891 net.cpp:122] Setting up pool4
I0726 09:51:09.165865 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.165868 27891 net.cpp:137] Memory required for data: 446705664
I0726 09:51:09.165871 27891 layer_factory.hpp:77] Creating layer conv5_1
I0726 09:51:09.165881 27891 net.cpp:84] Creating Layer conv5_1
I0726 09:51:09.165885 27891 net.cpp:406] conv5_1 <- pool4
I0726 09:51:09.165892 27891 net.cpp:380] conv5_1 -> conv5_1
I0726 09:51:09.189473 27891 net.cpp:122] Setting up conv5_1
I0726 09:51:09.189507 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.189512 27891 net.cpp:137] Memory required for data: 452997120
I0726 09:51:09.189523 27891 layer_factory.hpp:77] Creating layer relu5_1
I0726 09:51:09.189538 27891 net.cpp:84] Creating Layer relu5_1
I0726 09:51:09.189544 27891 net.cpp:406] relu5_1 <- conv5_1
I0726 09:51:09.189554 27891 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0726 09:51:09.190309 27891 net.cpp:122] Setting up relu5_1
I0726 09:51:09.190322 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.190328 27891 net.cpp:137] Memory required for data: 459288576
I0726 09:51:09.190335 27891 layer_factory.hpp:77] Creating layer conv5_2
I0726 09:51:09.190351 27891 net.cpp:84] Creating Layer conv5_2
I0726 09:51:09.190356 27891 net.cpp:406] conv5_2 <- conv5_1
I0726 09:51:09.190367 27891 net.cpp:380] conv5_2 -> conv5_2
I0726 09:51:09.220088 27891 net.cpp:122] Setting up conv5_2
I0726 09:51:09.220130 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.220139 27891 net.cpp:137] Memory required for data: 465580032
I0726 09:51:09.220165 27891 layer_factory.hpp:77] Creating layer relu5_2
I0726 09:51:09.220181 27891 net.cpp:84] Creating Layer relu5_2
I0726 09:51:09.220234 27891 net.cpp:406] relu5_2 <- conv5_2
I0726 09:51:09.220247 27891 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0726 09:51:09.220494 27891 net.cpp:122] Setting up relu5_2
I0726 09:51:09.220506 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.220512 27891 net.cpp:137] Memory required for data: 471871488
I0726 09:51:09.220517 27891 layer_factory.hpp:77] Creating layer conv5_3
I0726 09:51:09.220532 27891 net.cpp:84] Creating Layer conv5_3
I0726 09:51:09.220538 27891 net.cpp:406] conv5_3 <- conv5_2
I0726 09:51:09.220551 27891 net.cpp:380] conv5_3 -> conv5_3
I0726 09:51:09.250205 27891 net.cpp:122] Setting up conv5_3
I0726 09:51:09.250238 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.250244 27891 net.cpp:137] Memory required for data: 478162944
I0726 09:51:09.250255 27891 layer_factory.hpp:77] Creating layer relu5_3
I0726 09:51:09.250273 27891 net.cpp:84] Creating Layer relu5_3
I0726 09:51:09.250282 27891 net.cpp:406] relu5_3 <- conv5_3
I0726 09:51:09.250290 27891 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0726 09:51:09.251070 27891 net.cpp:122] Setting up relu5_3
I0726 09:51:09.251085 27891 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0726 09:51:09.251090 27891 net.cpp:137] Memory required for data: 484454400
I0726 09:51:09.251096 27891 layer_factory.hpp:77] Creating layer conv_score
I0726 09:51:09.251111 27891 net.cpp:84] Creating Layer conv_score
I0726 09:51:09.251118 27891 net.cpp:406] conv_score <- conv5_3
I0726 09:51:09.251127 27891 net.cpp:380] conv_score -> conv_score
I0726 09:51:09.342447 27891 net.cpp:122] Setting up conv_score
I0726 09:51:09.342474 27891 net.cpp:129] Top shape: 1 64 48 64 (196608)
I0726 09:51:09.342480 27891 net.cpp:137] Memory required for data: 485240832
I0726 09:51:09.342494 27891 layer_factory.hpp:77] Creating layer relu_score
I0726 09:51:09.342509 27891 net.cpp:84] Creating Layer relu_score
I0726 09:51:09.342515 27891 net.cpp:406] relu_score <- conv_score
I0726 09:51:09.342525 27891 net.cpp:367] relu_score -> conv_score (in-place)
I0726 09:51:09.342738 27891 net.cpp:122] Setting up relu_score
I0726 09:51:09.342751 27891 net.cpp:129] Top shape: 1 64 48 64 (196608)
I0726 09:51:09.342756 27891 net.cpp:137] Memory required for data: 486027264
I0726 09:51:09.342761 27891 layer_factory.hpp:77] Creating layer slicer_conv
I0726 09:51:09.342777 27891 net.cpp:84] Creating Layer slicer_conv
I0726 09:51:09.342783 27891 net.cpp:406] slicer_conv <- conv_score
I0726 09:51:09.342798 27891 net.cpp:380] slicer_conv -> score1
I0726 09:51:09.342814 27891 net.cpp:380] slicer_conv -> score2
I0726 09:51:09.342828 27891 net.cpp:380] slicer_conv -> score3
I0726 09:51:09.342839 27891 net.cpp:380] slicer_conv -> score4
I0726 09:51:09.342851 27891 net.cpp:380] slicer_conv -> score5
I0726 09:51:09.342864 27891 net.cpp:380] slicer_conv -> score6
I0726 09:51:09.342875 27891 net.cpp:380] slicer_conv -> score7
I0726 09:51:09.342886 27891 net.cpp:380] slicer_conv -> score8
I0726 09:51:09.342897 27891 net.cpp:380] slicer_conv -> score9
I0726 09:51:09.342909 27891 net.cpp:380] slicer_conv -> score10
I0726 09:51:09.342921 27891 net.cpp:380] slicer_conv -> score11
I0726 09:51:09.342933 27891 net.cpp:380] slicer_conv -> score12
I0726 09:51:09.342944 27891 net.cpp:380] slicer_conv -> score13
I0726 09:51:09.342958 27891 net.cpp:380] slicer_conv -> score14
I0726 09:51:09.342969 27891 net.cpp:380] slicer_conv -> score15
I0726 09:51:09.342980 27891 net.cpp:380] slicer_conv -> score16
I0726 09:51:09.342993 27891 net.cpp:380] slicer_conv -> score17
I0726 09:51:09.343003 27891 net.cpp:380] slicer_conv -> score18
I0726 09:51:09.343015 27891 net.cpp:380] slicer_conv -> score19
I0726 09:51:09.343027 27891 net.cpp:380] slicer_conv -> score20
I0726 09:51:09.343039 27891 net.cpp:380] slicer_conv -> score21
I0726 09:51:09.343050 27891 net.cpp:380] slicer_conv -> score22
I0726 09:51:09.343062 27891 net.cpp:380] slicer_conv -> score23
I0726 09:51:09.343073 27891 net.cpp:380] slicer_conv -> score24
I0726 09:51:09.343085 27891 net.cpp:380] slicer_conv -> score25
I0726 09:51:09.343184 27891 net.cpp:380] slicer_conv -> score26
I0726 09:51:09.343200 27891 net.cpp:380] slicer_conv -> score27
I0726 09:51:09.343212 27891 net.cpp:380] slicer_conv -> score28
I0726 09:51:09.343224 27891 net.cpp:380] slicer_conv -> score29
I0726 09:51:09.343235 27891 net.cpp:380] slicer_conv -> score30
I0726 09:51:09.343246 27891 net.cpp:380] slicer_conv -> score31
I0726 09:51:09.343257 27891 net.cpp:380] slicer_conv -> score32
I0726 09:51:09.343268 27891 net.cpp:380] slicer_conv -> score33
I0726 09:51:09.343282 27891 net.cpp:380] slicer_conv -> score34
I0726 09:51:09.343294 27891 net.cpp:380] slicer_conv -> score35
I0726 09:51:09.343305 27891 net.cpp:380] slicer_conv -> score36
I0726 09:51:09.343317 27891 net.cpp:380] slicer_conv -> score37
I0726 09:51:09.343327 27891 net.cpp:380] slicer_conv -> score38
I0726 09:51:09.343339 27891 net.cpp:380] slicer_conv -> score39
I0726 09:51:09.343351 27891 net.cpp:380] slicer_conv -> score40
I0726 09:51:09.343363 27891 net.cpp:380] slicer_conv -> score41
I0726 09:51:09.343374 27891 net.cpp:380] slicer_conv -> score42
I0726 09:51:09.343385 27891 net.cpp:380] slicer_conv -> score43
I0726 09:51:09.343396 27891 net.cpp:380] slicer_conv -> score44
I0726 09:51:09.343407 27891 net.cpp:380] slicer_conv -> score45
I0726 09:51:09.343433 27891 net.cpp:380] slicer_conv -> score46
I0726 09:51:09.343446 27891 net.cpp:380] slicer_conv -> score47
I0726 09:51:09.343457 27891 net.cpp:380] slicer_conv -> score48
I0726 09:51:09.343468 27891 net.cpp:380] slicer_conv -> score49
I0726 09:51:09.343479 27891 net.cpp:380] slicer_conv -> score50
I0726 09:51:09.343492 27891 net.cpp:380] slicer_conv -> score51
I0726 09:51:09.343502 27891 net.cpp:380] slicer_conv -> score52
I0726 09:51:09.343513 27891 net.cpp:380] slicer_conv -> score53
I0726 09:51:09.343524 27891 net.cpp:380] slicer_conv -> score54
I0726 09:51:09.343536 27891 net.cpp:380] slicer_conv -> score55
I0726 09:51:09.343547 27891 net.cpp:380] slicer_conv -> score56
I0726 09:51:09.343559 27891 net.cpp:380] slicer_conv -> score57
I0726 09:51:09.343569 27891 net.cpp:380] slicer_conv -> score58
I0726 09:51:09.343580 27891 net.cpp:380] slicer_conv -> score59
I0726 09:51:09.343590 27891 net.cpp:380] slicer_conv -> score60
I0726 09:51:09.343601 27891 net.cpp:380] slicer_conv -> score61
I0726 09:51:09.343612 27891 net.cpp:380] slicer_conv -> score62
I0726 09:51:09.343623 27891 net.cpp:380] slicer_conv -> score63
I0726 09:51:09.343634 27891 net.cpp:380] slicer_conv -> score64
I0726 09:51:09.344617 27891 net.cpp:122] Setting up slicer_conv
I0726 09:51:09.344630 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344637 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344643 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344650 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344656 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344662 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344668 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344676 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344681 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344687 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344693 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344699 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344707 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344712 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344718 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344724 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344730 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344738 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344743 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344749 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344755 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344761 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344789 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344796 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344802 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344808 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344815 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344821 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344827 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344833 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344840 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344846 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344852 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344858 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344864 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344871 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344877 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344882 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344889 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344895 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344902 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344907 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344914 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344920 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344928 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344933 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344939 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344946 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344952 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344959 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344964 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344970 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344976 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344982 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344990 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.344995 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345001 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345007 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345013 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345019 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345026 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345032 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345038 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345044 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345049 27891 net.cpp:137] Memory required for data: 486813696
I0726 09:51:09.345054 27891 layer_factory.hpp:77] Creating layer score1_slicer_conv_0_split
I0726 09:51:09.345063 27891 net.cpp:84] Creating Layer score1_slicer_conv_0_split
I0726 09:51:09.345069 27891 net.cpp:406] score1_slicer_conv_0_split <- score1
I0726 09:51:09.345079 27891 net.cpp:380] score1_slicer_conv_0_split -> score1_slicer_conv_0_split_0
I0726 09:51:09.345088 27891 net.cpp:380] score1_slicer_conv_0_split -> score1_slicer_conv_0_split_1
I0726 09:51:09.345146 27891 net.cpp:122] Setting up score1_slicer_conv_0_split
I0726 09:51:09.345155 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345161 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345166 27891 net.cpp:137] Memory required for data: 486838272
I0726 09:51:09.345171 27891 layer_factory.hpp:77] Creating layer score2_slicer_conv_1_split
I0726 09:51:09.345178 27891 net.cpp:84] Creating Layer score2_slicer_conv_1_split
I0726 09:51:09.345183 27891 net.cpp:406] score2_slicer_conv_1_split <- score2
I0726 09:51:09.345191 27891 net.cpp:380] score2_slicer_conv_1_split -> score2_slicer_conv_1_split_0
I0726 09:51:09.345199 27891 net.cpp:380] score2_slicer_conv_1_split -> score2_slicer_conv_1_split_1
I0726 09:51:09.345260 27891 net.cpp:122] Setting up score2_slicer_conv_1_split
I0726 09:51:09.345269 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345274 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345279 27891 net.cpp:137] Memory required for data: 486862848
I0726 09:51:09.345284 27891 layer_factory.hpp:77] Creating layer score3_slicer_conv_2_split
I0726 09:51:09.345293 27891 net.cpp:84] Creating Layer score3_slicer_conv_2_split
I0726 09:51:09.345297 27891 net.cpp:406] score3_slicer_conv_2_split <- score3
I0726 09:51:09.345311 27891 net.cpp:380] score3_slicer_conv_2_split -> score3_slicer_conv_2_split_0
I0726 09:51:09.345321 27891 net.cpp:380] score3_slicer_conv_2_split -> score3_slicer_conv_2_split_1
I0726 09:51:09.345371 27891 net.cpp:122] Setting up score3_slicer_conv_2_split
I0726 09:51:09.345382 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345389 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345394 27891 net.cpp:137] Memory required for data: 486887424
I0726 09:51:09.345399 27891 layer_factory.hpp:77] Creating layer score4_slicer_conv_3_split
I0726 09:51:09.345407 27891 net.cpp:84] Creating Layer score4_slicer_conv_3_split
I0726 09:51:09.345412 27891 net.cpp:406] score4_slicer_conv_3_split <- score4
I0726 09:51:09.345420 27891 net.cpp:380] score4_slicer_conv_3_split -> score4_slicer_conv_3_split_0
I0726 09:51:09.345430 27891 net.cpp:380] score4_slicer_conv_3_split -> score4_slicer_conv_3_split_1
I0726 09:51:09.345489 27891 net.cpp:122] Setting up score4_slicer_conv_3_split
I0726 09:51:09.345499 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345504 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345510 27891 net.cpp:137] Memory required for data: 486912000
I0726 09:51:09.345515 27891 layer_factory.hpp:77] Creating layer score5_slicer_conv_4_split
I0726 09:51:09.345523 27891 net.cpp:84] Creating Layer score5_slicer_conv_4_split
I0726 09:51:09.345528 27891 net.cpp:406] score5_slicer_conv_4_split <- score5
I0726 09:51:09.345536 27891 net.cpp:380] score5_slicer_conv_4_split -> score5_slicer_conv_4_split_0
I0726 09:51:09.345546 27891 net.cpp:380] score5_slicer_conv_4_split -> score5_slicer_conv_4_split_1
I0726 09:51:09.345592 27891 net.cpp:122] Setting up score5_slicer_conv_4_split
I0726 09:51:09.345600 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345607 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345613 27891 net.cpp:137] Memory required for data: 486936576
I0726 09:51:09.345618 27891 layer_factory.hpp:77] Creating layer score6_slicer_conv_5_split
I0726 09:51:09.345624 27891 net.cpp:84] Creating Layer score6_slicer_conv_5_split
I0726 09:51:09.345629 27891 net.cpp:406] score6_slicer_conv_5_split <- score6
I0726 09:51:09.345638 27891 net.cpp:380] score6_slicer_conv_5_split -> score6_slicer_conv_5_split_0
I0726 09:51:09.345645 27891 net.cpp:380] score6_slicer_conv_5_split -> score6_slicer_conv_5_split_1
I0726 09:51:09.345692 27891 net.cpp:122] Setting up score6_slicer_conv_5_split
I0726 09:51:09.345701 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345708 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345713 27891 net.cpp:137] Memory required for data: 486961152
I0726 09:51:09.345718 27891 layer_factory.hpp:77] Creating layer score7_slicer_conv_6_split
I0726 09:51:09.345727 27891 net.cpp:84] Creating Layer score7_slicer_conv_6_split
I0726 09:51:09.345732 27891 net.cpp:406] score7_slicer_conv_6_split <- score7
I0726 09:51:09.345741 27891 net.cpp:380] score7_slicer_conv_6_split -> score7_slicer_conv_6_split_0
I0726 09:51:09.345748 27891 net.cpp:380] score7_slicer_conv_6_split -> score7_slicer_conv_6_split_1
I0726 09:51:09.345796 27891 net.cpp:122] Setting up score7_slicer_conv_6_split
I0726 09:51:09.345805 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345811 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345816 27891 net.cpp:137] Memory required for data: 486985728
I0726 09:51:09.345832 27891 layer_factory.hpp:77] Creating layer score8_slicer_conv_7_split
I0726 09:51:09.345840 27891 net.cpp:84] Creating Layer score8_slicer_conv_7_split
I0726 09:51:09.345846 27891 net.cpp:406] score8_slicer_conv_7_split <- score8
I0726 09:51:09.345854 27891 net.cpp:380] score8_slicer_conv_7_split -> score8_slicer_conv_7_split_0
I0726 09:51:09.345862 27891 net.cpp:380] score8_slicer_conv_7_split -> score8_slicer_conv_7_split_1
I0726 09:51:09.345913 27891 net.cpp:122] Setting up score8_slicer_conv_7_split
I0726 09:51:09.345922 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345929 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.345934 27891 net.cpp:137] Memory required for data: 487010304
I0726 09:51:09.345939 27891 layer_factory.hpp:77] Creating layer score9_slicer_conv_8_split
I0726 09:51:09.345947 27891 net.cpp:84] Creating Layer score9_slicer_conv_8_split
I0726 09:51:09.345952 27891 net.cpp:406] score9_slicer_conv_8_split <- score9
I0726 09:51:09.345962 27891 net.cpp:380] score9_slicer_conv_8_split -> score9_slicer_conv_8_split_0
I0726 09:51:09.345969 27891 net.cpp:380] score9_slicer_conv_8_split -> score9_slicer_conv_8_split_1
I0726 09:51:09.346019 27891 net.cpp:122] Setting up score9_slicer_conv_8_split
I0726 09:51:09.346026 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346034 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346038 27891 net.cpp:137] Memory required for data: 487034880
I0726 09:51:09.346043 27891 layer_factory.hpp:77] Creating layer score10_slicer_conv_9_split
I0726 09:51:09.346050 27891 net.cpp:84] Creating Layer score10_slicer_conv_9_split
I0726 09:51:09.346056 27891 net.cpp:406] score10_slicer_conv_9_split <- score10
I0726 09:51:09.346065 27891 net.cpp:380] score10_slicer_conv_9_split -> score10_slicer_conv_9_split_0
I0726 09:51:09.346072 27891 net.cpp:380] score10_slicer_conv_9_split -> score10_slicer_conv_9_split_1
I0726 09:51:09.346122 27891 net.cpp:122] Setting up score10_slicer_conv_9_split
I0726 09:51:09.346132 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346138 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346143 27891 net.cpp:137] Memory required for data: 487059456
I0726 09:51:09.346148 27891 layer_factory.hpp:77] Creating layer score11_slicer_conv_10_split
I0726 09:51:09.346155 27891 net.cpp:84] Creating Layer score11_slicer_conv_10_split
I0726 09:51:09.346161 27891 net.cpp:406] score11_slicer_conv_10_split <- score11
I0726 09:51:09.346170 27891 net.cpp:380] score11_slicer_conv_10_split -> score11_slicer_conv_10_split_0
I0726 09:51:09.346179 27891 net.cpp:380] score11_slicer_conv_10_split -> score11_slicer_conv_10_split_1
I0726 09:51:09.346225 27891 net.cpp:122] Setting up score11_slicer_conv_10_split
I0726 09:51:09.346233 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346240 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346246 27891 net.cpp:137] Memory required for data: 487084032
I0726 09:51:09.346251 27891 layer_factory.hpp:77] Creating layer score12_slicer_conv_11_split
I0726 09:51:09.346261 27891 net.cpp:84] Creating Layer score12_slicer_conv_11_split
I0726 09:51:09.346266 27891 net.cpp:406] score12_slicer_conv_11_split <- score12
I0726 09:51:09.346274 27891 net.cpp:380] score12_slicer_conv_11_split -> score12_slicer_conv_11_split_0
I0726 09:51:09.346282 27891 net.cpp:380] score12_slicer_conv_11_split -> score12_slicer_conv_11_split_1
I0726 09:51:09.346329 27891 net.cpp:122] Setting up score12_slicer_conv_11_split
I0726 09:51:09.346338 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346345 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346350 27891 net.cpp:137] Memory required for data: 487108608
I0726 09:51:09.346355 27891 layer_factory.hpp:77] Creating layer score13_slicer_conv_12_split
I0726 09:51:09.346362 27891 net.cpp:84] Creating Layer score13_slicer_conv_12_split
I0726 09:51:09.346367 27891 net.cpp:406] score13_slicer_conv_12_split <- score13
I0726 09:51:09.346375 27891 net.cpp:380] score13_slicer_conv_12_split -> score13_slicer_conv_12_split_0
I0726 09:51:09.346396 27891 net.cpp:380] score13_slicer_conv_12_split -> score13_slicer_conv_12_split_1
I0726 09:51:09.346446 27891 net.cpp:122] Setting up score13_slicer_conv_12_split
I0726 09:51:09.346454 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346460 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346465 27891 net.cpp:137] Memory required for data: 487133184
I0726 09:51:09.346472 27891 layer_factory.hpp:77] Creating layer score14_slicer_conv_13_split
I0726 09:51:09.346479 27891 net.cpp:84] Creating Layer score14_slicer_conv_13_split
I0726 09:51:09.346485 27891 net.cpp:406] score14_slicer_conv_13_split <- score14
I0726 09:51:09.346493 27891 net.cpp:380] score14_slicer_conv_13_split -> score14_slicer_conv_13_split_0
I0726 09:51:09.346501 27891 net.cpp:380] score14_slicer_conv_13_split -> score14_slicer_conv_13_split_1
I0726 09:51:09.346556 27891 net.cpp:122] Setting up score14_slicer_conv_13_split
I0726 09:51:09.346565 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346571 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346576 27891 net.cpp:137] Memory required for data: 487157760
I0726 09:51:09.346581 27891 layer_factory.hpp:77] Creating layer score15_slicer_conv_14_split
I0726 09:51:09.346588 27891 net.cpp:84] Creating Layer score15_slicer_conv_14_split
I0726 09:51:09.346593 27891 net.cpp:406] score15_slicer_conv_14_split <- score15
I0726 09:51:09.346601 27891 net.cpp:380] score15_slicer_conv_14_split -> score15_slicer_conv_14_split_0
I0726 09:51:09.346609 27891 net.cpp:380] score15_slicer_conv_14_split -> score15_slicer_conv_14_split_1
I0726 09:51:09.346655 27891 net.cpp:122] Setting up score15_slicer_conv_14_split
I0726 09:51:09.346663 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346670 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346675 27891 net.cpp:137] Memory required for data: 487182336
I0726 09:51:09.346680 27891 layer_factory.hpp:77] Creating layer score16_slicer_conv_15_split
I0726 09:51:09.346688 27891 net.cpp:84] Creating Layer score16_slicer_conv_15_split
I0726 09:51:09.346693 27891 net.cpp:406] score16_slicer_conv_15_split <- score16
I0726 09:51:09.346701 27891 net.cpp:380] score16_slicer_conv_15_split -> score16_slicer_conv_15_split_0
I0726 09:51:09.346709 27891 net.cpp:380] score16_slicer_conv_15_split -> score16_slicer_conv_15_split_1
I0726 09:51:09.346755 27891 net.cpp:122] Setting up score16_slicer_conv_15_split
I0726 09:51:09.346765 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346771 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346776 27891 net.cpp:137] Memory required for data: 487206912
I0726 09:51:09.346781 27891 layer_factory.hpp:77] Creating layer score17_slicer_conv_16_split
I0726 09:51:09.346787 27891 net.cpp:84] Creating Layer score17_slicer_conv_16_split
I0726 09:51:09.346793 27891 net.cpp:406] score17_slicer_conv_16_split <- score17
I0726 09:51:09.346801 27891 net.cpp:380] score17_slicer_conv_16_split -> score17_slicer_conv_16_split_0
I0726 09:51:09.346808 27891 net.cpp:380] score17_slicer_conv_16_split -> score17_slicer_conv_16_split_1
I0726 09:51:09.346854 27891 net.cpp:122] Setting up score17_slicer_conv_16_split
I0726 09:51:09.346863 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346869 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346874 27891 net.cpp:137] Memory required for data: 487231488
I0726 09:51:09.346879 27891 layer_factory.hpp:77] Creating layer score18_slicer_conv_17_split
I0726 09:51:09.346886 27891 net.cpp:84] Creating Layer score18_slicer_conv_17_split
I0726 09:51:09.346891 27891 net.cpp:406] score18_slicer_conv_17_split <- score18
I0726 09:51:09.346900 27891 net.cpp:380] score18_slicer_conv_17_split -> score18_slicer_conv_17_split_0
I0726 09:51:09.346909 27891 net.cpp:380] score18_slicer_conv_17_split -> score18_slicer_conv_17_split_1
I0726 09:51:09.346953 27891 net.cpp:122] Setting up score18_slicer_conv_17_split
I0726 09:51:09.346961 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346977 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.346982 27891 net.cpp:137] Memory required for data: 487256064
I0726 09:51:09.346988 27891 layer_factory.hpp:77] Creating layer score19_slicer_conv_18_split
I0726 09:51:09.346997 27891 net.cpp:84] Creating Layer score19_slicer_conv_18_split
I0726 09:51:09.347002 27891 net.cpp:406] score19_slicer_conv_18_split <- score19
I0726 09:51:09.347007 27891 net.cpp:380] score19_slicer_conv_18_split -> score19_slicer_conv_18_split_0
I0726 09:51:09.347018 27891 net.cpp:380] score19_slicer_conv_18_split -> score19_slicer_conv_18_split_1
I0726 09:51:09.347069 27891 net.cpp:122] Setting up score19_slicer_conv_18_split
I0726 09:51:09.347079 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347084 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347090 27891 net.cpp:137] Memory required for data: 487280640
I0726 09:51:09.347095 27891 layer_factory.hpp:77] Creating layer score20_slicer_conv_19_split
I0726 09:51:09.347101 27891 net.cpp:84] Creating Layer score20_slicer_conv_19_split
I0726 09:51:09.347107 27891 net.cpp:406] score20_slicer_conv_19_split <- score20
I0726 09:51:09.347115 27891 net.cpp:380] score20_slicer_conv_19_split -> score20_slicer_conv_19_split_0
I0726 09:51:09.347126 27891 net.cpp:380] score20_slicer_conv_19_split -> score20_slicer_conv_19_split_1
I0726 09:51:09.347170 27891 net.cpp:122] Setting up score20_slicer_conv_19_split
I0726 09:51:09.347179 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347185 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347190 27891 net.cpp:137] Memory required for data: 487305216
I0726 09:51:09.347196 27891 layer_factory.hpp:77] Creating layer score21_slicer_conv_20_split
I0726 09:51:09.347204 27891 net.cpp:84] Creating Layer score21_slicer_conv_20_split
I0726 09:51:09.347210 27891 net.cpp:406] score21_slicer_conv_20_split <- score21
I0726 09:51:09.347218 27891 net.cpp:380] score21_slicer_conv_20_split -> score21_slicer_conv_20_split_0
I0726 09:51:09.347225 27891 net.cpp:380] score21_slicer_conv_20_split -> score21_slicer_conv_20_split_1
I0726 09:51:09.347272 27891 net.cpp:122] Setting up score21_slicer_conv_20_split
I0726 09:51:09.347281 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347287 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347292 27891 net.cpp:137] Memory required for data: 487329792
I0726 09:51:09.347297 27891 layer_factory.hpp:77] Creating layer score22_slicer_conv_21_split
I0726 09:51:09.347306 27891 net.cpp:84] Creating Layer score22_slicer_conv_21_split
I0726 09:51:09.347311 27891 net.cpp:406] score22_slicer_conv_21_split <- score22
I0726 09:51:09.347318 27891 net.cpp:380] score22_slicer_conv_21_split -> score22_slicer_conv_21_split_0
I0726 09:51:09.347326 27891 net.cpp:380] score22_slicer_conv_21_split -> score22_slicer_conv_21_split_1
I0726 09:51:09.347373 27891 net.cpp:122] Setting up score22_slicer_conv_21_split
I0726 09:51:09.347381 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347388 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347393 27891 net.cpp:137] Memory required for data: 487354368
I0726 09:51:09.347398 27891 layer_factory.hpp:77] Creating layer score23_slicer_conv_22_split
I0726 09:51:09.347407 27891 net.cpp:84] Creating Layer score23_slicer_conv_22_split
I0726 09:51:09.347414 27891 net.cpp:406] score23_slicer_conv_22_split <- score23
I0726 09:51:09.347421 27891 net.cpp:380] score23_slicer_conv_22_split -> score23_slicer_conv_22_split_0
I0726 09:51:09.347429 27891 net.cpp:380] score23_slicer_conv_22_split -> score23_slicer_conv_22_split_1
I0726 09:51:09.347476 27891 net.cpp:122] Setting up score23_slicer_conv_22_split
I0726 09:51:09.347486 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347491 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347497 27891 net.cpp:137] Memory required for data: 487378944
I0726 09:51:09.347502 27891 layer_factory.hpp:77] Creating layer score24_slicer_conv_23_split
I0726 09:51:09.347509 27891 net.cpp:84] Creating Layer score24_slicer_conv_23_split
I0726 09:51:09.347524 27891 net.cpp:406] score24_slicer_conv_23_split <- score24
I0726 09:51:09.347533 27891 net.cpp:380] score24_slicer_conv_23_split -> score24_slicer_conv_23_split_0
I0726 09:51:09.347542 27891 net.cpp:380] score24_slicer_conv_23_split -> score24_slicer_conv_23_split_1
I0726 09:51:09.347590 27891 net.cpp:122] Setting up score24_slicer_conv_23_split
I0726 09:51:09.347600 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347606 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347611 27891 net.cpp:137] Memory required for data: 487403520
I0726 09:51:09.347616 27891 layer_factory.hpp:77] Creating layer score25_slicer_conv_24_split
I0726 09:51:09.347623 27891 net.cpp:84] Creating Layer score25_slicer_conv_24_split
I0726 09:51:09.347630 27891 net.cpp:406] score25_slicer_conv_24_split <- score25
I0726 09:51:09.347637 27891 net.cpp:380] score25_slicer_conv_24_split -> score25_slicer_conv_24_split_0
I0726 09:51:09.347646 27891 net.cpp:380] score25_slicer_conv_24_split -> score25_slicer_conv_24_split_1
I0726 09:51:09.347692 27891 net.cpp:122] Setting up score25_slicer_conv_24_split
I0726 09:51:09.347700 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347707 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347712 27891 net.cpp:137] Memory required for data: 487428096
I0726 09:51:09.347718 27891 layer_factory.hpp:77] Creating layer score26_slicer_conv_25_split
I0726 09:51:09.347724 27891 net.cpp:84] Creating Layer score26_slicer_conv_25_split
I0726 09:51:09.347729 27891 net.cpp:406] score26_slicer_conv_25_split <- score26
I0726 09:51:09.347738 27891 net.cpp:380] score26_slicer_conv_25_split -> score26_slicer_conv_25_split_0
I0726 09:51:09.347745 27891 net.cpp:380] score26_slicer_conv_25_split -> score26_slicer_conv_25_split_1
I0726 09:51:09.347791 27891 net.cpp:122] Setting up score26_slicer_conv_25_split
I0726 09:51:09.347800 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347806 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347811 27891 net.cpp:137] Memory required for data: 487452672
I0726 09:51:09.347816 27891 layer_factory.hpp:77] Creating layer score27_slicer_conv_26_split
I0726 09:51:09.347823 27891 net.cpp:84] Creating Layer score27_slicer_conv_26_split
I0726 09:51:09.347828 27891 net.cpp:406] score27_slicer_conv_26_split <- score27
I0726 09:51:09.347837 27891 net.cpp:380] score27_slicer_conv_26_split -> score27_slicer_conv_26_split_0
I0726 09:51:09.347846 27891 net.cpp:380] score27_slicer_conv_26_split -> score27_slicer_conv_26_split_1
I0726 09:51:09.347889 27891 net.cpp:122] Setting up score27_slicer_conv_26_split
I0726 09:51:09.347898 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347904 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.347909 27891 net.cpp:137] Memory required for data: 487477248
I0726 09:51:09.347914 27891 layer_factory.hpp:77] Creating layer score28_slicer_conv_27_split
I0726 09:51:09.347923 27891 net.cpp:84] Creating Layer score28_slicer_conv_27_split
I0726 09:51:09.347929 27891 net.cpp:406] score28_slicer_conv_27_split <- score28
I0726 09:51:09.347936 27891 net.cpp:380] score28_slicer_conv_27_split -> score28_slicer_conv_27_split_0
I0726 09:51:09.347944 27891 net.cpp:380] score28_slicer_conv_27_split -> score28_slicer_conv_27_split_1
I0726 09:51:09.347990 27891 net.cpp:122] Setting up score28_slicer_conv_27_split
I0726 09:51:09.347998 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348004 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348009 27891 net.cpp:137] Memory required for data: 487501824
I0726 09:51:09.348014 27891 layer_factory.hpp:77] Creating layer score29_slicer_conv_28_split
I0726 09:51:09.348031 27891 net.cpp:84] Creating Layer score29_slicer_conv_28_split
I0726 09:51:09.348037 27891 net.cpp:406] score29_slicer_conv_28_split <- score29
I0726 09:51:09.348044 27891 net.cpp:380] score29_slicer_conv_28_split -> score29_slicer_conv_28_split_0
I0726 09:51:09.348053 27891 net.cpp:380] score29_slicer_conv_28_split -> score29_slicer_conv_28_split_1
I0726 09:51:09.348114 27891 net.cpp:122] Setting up score29_slicer_conv_28_split
I0726 09:51:09.348124 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348130 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348135 27891 net.cpp:137] Memory required for data: 487526400
I0726 09:51:09.348140 27891 layer_factory.hpp:77] Creating layer score30_slicer_conv_29_split
I0726 09:51:09.348148 27891 net.cpp:84] Creating Layer score30_slicer_conv_29_split
I0726 09:51:09.348155 27891 net.cpp:406] score30_slicer_conv_29_split <- score30
I0726 09:51:09.348163 27891 net.cpp:380] score30_slicer_conv_29_split -> score30_slicer_conv_29_split_0
I0726 09:51:09.348171 27891 net.cpp:380] score30_slicer_conv_29_split -> score30_slicer_conv_29_split_1
I0726 09:51:09.348217 27891 net.cpp:122] Setting up score30_slicer_conv_29_split
I0726 09:51:09.348225 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348232 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348237 27891 net.cpp:137] Memory required for data: 487550976
I0726 09:51:09.348242 27891 layer_factory.hpp:77] Creating layer score31_slicer_conv_30_split
I0726 09:51:09.348249 27891 net.cpp:84] Creating Layer score31_slicer_conv_30_split
I0726 09:51:09.348255 27891 net.cpp:406] score31_slicer_conv_30_split <- score31
I0726 09:51:09.348263 27891 net.cpp:380] score31_slicer_conv_30_split -> score31_slicer_conv_30_split_0
I0726 09:51:09.348270 27891 net.cpp:380] score31_slicer_conv_30_split -> score31_slicer_conv_30_split_1
I0726 09:51:09.348316 27891 net.cpp:122] Setting up score31_slicer_conv_30_split
I0726 09:51:09.348325 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348331 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348336 27891 net.cpp:137] Memory required for data: 487575552
I0726 09:51:09.348341 27891 layer_factory.hpp:77] Creating layer score32_slicer_conv_31_split
I0726 09:51:09.348348 27891 net.cpp:84] Creating Layer score32_slicer_conv_31_split
I0726 09:51:09.348353 27891 net.cpp:406] score32_slicer_conv_31_split <- score32
I0726 09:51:09.348362 27891 net.cpp:380] score32_slicer_conv_31_split -> score32_slicer_conv_31_split_0
I0726 09:51:09.348371 27891 net.cpp:380] score32_slicer_conv_31_split -> score32_slicer_conv_31_split_1
I0726 09:51:09.348414 27891 net.cpp:122] Setting up score32_slicer_conv_31_split
I0726 09:51:09.348423 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348429 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348434 27891 net.cpp:137] Memory required for data: 487600128
I0726 09:51:09.348439 27891 layer_factory.hpp:77] Creating layer score33_slicer_conv_32_split
I0726 09:51:09.348448 27891 net.cpp:84] Creating Layer score33_slicer_conv_32_split
I0726 09:51:09.348453 27891 net.cpp:406] score33_slicer_conv_32_split <- score33
I0726 09:51:09.348460 27891 net.cpp:380] score33_slicer_conv_32_split -> score33_slicer_conv_32_split_0
I0726 09:51:09.348469 27891 net.cpp:380] score33_slicer_conv_32_split -> score33_slicer_conv_32_split_1
I0726 09:51:09.348515 27891 net.cpp:122] Setting up score33_slicer_conv_32_split
I0726 09:51:09.348523 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348531 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348536 27891 net.cpp:137] Memory required for data: 487624704
I0726 09:51:09.348541 27891 layer_factory.hpp:77] Creating layer score34_slicer_conv_33_split
I0726 09:51:09.348547 27891 net.cpp:84] Creating Layer score34_slicer_conv_33_split
I0726 09:51:09.348552 27891 net.cpp:406] score34_slicer_conv_33_split <- score34
I0726 09:51:09.348559 27891 net.cpp:380] score34_slicer_conv_33_split -> score34_slicer_conv_33_split_0
I0726 09:51:09.348568 27891 net.cpp:380] score34_slicer_conv_33_split -> score34_slicer_conv_33_split_1
I0726 09:51:09.348610 27891 net.cpp:122] Setting up score34_slicer_conv_33_split
I0726 09:51:09.348618 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348620 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348633 27891 net.cpp:137] Memory required for data: 487649280
I0726 09:51:09.348636 27891 layer_factory.hpp:77] Creating layer score35_slicer_conv_34_split
I0726 09:51:09.348642 27891 net.cpp:84] Creating Layer score35_slicer_conv_34_split
I0726 09:51:09.348646 27891 net.cpp:406] score35_slicer_conv_34_split <- score35
I0726 09:51:09.348652 27891 net.cpp:380] score35_slicer_conv_34_split -> score35_slicer_conv_34_split_0
I0726 09:51:09.348661 27891 net.cpp:380] score35_slicer_conv_34_split -> score35_slicer_conv_34_split_1
I0726 09:51:09.348711 27891 net.cpp:122] Setting up score35_slicer_conv_34_split
I0726 09:51:09.348727 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348733 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348738 27891 net.cpp:137] Memory required for data: 487673856
I0726 09:51:09.348743 27891 layer_factory.hpp:77] Creating layer score36_slicer_conv_35_split
I0726 09:51:09.348750 27891 net.cpp:84] Creating Layer score36_slicer_conv_35_split
I0726 09:51:09.348755 27891 net.cpp:406] score36_slicer_conv_35_split <- score36
I0726 09:51:09.348762 27891 net.cpp:380] score36_slicer_conv_35_split -> score36_slicer_conv_35_split_0
I0726 09:51:09.348770 27891 net.cpp:380] score36_slicer_conv_35_split -> score36_slicer_conv_35_split_1
I0726 09:51:09.348817 27891 net.cpp:122] Setting up score36_slicer_conv_35_split
I0726 09:51:09.348825 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348831 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348836 27891 net.cpp:137] Memory required for data: 487698432
I0726 09:51:09.348841 27891 layer_factory.hpp:77] Creating layer score37_slicer_conv_36_split
I0726 09:51:09.348847 27891 net.cpp:84] Creating Layer score37_slicer_conv_36_split
I0726 09:51:09.348853 27891 net.cpp:406] score37_slicer_conv_36_split <- score37
I0726 09:51:09.348862 27891 net.cpp:380] score37_slicer_conv_36_split -> score37_slicer_conv_36_split_0
I0726 09:51:09.348870 27891 net.cpp:380] score37_slicer_conv_36_split -> score37_slicer_conv_36_split_1
I0726 09:51:09.348917 27891 net.cpp:122] Setting up score37_slicer_conv_36_split
I0726 09:51:09.348925 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348932 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.348935 27891 net.cpp:137] Memory required for data: 487723008
I0726 09:51:09.348940 27891 layer_factory.hpp:77] Creating layer score38_slicer_conv_37_split
I0726 09:51:09.348948 27891 net.cpp:84] Creating Layer score38_slicer_conv_37_split
I0726 09:51:09.348953 27891 net.cpp:406] score38_slicer_conv_37_split <- score38
I0726 09:51:09.348959 27891 net.cpp:380] score38_slicer_conv_37_split -> score38_slicer_conv_37_split_0
I0726 09:51:09.348968 27891 net.cpp:380] score38_slicer_conv_37_split -> score38_slicer_conv_37_split_1
I0726 09:51:09.349014 27891 net.cpp:122] Setting up score38_slicer_conv_37_split
I0726 09:51:09.349022 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349028 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349032 27891 net.cpp:137] Memory required for data: 487747584
I0726 09:51:09.349037 27891 layer_factory.hpp:77] Creating layer score39_slicer_conv_38_split
I0726 09:51:09.349045 27891 net.cpp:84] Creating Layer score39_slicer_conv_38_split
I0726 09:51:09.349050 27891 net.cpp:406] score39_slicer_conv_38_split <- score39
I0726 09:51:09.349057 27891 net.cpp:380] score39_slicer_conv_38_split -> score39_slicer_conv_38_split_0
I0726 09:51:09.349066 27891 net.cpp:380] score39_slicer_conv_38_split -> score39_slicer_conv_38_split_1
I0726 09:51:09.349112 27891 net.cpp:122] Setting up score39_slicer_conv_38_split
I0726 09:51:09.349119 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349125 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349129 27891 net.cpp:137] Memory required for data: 487772160
I0726 09:51:09.349134 27891 layer_factory.hpp:77] Creating layer score40_slicer_conv_39_split
I0726 09:51:09.349143 27891 net.cpp:84] Creating Layer score40_slicer_conv_39_split
I0726 09:51:09.349148 27891 net.cpp:406] score40_slicer_conv_39_split <- score40
I0726 09:51:09.349165 27891 net.cpp:380] score40_slicer_conv_39_split -> score40_slicer_conv_39_split_0
I0726 09:51:09.349174 27891 net.cpp:380] score40_slicer_conv_39_split -> score40_slicer_conv_39_split_1
I0726 09:51:09.349223 27891 net.cpp:122] Setting up score40_slicer_conv_39_split
I0726 09:51:09.349232 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349238 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349242 27891 net.cpp:137] Memory required for data: 487796736
I0726 09:51:09.349247 27891 layer_factory.hpp:77] Creating layer score41_slicer_conv_40_split
I0726 09:51:09.349254 27891 net.cpp:84] Creating Layer score41_slicer_conv_40_split
I0726 09:51:09.349259 27891 net.cpp:406] score41_slicer_conv_40_split <- score41
I0726 09:51:09.349267 27891 net.cpp:380] score41_slicer_conv_40_split -> score41_slicer_conv_40_split_0
I0726 09:51:09.349277 27891 net.cpp:380] score41_slicer_conv_40_split -> score41_slicer_conv_40_split_1
I0726 09:51:09.349333 27891 net.cpp:122] Setting up score41_slicer_conv_40_split
I0726 09:51:09.349342 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349349 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349352 27891 net.cpp:137] Memory required for data: 487821312
I0726 09:51:09.349357 27891 layer_factory.hpp:77] Creating layer score42_slicer_conv_41_split
I0726 09:51:09.349366 27891 net.cpp:84] Creating Layer score42_slicer_conv_41_split
I0726 09:51:09.349371 27891 net.cpp:406] score42_slicer_conv_41_split <- score42
I0726 09:51:09.349380 27891 net.cpp:380] score42_slicer_conv_41_split -> score42_slicer_conv_41_split_0
I0726 09:51:09.349387 27891 net.cpp:380] score42_slicer_conv_41_split -> score42_slicer_conv_41_split_1
I0726 09:51:09.349436 27891 net.cpp:122] Setting up score42_slicer_conv_41_split
I0726 09:51:09.349443 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349449 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349454 27891 net.cpp:137] Memory required for data: 487845888
I0726 09:51:09.349459 27891 layer_factory.hpp:77] Creating layer score43_slicer_conv_42_split
I0726 09:51:09.349465 27891 net.cpp:84] Creating Layer score43_slicer_conv_42_split
I0726 09:51:09.349470 27891 net.cpp:406] score43_slicer_conv_42_split <- score43
I0726 09:51:09.349478 27891 net.cpp:380] score43_slicer_conv_42_split -> score43_slicer_conv_42_split_0
I0726 09:51:09.349485 27891 net.cpp:380] score43_slicer_conv_42_split -> score43_slicer_conv_42_split_1
I0726 09:51:09.349532 27891 net.cpp:122] Setting up score43_slicer_conv_42_split
I0726 09:51:09.349540 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349546 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349551 27891 net.cpp:137] Memory required for data: 487870464
I0726 09:51:09.349556 27891 layer_factory.hpp:77] Creating layer score44_slicer_conv_43_split
I0726 09:51:09.349563 27891 net.cpp:84] Creating Layer score44_slicer_conv_43_split
I0726 09:51:09.349568 27891 net.cpp:406] score44_slicer_conv_43_split <- score44
I0726 09:51:09.349576 27891 net.cpp:380] score44_slicer_conv_43_split -> score44_slicer_conv_43_split_0
I0726 09:51:09.349584 27891 net.cpp:380] score44_slicer_conv_43_split -> score44_slicer_conv_43_split_1
I0726 09:51:09.349632 27891 net.cpp:122] Setting up score44_slicer_conv_43_split
I0726 09:51:09.349639 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349645 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349650 27891 net.cpp:137] Memory required for data: 487895040
I0726 09:51:09.349655 27891 layer_factory.hpp:77] Creating layer score45_slicer_conv_44_split
I0726 09:51:09.349663 27891 net.cpp:84] Creating Layer score45_slicer_conv_44_split
I0726 09:51:09.349668 27891 net.cpp:406] score45_slicer_conv_44_split <- score45
I0726 09:51:09.349674 27891 net.cpp:380] score45_slicer_conv_44_split -> score45_slicer_conv_44_split_0
I0726 09:51:09.349683 27891 net.cpp:380] score45_slicer_conv_44_split -> score45_slicer_conv_44_split_1
I0726 09:51:09.349731 27891 net.cpp:122] Setting up score45_slicer_conv_44_split
I0726 09:51:09.349751 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349758 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349763 27891 net.cpp:137] Memory required for data: 487919616
I0726 09:51:09.349768 27891 layer_factory.hpp:77] Creating layer score46_slicer_conv_45_split
I0726 09:51:09.349776 27891 net.cpp:84] Creating Layer score46_slicer_conv_45_split
I0726 09:51:09.349781 27891 net.cpp:406] score46_slicer_conv_45_split <- score46
I0726 09:51:09.349791 27891 net.cpp:380] score46_slicer_conv_45_split -> score46_slicer_conv_45_split_0
I0726 09:51:09.349798 27891 net.cpp:380] score46_slicer_conv_45_split -> score46_slicer_conv_45_split_1
I0726 09:51:09.349858 27891 net.cpp:122] Setting up score46_slicer_conv_45_split
I0726 09:51:09.349865 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349871 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349876 27891 net.cpp:137] Memory required for data: 487944192
I0726 09:51:09.349881 27891 layer_factory.hpp:77] Creating layer score47_slicer_conv_46_split
I0726 09:51:09.349887 27891 net.cpp:84] Creating Layer score47_slicer_conv_46_split
I0726 09:51:09.349894 27891 net.cpp:406] score47_slicer_conv_46_split <- score47
I0726 09:51:09.349900 27891 net.cpp:380] score47_slicer_conv_46_split -> score47_slicer_conv_46_split_0
I0726 09:51:09.349907 27891 net.cpp:380] score47_slicer_conv_46_split -> score47_slicer_conv_46_split_1
I0726 09:51:09.349954 27891 net.cpp:122] Setting up score47_slicer_conv_46_split
I0726 09:51:09.349962 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349968 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.349973 27891 net.cpp:137] Memory required for data: 487968768
I0726 09:51:09.349977 27891 layer_factory.hpp:77] Creating layer score48_slicer_conv_47_split
I0726 09:51:09.349984 27891 net.cpp:84] Creating Layer score48_slicer_conv_47_split
I0726 09:51:09.349989 27891 net.cpp:406] score48_slicer_conv_47_split <- score48
I0726 09:51:09.350000 27891 net.cpp:380] score48_slicer_conv_47_split -> score48_slicer_conv_47_split_0
I0726 09:51:09.350008 27891 net.cpp:380] score48_slicer_conv_47_split -> score48_slicer_conv_47_split_1
I0726 09:51:09.350054 27891 net.cpp:122] Setting up score48_slicer_conv_47_split
I0726 09:51:09.350062 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350069 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350075 27891 net.cpp:137] Memory required for data: 487993344
I0726 09:51:09.350080 27891 layer_factory.hpp:77] Creating layer score49_slicer_conv_48_split
I0726 09:51:09.350087 27891 net.cpp:84] Creating Layer score49_slicer_conv_48_split
I0726 09:51:09.350092 27891 net.cpp:406] score49_slicer_conv_48_split <- score49
I0726 09:51:09.350100 27891 net.cpp:380] score49_slicer_conv_48_split -> score49_slicer_conv_48_split_0
I0726 09:51:09.350107 27891 net.cpp:380] score49_slicer_conv_48_split -> score49_slicer_conv_48_split_1
I0726 09:51:09.350154 27891 net.cpp:122] Setting up score49_slicer_conv_48_split
I0726 09:51:09.350162 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350168 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350172 27891 net.cpp:137] Memory required for data: 488017920
I0726 09:51:09.350178 27891 layer_factory.hpp:77] Creating layer score50_slicer_conv_49_split
I0726 09:51:09.350184 27891 net.cpp:84] Creating Layer score50_slicer_conv_49_split
I0726 09:51:09.350189 27891 net.cpp:406] score50_slicer_conv_49_split <- score50
I0726 09:51:09.350196 27891 net.cpp:380] score50_slicer_conv_49_split -> score50_slicer_conv_49_split_0
I0726 09:51:09.350205 27891 net.cpp:380] score50_slicer_conv_49_split -> score50_slicer_conv_49_split_1
I0726 09:51:09.350250 27891 net.cpp:122] Setting up score50_slicer_conv_49_split
I0726 09:51:09.350257 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350263 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350268 27891 net.cpp:137] Memory required for data: 488042496
I0726 09:51:09.350281 27891 layer_factory.hpp:77] Creating layer score51_slicer_conv_50_split
I0726 09:51:09.350288 27891 net.cpp:84] Creating Layer score51_slicer_conv_50_split
I0726 09:51:09.350292 27891 net.cpp:406] score51_slicer_conv_50_split <- score51
I0726 09:51:09.350297 27891 net.cpp:380] score51_slicer_conv_50_split -> score51_slicer_conv_50_split_0
I0726 09:51:09.350303 27891 net.cpp:380] score51_slicer_conv_50_split -> score51_slicer_conv_50_split_1
I0726 09:51:09.350354 27891 net.cpp:122] Setting up score51_slicer_conv_50_split
I0726 09:51:09.350364 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350371 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350376 27891 net.cpp:137] Memory required for data: 488067072
I0726 09:51:09.350381 27891 layer_factory.hpp:77] Creating layer score52_slicer_conv_51_split
I0726 09:51:09.350389 27891 net.cpp:84] Creating Layer score52_slicer_conv_51_split
I0726 09:51:09.350394 27891 net.cpp:406] score52_slicer_conv_51_split <- score52
I0726 09:51:09.350401 27891 net.cpp:380] score52_slicer_conv_51_split -> score52_slicer_conv_51_split_0
I0726 09:51:09.350410 27891 net.cpp:380] score52_slicer_conv_51_split -> score52_slicer_conv_51_split_1
I0726 09:51:09.350457 27891 net.cpp:122] Setting up score52_slicer_conv_51_split
I0726 09:51:09.350466 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350472 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350477 27891 net.cpp:137] Memory required for data: 488091648
I0726 09:51:09.350482 27891 layer_factory.hpp:77] Creating layer score53_slicer_conv_52_split
I0726 09:51:09.350491 27891 net.cpp:84] Creating Layer score53_slicer_conv_52_split
I0726 09:51:09.350495 27891 net.cpp:406] score53_slicer_conv_52_split <- score53
I0726 09:51:09.350504 27891 net.cpp:380] score53_slicer_conv_52_split -> score53_slicer_conv_52_split_0
I0726 09:51:09.350512 27891 net.cpp:380] score53_slicer_conv_52_split -> score53_slicer_conv_52_split_1
I0726 09:51:09.350558 27891 net.cpp:122] Setting up score53_slicer_conv_52_split
I0726 09:51:09.350566 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350574 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350579 27891 net.cpp:137] Memory required for data: 488116224
I0726 09:51:09.350584 27891 layer_factory.hpp:77] Creating layer score54_slicer_conv_53_split
I0726 09:51:09.350590 27891 net.cpp:84] Creating Layer score54_slicer_conv_53_split
I0726 09:51:09.350596 27891 net.cpp:406] score54_slicer_conv_53_split <- score54
I0726 09:51:09.350603 27891 net.cpp:380] score54_slicer_conv_53_split -> score54_slicer_conv_53_split_0
I0726 09:51:09.350611 27891 net.cpp:380] score54_slicer_conv_53_split -> score54_slicer_conv_53_split_1
I0726 09:51:09.350658 27891 net.cpp:122] Setting up score54_slicer_conv_53_split
I0726 09:51:09.350667 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350673 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350678 27891 net.cpp:137] Memory required for data: 488140800
I0726 09:51:09.350684 27891 layer_factory.hpp:77] Creating layer score55_slicer_conv_54_split
I0726 09:51:09.350692 27891 net.cpp:84] Creating Layer score55_slicer_conv_54_split
I0726 09:51:09.350697 27891 net.cpp:406] score55_slicer_conv_54_split <- score55
I0726 09:51:09.350705 27891 net.cpp:380] score55_slicer_conv_54_split -> score55_slicer_conv_54_split_0
I0726 09:51:09.350739 27891 net.cpp:380] score55_slicer_conv_54_split -> score55_slicer_conv_54_split_1
I0726 09:51:09.350788 27891 net.cpp:122] Setting up score55_slicer_conv_54_split
I0726 09:51:09.350797 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350805 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350810 27891 net.cpp:137] Memory required for data: 488165376
I0726 09:51:09.350814 27891 layer_factory.hpp:77] Creating layer score56_slicer_conv_55_split
I0726 09:51:09.350821 27891 net.cpp:84] Creating Layer score56_slicer_conv_55_split
I0726 09:51:09.350827 27891 net.cpp:406] score56_slicer_conv_55_split <- score56
I0726 09:51:09.350834 27891 net.cpp:380] score56_slicer_conv_55_split -> score56_slicer_conv_55_split_0
I0726 09:51:09.350853 27891 net.cpp:380] score56_slicer_conv_55_split -> score56_slicer_conv_55_split_1
I0726 09:51:09.350901 27891 net.cpp:122] Setting up score56_slicer_conv_55_split
I0726 09:51:09.350910 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350915 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.350920 27891 net.cpp:137] Memory required for data: 488189952
I0726 09:51:09.350925 27891 layer_factory.hpp:77] Creating layer score57_slicer_conv_56_split
I0726 09:51:09.350932 27891 net.cpp:84] Creating Layer score57_slicer_conv_56_split
I0726 09:51:09.350937 27891 net.cpp:406] score57_slicer_conv_56_split <- score57
I0726 09:51:09.350946 27891 net.cpp:380] score57_slicer_conv_56_split -> score57_slicer_conv_56_split_0
I0726 09:51:09.350955 27891 net.cpp:380] score57_slicer_conv_56_split -> score57_slicer_conv_56_split_1
I0726 09:51:09.350999 27891 net.cpp:122] Setting up score57_slicer_conv_56_split
I0726 09:51:09.351008 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351014 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351018 27891 net.cpp:137] Memory required for data: 488214528
I0726 09:51:09.351023 27891 layer_factory.hpp:77] Creating layer score58_slicer_conv_57_split
I0726 09:51:09.351029 27891 net.cpp:84] Creating Layer score58_slicer_conv_57_split
I0726 09:51:09.351034 27891 net.cpp:406] score58_slicer_conv_57_split <- score58
I0726 09:51:09.351043 27891 net.cpp:380] score58_slicer_conv_57_split -> score58_slicer_conv_57_split_0
I0726 09:51:09.351052 27891 net.cpp:380] score58_slicer_conv_57_split -> score58_slicer_conv_57_split_1
I0726 09:51:09.351097 27891 net.cpp:122] Setting up score58_slicer_conv_57_split
I0726 09:51:09.351105 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351111 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351116 27891 net.cpp:137] Memory required for data: 488239104
I0726 09:51:09.351121 27891 layer_factory.hpp:77] Creating layer score59_slicer_conv_58_split
I0726 09:51:09.351127 27891 net.cpp:84] Creating Layer score59_slicer_conv_58_split
I0726 09:51:09.351132 27891 net.cpp:406] score59_slicer_conv_58_split <- score59
I0726 09:51:09.351141 27891 net.cpp:380] score59_slicer_conv_58_split -> score59_slicer_conv_58_split_0
I0726 09:51:09.351150 27891 net.cpp:380] score59_slicer_conv_58_split -> score59_slicer_conv_58_split_1
I0726 09:51:09.351197 27891 net.cpp:122] Setting up score59_slicer_conv_58_split
I0726 09:51:09.351207 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351212 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351217 27891 net.cpp:137] Memory required for data: 488263680
I0726 09:51:09.351222 27891 layer_factory.hpp:77] Creating layer score60_slicer_conv_59_split
I0726 09:51:09.351227 27891 net.cpp:84] Creating Layer score60_slicer_conv_59_split
I0726 09:51:09.351233 27891 net.cpp:406] score60_slicer_conv_59_split <- score60
I0726 09:51:09.351241 27891 net.cpp:380] score60_slicer_conv_59_split -> score60_slicer_conv_59_split_0
I0726 09:51:09.351249 27891 net.cpp:380] score60_slicer_conv_59_split -> score60_slicer_conv_59_split_1
I0726 09:51:09.351296 27891 net.cpp:122] Setting up score60_slicer_conv_59_split
I0726 09:51:09.351305 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351310 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351315 27891 net.cpp:137] Memory required for data: 488288256
I0726 09:51:09.351320 27891 layer_factory.hpp:77] Creating layer score61_slicer_conv_60_split
I0726 09:51:09.351326 27891 net.cpp:84] Creating Layer score61_slicer_conv_60_split
I0726 09:51:09.351331 27891 net.cpp:406] score61_slicer_conv_60_split <- score61
I0726 09:51:09.351339 27891 net.cpp:380] score61_slicer_conv_60_split -> score61_slicer_conv_60_split_0
I0726 09:51:09.351347 27891 net.cpp:380] score61_slicer_conv_60_split -> score61_slicer_conv_60_split_1
I0726 09:51:09.351395 27891 net.cpp:122] Setting up score61_slicer_conv_60_split
I0726 09:51:09.351403 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351418 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351423 27891 net.cpp:137] Memory required for data: 488312832
I0726 09:51:09.351428 27891 layer_factory.hpp:77] Creating layer score62_slicer_conv_61_split
I0726 09:51:09.351436 27891 net.cpp:84] Creating Layer score62_slicer_conv_61_split
I0726 09:51:09.351442 27891 net.cpp:406] score62_slicer_conv_61_split <- score62
I0726 09:51:09.351449 27891 net.cpp:380] score62_slicer_conv_61_split -> score62_slicer_conv_61_split_0
I0726 09:51:09.351457 27891 net.cpp:380] score62_slicer_conv_61_split -> score62_slicer_conv_61_split_1
I0726 09:51:09.351505 27891 net.cpp:122] Setting up score62_slicer_conv_61_split
I0726 09:51:09.351513 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351519 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351524 27891 net.cpp:137] Memory required for data: 488337408
I0726 09:51:09.351528 27891 layer_factory.hpp:77] Creating layer score63_slicer_conv_62_split
I0726 09:51:09.351536 27891 net.cpp:84] Creating Layer score63_slicer_conv_62_split
I0726 09:51:09.351541 27891 net.cpp:406] score63_slicer_conv_62_split <- score63
I0726 09:51:09.351547 27891 net.cpp:380] score63_slicer_conv_62_split -> score63_slicer_conv_62_split_0
I0726 09:51:09.351557 27891 net.cpp:380] score63_slicer_conv_62_split -> score63_slicer_conv_62_split_1
I0726 09:51:09.351600 27891 net.cpp:122] Setting up score63_slicer_conv_62_split
I0726 09:51:09.351608 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351614 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351619 27891 net.cpp:137] Memory required for data: 488361984
I0726 09:51:09.351624 27891 layer_factory.hpp:77] Creating layer score64_slicer_conv_63_split
I0726 09:51:09.351631 27891 net.cpp:84] Creating Layer score64_slicer_conv_63_split
I0726 09:51:09.351637 27891 net.cpp:406] score64_slicer_conv_63_split <- score64
I0726 09:51:09.351644 27891 net.cpp:380] score64_slicer_conv_63_split -> score64_slicer_conv_63_split_0
I0726 09:51:09.351651 27891 net.cpp:380] score64_slicer_conv_63_split -> score64_slicer_conv_63_split_1
I0726 09:51:09.351697 27891 net.cpp:122] Setting up score64_slicer_conv_63_split
I0726 09:51:09.351706 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351711 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.351716 27891 net.cpp:137] Memory required for data: 488386560
I0726 09:51:09.351721 27891 layer_factory.hpp:77] Creating layer sumscore
I0726 09:51:09.351743 27891 net.cpp:84] Creating Layer sumscore
I0726 09:51:09.351749 27891 net.cpp:406] sumscore <- score1_slicer_conv_0_split_0
I0726 09:51:09.351757 27891 net.cpp:406] sumscore <- score2_slicer_conv_1_split_0
I0726 09:51:09.351763 27891 net.cpp:406] sumscore <- score3_slicer_conv_2_split_0
I0726 09:51:09.351768 27891 net.cpp:406] sumscore <- score4_slicer_conv_3_split_0
I0726 09:51:09.351774 27891 net.cpp:406] sumscore <- score5_slicer_conv_4_split_0
I0726 09:51:09.351780 27891 net.cpp:406] sumscore <- score6_slicer_conv_5_split_0
I0726 09:51:09.351785 27891 net.cpp:406] sumscore <- score7_slicer_conv_6_split_0
I0726 09:51:09.351791 27891 net.cpp:406] sumscore <- score8_slicer_conv_7_split_0
I0726 09:51:09.351796 27891 net.cpp:406] sumscore <- score9_slicer_conv_8_split_0
I0726 09:51:09.351802 27891 net.cpp:406] sumscore <- score10_slicer_conv_9_split_0
I0726 09:51:09.351807 27891 net.cpp:406] sumscore <- score11_slicer_conv_10_split_0
I0726 09:51:09.351814 27891 net.cpp:406] sumscore <- score12_slicer_conv_11_split_0
I0726 09:51:09.351819 27891 net.cpp:406] sumscore <- score13_slicer_conv_12_split_0
I0726 09:51:09.351824 27891 net.cpp:406] sumscore <- score14_slicer_conv_13_split_0
I0726 09:51:09.351828 27891 net.cpp:406] sumscore <- score15_slicer_conv_14_split_0
I0726 09:51:09.351835 27891 net.cpp:406] sumscore <- score16_slicer_conv_15_split_0
I0726 09:51:09.351840 27891 net.cpp:406] sumscore <- score17_slicer_conv_16_split_0
I0726 09:51:09.351845 27891 net.cpp:406] sumscore <- score18_slicer_conv_17_split_0
I0726 09:51:09.351860 27891 net.cpp:406] sumscore <- score19_slicer_conv_18_split_0
I0726 09:51:09.351866 27891 net.cpp:406] sumscore <- score20_slicer_conv_19_split_0
I0726 09:51:09.351871 27891 net.cpp:406] sumscore <- score21_slicer_conv_20_split_0
I0726 09:51:09.351876 27891 net.cpp:406] sumscore <- score22_slicer_conv_21_split_0
I0726 09:51:09.351881 27891 net.cpp:406] sumscore <- score23_slicer_conv_22_split_0
I0726 09:51:09.351887 27891 net.cpp:406] sumscore <- score24_slicer_conv_23_split_0
I0726 09:51:09.351892 27891 net.cpp:406] sumscore <- score25_slicer_conv_24_split_0
I0726 09:51:09.351897 27891 net.cpp:406] sumscore <- score26_slicer_conv_25_split_0
I0726 09:51:09.351899 27891 net.cpp:406] sumscore <- score27_slicer_conv_26_split_0
I0726 09:51:09.351903 27891 net.cpp:406] sumscore <- score28_slicer_conv_27_split_0
I0726 09:51:09.351907 27891 net.cpp:406] sumscore <- score29_slicer_conv_28_split_0
I0726 09:51:09.351910 27891 net.cpp:406] sumscore <- score30_slicer_conv_29_split_0
I0726 09:51:09.351914 27891 net.cpp:406] sumscore <- score31_slicer_conv_30_split_0
I0726 09:51:09.351918 27891 net.cpp:406] sumscore <- score32_slicer_conv_31_split_0
I0726 09:51:09.351922 27891 net.cpp:406] sumscore <- score33_slicer_conv_32_split_0
I0726 09:51:09.351925 27891 net.cpp:406] sumscore <- score34_slicer_conv_33_split_0
I0726 09:51:09.351929 27891 net.cpp:406] sumscore <- score35_slicer_conv_34_split_0
I0726 09:51:09.351933 27891 net.cpp:406] sumscore <- score36_slicer_conv_35_split_0
I0726 09:51:09.351936 27891 net.cpp:406] sumscore <- score37_slicer_conv_36_split_0
I0726 09:51:09.351939 27891 net.cpp:406] sumscore <- score38_slicer_conv_37_split_0
I0726 09:51:09.351943 27891 net.cpp:406] sumscore <- score39_slicer_conv_38_split_0
I0726 09:51:09.351946 27891 net.cpp:406] sumscore <- score40_slicer_conv_39_split_0
I0726 09:51:09.351949 27891 net.cpp:406] sumscore <- score41_slicer_conv_40_split_0
I0726 09:51:09.351953 27891 net.cpp:406] sumscore <- score42_slicer_conv_41_split_0
I0726 09:51:09.351958 27891 net.cpp:406] sumscore <- score43_slicer_conv_42_split_0
I0726 09:51:09.351963 27891 net.cpp:406] sumscore <- score44_slicer_conv_43_split_0
I0726 09:51:09.351969 27891 net.cpp:406] sumscore <- score45_slicer_conv_44_split_0
I0726 09:51:09.351974 27891 net.cpp:406] sumscore <- score46_slicer_conv_45_split_0
I0726 09:51:09.351979 27891 net.cpp:406] sumscore <- score47_slicer_conv_46_split_0
I0726 09:51:09.351984 27891 net.cpp:406] sumscore <- score48_slicer_conv_47_split_0
I0726 09:51:09.351989 27891 net.cpp:406] sumscore <- score49_slicer_conv_48_split_0
I0726 09:51:09.351994 27891 net.cpp:406] sumscore <- score50_slicer_conv_49_split_0
I0726 09:51:09.351999 27891 net.cpp:406] sumscore <- score51_slicer_conv_50_split_0
I0726 09:51:09.352005 27891 net.cpp:406] sumscore <- score52_slicer_conv_51_split_0
I0726 09:51:09.352010 27891 net.cpp:406] sumscore <- score53_slicer_conv_52_split_0
I0726 09:51:09.352015 27891 net.cpp:406] sumscore <- score54_slicer_conv_53_split_0
I0726 09:51:09.352028 27891 net.cpp:406] sumscore <- score55_slicer_conv_54_split_0
I0726 09:51:09.352033 27891 net.cpp:406] sumscore <- score56_slicer_conv_55_split_0
I0726 09:51:09.352039 27891 net.cpp:406] sumscore <- score57_slicer_conv_56_split_0
I0726 09:51:09.352044 27891 net.cpp:406] sumscore <- score58_slicer_conv_57_split_0
I0726 09:51:09.352049 27891 net.cpp:406] sumscore <- score59_slicer_conv_58_split_0
I0726 09:51:09.352056 27891 net.cpp:406] sumscore <- score60_slicer_conv_59_split_0
I0726 09:51:09.352061 27891 net.cpp:406] sumscore <- score61_slicer_conv_60_split_0
I0726 09:51:09.352066 27891 net.cpp:406] sumscore <- score62_slicer_conv_61_split_0
I0726 09:51:09.352072 27891 net.cpp:406] sumscore <- score63_slicer_conv_62_split_0
I0726 09:51:09.352077 27891 net.cpp:406] sumscore <- score64_slicer_conv_63_split_0
I0726 09:51:09.352092 27891 net.cpp:380] sumscore -> sumscore
I0726 09:51:09.352140 27891 net.cpp:122] Setting up sumscore
I0726 09:51:09.352150 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.352155 27891 net.cpp:137] Memory required for data: 488398848
I0726 09:51:09.352171 27891 layer_factory.hpp:77] Creating layer sumscore_sumscore_0_split
I0726 09:51:09.352190 27891 net.cpp:84] Creating Layer sumscore_sumscore_0_split
I0726 09:51:09.352195 27891 net.cpp:406] sumscore_sumscore_0_split <- sumscore
I0726 09:51:09.352212 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_0
I0726 09:51:09.352228 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_1
I0726 09:51:09.352244 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_2
I0726 09:51:09.352260 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_3
I0726 09:51:09.352275 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_4
I0726 09:51:09.352291 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_5
I0726 09:51:09.352306 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_6
I0726 09:51:09.352336 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_7
I0726 09:51:09.352354 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_8
I0726 09:51:09.352370 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_9
I0726 09:51:09.352386 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_10
I0726 09:51:09.352402 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_11
I0726 09:51:09.352418 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_12
I0726 09:51:09.352440 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_13
I0726 09:51:09.352454 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_14
I0726 09:51:09.352470 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_15
I0726 09:51:09.352485 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_16
I0726 09:51:09.352501 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_17
I0726 09:51:09.352517 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_18
I0726 09:51:09.352540 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_19
I0726 09:51:09.352557 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_20
I0726 09:51:09.352573 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_21
I0726 09:51:09.352589 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_22
I0726 09:51:09.352605 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_23
I0726 09:51:09.352622 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_24
I0726 09:51:09.352638 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_25
I0726 09:51:09.352653 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_26
I0726 09:51:09.352669 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_27
I0726 09:51:09.352684 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_28
I0726 09:51:09.352701 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_29
I0726 09:51:09.352717 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_30
I0726 09:51:09.352733 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_31
I0726 09:51:09.352749 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_32
I0726 09:51:09.352766 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_33
I0726 09:51:09.352782 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_34
I0726 09:51:09.352798 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_35
I0726 09:51:09.352814 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_36
I0726 09:51:09.352830 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_37
I0726 09:51:09.352847 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_38
I0726 09:51:09.352872 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_39
I0726 09:51:09.352888 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_40
I0726 09:51:09.352905 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_41
I0726 09:51:09.352919 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_42
I0726 09:51:09.352936 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_43
I0726 09:51:09.352952 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_44
I0726 09:51:09.352967 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_45
I0726 09:51:09.352983 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_46
I0726 09:51:09.352998 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_47
I0726 09:51:09.353014 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_48
I0726 09:51:09.353031 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_49
I0726 09:51:09.353047 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_50
I0726 09:51:09.353071 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_51
I0726 09:51:09.353086 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_52
I0726 09:51:09.353102 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_53
I0726 09:51:09.353117 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_54
I0726 09:51:09.353133 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_55
I0726 09:51:09.353148 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_56
I0726 09:51:09.353163 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_57
I0726 09:51:09.353179 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_58
I0726 09:51:09.353195 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_59
I0726 09:51:09.353211 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_60
I0726 09:51:09.353227 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_61
I0726 09:51:09.353242 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_62
I0726 09:51:09.353258 27891 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_63
I0726 09:51:09.354259 27891 net.cpp:122] Setting up sumscore_sumscore_0_split
I0726 09:51:09.354269 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354277 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354284 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354290 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354296 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354302 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354308 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354315 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354321 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354327 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354333 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354339 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354346 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354352 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354358 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354365 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354372 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354377 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354384 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354390 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354396 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354403 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354420 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354427 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354434 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354440 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354446 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354452 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354460 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354465 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354472 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354478 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354485 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354490 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354497 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354503 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354509 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354516 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354522 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354528 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354535 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354542 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354547 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354554 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354560 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354567 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354573 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354579 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354585 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354591 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354598 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354604 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354610 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354616 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354624 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354629 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354635 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354642 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354648 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354655 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354660 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354667 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354673 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354679 27891 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0726 09:51:09.354684 27891 net.cpp:137] Memory required for data: 489185280
I0726 09:51:09.354691 27891 layer_factory.hpp:77] Creating layer loss1
I0726 09:51:09.354701 27891 net.cpp:84] Creating Layer loss1
I0726 09:51:09.354707 27891 net.cpp:406] loss1 <- score1_slicer_conv_0_split_1
I0726 09:51:09.354714 27891 net.cpp:406] loss1 <- label_label_0_split_0
I0726 09:51:09.354722 27891 net.cpp:406] loss1 <- sumscore_sumscore_0_split_0
I0726 09:51:09.354730 27891 net.cpp:380] loss1 -> loss1
I0726 09:51:09.354823 27891 net.cpp:122] Setting up loss1
I0726 09:51:09.354832 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.354837 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.354857 27891 net.cpp:137] Memory required for data: 489185284
I0726 09:51:09.354863 27891 layer_factory.hpp:77] Creating layer loss2
I0726 09:51:09.354872 27891 net.cpp:84] Creating Layer loss2
I0726 09:51:09.354878 27891 net.cpp:406] loss2 <- score2_slicer_conv_1_split_1
I0726 09:51:09.354887 27891 net.cpp:406] loss2 <- label_label_0_split_1
I0726 09:51:09.354893 27891 net.cpp:406] loss2 <- sumscore_sumscore_0_split_1
I0726 09:51:09.354902 27891 net.cpp:380] loss2 -> loss2
I0726 09:51:09.355000 27891 net.cpp:122] Setting up loss2
I0726 09:51:09.355010 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355013 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355020 27891 net.cpp:137] Memory required for data: 489185288
I0726 09:51:09.355026 27891 layer_factory.hpp:77] Creating layer loss3
I0726 09:51:09.355033 27891 net.cpp:84] Creating Layer loss3
I0726 09:51:09.355042 27891 net.cpp:406] loss3 <- score3_slicer_conv_2_split_1
I0726 09:51:09.355049 27891 net.cpp:406] loss3 <- label_label_0_split_2
I0726 09:51:09.355056 27891 net.cpp:406] loss3 <- sumscore_sumscore_0_split_2
I0726 09:51:09.355062 27891 net.cpp:380] loss3 -> loss3
I0726 09:51:09.355146 27891 net.cpp:122] Setting up loss3
I0726 09:51:09.355154 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355159 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355165 27891 net.cpp:137] Memory required for data: 489185292
I0726 09:51:09.355170 27891 layer_factory.hpp:77] Creating layer loss4
I0726 09:51:09.355178 27891 net.cpp:84] Creating Layer loss4
I0726 09:51:09.355183 27891 net.cpp:406] loss4 <- score4_slicer_conv_3_split_1
I0726 09:51:09.355190 27891 net.cpp:406] loss4 <- label_label_0_split_3
I0726 09:51:09.355197 27891 net.cpp:406] loss4 <- sumscore_sumscore_0_split_3
I0726 09:51:09.355204 27891 net.cpp:380] loss4 -> loss4
I0726 09:51:09.355281 27891 net.cpp:122] Setting up loss4
I0726 09:51:09.355290 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355295 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355303 27891 net.cpp:137] Memory required for data: 489185296
I0726 09:51:09.355307 27891 layer_factory.hpp:77] Creating layer loss5
I0726 09:51:09.355324 27891 net.cpp:84] Creating Layer loss5
I0726 09:51:09.355330 27891 net.cpp:406] loss5 <- score5_slicer_conv_4_split_1
I0726 09:51:09.355339 27891 net.cpp:406] loss5 <- label_label_0_split_4
I0726 09:51:09.355345 27891 net.cpp:406] loss5 <- sumscore_sumscore_0_split_4
I0726 09:51:09.355355 27891 net.cpp:380] loss5 -> loss5
I0726 09:51:09.355438 27891 net.cpp:122] Setting up loss5
I0726 09:51:09.355446 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355453 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355458 27891 net.cpp:137] Memory required for data: 489185300
I0726 09:51:09.355464 27891 layer_factory.hpp:77] Creating layer loss6
I0726 09:51:09.355473 27891 net.cpp:84] Creating Layer loss6
I0726 09:51:09.355479 27891 net.cpp:406] loss6 <- score6_slicer_conv_5_split_1
I0726 09:51:09.355486 27891 net.cpp:406] loss6 <- label_label_0_split_5
I0726 09:51:09.355494 27891 net.cpp:406] loss6 <- sumscore_sumscore_0_split_5
I0726 09:51:09.355501 27891 net.cpp:380] loss6 -> loss6
I0726 09:51:09.355587 27891 net.cpp:122] Setting up loss6
I0726 09:51:09.355595 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355600 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355607 27891 net.cpp:137] Memory required for data: 489185304
I0726 09:51:09.355612 27891 layer_factory.hpp:77] Creating layer loss7
I0726 09:51:09.355620 27891 net.cpp:84] Creating Layer loss7
I0726 09:51:09.355626 27891 net.cpp:406] loss7 <- score7_slicer_conv_6_split_1
I0726 09:51:09.355633 27891 net.cpp:406] loss7 <- label_label_0_split_6
I0726 09:51:09.355640 27891 net.cpp:406] loss7 <- sumscore_sumscore_0_split_6
I0726 09:51:09.355648 27891 net.cpp:380] loss7 -> loss7
I0726 09:51:09.355732 27891 net.cpp:122] Setting up loss7
I0726 09:51:09.355741 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355746 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355752 27891 net.cpp:137] Memory required for data: 489185308
I0726 09:51:09.355757 27891 layer_factory.hpp:77] Creating layer loss8
I0726 09:51:09.355765 27891 net.cpp:84] Creating Layer loss8
I0726 09:51:09.355772 27891 net.cpp:406] loss8 <- score8_slicer_conv_7_split_1
I0726 09:51:09.355778 27891 net.cpp:406] loss8 <- label_label_0_split_7
I0726 09:51:09.355785 27891 net.cpp:406] loss8 <- sumscore_sumscore_0_split_7
I0726 09:51:09.355793 27891 net.cpp:380] loss8 -> loss8
I0726 09:51:09.355876 27891 net.cpp:122] Setting up loss8
I0726 09:51:09.355895 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.355901 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.355907 27891 net.cpp:137] Memory required for data: 489185312
I0726 09:51:09.355913 27891 layer_factory.hpp:77] Creating layer loss9
I0726 09:51:09.355921 27891 net.cpp:84] Creating Layer loss9
I0726 09:51:09.355927 27891 net.cpp:406] loss9 <- score9_slicer_conv_8_split_1
I0726 09:51:09.355934 27891 net.cpp:406] loss9 <- label_label_0_split_8
I0726 09:51:09.355942 27891 net.cpp:406] loss9 <- sumscore_sumscore_0_split_8
I0726 09:51:09.355950 27891 net.cpp:380] loss9 -> loss9
I0726 09:51:09.356035 27891 net.cpp:122] Setting up loss9
I0726 09:51:09.356045 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356050 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356056 27891 net.cpp:137] Memory required for data: 489185316
I0726 09:51:09.356061 27891 layer_factory.hpp:77] Creating layer loss10
I0726 09:51:09.356073 27891 net.cpp:84] Creating Layer loss10
I0726 09:51:09.356081 27891 net.cpp:406] loss10 <- score10_slicer_conv_9_split_1
I0726 09:51:09.356087 27891 net.cpp:406] loss10 <- label_label_0_split_9
I0726 09:51:09.356093 27891 net.cpp:406] loss10 <- sumscore_sumscore_0_split_9
I0726 09:51:09.356101 27891 net.cpp:380] loss10 -> loss10
I0726 09:51:09.356189 27891 net.cpp:122] Setting up loss10
I0726 09:51:09.356196 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356202 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356209 27891 net.cpp:137] Memory required for data: 489185320
I0726 09:51:09.356215 27891 layer_factory.hpp:77] Creating layer loss11
I0726 09:51:09.356223 27891 net.cpp:84] Creating Layer loss11
I0726 09:51:09.356230 27891 net.cpp:406] loss11 <- score11_slicer_conv_10_split_1
I0726 09:51:09.356237 27891 net.cpp:406] loss11 <- label_label_0_split_10
I0726 09:51:09.356245 27891 net.cpp:406] loss11 <- sumscore_sumscore_0_split_10
I0726 09:51:09.356251 27891 net.cpp:380] loss11 -> loss11
I0726 09:51:09.356336 27891 net.cpp:122] Setting up loss11
I0726 09:51:09.356344 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356349 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356356 27891 net.cpp:137] Memory required for data: 489185324
I0726 09:51:09.356362 27891 layer_factory.hpp:77] Creating layer loss12
I0726 09:51:09.356370 27891 net.cpp:84] Creating Layer loss12
I0726 09:51:09.356375 27891 net.cpp:406] loss12 <- score12_slicer_conv_11_split_1
I0726 09:51:09.356384 27891 net.cpp:406] loss12 <- label_label_0_split_11
I0726 09:51:09.356389 27891 net.cpp:406] loss12 <- sumscore_sumscore_0_split_11
I0726 09:51:09.356397 27891 net.cpp:380] loss12 -> loss12
I0726 09:51:09.356487 27891 net.cpp:122] Setting up loss12
I0726 09:51:09.356497 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356501 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356508 27891 net.cpp:137] Memory required for data: 489185328
I0726 09:51:09.356513 27891 layer_factory.hpp:77] Creating layer loss13
I0726 09:51:09.356521 27891 net.cpp:84] Creating Layer loss13
I0726 09:51:09.356526 27891 net.cpp:406] loss13 <- score13_slicer_conv_12_split_1
I0726 09:51:09.356534 27891 net.cpp:406] loss13 <- label_label_0_split_12
I0726 09:51:09.356539 27891 net.cpp:406] loss13 <- sumscore_sumscore_0_split_12
I0726 09:51:09.356549 27891 net.cpp:380] loss13 -> loss13
I0726 09:51:09.356629 27891 net.cpp:122] Setting up loss13
I0726 09:51:09.356637 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356642 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356648 27891 net.cpp:137] Memory required for data: 489185332
I0726 09:51:09.356654 27891 layer_factory.hpp:77] Creating layer loss14
I0726 09:51:09.356663 27891 net.cpp:84] Creating Layer loss14
I0726 09:51:09.356668 27891 net.cpp:406] loss14 <- score14_slicer_conv_13_split_1
I0726 09:51:09.356675 27891 net.cpp:406] loss14 <- label_label_0_split_13
I0726 09:51:09.356681 27891 net.cpp:406] loss14 <- sumscore_sumscore_0_split_13
I0726 09:51:09.356688 27891 net.cpp:380] loss14 -> loss14
I0726 09:51:09.356770 27891 net.cpp:122] Setting up loss14
I0726 09:51:09.356788 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356793 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356799 27891 net.cpp:137] Memory required for data: 489185336
I0726 09:51:09.356806 27891 layer_factory.hpp:77] Creating layer loss15
I0726 09:51:09.356814 27891 net.cpp:84] Creating Layer loss15
I0726 09:51:09.356819 27891 net.cpp:406] loss15 <- score15_slicer_conv_14_split_1
I0726 09:51:09.356827 27891 net.cpp:406] loss15 <- label_label_0_split_14
I0726 09:51:09.356832 27891 net.cpp:406] loss15 <- sumscore_sumscore_0_split_14
I0726 09:51:09.356839 27891 net.cpp:380] loss15 -> loss15
I0726 09:51:09.356931 27891 net.cpp:122] Setting up loss15
I0726 09:51:09.356941 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.356946 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.356953 27891 net.cpp:137] Memory required for data: 489185340
I0726 09:51:09.356959 27891 layer_factory.hpp:77] Creating layer loss16
I0726 09:51:09.356967 27891 net.cpp:84] Creating Layer loss16
I0726 09:51:09.356973 27891 net.cpp:406] loss16 <- score16_slicer_conv_15_split_1
I0726 09:51:09.356981 27891 net.cpp:406] loss16 <- label_label_0_split_15
I0726 09:51:09.356986 27891 net.cpp:406] loss16 <- sumscore_sumscore_0_split_15
I0726 09:51:09.356994 27891 net.cpp:380] loss16 -> loss16
I0726 09:51:09.357077 27891 net.cpp:122] Setting up loss16
I0726 09:51:09.357085 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357090 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357097 27891 net.cpp:137] Memory required for data: 489185344
I0726 09:51:09.357102 27891 layer_factory.hpp:77] Creating layer loss17
I0726 09:51:09.357110 27891 net.cpp:84] Creating Layer loss17
I0726 09:51:09.357115 27891 net.cpp:406] loss17 <- score17_slicer_conv_16_split_1
I0726 09:51:09.357123 27891 net.cpp:406] loss17 <- label_label_0_split_16
I0726 09:51:09.357130 27891 net.cpp:406] loss17 <- sumscore_sumscore_0_split_16
I0726 09:51:09.357138 27891 net.cpp:380] loss17 -> loss17
I0726 09:51:09.357219 27891 net.cpp:122] Setting up loss17
I0726 09:51:09.357228 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357233 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357239 27891 net.cpp:137] Memory required for data: 489185348
I0726 09:51:09.357244 27891 layer_factory.hpp:77] Creating layer loss18
I0726 09:51:09.357254 27891 net.cpp:84] Creating Layer loss18
I0726 09:51:09.357259 27891 net.cpp:406] loss18 <- score18_slicer_conv_17_split_1
I0726 09:51:09.357266 27891 net.cpp:406] loss18 <- label_label_0_split_17
I0726 09:51:09.357272 27891 net.cpp:406] loss18 <- sumscore_sumscore_0_split_17
I0726 09:51:09.357280 27891 net.cpp:380] loss18 -> loss18
I0726 09:51:09.357372 27891 net.cpp:122] Setting up loss18
I0726 09:51:09.357381 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357386 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357393 27891 net.cpp:137] Memory required for data: 489185352
I0726 09:51:09.357399 27891 layer_factory.hpp:77] Creating layer loss19
I0726 09:51:09.357409 27891 net.cpp:84] Creating Layer loss19
I0726 09:51:09.357414 27891 net.cpp:406] loss19 <- score19_slicer_conv_18_split_1
I0726 09:51:09.357421 27891 net.cpp:406] loss19 <- label_label_0_split_18
I0726 09:51:09.357427 27891 net.cpp:406] loss19 <- sumscore_sumscore_0_split_18
I0726 09:51:09.357435 27891 net.cpp:380] loss19 -> loss19
I0726 09:51:09.357519 27891 net.cpp:122] Setting up loss19
I0726 09:51:09.357527 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357532 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357539 27891 net.cpp:137] Memory required for data: 489185356
I0726 09:51:09.357544 27891 layer_factory.hpp:77] Creating layer loss20
I0726 09:51:09.357553 27891 net.cpp:84] Creating Layer loss20
I0726 09:51:09.357558 27891 net.cpp:406] loss20 <- score20_slicer_conv_19_split_1
I0726 09:51:09.357564 27891 net.cpp:406] loss20 <- label_label_0_split_19
I0726 09:51:09.357571 27891 net.cpp:406] loss20 <- sumscore_sumscore_0_split_19
I0726 09:51:09.357578 27891 net.cpp:380] loss20 -> loss20
I0726 09:51:09.357661 27891 net.cpp:122] Setting up loss20
I0726 09:51:09.357681 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357686 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357693 27891 net.cpp:137] Memory required for data: 489185360
I0726 09:51:09.357699 27891 layer_factory.hpp:77] Creating layer loss21
I0726 09:51:09.357707 27891 net.cpp:84] Creating Layer loss21
I0726 09:51:09.357712 27891 net.cpp:406] loss21 <- score21_slicer_conv_20_split_1
I0726 09:51:09.357719 27891 net.cpp:406] loss21 <- label_label_0_split_20
I0726 09:51:09.357727 27891 net.cpp:406] loss21 <- sumscore_sumscore_0_split_20
I0726 09:51:09.357735 27891 net.cpp:380] loss21 -> loss21
I0726 09:51:09.357820 27891 net.cpp:122] Setting up loss21
I0726 09:51:09.357827 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357832 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357839 27891 net.cpp:137] Memory required for data: 489185364
I0726 09:51:09.357844 27891 layer_factory.hpp:77] Creating layer loss22
I0726 09:51:09.357854 27891 net.cpp:84] Creating Layer loss22
I0726 09:51:09.357861 27891 net.cpp:406] loss22 <- score22_slicer_conv_21_split_1
I0726 09:51:09.357867 27891 net.cpp:406] loss22 <- label_label_0_split_21
I0726 09:51:09.357873 27891 net.cpp:406] loss22 <- sumscore_sumscore_0_split_21
I0726 09:51:09.357882 27891 net.cpp:380] loss22 -> loss22
I0726 09:51:09.357969 27891 net.cpp:122] Setting up loss22
I0726 09:51:09.357976 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.357981 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.357988 27891 net.cpp:137] Memory required for data: 489185368
I0726 09:51:09.357993 27891 layer_factory.hpp:77] Creating layer loss23
I0726 09:51:09.358002 27891 net.cpp:84] Creating Layer loss23
I0726 09:51:09.358008 27891 net.cpp:406] loss23 <- score23_slicer_conv_22_split_1
I0726 09:51:09.358014 27891 net.cpp:406] loss23 <- label_label_0_split_22
I0726 09:51:09.358021 27891 net.cpp:406] loss23 <- sumscore_sumscore_0_split_22
I0726 09:51:09.358028 27891 net.cpp:380] loss23 -> loss23
I0726 09:51:09.358113 27891 net.cpp:122] Setting up loss23
I0726 09:51:09.358120 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358125 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358131 27891 net.cpp:137] Memory required for data: 489185372
I0726 09:51:09.358137 27891 layer_factory.hpp:77] Creating layer loss24
I0726 09:51:09.358144 27891 net.cpp:84] Creating Layer loss24
I0726 09:51:09.358150 27891 net.cpp:406] loss24 <- score24_slicer_conv_23_split_1
I0726 09:51:09.358157 27891 net.cpp:406] loss24 <- label_label_0_split_23
I0726 09:51:09.358163 27891 net.cpp:406] loss24 <- sumscore_sumscore_0_split_23
I0726 09:51:09.358171 27891 net.cpp:380] loss24 -> loss24
I0726 09:51:09.358253 27891 net.cpp:122] Setting up loss24
I0726 09:51:09.358260 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358265 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358273 27891 net.cpp:137] Memory required for data: 489185376
I0726 09:51:09.358278 27891 layer_factory.hpp:77] Creating layer loss25
I0726 09:51:09.358285 27891 net.cpp:84] Creating Layer loss25
I0726 09:51:09.358290 27891 net.cpp:406] loss25 <- score25_slicer_conv_24_split_1
I0726 09:51:09.358297 27891 net.cpp:406] loss25 <- label_label_0_split_24
I0726 09:51:09.358304 27891 net.cpp:406] loss25 <- sumscore_sumscore_0_split_24
I0726 09:51:09.358312 27891 net.cpp:380] loss25 -> loss25
I0726 09:51:09.358393 27891 net.cpp:122] Setting up loss25
I0726 09:51:09.358402 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358407 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358413 27891 net.cpp:137] Memory required for data: 489185380
I0726 09:51:09.358418 27891 layer_factory.hpp:77] Creating layer loss26
I0726 09:51:09.358428 27891 net.cpp:84] Creating Layer loss26
I0726 09:51:09.358433 27891 net.cpp:406] loss26 <- score26_slicer_conv_25_split_1
I0726 09:51:09.358440 27891 net.cpp:406] loss26 <- label_label_0_split_25
I0726 09:51:09.358446 27891 net.cpp:406] loss26 <- sumscore_sumscore_0_split_25
I0726 09:51:09.358454 27891 net.cpp:380] loss26 -> loss26
I0726 09:51:09.358525 27891 net.cpp:122] Setting up loss26
I0726 09:51:09.358544 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358551 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358557 27891 net.cpp:137] Memory required for data: 489185384
I0726 09:51:09.358563 27891 layer_factory.hpp:77] Creating layer loss27
I0726 09:51:09.358587 27891 net.cpp:84] Creating Layer loss27
I0726 09:51:09.358592 27891 net.cpp:406] loss27 <- score27_slicer_conv_26_split_1
I0726 09:51:09.358599 27891 net.cpp:406] loss27 <- label_label_0_split_26
I0726 09:51:09.358606 27891 net.cpp:406] loss27 <- sumscore_sumscore_0_split_26
I0726 09:51:09.358614 27891 net.cpp:380] loss27 -> loss27
I0726 09:51:09.358700 27891 net.cpp:122] Setting up loss27
I0726 09:51:09.358707 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358712 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358719 27891 net.cpp:137] Memory required for data: 489185388
I0726 09:51:09.358726 27891 layer_factory.hpp:77] Creating layer loss28
I0726 09:51:09.358734 27891 net.cpp:84] Creating Layer loss28
I0726 09:51:09.358741 27891 net.cpp:406] loss28 <- score28_slicer_conv_27_split_1
I0726 09:51:09.358747 27891 net.cpp:406] loss28 <- label_label_0_split_27
I0726 09:51:09.358753 27891 net.cpp:406] loss28 <- sumscore_sumscore_0_split_27
I0726 09:51:09.358762 27891 net.cpp:380] loss28 -> loss28
I0726 09:51:09.358844 27891 net.cpp:122] Setting up loss28
I0726 09:51:09.358852 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.358857 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.358863 27891 net.cpp:137] Memory required for data: 489185392
I0726 09:51:09.358870 27891 layer_factory.hpp:77] Creating layer loss29
I0726 09:51:09.358878 27891 net.cpp:84] Creating Layer loss29
I0726 09:51:09.358885 27891 net.cpp:406] loss29 <- score29_slicer_conv_28_split_1
I0726 09:51:09.358891 27891 net.cpp:406] loss29 <- label_label_0_split_28
I0726 09:51:09.358932 27891 net.cpp:406] loss29 <- sumscore_sumscore_0_split_28
I0726 09:51:09.358942 27891 net.cpp:380] loss29 -> loss29
I0726 09:51:09.359035 27891 net.cpp:122] Setting up loss29
I0726 09:51:09.359043 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359048 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359055 27891 net.cpp:137] Memory required for data: 489185396
I0726 09:51:09.359061 27891 layer_factory.hpp:77] Creating layer loss30
I0726 09:51:09.359071 27891 net.cpp:84] Creating Layer loss30
I0726 09:51:09.359076 27891 net.cpp:406] loss30 <- score30_slicer_conv_29_split_1
I0726 09:51:09.359083 27891 net.cpp:406] loss30 <- label_label_0_split_29
I0726 09:51:09.359089 27891 net.cpp:406] loss30 <- sumscore_sumscore_0_split_29
I0726 09:51:09.359097 27891 net.cpp:380] loss30 -> loss30
I0726 09:51:09.359182 27891 net.cpp:122] Setting up loss30
I0726 09:51:09.359190 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359195 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359202 27891 net.cpp:137] Memory required for data: 489185400
I0726 09:51:09.359207 27891 layer_factory.hpp:77] Creating layer loss31
I0726 09:51:09.359215 27891 net.cpp:84] Creating Layer loss31
I0726 09:51:09.359220 27891 net.cpp:406] loss31 <- score31_slicer_conv_30_split_1
I0726 09:51:09.359227 27891 net.cpp:406] loss31 <- label_label_0_split_30
I0726 09:51:09.359235 27891 net.cpp:406] loss31 <- sumscore_sumscore_0_split_30
I0726 09:51:09.359243 27891 net.cpp:380] loss31 -> loss31
I0726 09:51:09.359325 27891 net.cpp:122] Setting up loss31
I0726 09:51:09.359333 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359338 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359345 27891 net.cpp:137] Memory required for data: 489185404
I0726 09:51:09.359350 27891 layer_factory.hpp:77] Creating layer loss32
I0726 09:51:09.359359 27891 net.cpp:84] Creating Layer loss32
I0726 09:51:09.359365 27891 net.cpp:406] loss32 <- score32_slicer_conv_31_split_1
I0726 09:51:09.359371 27891 net.cpp:406] loss32 <- label_label_0_split_31
I0726 09:51:09.359378 27891 net.cpp:406] loss32 <- sumscore_sumscore_0_split_31
I0726 09:51:09.359385 27891 net.cpp:380] loss32 -> loss32
I0726 09:51:09.359469 27891 net.cpp:122] Setting up loss32
I0726 09:51:09.359496 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359503 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359509 27891 net.cpp:137] Memory required for data: 489185408
I0726 09:51:09.359515 27891 layer_factory.hpp:77] Creating layer loss33
I0726 09:51:09.359525 27891 net.cpp:84] Creating Layer loss33
I0726 09:51:09.359530 27891 net.cpp:406] loss33 <- score33_slicer_conv_32_split_1
I0726 09:51:09.359539 27891 net.cpp:406] loss33 <- label_label_0_split_32
I0726 09:51:09.359544 27891 net.cpp:406] loss33 <- sumscore_sumscore_0_split_32
I0726 09:51:09.359552 27891 net.cpp:380] loss33 -> loss33
I0726 09:51:09.359643 27891 net.cpp:122] Setting up loss33
I0726 09:51:09.359652 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359657 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359663 27891 net.cpp:137] Memory required for data: 489185412
I0726 09:51:09.359668 27891 layer_factory.hpp:77] Creating layer loss34
I0726 09:51:09.359676 27891 net.cpp:84] Creating Layer loss34
I0726 09:51:09.359683 27891 net.cpp:406] loss34 <- score34_slicer_conv_33_split_1
I0726 09:51:09.359688 27891 net.cpp:406] loss34 <- label_label_0_split_33
I0726 09:51:09.359695 27891 net.cpp:406] loss34 <- sumscore_sumscore_0_split_33
I0726 09:51:09.359702 27891 net.cpp:380] loss34 -> loss34
I0726 09:51:09.359786 27891 net.cpp:122] Setting up loss34
I0726 09:51:09.359796 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359800 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359807 27891 net.cpp:137] Memory required for data: 489185416
I0726 09:51:09.359812 27891 layer_factory.hpp:77] Creating layer loss35
I0726 09:51:09.359820 27891 net.cpp:84] Creating Layer loss35
I0726 09:51:09.359825 27891 net.cpp:406] loss35 <- score35_slicer_conv_34_split_1
I0726 09:51:09.359833 27891 net.cpp:406] loss35 <- label_label_0_split_34
I0726 09:51:09.359838 27891 net.cpp:406] loss35 <- sumscore_sumscore_0_split_34
I0726 09:51:09.359848 27891 net.cpp:380] loss35 -> loss35
I0726 09:51:09.359930 27891 net.cpp:122] Setting up loss35
I0726 09:51:09.359937 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.359942 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.359948 27891 net.cpp:137] Memory required for data: 489185420
I0726 09:51:09.359953 27891 layer_factory.hpp:77] Creating layer loss36
I0726 09:51:09.359961 27891 net.cpp:84] Creating Layer loss36
I0726 09:51:09.359966 27891 net.cpp:406] loss36 <- score36_slicer_conv_35_split_1
I0726 09:51:09.359972 27891 net.cpp:406] loss36 <- label_label_0_split_35
I0726 09:51:09.359977 27891 net.cpp:406] loss36 <- sumscore_sumscore_0_split_35
I0726 09:51:09.359985 27891 net.cpp:380] loss36 -> loss36
I0726 09:51:09.360081 27891 net.cpp:122] Setting up loss36
I0726 09:51:09.360090 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360095 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360101 27891 net.cpp:137] Memory required for data: 489185424
I0726 09:51:09.360105 27891 layer_factory.hpp:77] Creating layer loss37
I0726 09:51:09.360111 27891 net.cpp:84] Creating Layer loss37
I0726 09:51:09.360116 27891 net.cpp:406] loss37 <- score37_slicer_conv_36_split_1
I0726 09:51:09.360121 27891 net.cpp:406] loss37 <- label_label_0_split_36
I0726 09:51:09.360124 27891 net.cpp:406] loss37 <- sumscore_sumscore_0_split_36
I0726 09:51:09.360129 27891 net.cpp:380] loss37 -> loss37
I0726 09:51:09.360225 27891 net.cpp:122] Setting up loss37
I0726 09:51:09.360235 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360239 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360246 27891 net.cpp:137] Memory required for data: 489185428
I0726 09:51:09.360251 27891 layer_factory.hpp:77] Creating layer loss38
I0726 09:51:09.360260 27891 net.cpp:84] Creating Layer loss38
I0726 09:51:09.360265 27891 net.cpp:406] loss38 <- score38_slicer_conv_37_split_1
I0726 09:51:09.360271 27891 net.cpp:406] loss38 <- label_label_0_split_37
I0726 09:51:09.360277 27891 net.cpp:406] loss38 <- sumscore_sumscore_0_split_37
I0726 09:51:09.360285 27891 net.cpp:380] loss38 -> loss38
I0726 09:51:09.360383 27891 net.cpp:122] Setting up loss38
I0726 09:51:09.360404 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360409 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360415 27891 net.cpp:137] Memory required for data: 489185432
I0726 09:51:09.360420 27891 layer_factory.hpp:77] Creating layer loss39
I0726 09:51:09.360429 27891 net.cpp:84] Creating Layer loss39
I0726 09:51:09.360433 27891 net.cpp:406] loss39 <- score39_slicer_conv_38_split_1
I0726 09:51:09.360440 27891 net.cpp:406] loss39 <- label_label_0_split_38
I0726 09:51:09.360446 27891 net.cpp:406] loss39 <- sumscore_sumscore_0_split_38
I0726 09:51:09.360455 27891 net.cpp:380] loss39 -> loss39
I0726 09:51:09.360555 27891 net.cpp:122] Setting up loss39
I0726 09:51:09.360564 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360569 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360575 27891 net.cpp:137] Memory required for data: 489185436
I0726 09:51:09.360580 27891 layer_factory.hpp:77] Creating layer loss40
I0726 09:51:09.360587 27891 net.cpp:84] Creating Layer loss40
I0726 09:51:09.360594 27891 net.cpp:406] loss40 <- score40_slicer_conv_39_split_1
I0726 09:51:09.360599 27891 net.cpp:406] loss40 <- label_label_0_split_39
I0726 09:51:09.360605 27891 net.cpp:406] loss40 <- sumscore_sumscore_0_split_39
I0726 09:51:09.360615 27891 net.cpp:380] loss40 -> loss40
I0726 09:51:09.360708 27891 net.cpp:122] Setting up loss40
I0726 09:51:09.360718 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360721 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360728 27891 net.cpp:137] Memory required for data: 489185440
I0726 09:51:09.360733 27891 layer_factory.hpp:77] Creating layer loss41
I0726 09:51:09.360743 27891 net.cpp:84] Creating Layer loss41
I0726 09:51:09.360747 27891 net.cpp:406] loss41 <- score41_slicer_conv_40_split_1
I0726 09:51:09.360754 27891 net.cpp:406] loss41 <- label_label_0_split_40
I0726 09:51:09.360760 27891 net.cpp:406] loss41 <- sumscore_sumscore_0_split_40
I0726 09:51:09.360767 27891 net.cpp:380] loss41 -> loss41
I0726 09:51:09.360864 27891 net.cpp:122] Setting up loss41
I0726 09:51:09.360873 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.360877 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.360883 27891 net.cpp:137] Memory required for data: 489185444
I0726 09:51:09.360888 27891 layer_factory.hpp:77] Creating layer loss42
I0726 09:51:09.360896 27891 net.cpp:84] Creating Layer loss42
I0726 09:51:09.360901 27891 net.cpp:406] loss42 <- score42_slicer_conv_41_split_1
I0726 09:51:09.360908 27891 net.cpp:406] loss42 <- label_label_0_split_41
I0726 09:51:09.360914 27891 net.cpp:406] loss42 <- sumscore_sumscore_0_split_41
I0726 09:51:09.360921 27891 net.cpp:380] loss42 -> loss42
I0726 09:51:09.361016 27891 net.cpp:122] Setting up loss42
I0726 09:51:09.361026 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361030 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361037 27891 net.cpp:137] Memory required for data: 489185448
I0726 09:51:09.361042 27891 layer_factory.hpp:77] Creating layer loss43
I0726 09:51:09.361049 27891 net.cpp:84] Creating Layer loss43
I0726 09:51:09.361054 27891 net.cpp:406] loss43 <- score43_slicer_conv_42_split_1
I0726 09:51:09.361060 27891 net.cpp:406] loss43 <- label_label_0_split_42
I0726 09:51:09.361066 27891 net.cpp:406] loss43 <- sumscore_sumscore_0_split_42
I0726 09:51:09.361073 27891 net.cpp:380] loss43 -> loss43
I0726 09:51:09.361166 27891 net.cpp:122] Setting up loss43
I0726 09:51:09.361176 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361181 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361193 27891 net.cpp:137] Memory required for data: 489185452
I0726 09:51:09.361199 27891 layer_factory.hpp:77] Creating layer loss44
I0726 09:51:09.361217 27891 net.cpp:84] Creating Layer loss44
I0726 09:51:09.361222 27891 net.cpp:406] loss44 <- score44_slicer_conv_43_split_1
I0726 09:51:09.361228 27891 net.cpp:406] loss44 <- label_label_0_split_43
I0726 09:51:09.361235 27891 net.cpp:406] loss44 <- sumscore_sumscore_0_split_43
I0726 09:51:09.361244 27891 net.cpp:380] loss44 -> loss44
I0726 09:51:09.361341 27891 net.cpp:122] Setting up loss44
I0726 09:51:09.361363 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361368 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361376 27891 net.cpp:137] Memory required for data: 489185456
I0726 09:51:09.361380 27891 layer_factory.hpp:77] Creating layer loss45
I0726 09:51:09.361389 27891 net.cpp:84] Creating Layer loss45
I0726 09:51:09.361394 27891 net.cpp:406] loss45 <- score45_slicer_conv_44_split_1
I0726 09:51:09.361402 27891 net.cpp:406] loss45 <- label_label_0_split_44
I0726 09:51:09.361407 27891 net.cpp:406] loss45 <- sumscore_sumscore_0_split_44
I0726 09:51:09.361414 27891 net.cpp:380] loss45 -> loss45
I0726 09:51:09.361513 27891 net.cpp:122] Setting up loss45
I0726 09:51:09.361522 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361526 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361532 27891 net.cpp:137] Memory required for data: 489185460
I0726 09:51:09.361538 27891 layer_factory.hpp:77] Creating layer loss46
I0726 09:51:09.361546 27891 net.cpp:84] Creating Layer loss46
I0726 09:51:09.361551 27891 net.cpp:406] loss46 <- score46_slicer_conv_45_split_1
I0726 09:51:09.361557 27891 net.cpp:406] loss46 <- label_label_0_split_45
I0726 09:51:09.361563 27891 net.cpp:406] loss46 <- sumscore_sumscore_0_split_45
I0726 09:51:09.361570 27891 net.cpp:380] loss46 -> loss46
I0726 09:51:09.361665 27891 net.cpp:122] Setting up loss46
I0726 09:51:09.361673 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361678 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361685 27891 net.cpp:137] Memory required for data: 489185464
I0726 09:51:09.361690 27891 layer_factory.hpp:77] Creating layer loss47
I0726 09:51:09.361696 27891 net.cpp:84] Creating Layer loss47
I0726 09:51:09.361702 27891 net.cpp:406] loss47 <- score47_slicer_conv_46_split_1
I0726 09:51:09.361708 27891 net.cpp:406] loss47 <- label_label_0_split_46
I0726 09:51:09.361714 27891 net.cpp:406] loss47 <- sumscore_sumscore_0_split_46
I0726 09:51:09.361721 27891 net.cpp:380] loss47 -> loss47
I0726 09:51:09.361802 27891 net.cpp:122] Setting up loss47
I0726 09:51:09.361810 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361815 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361821 27891 net.cpp:137] Memory required for data: 489185468
I0726 09:51:09.361825 27891 layer_factory.hpp:77] Creating layer loss48
I0726 09:51:09.361830 27891 net.cpp:84] Creating Layer loss48
I0726 09:51:09.361835 27891 net.cpp:406] loss48 <- score48_slicer_conv_47_split_1
I0726 09:51:09.361840 27891 net.cpp:406] loss48 <- label_label_0_split_47
I0726 09:51:09.361843 27891 net.cpp:406] loss48 <- sumscore_sumscore_0_split_47
I0726 09:51:09.361853 27891 net.cpp:380] loss48 -> loss48
I0726 09:51:09.361950 27891 net.cpp:122] Setting up loss48
I0726 09:51:09.361960 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.361965 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.361973 27891 net.cpp:137] Memory required for data: 489185472
I0726 09:51:09.361977 27891 layer_factory.hpp:77] Creating layer loss49
I0726 09:51:09.361987 27891 net.cpp:84] Creating Layer loss49
I0726 09:51:09.361992 27891 net.cpp:406] loss49 <- score49_slicer_conv_48_split_1
I0726 09:51:09.361999 27891 net.cpp:406] loss49 <- label_label_0_split_48
I0726 09:51:09.362004 27891 net.cpp:406] loss49 <- sumscore_sumscore_0_split_48
I0726 09:51:09.362012 27891 net.cpp:380] loss49 -> loss49
I0726 09:51:09.362104 27891 net.cpp:122] Setting up loss49
I0726 09:51:09.362113 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362118 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362124 27891 net.cpp:137] Memory required for data: 489185476
I0726 09:51:09.362129 27891 layer_factory.hpp:77] Creating layer loss50
I0726 09:51:09.362138 27891 net.cpp:84] Creating Layer loss50
I0726 09:51:09.362143 27891 net.cpp:406] loss50 <- score50_slicer_conv_49_split_1
I0726 09:51:09.362149 27891 net.cpp:406] loss50 <- label_label_0_split_49
I0726 09:51:09.362155 27891 net.cpp:406] loss50 <- sumscore_sumscore_0_split_49
I0726 09:51:09.362162 27891 net.cpp:380] loss50 -> loss50
I0726 09:51:09.362257 27891 net.cpp:122] Setting up loss50
I0726 09:51:09.362277 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362282 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362287 27891 net.cpp:137] Memory required for data: 489185480
I0726 09:51:09.362293 27891 layer_factory.hpp:77] Creating layer loss51
I0726 09:51:09.362300 27891 net.cpp:84] Creating Layer loss51
I0726 09:51:09.362313 27891 net.cpp:406] loss51 <- score51_slicer_conv_50_split_1
I0726 09:51:09.362320 27891 net.cpp:406] loss51 <- label_label_0_split_50
I0726 09:51:09.362327 27891 net.cpp:406] loss51 <- sumscore_sumscore_0_split_50
I0726 09:51:09.362334 27891 net.cpp:380] loss51 -> loss51
I0726 09:51:09.362419 27891 net.cpp:122] Setting up loss51
I0726 09:51:09.362427 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362432 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362438 27891 net.cpp:137] Memory required for data: 489185484
I0726 09:51:09.362443 27891 layer_factory.hpp:77] Creating layer loss52
I0726 09:51:09.362457 27891 net.cpp:84] Creating Layer loss52
I0726 09:51:09.362464 27891 net.cpp:406] loss52 <- score52_slicer_conv_51_split_1
I0726 09:51:09.362470 27891 net.cpp:406] loss52 <- label_label_0_split_51
I0726 09:51:09.362476 27891 net.cpp:406] loss52 <- sumscore_sumscore_0_split_51
I0726 09:51:09.362484 27891 net.cpp:380] loss52 -> loss52
I0726 09:51:09.362576 27891 net.cpp:122] Setting up loss52
I0726 09:51:09.362584 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362588 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362596 27891 net.cpp:137] Memory required for data: 489185488
I0726 09:51:09.362601 27891 layer_factory.hpp:77] Creating layer loss53
I0726 09:51:09.362610 27891 net.cpp:84] Creating Layer loss53
I0726 09:51:09.362615 27891 net.cpp:406] loss53 <- score53_slicer_conv_52_split_1
I0726 09:51:09.362622 27891 net.cpp:406] loss53 <- label_label_0_split_52
I0726 09:51:09.362627 27891 net.cpp:406] loss53 <- sumscore_sumscore_0_split_52
I0726 09:51:09.362634 27891 net.cpp:380] loss53 -> loss53
I0726 09:51:09.362720 27891 net.cpp:122] Setting up loss53
I0726 09:51:09.362727 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362731 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362737 27891 net.cpp:137] Memory required for data: 489185492
I0726 09:51:09.362742 27891 layer_factory.hpp:77] Creating layer loss54
I0726 09:51:09.362761 27891 net.cpp:84] Creating Layer loss54
I0726 09:51:09.362766 27891 net.cpp:406] loss54 <- score54_slicer_conv_53_split_1
I0726 09:51:09.362772 27891 net.cpp:406] loss54 <- label_label_0_split_53
I0726 09:51:09.362779 27891 net.cpp:406] loss54 <- sumscore_sumscore_0_split_53
I0726 09:51:09.362787 27891 net.cpp:380] loss54 -> loss54
I0726 09:51:09.362870 27891 net.cpp:122] Setting up loss54
I0726 09:51:09.362879 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.362884 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.362890 27891 net.cpp:137] Memory required for data: 489185496
I0726 09:51:09.362895 27891 layer_factory.hpp:77] Creating layer loss55
I0726 09:51:09.362903 27891 net.cpp:84] Creating Layer loss55
I0726 09:51:09.362908 27891 net.cpp:406] loss55 <- score55_slicer_conv_54_split_1
I0726 09:51:09.362915 27891 net.cpp:406] loss55 <- label_label_0_split_54
I0726 09:51:09.362921 27891 net.cpp:406] loss55 <- sumscore_sumscore_0_split_54
I0726 09:51:09.362928 27891 net.cpp:380] loss55 -> loss55
I0726 09:51:09.363009 27891 net.cpp:122] Setting up loss55
I0726 09:51:09.363018 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363023 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.363029 27891 net.cpp:137] Memory required for data: 489185500
I0726 09:51:09.363034 27891 layer_factory.hpp:77] Creating layer loss56
I0726 09:51:09.363042 27891 net.cpp:84] Creating Layer loss56
I0726 09:51:09.363047 27891 net.cpp:406] loss56 <- score56_slicer_conv_55_split_1
I0726 09:51:09.363054 27891 net.cpp:406] loss56 <- label_label_0_split_55
I0726 09:51:09.363060 27891 net.cpp:406] loss56 <- sumscore_sumscore_0_split_55
I0726 09:51:09.363068 27891 net.cpp:380] loss56 -> loss56
I0726 09:51:09.363164 27891 net.cpp:122] Setting up loss56
I0726 09:51:09.363173 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363178 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.363184 27891 net.cpp:137] Memory required for data: 489185504
I0726 09:51:09.363190 27891 layer_factory.hpp:77] Creating layer loss57
I0726 09:51:09.363199 27891 net.cpp:84] Creating Layer loss57
I0726 09:51:09.363204 27891 net.cpp:406] loss57 <- score57_slicer_conv_56_split_1
I0726 09:51:09.363211 27891 net.cpp:406] loss57 <- label_label_0_split_56
I0726 09:51:09.363217 27891 net.cpp:406] loss57 <- sumscore_sumscore_0_split_56
I0726 09:51:09.363225 27891 net.cpp:380] loss57 -> loss57
I0726 09:51:09.363308 27891 net.cpp:122] Setting up loss57
I0726 09:51:09.363317 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363322 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.363328 27891 net.cpp:137] Memory required for data: 489185508
I0726 09:51:09.363333 27891 layer_factory.hpp:77] Creating layer loss58
I0726 09:51:09.363343 27891 net.cpp:84] Creating Layer loss58
I0726 09:51:09.363348 27891 net.cpp:406] loss58 <- score58_slicer_conv_57_split_1
I0726 09:51:09.363355 27891 net.cpp:406] loss58 <- label_label_0_split_57
I0726 09:51:09.363361 27891 net.cpp:406] loss58 <- sumscore_sumscore_0_split_57
I0726 09:51:09.363368 27891 net.cpp:380] loss58 -> loss58
I0726 09:51:09.363446 27891 net.cpp:122] Setting up loss58
I0726 09:51:09.363453 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363456 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.363461 27891 net.cpp:137] Memory required for data: 489185512
I0726 09:51:09.363464 27891 layer_factory.hpp:77] Creating layer loss59
I0726 09:51:09.363469 27891 net.cpp:84] Creating Layer loss59
I0726 09:51:09.363473 27891 net.cpp:406] loss59 <- score59_slicer_conv_58_split_1
I0726 09:51:09.363477 27891 net.cpp:406] loss59 <- label_label_0_split_58
I0726 09:51:09.363492 27891 net.cpp:406] loss59 <- sumscore_sumscore_0_split_58
I0726 09:51:09.363497 27891 net.cpp:380] loss59 -> loss59
I0726 09:51:09.363579 27891 net.cpp:122] Setting up loss59
I0726 09:51:09.363587 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363592 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.363600 27891 net.cpp:137] Memory required for data: 489185516
I0726 09:51:09.363605 27891 layer_factory.hpp:77] Creating layer loss60
I0726 09:51:09.363612 27891 net.cpp:84] Creating Layer loss60
I0726 09:51:09.363618 27891 net.cpp:406] loss60 <- score60_slicer_conv_59_split_1
I0726 09:51:09.363626 27891 net.cpp:406] loss60 <- label_label_0_split_59
I0726 09:51:09.363632 27891 net.cpp:406] loss60 <- sumscore_sumscore_0_split_59
I0726 09:51:09.363641 27891 net.cpp:380] loss60 -> loss60
I0726 09:51:09.363725 27891 net.cpp:122] Setting up loss60
I0726 09:51:09.363734 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.363739 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.384745 27891 net.cpp:137] Memory required for data: 489185520
I0726 09:51:09.384769 27891 layer_factory.hpp:77] Creating layer loss61
I0726 09:51:09.384796 27891 net.cpp:84] Creating Layer loss61
I0726 09:51:09.384805 27891 net.cpp:406] loss61 <- score61_slicer_conv_60_split_1
I0726 09:51:09.384817 27891 net.cpp:406] loss61 <- label_label_0_split_60
I0726 09:51:09.384825 27891 net.cpp:406] loss61 <- sumscore_sumscore_0_split_60
I0726 09:51:09.384835 27891 net.cpp:380] loss61 -> loss61
I0726 09:51:09.385012 27891 net.cpp:122] Setting up loss61
I0726 09:51:09.385021 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.385025 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.385035 27891 net.cpp:137] Memory required for data: 489185524
I0726 09:51:09.385037 27891 layer_factory.hpp:77] Creating layer loss62
I0726 09:51:09.385047 27891 net.cpp:84] Creating Layer loss62
I0726 09:51:09.385062 27891 net.cpp:406] loss62 <- score62_slicer_conv_61_split_1
I0726 09:51:09.385073 27891 net.cpp:406] loss62 <- label_label_0_split_61
I0726 09:51:09.385082 27891 net.cpp:406] loss62 <- sumscore_sumscore_0_split_61
I0726 09:51:09.385095 27891 net.cpp:380] loss62 -> loss62
I0726 09:51:09.385236 27891 net.cpp:122] Setting up loss62
I0726 09:51:09.385246 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.385251 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.385258 27891 net.cpp:137] Memory required for data: 489185528
I0726 09:51:09.385264 27891 layer_factory.hpp:77] Creating layer loss63
I0726 09:51:09.385273 27891 net.cpp:84] Creating Layer loss63
I0726 09:51:09.385279 27891 net.cpp:406] loss63 <- score63_slicer_conv_62_split_1
I0726 09:51:09.385288 27891 net.cpp:406] loss63 <- label_label_0_split_62
I0726 09:51:09.385293 27891 net.cpp:406] loss63 <- sumscore_sumscore_0_split_62
I0726 09:51:09.385313 27891 net.cpp:380] loss63 -> loss63
I0726 09:51:09.385403 27891 net.cpp:122] Setting up loss63
I0726 09:51:09.385412 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.385417 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.385424 27891 net.cpp:137] Memory required for data: 489185532
I0726 09:51:09.385431 27891 layer_factory.hpp:77] Creating layer loss64
I0726 09:51:09.385438 27891 net.cpp:84] Creating Layer loss64
I0726 09:51:09.385444 27891 net.cpp:406] loss64 <- score64_slicer_conv_63_split_1
I0726 09:51:09.385452 27891 net.cpp:406] loss64 <- label_label_0_split_63
I0726 09:51:09.385459 27891 net.cpp:406] loss64 <- sumscore_sumscore_0_split_63
I0726 09:51:09.385468 27891 net.cpp:380] loss64 -> loss64
I0726 09:51:09.385553 27891 net.cpp:122] Setting up loss64
I0726 09:51:09.385561 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.385567 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.385574 27891 net.cpp:137] Memory required for data: 489185536
I0726 09:51:09.385581 27891 net.cpp:198] loss64 needs backward computation.
I0726 09:51:09.385592 27891 net.cpp:198] loss63 needs backward computation.
I0726 09:51:09.385599 27891 net.cpp:198] loss62 needs backward computation.
I0726 09:51:09.385607 27891 net.cpp:198] loss61 needs backward computation.
I0726 09:51:09.385614 27891 net.cpp:198] loss60 needs backward computation.
I0726 09:51:09.385622 27891 net.cpp:198] loss59 needs backward computation.
I0726 09:51:09.385628 27891 net.cpp:198] loss58 needs backward computation.
I0726 09:51:09.385635 27891 net.cpp:198] loss57 needs backward computation.
I0726 09:51:09.385643 27891 net.cpp:198] loss56 needs backward computation.
I0726 09:51:09.385649 27891 net.cpp:198] loss55 needs backward computation.
I0726 09:51:09.385655 27891 net.cpp:198] loss54 needs backward computation.
I0726 09:51:09.385663 27891 net.cpp:198] loss53 needs backward computation.
I0726 09:51:09.385670 27891 net.cpp:198] loss52 needs backward computation.
I0726 09:51:09.385679 27891 net.cpp:198] loss51 needs backward computation.
I0726 09:51:09.385685 27891 net.cpp:198] loss50 needs backward computation.
I0726 09:51:09.385692 27891 net.cpp:198] loss49 needs backward computation.
I0726 09:51:09.385700 27891 net.cpp:198] loss48 needs backward computation.
I0726 09:51:09.385707 27891 net.cpp:198] loss47 needs backward computation.
I0726 09:51:09.385715 27891 net.cpp:198] loss46 needs backward computation.
I0726 09:51:09.385721 27891 net.cpp:198] loss45 needs backward computation.
I0726 09:51:09.385727 27891 net.cpp:198] loss44 needs backward computation.
I0726 09:51:09.385736 27891 net.cpp:198] loss43 needs backward computation.
I0726 09:51:09.385743 27891 net.cpp:198] loss42 needs backward computation.
I0726 09:51:09.385751 27891 net.cpp:198] loss41 needs backward computation.
I0726 09:51:09.385757 27891 net.cpp:198] loss40 needs backward computation.
I0726 09:51:09.385764 27891 net.cpp:198] loss39 needs backward computation.
I0726 09:51:09.385771 27891 net.cpp:198] loss38 needs backward computation.
I0726 09:51:09.385778 27891 net.cpp:198] loss37 needs backward computation.
I0726 09:51:09.385785 27891 net.cpp:198] loss36 needs backward computation.
I0726 09:51:09.385792 27891 net.cpp:198] loss35 needs backward computation.
I0726 09:51:09.385800 27891 net.cpp:198] loss34 needs backward computation.
I0726 09:51:09.385807 27891 net.cpp:198] loss33 needs backward computation.
I0726 09:51:09.385814 27891 net.cpp:198] loss32 needs backward computation.
I0726 09:51:09.385833 27891 net.cpp:198] loss31 needs backward computation.
I0726 09:51:09.385843 27891 net.cpp:198] loss30 needs backward computation.
I0726 09:51:09.385850 27891 net.cpp:198] loss29 needs backward computation.
I0726 09:51:09.385857 27891 net.cpp:198] loss28 needs backward computation.
I0726 09:51:09.385864 27891 net.cpp:198] loss27 needs backward computation.
I0726 09:51:09.385874 27891 net.cpp:198] loss26 needs backward computation.
I0726 09:51:09.385881 27891 net.cpp:198] loss25 needs backward computation.
I0726 09:51:09.385888 27891 net.cpp:198] loss24 needs backward computation.
I0726 09:51:09.385895 27891 net.cpp:198] loss23 needs backward computation.
I0726 09:51:09.385901 27891 net.cpp:198] loss22 needs backward computation.
I0726 09:51:09.385908 27891 net.cpp:198] loss21 needs backward computation.
I0726 09:51:09.385915 27891 net.cpp:198] loss20 needs backward computation.
I0726 09:51:09.385922 27891 net.cpp:198] loss19 needs backward computation.
I0726 09:51:09.385929 27891 net.cpp:198] loss18 needs backward computation.
I0726 09:51:09.385937 27891 net.cpp:198] loss17 needs backward computation.
I0726 09:51:09.385946 27891 net.cpp:198] loss16 needs backward computation.
I0726 09:51:09.385952 27891 net.cpp:198] loss15 needs backward computation.
I0726 09:51:09.385959 27891 net.cpp:198] loss14 needs backward computation.
I0726 09:51:09.385967 27891 net.cpp:198] loss13 needs backward computation.
I0726 09:51:09.385973 27891 net.cpp:198] loss12 needs backward computation.
I0726 09:51:09.385982 27891 net.cpp:198] loss11 needs backward computation.
I0726 09:51:09.385987 27891 net.cpp:198] loss10 needs backward computation.
I0726 09:51:09.385996 27891 net.cpp:198] loss9 needs backward computation.
I0726 09:51:09.386004 27891 net.cpp:198] loss8 needs backward computation.
I0726 09:51:09.386011 27891 net.cpp:198] loss7 needs backward computation.
I0726 09:51:09.386019 27891 net.cpp:198] loss6 needs backward computation.
I0726 09:51:09.386026 27891 net.cpp:198] loss5 needs backward computation.
I0726 09:51:09.386034 27891 net.cpp:198] loss4 needs backward computation.
I0726 09:51:09.386040 27891 net.cpp:198] loss3 needs backward computation.
I0726 09:51:09.386047 27891 net.cpp:198] loss2 needs backward computation.
I0726 09:51:09.386055 27891 net.cpp:198] loss1 needs backward computation.
I0726 09:51:09.386063 27891 net.cpp:198] sumscore_sumscore_0_split needs backward computation.
I0726 09:51:09.386070 27891 net.cpp:198] sumscore needs backward computation.
I0726 09:51:09.386101 27891 net.cpp:198] score64_slicer_conv_63_split needs backward computation.
I0726 09:51:09.386108 27891 net.cpp:198] score63_slicer_conv_62_split needs backward computation.
I0726 09:51:09.386114 27891 net.cpp:198] score62_slicer_conv_61_split needs backward computation.
I0726 09:51:09.386121 27891 net.cpp:198] score61_slicer_conv_60_split needs backward computation.
I0726 09:51:09.386126 27891 net.cpp:198] score60_slicer_conv_59_split needs backward computation.
I0726 09:51:09.386133 27891 net.cpp:198] score59_slicer_conv_58_split needs backward computation.
I0726 09:51:09.386139 27891 net.cpp:198] score58_slicer_conv_57_split needs backward computation.
I0726 09:51:09.386145 27891 net.cpp:198] score57_slicer_conv_56_split needs backward computation.
I0726 09:51:09.386152 27891 net.cpp:198] score56_slicer_conv_55_split needs backward computation.
I0726 09:51:09.386157 27891 net.cpp:198] score55_slicer_conv_54_split needs backward computation.
I0726 09:51:09.386163 27891 net.cpp:198] score54_slicer_conv_53_split needs backward computation.
I0726 09:51:09.386169 27891 net.cpp:198] score53_slicer_conv_52_split needs backward computation.
I0726 09:51:09.386176 27891 net.cpp:198] score52_slicer_conv_51_split needs backward computation.
I0726 09:51:09.386183 27891 net.cpp:198] score51_slicer_conv_50_split needs backward computation.
I0726 09:51:09.386188 27891 net.cpp:198] score50_slicer_conv_49_split needs backward computation.
I0726 09:51:09.386194 27891 net.cpp:198] score49_slicer_conv_48_split needs backward computation.
I0726 09:51:09.386209 27891 net.cpp:198] score48_slicer_conv_47_split needs backward computation.
I0726 09:51:09.386215 27891 net.cpp:198] score47_slicer_conv_46_split needs backward computation.
I0726 09:51:09.386221 27891 net.cpp:198] score46_slicer_conv_45_split needs backward computation.
I0726 09:51:09.386227 27891 net.cpp:198] score45_slicer_conv_44_split needs backward computation.
I0726 09:51:09.386234 27891 net.cpp:198] score44_slicer_conv_43_split needs backward computation.
I0726 09:51:09.386240 27891 net.cpp:198] score43_slicer_conv_42_split needs backward computation.
I0726 09:51:09.386245 27891 net.cpp:198] score42_slicer_conv_41_split needs backward computation.
I0726 09:51:09.386251 27891 net.cpp:198] score41_slicer_conv_40_split needs backward computation.
I0726 09:51:09.386257 27891 net.cpp:198] score40_slicer_conv_39_split needs backward computation.
I0726 09:51:09.386263 27891 net.cpp:198] score39_slicer_conv_38_split needs backward computation.
I0726 09:51:09.386270 27891 net.cpp:198] score38_slicer_conv_37_split needs backward computation.
I0726 09:51:09.386274 27891 net.cpp:198] score37_slicer_conv_36_split needs backward computation.
I0726 09:51:09.386278 27891 net.cpp:198] score36_slicer_conv_35_split needs backward computation.
I0726 09:51:09.386284 27891 net.cpp:198] score35_slicer_conv_34_split needs backward computation.
I0726 09:51:09.386291 27891 net.cpp:198] score34_slicer_conv_33_split needs backward computation.
I0726 09:51:09.386296 27891 net.cpp:198] score33_slicer_conv_32_split needs backward computation.
I0726 09:51:09.386301 27891 net.cpp:198] score32_slicer_conv_31_split needs backward computation.
I0726 09:51:09.386307 27891 net.cpp:198] score31_slicer_conv_30_split needs backward computation.
I0726 09:51:09.386313 27891 net.cpp:198] score30_slicer_conv_29_split needs backward computation.
I0726 09:51:09.386319 27891 net.cpp:198] score29_slicer_conv_28_split needs backward computation.
I0726 09:51:09.386323 27891 net.cpp:198] score28_slicer_conv_27_split needs backward computation.
I0726 09:51:09.386329 27891 net.cpp:198] score27_slicer_conv_26_split needs backward computation.
I0726 09:51:09.386334 27891 net.cpp:198] score26_slicer_conv_25_split needs backward computation.
I0726 09:51:09.386349 27891 net.cpp:198] score25_slicer_conv_24_split needs backward computation.
I0726 09:51:09.386355 27891 net.cpp:198] score24_slicer_conv_23_split needs backward computation.
I0726 09:51:09.386360 27891 net.cpp:198] score23_slicer_conv_22_split needs backward computation.
I0726 09:51:09.386366 27891 net.cpp:198] score22_slicer_conv_21_split needs backward computation.
I0726 09:51:09.386373 27891 net.cpp:198] score21_slicer_conv_20_split needs backward computation.
I0726 09:51:09.386379 27891 net.cpp:198] score20_slicer_conv_19_split needs backward computation.
I0726 09:51:09.386384 27891 net.cpp:198] score19_slicer_conv_18_split needs backward computation.
I0726 09:51:09.386390 27891 net.cpp:198] score18_slicer_conv_17_split needs backward computation.
I0726 09:51:09.386397 27891 net.cpp:198] score17_slicer_conv_16_split needs backward computation.
I0726 09:51:09.386404 27891 net.cpp:198] score16_slicer_conv_15_split needs backward computation.
I0726 09:51:09.386409 27891 net.cpp:198] score15_slicer_conv_14_split needs backward computation.
I0726 09:51:09.386415 27891 net.cpp:198] score14_slicer_conv_13_split needs backward computation.
I0726 09:51:09.386421 27891 net.cpp:198] score13_slicer_conv_12_split needs backward computation.
I0726 09:51:09.386427 27891 net.cpp:198] score12_slicer_conv_11_split needs backward computation.
I0726 09:51:09.386433 27891 net.cpp:198] score11_slicer_conv_10_split needs backward computation.
I0726 09:51:09.386440 27891 net.cpp:198] score10_slicer_conv_9_split needs backward computation.
I0726 09:51:09.386445 27891 net.cpp:198] score9_slicer_conv_8_split needs backward computation.
I0726 09:51:09.386451 27891 net.cpp:198] score8_slicer_conv_7_split needs backward computation.
I0726 09:51:09.386457 27891 net.cpp:198] score7_slicer_conv_6_split needs backward computation.
I0726 09:51:09.386471 27891 net.cpp:198] score6_slicer_conv_5_split needs backward computation.
I0726 09:51:09.386477 27891 net.cpp:198] score5_slicer_conv_4_split needs backward computation.
I0726 09:51:09.386483 27891 net.cpp:198] score4_slicer_conv_3_split needs backward computation.
I0726 09:51:09.386489 27891 net.cpp:198] score3_slicer_conv_2_split needs backward computation.
I0726 09:51:09.386495 27891 net.cpp:198] score2_slicer_conv_1_split needs backward computation.
I0726 09:51:09.386502 27891 net.cpp:198] score1_slicer_conv_0_split needs backward computation.
I0726 09:51:09.386507 27891 net.cpp:198] slicer_conv needs backward computation.
I0726 09:51:09.386513 27891 net.cpp:198] relu_score needs backward computation.
I0726 09:51:09.386519 27891 net.cpp:198] conv_score needs backward computation.
I0726 09:51:09.386524 27891 net.cpp:198] relu5_3 needs backward computation.
I0726 09:51:09.386530 27891 net.cpp:198] conv5_3 needs backward computation.
I0726 09:51:09.386536 27891 net.cpp:198] relu5_2 needs backward computation.
I0726 09:51:09.386541 27891 net.cpp:198] conv5_2 needs backward computation.
I0726 09:51:09.386548 27891 net.cpp:198] relu5_1 needs backward computation.
I0726 09:51:09.386554 27891 net.cpp:198] conv5_1 needs backward computation.
I0726 09:51:09.386559 27891 net.cpp:198] pool4 needs backward computation.
I0726 09:51:09.386565 27891 net.cpp:198] relu4_3 needs backward computation.
I0726 09:51:09.386570 27891 net.cpp:198] conv4_3 needs backward computation.
I0726 09:51:09.386576 27891 net.cpp:198] relu4_2 needs backward computation.
I0726 09:51:09.386582 27891 net.cpp:198] conv4_2 needs backward computation.
I0726 09:51:09.386587 27891 net.cpp:198] relu4_1 needs backward computation.
I0726 09:51:09.386593 27891 net.cpp:198] conv4_1 needs backward computation.
I0726 09:51:09.386600 27891 net.cpp:198] pool3 needs backward computation.
I0726 09:51:09.386605 27891 net.cpp:198] relu3_3 needs backward computation.
I0726 09:51:09.386610 27891 net.cpp:198] conv3_3 needs backward computation.
I0726 09:51:09.386616 27891 net.cpp:198] relu3_2 needs backward computation.
I0726 09:51:09.386621 27891 net.cpp:198] conv3_2 needs backward computation.
I0726 09:51:09.386627 27891 net.cpp:198] relu3_1 needs backward computation.
I0726 09:51:09.386632 27891 net.cpp:198] conv3_1 needs backward computation.
I0726 09:51:09.386638 27891 net.cpp:198] pool2 needs backward computation.
I0726 09:51:09.386644 27891 net.cpp:198] relu2_2 needs backward computation.
I0726 09:51:09.386651 27891 net.cpp:198] conv2_2 needs backward computation.
I0726 09:51:09.386656 27891 net.cpp:198] relu2_1 needs backward computation.
I0726 09:51:09.386662 27891 net.cpp:198] conv2_1 needs backward computation.
I0726 09:51:09.386667 27891 net.cpp:198] pool1 needs backward computation.
I0726 09:51:09.386672 27891 net.cpp:198] relu1_2 needs backward computation.
I0726 09:51:09.386677 27891 net.cpp:198] conv1_2 needs backward computation.
I0726 09:51:09.386680 27891 net.cpp:198] relu1_1 needs backward computation.
I0726 09:51:09.386684 27891 net.cpp:198] conv1_1 needs backward computation.
I0726 09:51:09.386700 27891 net.cpp:200] label_label_0_split does not need backward computation.
I0726 09:51:09.386705 27891 net.cpp:200] label does not need backward computation.
I0726 09:51:09.386709 27891 net.cpp:200] data does not need backward computation.
I0726 09:51:09.386713 27891 net.cpp:242] This network produces output loss1
I0726 09:51:09.386718 27891 net.cpp:242] This network produces output loss10
I0726 09:51:09.386721 27891 net.cpp:242] This network produces output loss11
I0726 09:51:09.386725 27891 net.cpp:242] This network produces output loss12
I0726 09:51:09.386729 27891 net.cpp:242] This network produces output loss13
I0726 09:51:09.386732 27891 net.cpp:242] This network produces output loss14
I0726 09:51:09.386736 27891 net.cpp:242] This network produces output loss15
I0726 09:51:09.386740 27891 net.cpp:242] This network produces output loss16
I0726 09:51:09.386744 27891 net.cpp:242] This network produces output loss17
I0726 09:51:09.386754 27891 net.cpp:242] This network produces output loss18
I0726 09:51:09.386759 27891 net.cpp:242] This network produces output loss19
I0726 09:51:09.386761 27891 net.cpp:242] This network produces output loss2
I0726 09:51:09.386765 27891 net.cpp:242] This network produces output loss20
I0726 09:51:09.386768 27891 net.cpp:242] This network produces output loss21
I0726 09:51:09.386772 27891 net.cpp:242] This network produces output loss22
I0726 09:51:09.386775 27891 net.cpp:242] This network produces output loss23
I0726 09:51:09.386778 27891 net.cpp:242] This network produces output loss24
I0726 09:51:09.386782 27891 net.cpp:242] This network produces output loss25
I0726 09:51:09.386786 27891 net.cpp:242] This network produces output loss26
I0726 09:51:09.386790 27891 net.cpp:242] This network produces output loss27
I0726 09:51:09.386795 27891 net.cpp:242] This network produces output loss28
I0726 09:51:09.386801 27891 net.cpp:242] This network produces output loss29
I0726 09:51:09.386806 27891 net.cpp:242] This network produces output loss3
I0726 09:51:09.386811 27891 net.cpp:242] This network produces output loss30
I0726 09:51:09.386817 27891 net.cpp:242] This network produces output loss31
I0726 09:51:09.386822 27891 net.cpp:242] This network produces output loss32
I0726 09:51:09.386827 27891 net.cpp:242] This network produces output loss33
I0726 09:51:09.386832 27891 net.cpp:242] This network produces output loss34
I0726 09:51:09.386837 27891 net.cpp:242] This network produces output loss35
I0726 09:51:09.386843 27891 net.cpp:242] This network produces output loss36
I0726 09:51:09.386848 27891 net.cpp:242] This network produces output loss37
I0726 09:51:09.386853 27891 net.cpp:242] This network produces output loss38
I0726 09:51:09.386858 27891 net.cpp:242] This network produces output loss39
I0726 09:51:09.386867 27891 net.cpp:242] This network produces output loss4
I0726 09:51:09.386871 27891 net.cpp:242] This network produces output loss40
I0726 09:51:09.386878 27891 net.cpp:242] This network produces output loss41
I0726 09:51:09.386883 27891 net.cpp:242] This network produces output loss42
I0726 09:51:09.386888 27891 net.cpp:242] This network produces output loss43
I0726 09:51:09.386893 27891 net.cpp:242] This network produces output loss44
I0726 09:51:09.386898 27891 net.cpp:242] This network produces output loss45
I0726 09:51:09.386903 27891 net.cpp:242] This network produces output loss46
I0726 09:51:09.386907 27891 net.cpp:242] This network produces output loss47
I0726 09:51:09.386914 27891 net.cpp:242] This network produces output loss48
I0726 09:51:09.386919 27891 net.cpp:242] This network produces output loss49
I0726 09:51:09.386924 27891 net.cpp:242] This network produces output loss5
I0726 09:51:09.386929 27891 net.cpp:242] This network produces output loss50
I0726 09:51:09.386934 27891 net.cpp:242] This network produces output loss51
I0726 09:51:09.386939 27891 net.cpp:242] This network produces output loss52
I0726 09:51:09.386943 27891 net.cpp:242] This network produces output loss53
I0726 09:51:09.386950 27891 net.cpp:242] This network produces output loss54
I0726 09:51:09.386955 27891 net.cpp:242] This network produces output loss55
I0726 09:51:09.386960 27891 net.cpp:242] This network produces output loss56
I0726 09:51:09.386965 27891 net.cpp:242] This network produces output loss57
I0726 09:51:09.386970 27891 net.cpp:242] This network produces output loss58
I0726 09:51:09.386975 27891 net.cpp:242] This network produces output loss59
I0726 09:51:09.386979 27891 net.cpp:242] This network produces output loss6
I0726 09:51:09.386984 27891 net.cpp:242] This network produces output loss60
I0726 09:51:09.386989 27891 net.cpp:242] This network produces output loss61
I0726 09:51:09.386994 27891 net.cpp:242] This network produces output loss62
I0726 09:51:09.386999 27891 net.cpp:242] This network produces output loss63
I0726 09:51:09.387004 27891 net.cpp:242] This network produces output loss64
I0726 09:51:09.387009 27891 net.cpp:242] This network produces output loss7
I0726 09:51:09.387022 27891 net.cpp:242] This network produces output loss8
I0726 09:51:09.387027 27891 net.cpp:242] This network produces output loss9
I0726 09:51:09.387248 27891 net.cpp:255] Network initialization done.
I0726 09:51:09.388473 27891 solver.cpp:173] Creating test net (#0) specified by net file: examples/crowd/code/shanghaiA/network_vgg_v1.prototxt
I0726 09:51:09.388566 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0726 09:51:09.388576 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0726 09:51:09.388614 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss1
I0726 09:51:09.388622 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss2
I0726 09:51:09.388626 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss3
I0726 09:51:09.388633 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss4
I0726 09:51:09.388638 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss5
I0726 09:51:09.388643 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss6
I0726 09:51:09.388648 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss7
I0726 09:51:09.388654 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss8
I0726 09:51:09.388659 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss9
I0726 09:51:09.388664 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss10
I0726 09:51:09.388670 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss11
I0726 09:51:09.388675 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss12
I0726 09:51:09.388681 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss13
I0726 09:51:09.388686 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss14
I0726 09:51:09.388692 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss15
I0726 09:51:09.388697 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss16
I0726 09:51:09.388703 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss17
I0726 09:51:09.388708 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss18
I0726 09:51:09.388715 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss19
I0726 09:51:09.388720 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss20
I0726 09:51:09.388725 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss21
I0726 09:51:09.388731 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss22
I0726 09:51:09.388736 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss23
I0726 09:51:09.388741 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss24
I0726 09:51:09.388747 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss25
I0726 09:51:09.388752 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss26
I0726 09:51:09.388758 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss27
I0726 09:51:09.388763 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss28
I0726 09:51:09.388782 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss29
I0726 09:51:09.388787 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss30
I0726 09:51:09.388792 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss31
I0726 09:51:09.388798 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss32
I0726 09:51:09.388803 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss33
I0726 09:51:09.388809 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss34
I0726 09:51:09.388814 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss35
I0726 09:51:09.388819 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss36
I0726 09:51:09.388825 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss37
I0726 09:51:09.388830 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss38
I0726 09:51:09.388836 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss39
I0726 09:51:09.388842 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss40
I0726 09:51:09.388847 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss41
I0726 09:51:09.388852 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss42
I0726 09:51:09.388859 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss43
I0726 09:51:09.388864 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss44
I0726 09:51:09.388870 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss45
I0726 09:51:09.388875 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss46
I0726 09:51:09.388880 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss47
I0726 09:51:09.388886 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss48
I0726 09:51:09.388891 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss49
I0726 09:51:09.388897 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss50
I0726 09:51:09.388902 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss51
I0726 09:51:09.388908 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss52
I0726 09:51:09.388913 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss53
I0726 09:51:09.388918 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss54
I0726 09:51:09.388924 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss55
I0726 09:51:09.388929 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss56
I0726 09:51:09.388936 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss57
I0726 09:51:09.388941 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss58
I0726 09:51:09.388947 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss59
I0726 09:51:09.388952 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss60
I0726 09:51:09.388963 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss61
I0726 09:51:09.388969 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss62
I0726 09:51:09.388975 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss63
I0726 09:51:09.388980 27891 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss64
I0726 09:51:09.389328 27891 net.cpp:51] Initializing net from parameters: 
name: "crowd_counting"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/image_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/dmap_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv_score"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv_score"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    group: 64
    stride: 1
    weight_filler {
      type: "constant"
      value: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_score"
  type: "ReLU"
  bottom: "conv_score"
  top: "conv_score"
}
layer {
  name: "slicer_conv"
  type: "Slice"
  bottom: "conv_score"
  top: "score1"
  top: "score2"
  top: "score3"
  top: "score4"
  top: "score5"
  top: "score6"
  top: "score7"
  top: "score8"
  top: "score9"
  top: "score10"
  top: "score11"
  top: "score12"
  top: "score13"
  top: "score14"
  top: "score15"
  top: "score16"
  top: "score17"
  top: "score18"
  top: "score19"
  top: "score20"
  top: "score21"
  top: "score22"
  top: "score23"
  top: "score24"
  top: "score25"
  top: "score26"
  top: "score27"
  top: "score28"
  top: "score29"
  top: "score30"
  top: "score31"
  top: "score32"
  top: "score33"
  top: "score34"
  top: "score35"
  top: "score36"
  top: "score37"
  top: "score38"
  top: "score39"
  top: "score40"
  top: "score41"
  top: "score42"
  top: "score43"
  top: "score44"
  top: "score45"
  top: "score46"
  top: "score47"
  top: "score48"
  top: "score49"
  top: "score50"
  top: "score51"
  top: "score52"
  top: "score53"
  top: "score54"
  top: "score55"
  top: "score56"
  top: "score57"
  top: "score58"
  top: "score59"
  top: "score60"
  top: "score61"
  top: "score62"
  top: "score63"
  top: "score64"
  slice_param {
    axis: 1
  }
}
layer {
  name: "sumscore"
  type: "Eltwise"
  bottom: "score1"
  bottom: "score2"
  bottom: "score3"
  bottom: "score4"
  bottom: "score5"
  bottom: "score6"
  bottom: "score7"
  bottom: "score8"
  bottom: "score9"
  bottom: "score10"
  bottom: "score11"
  bottom: "score12"
  bottom: "score13"
  bottom: "score14"
  bottom: "score15"
  bottom: "score16"
  bottom: "score17"
  bottom: "score18"
  bottom: "score19"
  bottom: "score20"
  bottom: "score21"
  bottom: "score22"
  bottom: "score23"
  bottom: "score24"
  bottom: "score25"
  bottom: "score26"
  bottom: "score27"
  bottom: "score28"
  bottom: "score29"
  bottom: "score30"
  bottom: "score31"
  bottom: "score32"
  bottom: "score33"
  bottom: "score34"
  bottom: "score35"
  bottom: "score36"
  bottom: "score37"
  bottom: "score38"
  bottom: "score39"
  bottom: "score40"
  bottom: "score41"
  bottom: "score42"
  bottom: "score43"
  bottom: "score44"
  bottom: "score45"
  bottom: "score46"
  bottom: "score47"
  bottom: "score48"
  bottom: "score49"
  bottom: "score50"
  bottom: "score51"
  bottom: "score52"
  bottom: "score53"
  bottom: "score54"
  bottom: "score55"
  bottom: "score56"
  bottom: "score57"
  bottom: "score58"
  bottom: "score59"
  bottom: "score60"
  bottom: "score61"
  bottom: "score62"
  bottom: "score63"
  bottom: "score64"
  top: "sumscore"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "avgscore"
  type: "Power"
  bottom: "sumscore"
  top: "avgscore"
  include {
    phase: TEST
  }
  power_param {
    power: 1
    scale: 0.015625
    shift: 0
  }
}
layer {
  name: "mae"
  type: "MAELoss"
  bottom: "avgscore"
  bottom: "label"
  top: "mae"
  include {
    phase: TEST
  }
}
layer {
  name: "mse"
  type: "MSELoss"
  bottom: "avgscore"
  bottom: "label"
  top: "mse"
  include {
    phase: TEST
  }
}
I0726 09:51:09.390111 27891 layer_factory.hpp:77] Creating layer data
I0726 09:51:09.390313 27891 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/image_lmdb
I0726 09:51:09.390353 27891 net.cpp:84] Creating Layer data
I0726 09:51:09.390363 27891 net.cpp:380] data -> data
I0726 09:51:09.392323 27891 data_layer.cpp:45] output data size: 1,3,704,1024
I0726 09:51:09.408244 27891 net.cpp:122] Setting up data
I0726 09:51:09.408274 27891 net.cpp:129] Top shape: 1 3 704 1024 (2162688)
I0726 09:51:09.408278 27891 net.cpp:137] Memory required for data: 8650752
I0726 09:51:09.408284 27891 layer_factory.hpp:77] Creating layer label
I0726 09:51:09.408555 27891 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/dmap_lmdb
I0726 09:51:09.408584 27891 net.cpp:84] Creating Layer label
I0726 09:51:09.408591 27891 net.cpp:380] label -> label
I0726 09:51:09.408764 27891 data_layer.cpp:45] output data size: 1,1,88,128
I0726 09:51:09.408910 27891 net.cpp:122] Setting up label
I0726 09:51:09.408921 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.408924 27891 net.cpp:137] Memory required for data: 8695808
I0726 09:51:09.408929 27891 layer_factory.hpp:77] Creating layer label_label_0_split
I0726 09:51:09.408936 27891 net.cpp:84] Creating Layer label_label_0_split
I0726 09:51:09.408941 27891 net.cpp:406] label_label_0_split <- label
I0726 09:51:09.408946 27891 net.cpp:380] label_label_0_split -> label_label_0_split_0
I0726 09:51:09.408953 27891 net.cpp:380] label_label_0_split -> label_label_0_split_1
I0726 09:51:09.409031 27891 net.cpp:122] Setting up label_label_0_split
I0726 09:51:09.409039 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.409044 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.409046 27891 net.cpp:137] Memory required for data: 8785920
I0726 09:51:09.409049 27891 layer_factory.hpp:77] Creating layer conv1_1
I0726 09:51:09.409061 27891 net.cpp:84] Creating Layer conv1_1
I0726 09:51:09.409065 27891 net.cpp:406] conv1_1 <- data
I0726 09:51:09.409071 27891 net.cpp:380] conv1_1 -> conv1_1
I0726 09:51:09.413002 27891 net.cpp:122] Setting up conv1_1
I0726 09:51:09.413022 27891 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0726 09:51:09.413028 27891 net.cpp:137] Memory required for data: 193335296
I0726 09:51:09.413038 27891 layer_factory.hpp:77] Creating layer relu1_1
I0726 09:51:09.413048 27891 net.cpp:84] Creating Layer relu1_1
I0726 09:51:09.413053 27891 net.cpp:406] relu1_1 <- conv1_1
I0726 09:51:09.413058 27891 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0726 09:51:09.413636 27891 net.cpp:122] Setting up relu1_1
I0726 09:51:09.413648 27891 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0726 09:51:09.413652 27891 net.cpp:137] Memory required for data: 377884672
I0726 09:51:09.413655 27891 layer_factory.hpp:77] Creating layer conv1_2
I0726 09:51:09.413667 27891 net.cpp:84] Creating Layer conv1_2
I0726 09:51:09.413671 27891 net.cpp:406] conv1_2 <- conv1_1
I0726 09:51:09.413677 27891 net.cpp:380] conv1_2 -> conv1_2
I0726 09:51:09.417376 27891 net.cpp:122] Setting up conv1_2
I0726 09:51:09.417394 27891 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0726 09:51:09.417398 27891 net.cpp:137] Memory required for data: 562434048
I0726 09:51:09.417408 27891 layer_factory.hpp:77] Creating layer relu1_2
I0726 09:51:09.417415 27891 net.cpp:84] Creating Layer relu1_2
I0726 09:51:09.417420 27891 net.cpp:406] relu1_2 <- conv1_2
I0726 09:51:09.417426 27891 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0726 09:51:09.418261 27891 net.cpp:122] Setting up relu1_2
I0726 09:51:09.418272 27891 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0726 09:51:09.418274 27891 net.cpp:137] Memory required for data: 746983424
I0726 09:51:09.418278 27891 layer_factory.hpp:77] Creating layer pool1
I0726 09:51:09.418284 27891 net.cpp:84] Creating Layer pool1
I0726 09:51:09.418287 27891 net.cpp:406] pool1 <- conv1_2
I0726 09:51:09.418293 27891 net.cpp:380] pool1 -> pool1
I0726 09:51:09.418350 27891 net.cpp:122] Setting up pool1
I0726 09:51:09.418357 27891 net.cpp:129] Top shape: 1 64 352 512 (11534336)
I0726 09:51:09.418360 27891 net.cpp:137] Memory required for data: 793120768
I0726 09:51:09.418364 27891 layer_factory.hpp:77] Creating layer conv2_1
I0726 09:51:09.418375 27891 net.cpp:84] Creating Layer conv2_1
I0726 09:51:09.418378 27891 net.cpp:406] conv2_1 <- pool1
I0726 09:51:09.418383 27891 net.cpp:380] conv2_1 -> conv2_1
I0726 09:51:09.421339 27891 net.cpp:122] Setting up conv2_1
I0726 09:51:09.421365 27891 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0726 09:51:09.421368 27891 net.cpp:137] Memory required for data: 885395456
I0726 09:51:09.421380 27891 layer_factory.hpp:77] Creating layer relu2_1
I0726 09:51:09.421386 27891 net.cpp:84] Creating Layer relu2_1
I0726 09:51:09.421391 27891 net.cpp:406] relu2_1 <- conv2_1
I0726 09:51:09.421396 27891 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0726 09:51:09.421964 27891 net.cpp:122] Setting up relu2_1
I0726 09:51:09.422010 27891 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0726 09:51:09.422014 27891 net.cpp:137] Memory required for data: 977670144
I0726 09:51:09.422019 27891 layer_factory.hpp:77] Creating layer conv2_2
I0726 09:51:09.422029 27891 net.cpp:84] Creating Layer conv2_2
I0726 09:51:09.422032 27891 net.cpp:406] conv2_2 <- conv2_1
I0726 09:51:09.422039 27891 net.cpp:380] conv2_2 -> conv2_2
I0726 09:51:09.425825 27891 net.cpp:122] Setting up conv2_2
I0726 09:51:09.425843 27891 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0726 09:51:09.425848 27891 net.cpp:137] Memory required for data: 1069944832
I0726 09:51:09.425854 27891 layer_factory.hpp:77] Creating layer relu2_2
I0726 09:51:09.425861 27891 net.cpp:84] Creating Layer relu2_2
I0726 09:51:09.425865 27891 net.cpp:406] relu2_2 <- conv2_2
I0726 09:51:09.425871 27891 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0726 09:51:09.427155 27891 net.cpp:122] Setting up relu2_2
I0726 09:51:09.427170 27891 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0726 09:51:09.427173 27891 net.cpp:137] Memory required for data: 1162219520
I0726 09:51:09.427176 27891 layer_factory.hpp:77] Creating layer pool2
I0726 09:51:09.427184 27891 net.cpp:84] Creating Layer pool2
I0726 09:51:09.427188 27891 net.cpp:406] pool2 <- conv2_2
I0726 09:51:09.427194 27891 net.cpp:380] pool2 -> pool2
I0726 09:51:09.427254 27891 net.cpp:122] Setting up pool2
I0726 09:51:09.427261 27891 net.cpp:129] Top shape: 1 128 176 256 (5767168)
I0726 09:51:09.427265 27891 net.cpp:137] Memory required for data: 1185288192
I0726 09:51:09.427268 27891 layer_factory.hpp:77] Creating layer conv3_1
I0726 09:51:09.427278 27891 net.cpp:84] Creating Layer conv3_1
I0726 09:51:09.427283 27891 net.cpp:406] conv3_1 <- pool2
I0726 09:51:09.427287 27891 net.cpp:380] conv3_1 -> conv3_1
I0726 09:51:09.431900 27891 net.cpp:122] Setting up conv3_1
I0726 09:51:09.431912 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.431916 27891 net.cpp:137] Memory required for data: 1231425536
I0726 09:51:09.431926 27891 layer_factory.hpp:77] Creating layer relu3_1
I0726 09:51:09.431931 27891 net.cpp:84] Creating Layer relu3_1
I0726 09:51:09.431936 27891 net.cpp:406] relu3_1 <- conv3_1
I0726 09:51:09.431941 27891 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0726 09:51:09.432101 27891 net.cpp:122] Setting up relu3_1
I0726 09:51:09.432109 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.432112 27891 net.cpp:137] Memory required for data: 1277562880
I0726 09:51:09.432116 27891 layer_factory.hpp:77] Creating layer conv3_2
I0726 09:51:09.432124 27891 net.cpp:84] Creating Layer conv3_2
I0726 09:51:09.432128 27891 net.cpp:406] conv3_2 <- conv3_1
I0726 09:51:09.432133 27891 net.cpp:380] conv3_2 -> conv3_2
I0726 09:51:09.439252 27891 net.cpp:122] Setting up conv3_2
I0726 09:51:09.439268 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.439271 27891 net.cpp:137] Memory required for data: 1323700224
I0726 09:51:09.439277 27891 layer_factory.hpp:77] Creating layer relu3_2
I0726 09:51:09.439285 27891 net.cpp:84] Creating Layer relu3_2
I0726 09:51:09.439288 27891 net.cpp:406] relu3_2 <- conv3_2
I0726 09:51:09.439294 27891 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0726 09:51:09.439836 27891 net.cpp:122] Setting up relu3_2
I0726 09:51:09.439847 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.439851 27891 net.cpp:137] Memory required for data: 1369837568
I0726 09:51:09.439855 27891 layer_factory.hpp:77] Creating layer conv3_3
I0726 09:51:09.439864 27891 net.cpp:84] Creating Layer conv3_3
I0726 09:51:09.439868 27891 net.cpp:406] conv3_3 <- conv3_2
I0726 09:51:09.439874 27891 net.cpp:380] conv3_3 -> conv3_3
I0726 09:51:09.446880 27891 net.cpp:122] Setting up conv3_3
I0726 09:51:09.446893 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.446897 27891 net.cpp:137] Memory required for data: 1415974912
I0726 09:51:09.446903 27891 layer_factory.hpp:77] Creating layer relu3_3
I0726 09:51:09.446909 27891 net.cpp:84] Creating Layer relu3_3
I0726 09:51:09.446935 27891 net.cpp:406] relu3_3 <- conv3_3
I0726 09:51:09.446940 27891 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0726 09:51:09.447485 27891 net.cpp:122] Setting up relu3_3
I0726 09:51:09.447496 27891 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0726 09:51:09.447499 27891 net.cpp:137] Memory required for data: 1462112256
I0726 09:51:09.447502 27891 layer_factory.hpp:77] Creating layer pool3
I0726 09:51:09.447507 27891 net.cpp:84] Creating Layer pool3
I0726 09:51:09.447511 27891 net.cpp:406] pool3 <- conv3_3
I0726 09:51:09.447516 27891 net.cpp:380] pool3 -> pool3
I0726 09:51:09.447571 27891 net.cpp:122] Setting up pool3
I0726 09:51:09.447577 27891 net.cpp:129] Top shape: 1 256 88 128 (2883584)
I0726 09:51:09.447580 27891 net.cpp:137] Memory required for data: 1473646592
I0726 09:51:09.447583 27891 layer_factory.hpp:77] Creating layer conv4_1
I0726 09:51:09.447592 27891 net.cpp:84] Creating Layer conv4_1
I0726 09:51:09.447595 27891 net.cpp:406] conv4_1 <- pool3
I0726 09:51:09.447602 27891 net.cpp:380] conv4_1 -> conv4_1
I0726 09:51:09.459626 27891 net.cpp:122] Setting up conv4_1
I0726 09:51:09.459642 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.459645 27891 net.cpp:137] Memory required for data: 1496715264
I0726 09:51:09.459651 27891 layer_factory.hpp:77] Creating layer relu4_1
I0726 09:51:09.459657 27891 net.cpp:84] Creating Layer relu4_1
I0726 09:51:09.459661 27891 net.cpp:406] relu4_1 <- conv4_1
I0726 09:51:09.459666 27891 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0726 09:51:09.459831 27891 net.cpp:122] Setting up relu4_1
I0726 09:51:09.459841 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.459843 27891 net.cpp:137] Memory required for data: 1519783936
I0726 09:51:09.459847 27891 layer_factory.hpp:77] Creating layer conv4_2
I0726 09:51:09.459856 27891 net.cpp:84] Creating Layer conv4_2
I0726 09:51:09.459859 27891 net.cpp:406] conv4_2 <- conv4_1
I0726 09:51:09.459866 27891 net.cpp:380] conv4_2 -> conv4_2
I0726 09:51:09.482276 27891 net.cpp:122] Setting up conv4_2
I0726 09:51:09.482302 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.482306 27891 net.cpp:137] Memory required for data: 1542852608
I0726 09:51:09.482316 27891 layer_factory.hpp:77] Creating layer relu4_2
I0726 09:51:09.482326 27891 net.cpp:84] Creating Layer relu4_2
I0726 09:51:09.482331 27891 net.cpp:406] relu4_2 <- conv4_2
I0726 09:51:09.482336 27891 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0726 09:51:09.482892 27891 net.cpp:122] Setting up relu4_2
I0726 09:51:09.482903 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.482904 27891 net.cpp:137] Memory required for data: 1565921280
I0726 09:51:09.482908 27891 layer_factory.hpp:77] Creating layer conv4_3
I0726 09:51:09.482915 27891 net.cpp:84] Creating Layer conv4_3
I0726 09:51:09.482920 27891 net.cpp:406] conv4_3 <- conv4_2
I0726 09:51:09.482926 27891 net.cpp:380] conv4_3 -> conv4_3
I0726 09:51:09.508502 27891 net.cpp:122] Setting up conv4_3
I0726 09:51:09.508527 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.508532 27891 net.cpp:137] Memory required for data: 1588989952
I0726 09:51:09.508540 27891 layer_factory.hpp:77] Creating layer relu4_3
I0726 09:51:09.508549 27891 net.cpp:84] Creating Layer relu4_3
I0726 09:51:09.508553 27891 net.cpp:406] relu4_3 <- conv4_3
I0726 09:51:09.508559 27891 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0726 09:51:09.509112 27891 net.cpp:122] Setting up relu4_3
I0726 09:51:09.509124 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.509127 27891 net.cpp:137] Memory required for data: 1612058624
I0726 09:51:09.509131 27891 layer_factory.hpp:77] Creating layer pool4
I0726 09:51:09.509138 27891 net.cpp:84] Creating Layer pool4
I0726 09:51:09.509142 27891 net.cpp:406] pool4 <- conv4_3
I0726 09:51:09.509147 27891 net.cpp:380] pool4 -> pool4
I0726 09:51:09.509204 27891 net.cpp:122] Setting up pool4
I0726 09:51:09.509212 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.509214 27891 net.cpp:137] Memory required for data: 1635127296
I0726 09:51:09.509250 27891 layer_factory.hpp:77] Creating layer conv5_1
I0726 09:51:09.509261 27891 net.cpp:84] Creating Layer conv5_1
I0726 09:51:09.509264 27891 net.cpp:406] conv5_1 <- pool4
I0726 09:51:09.509270 27891 net.cpp:380] conv5_1 -> conv5_1
I0726 09:51:09.535538 27891 net.cpp:122] Setting up conv5_1
I0726 09:51:09.535568 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.535574 27891 net.cpp:137] Memory required for data: 1658195968
I0726 09:51:09.535586 27891 layer_factory.hpp:77] Creating layer relu5_1
I0726 09:51:09.535598 27891 net.cpp:84] Creating Layer relu5_1
I0726 09:51:09.535606 27891 net.cpp:406] relu5_1 <- conv5_1
I0726 09:51:09.535617 27891 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0726 09:51:09.535871 27891 net.cpp:122] Setting up relu5_1
I0726 09:51:09.535883 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.535889 27891 net.cpp:137] Memory required for data: 1681264640
I0726 09:51:09.535895 27891 layer_factory.hpp:77] Creating layer conv5_2
I0726 09:51:09.535909 27891 net.cpp:84] Creating Layer conv5_2
I0726 09:51:09.535917 27891 net.cpp:406] conv5_2 <- conv5_1
I0726 09:51:09.535928 27891 net.cpp:380] conv5_2 -> conv5_2
I0726 09:51:09.564518 27891 net.cpp:122] Setting up conv5_2
I0726 09:51:09.564553 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.564560 27891 net.cpp:137] Memory required for data: 1704333312
I0726 09:51:09.564573 27891 layer_factory.hpp:77] Creating layer relu5_2
I0726 09:51:09.564584 27891 net.cpp:84] Creating Layer relu5_2
I0726 09:51:09.564591 27891 net.cpp:406] relu5_2 <- conv5_2
I0726 09:51:09.564600 27891 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0726 09:51:09.565446 27891 net.cpp:122] Setting up relu5_2
I0726 09:51:09.565462 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.565467 27891 net.cpp:137] Memory required for data: 1727401984
I0726 09:51:09.565474 27891 layer_factory.hpp:77] Creating layer conv5_3
I0726 09:51:09.565487 27891 net.cpp:84] Creating Layer conv5_3
I0726 09:51:09.565493 27891 net.cpp:406] conv5_3 <- conv5_2
I0726 09:51:09.565502 27891 net.cpp:380] conv5_3 -> conv5_3
I0726 09:51:09.594480 27891 net.cpp:122] Setting up conv5_3
I0726 09:51:09.594513 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.594519 27891 net.cpp:137] Memory required for data: 1750470656
I0726 09:51:09.594530 27891 layer_factory.hpp:77] Creating layer relu5_3
I0726 09:51:09.594547 27891 net.cpp:84] Creating Layer relu5_3
I0726 09:51:09.594552 27891 net.cpp:406] relu5_3 <- conv5_3
I0726 09:51:09.594561 27891 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0726 09:51:09.594823 27891 net.cpp:122] Setting up relu5_3
I0726 09:51:09.594836 27891 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0726 09:51:09.594841 27891 net.cpp:137] Memory required for data: 1773539328
I0726 09:51:09.594846 27891 layer_factory.hpp:77] Creating layer conv_score
I0726 09:51:09.594861 27891 net.cpp:84] Creating Layer conv_score
I0726 09:51:09.594866 27891 net.cpp:406] conv_score <- conv5_3
I0726 09:51:09.594874 27891 net.cpp:380] conv_score -> conv_score
I0726 09:51:09.680233 27891 net.cpp:122] Setting up conv_score
I0726 09:51:09.680260 27891 net.cpp:129] Top shape: 1 64 88 128 (720896)
I0726 09:51:09.680266 27891 net.cpp:137] Memory required for data: 1776422912
I0726 09:51:09.680279 27891 layer_factory.hpp:77] Creating layer relu_score
I0726 09:51:09.680292 27891 net.cpp:84] Creating Layer relu_score
I0726 09:51:09.680299 27891 net.cpp:406] relu_score <- conv_score
I0726 09:51:09.680306 27891 net.cpp:367] relu_score -> conv_score (in-place)
I0726 09:51:09.680496 27891 net.cpp:122] Setting up relu_score
I0726 09:51:09.680506 27891 net.cpp:129] Top shape: 1 64 88 128 (720896)
I0726 09:51:09.680511 27891 net.cpp:137] Memory required for data: 1779306496
I0726 09:51:09.680517 27891 layer_factory.hpp:77] Creating layer slicer_conv
I0726 09:51:09.680533 27891 net.cpp:84] Creating Layer slicer_conv
I0726 09:51:09.680537 27891 net.cpp:406] slicer_conv <- conv_score
I0726 09:51:09.680550 27891 net.cpp:380] slicer_conv -> score1
I0726 09:51:09.680591 27891 net.cpp:380] slicer_conv -> score2
I0726 09:51:09.680608 27891 net.cpp:380] slicer_conv -> score3
I0726 09:51:09.680622 27891 net.cpp:380] slicer_conv -> score4
I0726 09:51:09.680637 27891 net.cpp:380] slicer_conv -> score5
I0726 09:51:09.680651 27891 net.cpp:380] slicer_conv -> score6
I0726 09:51:09.680665 27891 net.cpp:380] slicer_conv -> score7
I0726 09:51:09.680680 27891 net.cpp:380] slicer_conv -> score8
I0726 09:51:09.680694 27891 net.cpp:380] slicer_conv -> score9
I0726 09:51:09.680708 27891 net.cpp:380] slicer_conv -> score10
I0726 09:51:09.680722 27891 net.cpp:380] slicer_conv -> score11
I0726 09:51:09.680743 27891 net.cpp:380] slicer_conv -> score12
I0726 09:51:09.680757 27891 net.cpp:380] slicer_conv -> score13
I0726 09:51:09.680770 27891 net.cpp:380] slicer_conv -> score14
I0726 09:51:09.680783 27891 net.cpp:380] slicer_conv -> score15
I0726 09:51:09.680797 27891 net.cpp:380] slicer_conv -> score16
I0726 09:51:09.680811 27891 net.cpp:380] slicer_conv -> score17
I0726 09:51:09.680825 27891 net.cpp:380] slicer_conv -> score18
I0726 09:51:09.680838 27891 net.cpp:380] slicer_conv -> score19
I0726 09:51:09.680852 27891 net.cpp:380] slicer_conv -> score20
I0726 09:51:09.680866 27891 net.cpp:380] slicer_conv -> score21
I0726 09:51:09.680882 27891 net.cpp:380] slicer_conv -> score22
I0726 09:51:09.680896 27891 net.cpp:380] slicer_conv -> score23
I0726 09:51:09.680909 27891 net.cpp:380] slicer_conv -> score24
I0726 09:51:09.680923 27891 net.cpp:380] slicer_conv -> score25
I0726 09:51:09.680936 27891 net.cpp:380] slicer_conv -> score26
I0726 09:51:09.680949 27891 net.cpp:380] slicer_conv -> score27
I0726 09:51:09.680963 27891 net.cpp:380] slicer_conv -> score28
I0726 09:51:09.680976 27891 net.cpp:380] slicer_conv -> score29
I0726 09:51:09.680991 27891 net.cpp:380] slicer_conv -> score30
I0726 09:51:09.681006 27891 net.cpp:380] slicer_conv -> score31
I0726 09:51:09.681020 27891 net.cpp:380] slicer_conv -> score32
I0726 09:51:09.681033 27891 net.cpp:380] slicer_conv -> score33
I0726 09:51:09.681049 27891 net.cpp:380] slicer_conv -> score34
I0726 09:51:09.681063 27891 net.cpp:380] slicer_conv -> score35
I0726 09:51:09.681077 27891 net.cpp:380] slicer_conv -> score36
I0726 09:51:09.681090 27891 net.cpp:380] slicer_conv -> score37
I0726 09:51:09.681103 27891 net.cpp:380] slicer_conv -> score38
I0726 09:51:09.681118 27891 net.cpp:380] slicer_conv -> score39
I0726 09:51:09.681130 27891 net.cpp:380] slicer_conv -> score40
I0726 09:51:09.681144 27891 net.cpp:380] slicer_conv -> score41
I0726 09:51:09.681157 27891 net.cpp:380] slicer_conv -> score42
I0726 09:51:09.681172 27891 net.cpp:380] slicer_conv -> score43
I0726 09:51:09.681193 27891 net.cpp:380] slicer_conv -> score44
I0726 09:51:09.681207 27891 net.cpp:380] slicer_conv -> score45
I0726 09:51:09.681221 27891 net.cpp:380] slicer_conv -> score46
I0726 09:51:09.681234 27891 net.cpp:380] slicer_conv -> score47
I0726 09:51:09.681248 27891 net.cpp:380] slicer_conv -> score48
I0726 09:51:09.681262 27891 net.cpp:380] slicer_conv -> score49
I0726 09:51:09.681275 27891 net.cpp:380] slicer_conv -> score50
I0726 09:51:09.681288 27891 net.cpp:380] slicer_conv -> score51
I0726 09:51:09.681306 27891 net.cpp:380] slicer_conv -> score52
I0726 09:51:09.681322 27891 net.cpp:380] slicer_conv -> score53
I0726 09:51:09.681336 27891 net.cpp:380] slicer_conv -> score54
I0726 09:51:09.681350 27891 net.cpp:380] slicer_conv -> score55
I0726 09:51:09.681363 27891 net.cpp:380] slicer_conv -> score56
I0726 09:51:09.681376 27891 net.cpp:380] slicer_conv -> score57
I0726 09:51:09.681391 27891 net.cpp:380] slicer_conv -> score58
I0726 09:51:09.681404 27891 net.cpp:380] slicer_conv -> score59
I0726 09:51:09.681417 27891 net.cpp:380] slicer_conv -> score60
I0726 09:51:09.681433 27891 net.cpp:380] slicer_conv -> score61
I0726 09:51:09.681447 27891 net.cpp:380] slicer_conv -> score62
I0726 09:51:09.681462 27891 net.cpp:380] slicer_conv -> score63
I0726 09:51:09.681474 27891 net.cpp:380] slicer_conv -> score64
I0726 09:51:09.682940 27891 net.cpp:122] Setting up slicer_conv
I0726 09:51:09.682982 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.682992 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.682999 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683006 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683012 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683018 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683024 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683030 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683037 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683043 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683050 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683056 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683063 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683069 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683075 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683081 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683087 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683094 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683100 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683106 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683112 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683120 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683125 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683131 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683138 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683145 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683151 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683156 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683162 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683169 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683176 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683182 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683187 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683193 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683200 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683207 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683212 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683218 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683225 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683231 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683238 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683243 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683250 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683256 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683262 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683269 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683275 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683281 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683287 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683293 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683300 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683306 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683312 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683318 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683324 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683331 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683337 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683343 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683358 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683363 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683367 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683372 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683377 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683380 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683384 27891 net.cpp:137] Memory required for data: 1782190080
I0726 09:51:09.683388 27891 layer_factory.hpp:77] Creating layer sumscore
I0726 09:51:09.683400 27891 net.cpp:84] Creating Layer sumscore
I0726 09:51:09.683405 27891 net.cpp:406] sumscore <- score1
I0726 09:51:09.683410 27891 net.cpp:406] sumscore <- score2
I0726 09:51:09.683414 27891 net.cpp:406] sumscore <- score3
I0726 09:51:09.683418 27891 net.cpp:406] sumscore <- score4
I0726 09:51:09.683421 27891 net.cpp:406] sumscore <- score5
I0726 09:51:09.683425 27891 net.cpp:406] sumscore <- score6
I0726 09:51:09.683429 27891 net.cpp:406] sumscore <- score7
I0726 09:51:09.683432 27891 net.cpp:406] sumscore <- score8
I0726 09:51:09.683435 27891 net.cpp:406] sumscore <- score9
I0726 09:51:09.683439 27891 net.cpp:406] sumscore <- score10
I0726 09:51:09.683444 27891 net.cpp:406] sumscore <- score11
I0726 09:51:09.683447 27891 net.cpp:406] sumscore <- score12
I0726 09:51:09.683450 27891 net.cpp:406] sumscore <- score13
I0726 09:51:09.683454 27891 net.cpp:406] sumscore <- score14
I0726 09:51:09.683457 27891 net.cpp:406] sumscore <- score15
I0726 09:51:09.683460 27891 net.cpp:406] sumscore <- score16
I0726 09:51:09.683465 27891 net.cpp:406] sumscore <- score17
I0726 09:51:09.683467 27891 net.cpp:406] sumscore <- score18
I0726 09:51:09.683471 27891 net.cpp:406] sumscore <- score19
I0726 09:51:09.683475 27891 net.cpp:406] sumscore <- score20
I0726 09:51:09.683478 27891 net.cpp:406] sumscore <- score21
I0726 09:51:09.683481 27891 net.cpp:406] sumscore <- score22
I0726 09:51:09.683485 27891 net.cpp:406] sumscore <- score23
I0726 09:51:09.683488 27891 net.cpp:406] sumscore <- score24
I0726 09:51:09.683492 27891 net.cpp:406] sumscore <- score25
I0726 09:51:09.683495 27891 net.cpp:406] sumscore <- score26
I0726 09:51:09.683498 27891 net.cpp:406] sumscore <- score27
I0726 09:51:09.683502 27891 net.cpp:406] sumscore <- score28
I0726 09:51:09.683506 27891 net.cpp:406] sumscore <- score29
I0726 09:51:09.683509 27891 net.cpp:406] sumscore <- score30
I0726 09:51:09.683512 27891 net.cpp:406] sumscore <- score31
I0726 09:51:09.683516 27891 net.cpp:406] sumscore <- score32
I0726 09:51:09.683518 27891 net.cpp:406] sumscore <- score33
I0726 09:51:09.683523 27891 net.cpp:406] sumscore <- score34
I0726 09:51:09.683527 27891 net.cpp:406] sumscore <- score35
I0726 09:51:09.683531 27891 net.cpp:406] sumscore <- score36
I0726 09:51:09.683533 27891 net.cpp:406] sumscore <- score37
I0726 09:51:09.683537 27891 net.cpp:406] sumscore <- score38
I0726 09:51:09.683540 27891 net.cpp:406] sumscore <- score39
I0726 09:51:09.683544 27891 net.cpp:406] sumscore <- score40
I0726 09:51:09.683547 27891 net.cpp:406] sumscore <- score41
I0726 09:51:09.683552 27891 net.cpp:406] sumscore <- score42
I0726 09:51:09.683554 27891 net.cpp:406] sumscore <- score43
I0726 09:51:09.683558 27891 net.cpp:406] sumscore <- score44
I0726 09:51:09.683562 27891 net.cpp:406] sumscore <- score45
I0726 09:51:09.683564 27891 net.cpp:406] sumscore <- score46
I0726 09:51:09.683568 27891 net.cpp:406] sumscore <- score47
I0726 09:51:09.683571 27891 net.cpp:406] sumscore <- score48
I0726 09:51:09.683575 27891 net.cpp:406] sumscore <- score49
I0726 09:51:09.683578 27891 net.cpp:406] sumscore <- score50
I0726 09:51:09.683583 27891 net.cpp:406] sumscore <- score51
I0726 09:51:09.683585 27891 net.cpp:406] sumscore <- score52
I0726 09:51:09.683589 27891 net.cpp:406] sumscore <- score53
I0726 09:51:09.683593 27891 net.cpp:406] sumscore <- score54
I0726 09:51:09.683596 27891 net.cpp:406] sumscore <- score55
I0726 09:51:09.683599 27891 net.cpp:406] sumscore <- score56
I0726 09:51:09.683609 27891 net.cpp:406] sumscore <- score57
I0726 09:51:09.683612 27891 net.cpp:406] sumscore <- score58
I0726 09:51:09.683616 27891 net.cpp:406] sumscore <- score59
I0726 09:51:09.683619 27891 net.cpp:406] sumscore <- score60
I0726 09:51:09.683624 27891 net.cpp:406] sumscore <- score61
I0726 09:51:09.683626 27891 net.cpp:406] sumscore <- score62
I0726 09:51:09.683629 27891 net.cpp:406] sumscore <- score63
I0726 09:51:09.683634 27891 net.cpp:406] sumscore <- score64
I0726 09:51:09.683640 27891 net.cpp:380] sumscore -> sumscore
I0726 09:51:09.683689 27891 net.cpp:122] Setting up sumscore
I0726 09:51:09.683696 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683699 27891 net.cpp:137] Memory required for data: 1782235136
I0726 09:51:09.683703 27891 layer_factory.hpp:77] Creating layer avgscore
I0726 09:51:09.683709 27891 net.cpp:84] Creating Layer avgscore
I0726 09:51:09.683712 27891 net.cpp:406] avgscore <- sumscore
I0726 09:51:09.683718 27891 net.cpp:380] avgscore -> avgscore
I0726 09:51:09.683758 27891 net.cpp:122] Setting up avgscore
I0726 09:51:09.683765 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683768 27891 net.cpp:137] Memory required for data: 1782280192
I0726 09:51:09.683773 27891 layer_factory.hpp:77] Creating layer avgscore_avgscore_0_split
I0726 09:51:09.683778 27891 net.cpp:84] Creating Layer avgscore_avgscore_0_split
I0726 09:51:09.683780 27891 net.cpp:406] avgscore_avgscore_0_split <- avgscore
I0726 09:51:09.683785 27891 net.cpp:380] avgscore_avgscore_0_split -> avgscore_avgscore_0_split_0
I0726 09:51:09.683791 27891 net.cpp:380] avgscore_avgscore_0_split -> avgscore_avgscore_0_split_1
I0726 09:51:09.683851 27891 net.cpp:122] Setting up avgscore_avgscore_0_split
I0726 09:51:09.683856 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683861 27891 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0726 09:51:09.683863 27891 net.cpp:137] Memory required for data: 1782370304
I0726 09:51:09.683866 27891 layer_factory.hpp:77] Creating layer mae
I0726 09:51:09.683872 27891 net.cpp:84] Creating Layer mae
I0726 09:51:09.683876 27891 net.cpp:406] mae <- avgscore_avgscore_0_split_0
I0726 09:51:09.683879 27891 net.cpp:406] mae <- label_label_0_split_0
I0726 09:51:09.683884 27891 net.cpp:380] mae -> mae
I0726 09:51:09.683944 27891 net.cpp:122] Setting up mae
I0726 09:51:09.683951 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.683954 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.683964 27891 net.cpp:137] Memory required for data: 1782370308
I0726 09:51:09.683967 27891 layer_factory.hpp:77] Creating layer mse
I0726 09:51:09.683972 27891 net.cpp:84] Creating Layer mse
I0726 09:51:09.683976 27891 net.cpp:406] mse <- avgscore_avgscore_0_split_1
I0726 09:51:09.683980 27891 net.cpp:406] mse <- label_label_0_split_1
I0726 09:51:09.683986 27891 net.cpp:380] mse -> mse
I0726 09:51:09.684047 27891 net.cpp:122] Setting up mse
I0726 09:51:09.684053 27891 net.cpp:129] Top shape: (1)
I0726 09:51:09.684057 27891 net.cpp:132]     with loss weight 1
I0726 09:51:09.684062 27891 net.cpp:137] Memory required for data: 1782370312
I0726 09:51:09.684065 27891 net.cpp:198] mse needs backward computation.
I0726 09:51:09.684069 27891 net.cpp:198] mae needs backward computation.
I0726 09:51:09.684073 27891 net.cpp:198] avgscore_avgscore_0_split needs backward computation.
I0726 09:51:09.684077 27891 net.cpp:198] avgscore needs backward computation.
I0726 09:51:09.684080 27891 net.cpp:198] sumscore needs backward computation.
I0726 09:51:09.684094 27891 net.cpp:198] slicer_conv needs backward computation.
I0726 09:51:09.684098 27891 net.cpp:198] relu_score needs backward computation.
I0726 09:51:09.684103 27891 net.cpp:198] conv_score needs backward computation.
I0726 09:51:09.684105 27891 net.cpp:198] relu5_3 needs backward computation.
I0726 09:51:09.684109 27891 net.cpp:198] conv5_3 needs backward computation.
I0726 09:51:09.684113 27891 net.cpp:198] relu5_2 needs backward computation.
I0726 09:51:09.684116 27891 net.cpp:198] conv5_2 needs backward computation.
I0726 09:51:09.684128 27891 net.cpp:198] relu5_1 needs backward computation.
I0726 09:51:09.684132 27891 net.cpp:198] conv5_1 needs backward computation.
I0726 09:51:09.684135 27891 net.cpp:198] pool4 needs backward computation.
I0726 09:51:09.684139 27891 net.cpp:198] relu4_3 needs backward computation.
I0726 09:51:09.684142 27891 net.cpp:198] conv4_3 needs backward computation.
I0726 09:51:09.684145 27891 net.cpp:198] relu4_2 needs backward computation.
I0726 09:51:09.684149 27891 net.cpp:198] conv4_2 needs backward computation.
I0726 09:51:09.684152 27891 net.cpp:198] relu4_1 needs backward computation.
I0726 09:51:09.684156 27891 net.cpp:198] conv4_1 needs backward computation.
I0726 09:51:09.684159 27891 net.cpp:198] pool3 needs backward computation.
I0726 09:51:09.684164 27891 net.cpp:198] relu3_3 needs backward computation.
I0726 09:51:09.684166 27891 net.cpp:198] conv3_3 needs backward computation.
I0726 09:51:09.684170 27891 net.cpp:198] relu3_2 needs backward computation.
I0726 09:51:09.684173 27891 net.cpp:198] conv3_2 needs backward computation.
I0726 09:51:09.684176 27891 net.cpp:198] relu3_1 needs backward computation.
I0726 09:51:09.684180 27891 net.cpp:198] conv3_1 needs backward computation.
I0726 09:51:09.684183 27891 net.cpp:198] pool2 needs backward computation.
I0726 09:51:09.684187 27891 net.cpp:198] relu2_2 needs backward computation.
I0726 09:51:09.684190 27891 net.cpp:198] conv2_2 needs backward computation.
I0726 09:51:09.684193 27891 net.cpp:198] relu2_1 needs backward computation.
I0726 09:51:09.684197 27891 net.cpp:198] conv2_1 needs backward computation.
I0726 09:51:09.684201 27891 net.cpp:198] pool1 needs backward computation.
I0726 09:51:09.684204 27891 net.cpp:198] relu1_2 needs backward computation.
I0726 09:51:09.684207 27891 net.cpp:198] conv1_2 needs backward computation.
I0726 09:51:09.684211 27891 net.cpp:198] relu1_1 needs backward computation.
I0726 09:51:09.684216 27891 net.cpp:198] conv1_1 needs backward computation.
I0726 09:51:09.684218 27891 net.cpp:200] label_label_0_split does not need backward computation.
I0726 09:51:09.684223 27891 net.cpp:200] label does not need backward computation.
I0726 09:51:09.684227 27891 net.cpp:200] data does not need backward computation.
I0726 09:51:09.684231 27891 net.cpp:242] This network produces output mae
I0726 09:51:09.684234 27891 net.cpp:242] This network produces output mse
I0726 09:51:09.684262 27891 net.cpp:255] Network initialization done.
I0726 09:51:09.684475 27891 solver.cpp:56] Solver scaffolding done.
I0726 09:51:09.686414 27891 caffe.cpp:155] Finetuning from ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0726 09:51:11.039357 27891 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0726 09:51:12.317325 27891 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0726 09:51:12.319654 27891 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0726 09:51:12.319676 27891 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0726 09:51:12.319685 27891 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0726 09:51:12.555284 27891 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0726 09:51:12.849634 27891 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0726 09:51:12.850733 27891 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0726 09:51:12.850746 27891 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0726 09:51:12.850754 27891 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0726 09:51:12.864681 27891 caffe.cpp:248] Starting Optimization
I0726 09:51:12.864704 27891 solver.cpp:273] Solving crowd_counting
I0726 09:51:12.864709 27891 solver.cpp:274] Learning Rate Policy: step
I0726 09:51:12.869637 27891 solver.cpp:331] Iteration 0, Testing net (#0)
I0726 09:51:26.728677 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 09:51:26.729823 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 09:51:27.141075 27891 solver.cpp:398]     Test net output #0: mae = 427.436 (* 1 = 427.436 loss)
I0726 09:51:27.141103 27891 solver.cpp:398]     Test net output #1: mse = 308720 (* 1 = 308720 loss)
I0726 09:51:27.275048 27891 solver.cpp:219] Iteration 0 (-1.30515e+30 iter/s, 14.41s/5400 iters), loss = 60820
I0726 09:51:27.275105 27891 solver.cpp:238]     Train net output #0: loss1 = 950.468 (* 1 = 950.468 loss)
I0726 09:51:27.275118 27891 solver.cpp:238]     Train net output #1: loss10 = 950.57 (* 1 = 950.57 loss)
I0726 09:51:27.275128 27891 solver.cpp:238]     Train net output #2: loss11 = 950.455 (* 1 = 950.455 loss)
I0726 09:51:27.275137 27891 solver.cpp:238]     Train net output #3: loss12 = 950.492 (* 1 = 950.492 loss)
I0726 09:51:27.275146 27891 solver.cpp:238]     Train net output #4: loss13 = 950.589 (* 1 = 950.589 loss)
I0726 09:51:27.275154 27891 solver.cpp:238]     Train net output #5: loss14 = 950.321 (* 1 = 950.321 loss)
I0726 09:51:27.275163 27891 solver.cpp:238]     Train net output #6: loss15 = 950.223 (* 1 = 950.223 loss)
I0726 09:51:27.275172 27891 solver.cpp:238]     Train net output #7: loss16 = 950.53 (* 1 = 950.53 loss)
I0726 09:51:27.275182 27891 solver.cpp:238]     Train net output #8: loss17 = 950.202 (* 1 = 950.202 loss)
I0726 09:51:27.275190 27891 solver.cpp:238]     Train net output #9: loss18 = 950.182 (* 1 = 950.182 loss)
I0726 09:51:27.275199 27891 solver.cpp:238]     Train net output #10: loss19 = 950.552 (* 1 = 950.552 loss)
I0726 09:51:27.275208 27891 solver.cpp:238]     Train net output #11: loss2 = 950.328 (* 1 = 950.328 loss)
I0726 09:51:27.275216 27891 solver.cpp:238]     Train net output #12: loss20 = 950.077 (* 1 = 950.077 loss)
I0726 09:51:27.275225 27891 solver.cpp:238]     Train net output #13: loss21 = 950.318 (* 1 = 950.318 loss)
I0726 09:51:27.275234 27891 solver.cpp:238]     Train net output #14: loss22 = 949.539 (* 1 = 949.539 loss)
I0726 09:51:27.275243 27891 solver.cpp:238]     Train net output #15: loss23 = 950.395 (* 1 = 950.395 loss)
I0726 09:51:27.275252 27891 solver.cpp:238]     Train net output #16: loss24 = 950.221 (* 1 = 950.221 loss)
I0726 09:51:27.275261 27891 solver.cpp:238]     Train net output #17: loss25 = 950.596 (* 1 = 950.596 loss)
I0726 09:51:27.275270 27891 solver.cpp:238]     Train net output #18: loss26 = 950.591 (* 1 = 950.591 loss)
I0726 09:51:27.275279 27891 solver.cpp:238]     Train net output #19: loss27 = 950.211 (* 1 = 950.211 loss)
I0726 09:51:27.275288 27891 solver.cpp:238]     Train net output #20: loss28 = 950.341 (* 1 = 950.341 loss)
I0726 09:51:27.275296 27891 solver.cpp:238]     Train net output #21: loss29 = 950.436 (* 1 = 950.436 loss)
I0726 09:51:27.275305 27891 solver.cpp:238]     Train net output #22: loss3 = 950.447 (* 1 = 950.447 loss)
I0726 09:51:27.275315 27891 solver.cpp:238]     Train net output #23: loss30 = 950.329 (* 1 = 950.329 loss)
I0726 09:51:27.275323 27891 solver.cpp:238]     Train net output #24: loss31 = 950.156 (* 1 = 950.156 loss)
I0726 09:51:27.275332 27891 solver.cpp:238]     Train net output #25: loss32 = 950.394 (* 1 = 950.394 loss)
I0726 09:51:27.275341 27891 solver.cpp:238]     Train net output #26: loss33 = 950.169 (* 1 = 950.169 loss)
I0726 09:51:27.275349 27891 solver.cpp:238]     Train net output #27: loss34 = 950.564 (* 1 = 950.564 loss)
I0726 09:51:27.275359 27891 solver.cpp:238]     Train net output #28: loss35 = 950.117 (* 1 = 950.117 loss)
I0726 09:51:27.275365 27891 solver.cpp:238]     Train net output #29: loss36 = 950.544 (* 1 = 950.544 loss)
I0726 09:51:27.275372 27891 solver.cpp:238]     Train net output #30: loss37 = 950.534 (* 1 = 950.534 loss)
I0726 09:51:27.275413 27891 solver.cpp:238]     Train net output #31: loss38 = 950.415 (* 1 = 950.415 loss)
I0726 09:51:27.275425 27891 solver.cpp:238]     Train net output #32: loss39 = 950.351 (* 1 = 950.351 loss)
I0726 09:51:27.275437 27891 solver.cpp:238]     Train net output #33: loss4 = 950.321 (* 1 = 950.321 loss)
I0726 09:51:27.275445 27891 solver.cpp:238]     Train net output #34: loss40 = 950.541 (* 1 = 950.541 loss)
I0726 09:51:27.275451 27891 solver.cpp:238]     Train net output #35: loss41 = 950.42 (* 1 = 950.42 loss)
I0726 09:51:27.275457 27891 solver.cpp:238]     Train net output #36: loss42 = 949.477 (* 1 = 949.477 loss)
I0726 09:51:27.275462 27891 solver.cpp:238]     Train net output #37: loss43 = 950.557 (* 1 = 950.557 loss)
I0726 09:51:27.275468 27891 solver.cpp:238]     Train net output #38: loss44 = 950.548 (* 1 = 950.548 loss)
I0726 09:51:27.275475 27891 solver.cpp:238]     Train net output #39: loss45 = 950.452 (* 1 = 950.452 loss)
I0726 09:51:27.275480 27891 solver.cpp:238]     Train net output #40: loss46 = 950.489 (* 1 = 950.489 loss)
I0726 09:51:27.275486 27891 solver.cpp:238]     Train net output #41: loss47 = 950.168 (* 1 = 950.168 loss)
I0726 09:51:27.275491 27891 solver.cpp:238]     Train net output #42: loss48 = 949.772 (* 1 = 949.772 loss)
I0726 09:51:27.275497 27891 solver.cpp:238]     Train net output #43: loss49 = 949.8 (* 1 = 949.8 loss)
I0726 09:51:27.275503 27891 solver.cpp:238]     Train net output #44: loss5 = 950.574 (* 1 = 950.574 loss)
I0726 09:51:27.275509 27891 solver.cpp:238]     Train net output #45: loss50 = 950.428 (* 1 = 950.428 loss)
I0726 09:51:27.275516 27891 solver.cpp:238]     Train net output #46: loss51 = 950.592 (* 1 = 950.592 loss)
I0726 09:51:27.275521 27891 solver.cpp:238]     Train net output #47: loss52 = 950.354 (* 1 = 950.354 loss)
I0726 09:51:27.275527 27891 solver.cpp:238]     Train net output #48: loss53 = 950.552 (* 1 = 950.552 loss)
I0726 09:51:27.275532 27891 solver.cpp:238]     Train net output #49: loss54 = 950.572 (* 1 = 950.572 loss)
I0726 09:51:27.275538 27891 solver.cpp:238]     Train net output #50: loss55 = 950.153 (* 1 = 950.153 loss)
I0726 09:51:27.275544 27891 solver.cpp:238]     Train net output #51: loss56 = 950.203 (* 1 = 950.203 loss)
I0726 09:51:27.275550 27891 solver.cpp:238]     Train net output #52: loss57 = 949.754 (* 1 = 949.754 loss)
I0726 09:51:27.275557 27891 solver.cpp:238]     Train net output #53: loss58 = 950.324 (* 1 = 950.324 loss)
I0726 09:51:27.275563 27891 solver.cpp:238]     Train net output #54: loss59 = 950.579 (* 1 = 950.579 loss)
I0726 09:51:27.275568 27891 solver.cpp:238]     Train net output #55: loss6 = 950.294 (* 1 = 950.294 loss)
I0726 09:51:27.275574 27891 solver.cpp:238]     Train net output #56: loss60 = 950.492 (* 1 = 950.492 loss)
I0726 09:51:27.275579 27891 solver.cpp:238]     Train net output #57: loss61 = 949.673 (* 1 = 949.673 loss)
I0726 09:51:27.275585 27891 solver.cpp:238]     Train net output #58: loss62 = 950.601 (* 1 = 950.601 loss)
I0726 09:51:27.275591 27891 solver.cpp:238]     Train net output #59: loss63 = 950.614 (* 1 = 950.614 loss)
I0726 09:51:27.275599 27891 solver.cpp:238]     Train net output #60: loss64 = 948.919 (* 1 = 948.919 loss)
I0726 09:51:27.275604 27891 solver.cpp:238]     Train net output #61: loss7 = 950.302 (* 1 = 950.302 loss)
I0726 09:51:27.275609 27891 solver.cpp:238]     Train net output #62: loss8 = 950.471 (* 1 = 950.471 loss)
I0726 09:51:27.275615 27891 solver.cpp:238]     Train net output #63: loss9 = 950.378 (* 1 = 950.378 loss)
I0726 09:51:27.275629 27891 sgd_solver.cpp:105] Iteration 0, lr = 1e-09
I0726 10:00:19.215273 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:00:19.215903 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:00:19.602376 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_5400.caffemodel
I0726 10:00:19.854182 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_5400.solverstate
I0726 10:00:19.938971 27891 solver.cpp:331] Iteration 5400, Testing net (#0)
I0726 10:00:35.338879 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:00:35.351380 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:00:35.811312 27891 solver.cpp:398]     Test net output #0: mae = 136.793 (* 1 = 136.793 loss)
I0726 10:00:35.811336 27891 solver.cpp:398]     Test net output #1: mse = 30773.1 (* 1 = 30773.1 loss)
I0726 10:00:35.935788 27891 solver.cpp:219] Iteration 5400 (9.84233 iter/s, 548.65s/5400 iters), loss = 121094
I0726 10:00:35.935832 27891 solver.cpp:238]     Train net output #0: loss1 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935842 27891 solver.cpp:238]     Train net output #1: loss10 = 1923.63 (* 1 = 1923.63 loss)
I0726 10:00:35.935850 27891 solver.cpp:238]     Train net output #2: loss11 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935855 27891 solver.cpp:238]     Train net output #3: loss12 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935860 27891 solver.cpp:238]     Train net output #4: loss13 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935865 27891 solver.cpp:238]     Train net output #5: loss14 = 1945.03 (* 1 = 1945.03 loss)
I0726 10:00:35.935870 27891 solver.cpp:238]     Train net output #6: loss15 = 1898.19 (* 1 = 1898.19 loss)
I0726 10:00:35.935878 27891 solver.cpp:238]     Train net output #7: loss16 = 1884.75 (* 1 = 1884.75 loss)
I0726 10:00:35.935885 27891 solver.cpp:238]     Train net output #8: loss17 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935891 27891 solver.cpp:238]     Train net output #9: loss18 = 1974.13 (* 1 = 1974.13 loss)
I0726 10:00:35.935897 27891 solver.cpp:238]     Train net output #10: loss19 = 1923.18 (* 1 = 1923.18 loss)
I0726 10:00:35.935904 27891 solver.cpp:238]     Train net output #11: loss2 = 1894.21 (* 1 = 1894.21 loss)
I0726 10:00:35.935909 27891 solver.cpp:238]     Train net output #12: loss20 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935915 27891 solver.cpp:238]     Train net output #13: loss21 = 1937.51 (* 1 = 1937.51 loss)
I0726 10:00:35.935921 27891 solver.cpp:238]     Train net output #14: loss22 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935927 27891 solver.cpp:238]     Train net output #15: loss23 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.935933 27891 solver.cpp:238]     Train net output #16: loss24 = 1837.87 (* 1 = 1837.87 loss)
I0726 10:00:35.935940 27891 solver.cpp:238]     Train net output #17: loss25 = 1928.73 (* 1 = 1928.73 loss)
I0726 10:00:35.935945 27891 solver.cpp:238]     Train net output #18: loss26 = 1873.95 (* 1 = 1873.95 loss)
I0726 10:00:35.935951 27891 solver.cpp:238]     Train net output #19: loss27 = 1874.35 (* 1 = 1874.35 loss)
I0726 10:00:35.935957 27891 solver.cpp:238]     Train net output #20: loss28 = 1892.07 (* 1 = 1892.07 loss)
I0726 10:00:35.935963 27891 solver.cpp:238]     Train net output #21: loss29 = 2026.29 (* 1 = 2026.29 loss)
I0726 10:00:35.935969 27891 solver.cpp:238]     Train net output #22: loss3 = 1891.79 (* 1 = 1891.79 loss)
I0726 10:00:35.935976 27891 solver.cpp:238]     Train net output #23: loss30 = 1932.69 (* 1 = 1932.69 loss)
I0726 10:00:35.935981 27891 solver.cpp:238]     Train net output #24: loss31 = 1868.06 (* 1 = 1868.06 loss)
I0726 10:00:35.935987 27891 solver.cpp:238]     Train net output #25: loss32 = 1929.54 (* 1 = 1929.54 loss)
I0726 10:00:35.935993 27891 solver.cpp:238]     Train net output #26: loss33 = 2003.68 (* 1 = 2003.68 loss)
I0726 10:00:35.935999 27891 solver.cpp:238]     Train net output #27: loss34 = 1925.69 (* 1 = 1925.69 loss)
I0726 10:00:35.936005 27891 solver.cpp:238]     Train net output #28: loss35 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936012 27891 solver.cpp:238]     Train net output #29: loss36 = 1854.56 (* 1 = 1854.56 loss)
I0726 10:00:35.936054 27891 solver.cpp:238]     Train net output #30: loss37 = 1916.69 (* 1 = 1916.69 loss)
I0726 10:00:35.936065 27891 solver.cpp:238]     Train net output #31: loss38 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936075 27891 solver.cpp:238]     Train net output #32: loss39 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936082 27891 solver.cpp:238]     Train net output #33: loss4 = 1890.21 (* 1 = 1890.21 loss)
I0726 10:00:35.936089 27891 solver.cpp:238]     Train net output #34: loss40 = 1870.09 (* 1 = 1870.09 loss)
I0726 10:00:35.936094 27891 solver.cpp:238]     Train net output #35: loss41 = 1878.82 (* 1 = 1878.82 loss)
I0726 10:00:35.936100 27891 solver.cpp:238]     Train net output #36: loss42 = 1987.25 (* 1 = 1987.25 loss)
I0726 10:00:35.936106 27891 solver.cpp:238]     Train net output #37: loss43 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936112 27891 solver.cpp:238]     Train net output #38: loss44 = 1839.58 (* 1 = 1839.58 loss)
I0726 10:00:35.936118 27891 solver.cpp:238]     Train net output #39: loss45 = 1920.64 (* 1 = 1920.64 loss)
I0726 10:00:35.936125 27891 solver.cpp:238]     Train net output #40: loss46 = 1899.19 (* 1 = 1899.19 loss)
I0726 10:00:35.936131 27891 solver.cpp:238]     Train net output #41: loss47 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936137 27891 solver.cpp:238]     Train net output #42: loss48 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936143 27891 solver.cpp:238]     Train net output #43: loss49 = 2051.62 (* 1 = 2051.62 loss)
I0726 10:00:35.936149 27891 solver.cpp:238]     Train net output #44: loss5 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936156 27891 solver.cpp:238]     Train net output #45: loss50 = 1896.49 (* 1 = 1896.49 loss)
I0726 10:00:35.936161 27891 solver.cpp:238]     Train net output #46: loss51 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936167 27891 solver.cpp:238]     Train net output #47: loss52 = 1958.54 (* 1 = 1958.54 loss)
I0726 10:00:35.936173 27891 solver.cpp:238]     Train net output #48: loss53 = 1903.63 (* 1 = 1903.63 loss)
I0726 10:00:35.936179 27891 solver.cpp:238]     Train net output #49: loss54 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936185 27891 solver.cpp:238]     Train net output #50: loss55 = 1887.43 (* 1 = 1887.43 loss)
I0726 10:00:35.936192 27891 solver.cpp:238]     Train net output #51: loss56 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936197 27891 solver.cpp:238]     Train net output #52: loss57 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936203 27891 solver.cpp:238]     Train net output #53: loss58 = 1882.57 (* 1 = 1882.57 loss)
I0726 10:00:35.936209 27891 solver.cpp:238]     Train net output #54: loss59 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936215 27891 solver.cpp:238]     Train net output #55: loss6 = 2074.77 (* 1 = 2074.77 loss)
I0726 10:00:35.936221 27891 solver.cpp:238]     Train net output #56: loss60 = 1961.1 (* 1 = 1961.1 loss)
I0726 10:00:35.936228 27891 solver.cpp:238]     Train net output #57: loss61 = 2054.12 (* 1 = 2054.12 loss)
I0726 10:00:35.936234 27891 solver.cpp:238]     Train net output #58: loss62 = 1849.73 (* 1 = 1849.73 loss)
I0726 10:00:35.936240 27891 solver.cpp:238]     Train net output #59: loss63 = 1979.01 (* 1 = 1979.01 loss)
I0726 10:00:35.936246 27891 solver.cpp:238]     Train net output #60: loss64 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936252 27891 solver.cpp:238]     Train net output #61: loss7 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936259 27891 solver.cpp:238]     Train net output #62: loss8 = 1885.97 (* 1 = 1885.97 loss)
I0726 10:00:35.936264 27891 solver.cpp:238]     Train net output #63: loss9 = 1837.58 (* 1 = 1837.58 loss)
I0726 10:00:35.936271 27891 sgd_solver.cpp:105] Iteration 5400, lr = 1e-09
I0726 10:09:30.778573 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:09:30.778969 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:09:31.167742 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_10800.caffemodel
I0726 10:09:31.415807 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_10800.solverstate
I0726 10:09:31.509572 27891 solver.cpp:331] Iteration 10800, Testing net (#0)
I0726 10:09:46.947760 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:09:47.046809 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:09:47.415462 27891 solver.cpp:398]     Test net output #0: mae = 115.095 (* 1 = 115.095 loss)
I0726 10:09:47.415493 27891 solver.cpp:398]     Test net output #1: mse = 22869.6 (* 1 = 22869.6 loss)
I0726 10:09:47.541067 27891 solver.cpp:219] Iteration 10800 (9.78978 iter/s, 551.595s/5400 iters), loss = 89003.8
I0726 10:09:47.541131 27891 solver.cpp:238]     Train net output #0: loss1 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541146 27891 solver.cpp:238]     Train net output #1: loss10 = 1414.06 (* 1 = 1414.06 loss)
I0726 10:09:47.541158 27891 solver.cpp:238]     Train net output #2: loss11 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541170 27891 solver.cpp:238]     Train net output #3: loss12 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541182 27891 solver.cpp:238]     Train net output #4: loss13 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541193 27891 solver.cpp:238]     Train net output #5: loss14 = 1425.97 (* 1 = 1425.97 loss)
I0726 10:09:47.541205 27891 solver.cpp:238]     Train net output #6: loss15 = 1383.54 (* 1 = 1383.54 loss)
I0726 10:09:47.541216 27891 solver.cpp:238]     Train net output #7: loss16 = 1383.35 (* 1 = 1383.35 loss)
I0726 10:09:47.541229 27891 solver.cpp:238]     Train net output #8: loss17 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541244 27891 solver.cpp:238]     Train net output #9: loss18 = 1448.58 (* 1 = 1448.58 loss)
I0726 10:09:47.541254 27891 solver.cpp:238]     Train net output #10: loss19 = 1428.24 (* 1 = 1428.24 loss)
I0726 10:09:47.541263 27891 solver.cpp:238]     Train net output #11: loss2 = 1387.78 (* 1 = 1387.78 loss)
I0726 10:09:47.541272 27891 solver.cpp:238]     Train net output #12: loss20 = 1405.53 (* 1 = 1405.53 loss)
I0726 10:09:47.541281 27891 solver.cpp:238]     Train net output #13: loss21 = 1402.25 (* 1 = 1402.25 loss)
I0726 10:09:47.541291 27891 solver.cpp:238]     Train net output #14: loss22 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541301 27891 solver.cpp:238]     Train net output #15: loss23 = 1353.64 (* 1 = 1353.64 loss)
I0726 10:09:47.541314 27891 solver.cpp:238]     Train net output #16: loss24 = 1353.64 (* 1 = 1353.64 loss)
I0726 10:09:47.541324 27891 solver.cpp:238]     Train net output #17: loss25 = 1431.99 (* 1 = 1431.99 loss)
I0726 10:09:47.541333 27891 solver.cpp:238]     Train net output #18: loss26 = 1366.65 (* 1 = 1366.65 loss)
I0726 10:09:47.541342 27891 solver.cpp:238]     Train net output #19: loss27 = 1371.37 (* 1 = 1371.37 loss)
I0726 10:09:47.541352 27891 solver.cpp:238]     Train net output #20: loss28 = 1371.81 (* 1 = 1371.81 loss)
I0726 10:09:47.541362 27891 solver.cpp:238]     Train net output #21: loss29 = 1481.58 (* 1 = 1481.58 loss)
I0726 10:09:47.541371 27891 solver.cpp:238]     Train net output #22: loss3 = 1403.55 (* 1 = 1403.55 loss)
I0726 10:09:47.541380 27891 solver.cpp:238]     Train net output #23: loss30 = 1437.66 (* 1 = 1437.66 loss)
I0726 10:09:47.541390 27891 solver.cpp:238]     Train net output #24: loss31 = 1358.33 (* 1 = 1358.33 loss)
I0726 10:09:47.541400 27891 solver.cpp:238]     Train net output #25: loss32 = 1436.12 (* 1 = 1436.12 loss)
I0726 10:09:47.541409 27891 solver.cpp:238]     Train net output #26: loss33 = 1423.77 (* 1 = 1423.77 loss)
I0726 10:09:47.541419 27891 solver.cpp:238]     Train net output #27: loss34 = 1438.87 (* 1 = 1438.87 loss)
I0726 10:09:47.541429 27891 solver.cpp:238]     Train net output #28: loss35 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.541438 27891 solver.cpp:238]     Train net output #29: loss36 = 1371.73 (* 1 = 1371.73 loss)
I0726 10:09:47.543259 27891 solver.cpp:238]     Train net output #30: loss37 = 1411.35 (* 1 = 1411.35 loss)
I0726 10:09:47.543272 27891 solver.cpp:238]     Train net output #31: loss38 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543282 27891 solver.cpp:238]     Train net output #32: loss39 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543292 27891 solver.cpp:238]     Train net output #33: loss4 = 1366.37 (* 1 = 1366.37 loss)
I0726 10:09:47.543303 27891 solver.cpp:238]     Train net output #34: loss40 = 1362.42 (* 1 = 1362.42 loss)
I0726 10:09:47.543311 27891 solver.cpp:238]     Train net output #35: loss41 = 1396.77 (* 1 = 1396.77 loss)
I0726 10:09:47.543320 27891 solver.cpp:238]     Train net output #36: loss42 = 1440.44 (* 1 = 1440.44 loss)
I0726 10:09:47.543330 27891 solver.cpp:238]     Train net output #37: loss43 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543340 27891 solver.cpp:238]     Train net output #38: loss44 = 1354.31 (* 1 = 1354.31 loss)
I0726 10:09:47.543349 27891 solver.cpp:238]     Train net output #39: loss45 = 1396.58 (* 1 = 1396.58 loss)
I0726 10:09:47.543359 27891 solver.cpp:238]     Train net output #40: loss46 = 1398.6 (* 1 = 1398.6 loss)
I0726 10:09:47.543368 27891 solver.cpp:238]     Train net output #41: loss47 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543378 27891 solver.cpp:238]     Train net output #42: loss48 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543387 27891 solver.cpp:238]     Train net output #43: loss49 = 1471.55 (* 1 = 1471.55 loss)
I0726 10:09:47.543397 27891 solver.cpp:238]     Train net output #44: loss5 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543406 27891 solver.cpp:238]     Train net output #45: loss50 = 1486.74 (* 1 = 1486.74 loss)
I0726 10:09:47.543416 27891 solver.cpp:238]     Train net output #46: loss51 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543426 27891 solver.cpp:238]     Train net output #47: loss52 = 1429.21 (* 1 = 1429.21 loss)
I0726 10:09:47.543436 27891 solver.cpp:238]     Train net output #48: loss53 = 1376.04 (* 1 = 1376.04 loss)
I0726 10:09:47.543444 27891 solver.cpp:238]     Train net output #49: loss54 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543454 27891 solver.cpp:238]     Train net output #50: loss55 = 1360.17 (* 1 = 1360.17 loss)
I0726 10:09:47.543463 27891 solver.cpp:238]     Train net output #51: loss56 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543473 27891 solver.cpp:238]     Train net output #52: loss57 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543483 27891 solver.cpp:238]     Train net output #53: loss58 = 1364.69 (* 1 = 1364.69 loss)
I0726 10:09:47.543493 27891 solver.cpp:238]     Train net output #54: loss59 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543501 27891 solver.cpp:238]     Train net output #55: loss6 = 1473.16 (* 1 = 1473.16 loss)
I0726 10:09:47.543511 27891 solver.cpp:238]     Train net output #56: loss60 = 1486.29 (* 1 = 1486.29 loss)
I0726 10:09:47.543520 27891 solver.cpp:238]     Train net output #57: loss61 = 1476.43 (* 1 = 1476.43 loss)
I0726 10:09:47.543530 27891 solver.cpp:238]     Train net output #58: loss62 = 1359.02 (* 1 = 1359.02 loss)
I0726 10:09:47.543540 27891 solver.cpp:238]     Train net output #59: loss63 = 1492.58 (* 1 = 1492.58 loss)
I0726 10:09:47.543550 27891 solver.cpp:238]     Train net output #60: loss64 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543558 27891 solver.cpp:238]     Train net output #61: loss7 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543567 27891 solver.cpp:238]     Train net output #62: loss8 = 1379.36 (* 1 = 1379.36 loss)
I0726 10:09:47.543577 27891 solver.cpp:238]     Train net output #63: loss9 = 1353.63 (* 1 = 1353.63 loss)
I0726 10:09:47.543586 27891 sgd_solver.cpp:105] Iteration 10800, lr = 1e-09
I0726 10:18:41.961762 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:18:41.962921 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:18:42.352999 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_16200.caffemodel
I0726 10:18:42.603301 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_16200.solverstate
I0726 10:18:42.687669 27891 solver.cpp:331] Iteration 16200, Testing net (#0)
I0726 10:18:58.056349 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:18:58.068972 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:18:58.522192 27891 solver.cpp:398]     Test net output #0: mae = 109.206 (* 1 = 109.206 loss)
I0726 10:18:58.522214 27891 solver.cpp:398]     Test net output #1: mse = 21288.9 (* 1 = 21288.9 loss)
I0726 10:18:58.646705 27891 solver.cpp:219] Iteration 16200 (9.79866 iter/s, 551.096s/5400 iters), loss = 73732.4
I0726 10:18:58.646754 27891 solver.cpp:238]     Train net output #0: loss1 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646770 27891 solver.cpp:238]     Train net output #1: loss10 = 1164.5 (* 1 = 1164.5 loss)
I0726 10:18:58.646780 27891 solver.cpp:238]     Train net output #2: loss11 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646790 27891 solver.cpp:238]     Train net output #3: loss12 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646800 27891 solver.cpp:238]     Train net output #4: loss13 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646811 27891 solver.cpp:238]     Train net output #5: loss14 = 1171.66 (* 1 = 1171.66 loss)
I0726 10:18:58.646822 27891 solver.cpp:238]     Train net output #6: loss15 = 1154.26 (* 1 = 1154.26 loss)
I0726 10:18:58.646833 27891 solver.cpp:238]     Train net output #7: loss16 = 1152.5 (* 1 = 1152.5 loss)
I0726 10:18:58.646845 27891 solver.cpp:238]     Train net output #8: loss17 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646857 27891 solver.cpp:238]     Train net output #9: loss18 = 1196.01 (* 1 = 1196.01 loss)
I0726 10:18:58.646868 27891 solver.cpp:238]     Train net output #10: loss19 = 1187.99 (* 1 = 1187.99 loss)
I0726 10:18:58.646880 27891 solver.cpp:238]     Train net output #11: loss2 = 1162.87 (* 1 = 1162.87 loss)
I0726 10:18:58.646891 27891 solver.cpp:238]     Train net output #12: loss20 = 1186.67 (* 1 = 1186.67 loss)
I0726 10:18:58.646903 27891 solver.cpp:238]     Train net output #13: loss21 = 1153.67 (* 1 = 1153.67 loss)
I0726 10:18:58.646914 27891 solver.cpp:238]     Train net output #14: loss22 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646925 27891 solver.cpp:238]     Train net output #15: loss23 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.646937 27891 solver.cpp:238]     Train net output #16: loss24 = 1122.25 (* 1 = 1122.25 loss)
I0726 10:18:58.646948 27891 solver.cpp:238]     Train net output #17: loss25 = 1189.14 (* 1 = 1189.14 loss)
I0726 10:18:58.646960 27891 solver.cpp:238]     Train net output #18: loss26 = 1134.45 (* 1 = 1134.45 loss)
I0726 10:18:58.646972 27891 solver.cpp:238]     Train net output #19: loss27 = 1132.73 (* 1 = 1132.73 loss)
I0726 10:18:58.646983 27891 solver.cpp:238]     Train net output #20: loss28 = 1140.7 (* 1 = 1140.7 loss)
I0726 10:18:58.646994 27891 solver.cpp:238]     Train net output #21: loss29 = 1213.28 (* 1 = 1213.28 loss)
I0726 10:18:58.647006 27891 solver.cpp:238]     Train net output #22: loss3 = 1170.06 (* 1 = 1170.06 loss)
I0726 10:18:58.647017 27891 solver.cpp:238]     Train net output #23: loss30 = 1195.96 (* 1 = 1195.96 loss)
I0726 10:18:58.647029 27891 solver.cpp:238]     Train net output #24: loss31 = 1126.11 (* 1 = 1126.11 loss)
I0726 10:18:58.647042 27891 solver.cpp:238]     Train net output #25: loss32 = 1186.36 (* 1 = 1186.36 loss)
I0726 10:18:58.647053 27891 solver.cpp:238]     Train net output #26: loss33 = 1172.53 (* 1 = 1172.53 loss)
I0726 10:18:58.647064 27891 solver.cpp:238]     Train net output #27: loss34 = 1197.46 (* 1 = 1197.46 loss)
I0726 10:18:58.647075 27891 solver.cpp:238]     Train net output #28: loss35 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647086 27891 solver.cpp:238]     Train net output #29: loss36 = 1145.99 (* 1 = 1145.99 loss)
I0726 10:18:58.647143 27891 solver.cpp:238]     Train net output #30: loss37 = 1155.83 (* 1 = 1155.83 loss)
I0726 10:18:58.647156 27891 solver.cpp:238]     Train net output #31: loss38 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647168 27891 solver.cpp:238]     Train net output #32: loss39 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647181 27891 solver.cpp:238]     Train net output #33: loss4 = 1123.14 (* 1 = 1123.14 loss)
I0726 10:18:58.647192 27891 solver.cpp:238]     Train net output #34: loss40 = 1125.87 (* 1 = 1125.87 loss)
I0726 10:18:58.647203 27891 solver.cpp:238]     Train net output #35: loss41 = 1174.35 (* 1 = 1174.35 loss)
I0726 10:18:58.647217 27891 solver.cpp:238]     Train net output #36: loss42 = 1166.98 (* 1 = 1166.98 loss)
I0726 10:18:58.647227 27891 solver.cpp:238]     Train net output #37: loss43 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647245 27891 solver.cpp:238]     Train net output #38: loss44 = 1124.25 (* 1 = 1124.25 loss)
I0726 10:18:58.647255 27891 solver.cpp:238]     Train net output #39: loss45 = 1149.18 (* 1 = 1149.18 loss)
I0726 10:18:58.647265 27891 solver.cpp:238]     Train net output #40: loss46 = 1153.18 (* 1 = 1153.18 loss)
I0726 10:18:58.647275 27891 solver.cpp:238]     Train net output #41: loss47 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647286 27891 solver.cpp:238]     Train net output #42: loss48 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647295 27891 solver.cpp:238]     Train net output #43: loss49 = 1216.75 (* 1 = 1216.75 loss)
I0726 10:18:58.647306 27891 solver.cpp:238]     Train net output #44: loss5 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647317 27891 solver.cpp:238]     Train net output #45: loss50 = 1253.81 (* 1 = 1253.81 loss)
I0726 10:18:58.647328 27891 solver.cpp:238]     Train net output #46: loss51 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647339 27891 solver.cpp:238]     Train net output #47: loss52 = 1188.58 (* 1 = 1188.58 loss)
I0726 10:18:58.647351 27891 solver.cpp:238]     Train net output #48: loss53 = 1135.07 (* 1 = 1135.07 loss)
I0726 10:18:58.647361 27891 solver.cpp:238]     Train net output #49: loss54 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647370 27891 solver.cpp:238]     Train net output #50: loss55 = 1127.85 (* 1 = 1127.85 loss)
I0726 10:18:58.647382 27891 solver.cpp:238]     Train net output #51: loss56 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647392 27891 solver.cpp:238]     Train net output #52: loss57 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647403 27891 solver.cpp:238]     Train net output #53: loss58 = 1133.62 (* 1 = 1133.62 loss)
I0726 10:18:58.647413 27891 solver.cpp:238]     Train net output #54: loss59 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647424 27891 solver.cpp:238]     Train net output #55: loss6 = 1202.33 (* 1 = 1202.33 loss)
I0726 10:18:58.647435 27891 solver.cpp:238]     Train net output #56: loss60 = 1238.8 (* 1 = 1238.8 loss)
I0726 10:18:58.647446 27891 solver.cpp:238]     Train net output #57: loss61 = 1187.5 (* 1 = 1187.5 loss)
I0726 10:18:58.647456 27891 solver.cpp:238]     Train net output #58: loss62 = 1125.97 (* 1 = 1125.97 loss)
I0726 10:18:58.647465 27891 solver.cpp:238]     Train net output #59: loss63 = 1238.26 (* 1 = 1238.26 loss)
I0726 10:18:58.647475 27891 solver.cpp:238]     Train net output #60: loss64 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647485 27891 solver.cpp:238]     Train net output #61: loss7 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647497 27891 solver.cpp:238]     Train net output #62: loss8 = 1148.41 (* 1 = 1148.41 loss)
I0726 10:18:58.647507 27891 solver.cpp:238]     Train net output #63: loss9 = 1121.83 (* 1 = 1121.83 loss)
I0726 10:18:58.647518 27891 sgd_solver.cpp:105] Iteration 16200, lr = 1e-09
I0726 10:27:53.181488 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:27:53.206743 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:27:53.570044 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_21600.caffemodel
I0726 10:27:53.806380 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_21600.solverstate
I0726 10:27:53.905220 27891 solver.cpp:331] Iteration 21600, Testing net (#0)
I0726 10:28:09.299819 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:28:09.324344 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:28:09.765192 27891 solver.cpp:398]     Test net output #0: mae = 101.398 (* 1 = 101.398 loss)
I0726 10:28:09.765221 27891 solver.cpp:398]     Test net output #1: mse = 18989.9 (* 1 = 18989.9 loss)
I0726 10:28:09.891824 27891 solver.cpp:219] Iteration 21600 (9.79622 iter/s, 551.233s/5400 iters), loss = 60834.9
I0726 10:28:09.891880 27891 solver.cpp:238]     Train net output #0: loss1 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.891892 27891 solver.cpp:238]     Train net output #1: loss10 = 960.419 (* 1 = 960.419 loss)
I0726 10:28:09.891903 27891 solver.cpp:238]     Train net output #2: loss11 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.891916 27891 solver.cpp:238]     Train net output #3: loss12 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.891927 27891 solver.cpp:238]     Train net output #4: loss13 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.891939 27891 solver.cpp:238]     Train net output #5: loss14 = 964.042 (* 1 = 964.042 loss)
I0726 10:28:09.891952 27891 solver.cpp:238]     Train net output #6: loss15 = 954.862 (* 1 = 954.862 loss)
I0726 10:28:09.891964 27891 solver.cpp:238]     Train net output #7: loss16 = 965.371 (* 1 = 965.371 loss)
I0726 10:28:09.891976 27891 solver.cpp:238]     Train net output #8: loss17 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.891988 27891 solver.cpp:238]     Train net output #9: loss18 = 979.783 (* 1 = 979.783 loss)
I0726 10:28:09.891999 27891 solver.cpp:238]     Train net output #10: loss19 = 984.771 (* 1 = 984.771 loss)
I0726 10:28:09.892011 27891 solver.cpp:238]     Train net output #11: loss2 = 960.695 (* 1 = 960.695 loss)
I0726 10:28:09.892024 27891 solver.cpp:238]     Train net output #12: loss20 = 991.735 (* 1 = 991.735 loss)
I0726 10:28:09.892035 27891 solver.cpp:238]     Train net output #13: loss21 = 952.065 (* 1 = 952.065 loss)
I0726 10:28:09.892047 27891 solver.cpp:238]     Train net output #14: loss22 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892058 27891 solver.cpp:238]     Train net output #15: loss23 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892071 27891 solver.cpp:238]     Train net output #16: loss24 = 928.736 (* 1 = 928.736 loss)
I0726 10:28:09.892091 27891 solver.cpp:238]     Train net output #17: loss25 = 980.056 (* 1 = 980.056 loss)
I0726 10:28:09.892102 27891 solver.cpp:238]     Train net output #18: loss26 = 936.586 (* 1 = 936.586 loss)
I0726 10:28:09.892113 27891 solver.cpp:238]     Train net output #19: loss27 = 933.511 (* 1 = 933.511 loss)
I0726 10:28:09.892125 27891 solver.cpp:238]     Train net output #20: loss28 = 939.507 (* 1 = 939.507 loss)
I0726 10:28:09.892138 27891 solver.cpp:238]     Train net output #21: loss29 = 992.273 (* 1 = 992.273 loss)
I0726 10:28:09.892149 27891 solver.cpp:238]     Train net output #22: loss3 = 963.847 (* 1 = 963.847 loss)
I0726 10:28:09.892160 27891 solver.cpp:238]     Train net output #23: loss30 = 992.452 (* 1 = 992.452 loss)
I0726 10:28:09.892172 27891 solver.cpp:238]     Train net output #24: loss31 = 931.918 (* 1 = 931.918 loss)
I0726 10:28:09.892184 27891 solver.cpp:238]     Train net output #25: loss32 = 974.01 (* 1 = 974.01 loss)
I0726 10:28:09.892195 27891 solver.cpp:238]     Train net output #26: loss33 = 966.771 (* 1 = 966.771 loss)
I0726 10:28:09.892206 27891 solver.cpp:238]     Train net output #27: loss34 = 990.521 (* 1 = 990.521 loss)
I0726 10:28:09.892218 27891 solver.cpp:238]     Train net output #28: loss35 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892230 27891 solver.cpp:238]     Train net output #29: loss36 = 953.983 (* 1 = 953.983 loss)
I0726 10:28:09.892493 27891 solver.cpp:238]     Train net output #30: loss37 = 944.862 (* 1 = 944.862 loss)
I0726 10:28:09.892509 27891 solver.cpp:238]     Train net output #31: loss38 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892523 27891 solver.cpp:238]     Train net output #32: loss39 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892534 27891 solver.cpp:238]     Train net output #33: loss4 = 928.339 (* 1 = 928.339 loss)
I0726 10:28:09.892546 27891 solver.cpp:238]     Train net output #34: loss40 = 928.898 (* 1 = 928.898 loss)
I0726 10:28:09.892558 27891 solver.cpp:238]     Train net output #35: loss41 = 975.186 (* 1 = 975.186 loss)
I0726 10:28:09.892570 27891 solver.cpp:238]     Train net output #36: loss42 = 955.379 (* 1 = 955.379 loss)
I0726 10:28:09.892581 27891 solver.cpp:238]     Train net output #37: loss43 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892592 27891 solver.cpp:238]     Train net output #38: loss44 = 932.486 (* 1 = 932.486 loss)
I0726 10:28:09.892604 27891 solver.cpp:238]     Train net output #39: loss45 = 946.435 (* 1 = 946.435 loss)
I0726 10:28:09.892616 27891 solver.cpp:238]     Train net output #40: loss46 = 950.262 (* 1 = 950.262 loss)
I0726 10:28:09.892627 27891 solver.cpp:238]     Train net output #41: loss47 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892639 27891 solver.cpp:238]     Train net output #42: loss48 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892650 27891 solver.cpp:238]     Train net output #43: loss49 = 993.241 (* 1 = 993.241 loss)
I0726 10:28:09.892662 27891 solver.cpp:238]     Train net output #44: loss5 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892673 27891 solver.cpp:238]     Train net output #45: loss50 = 1034.75 (* 1 = 1034.75 loss)
I0726 10:28:09.892684 27891 solver.cpp:238]     Train net output #46: loss51 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892696 27891 solver.cpp:238]     Train net output #47: loss52 = 976.005 (* 1 = 976.005 loss)
I0726 10:28:09.892709 27891 solver.cpp:238]     Train net output #48: loss53 = 933.211 (* 1 = 933.211 loss)
I0726 10:28:09.892719 27891 solver.cpp:238]     Train net output #49: loss54 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892731 27891 solver.cpp:238]     Train net output #50: loss55 = 933.278 (* 1 = 933.278 loss)
I0726 10:28:09.892742 27891 solver.cpp:238]     Train net output #51: loss56 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892753 27891 solver.cpp:238]     Train net output #52: loss57 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892765 27891 solver.cpp:238]     Train net output #53: loss58 = 939.719 (* 1 = 939.719 loss)
I0726 10:28:09.892776 27891 solver.cpp:238]     Train net output #54: loss59 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892788 27891 solver.cpp:238]     Train net output #55: loss6 = 984.889 (* 1 = 984.889 loss)
I0726 10:28:09.892799 27891 solver.cpp:238]     Train net output #56: loss60 = 1025.65 (* 1 = 1025.65 loss)
I0726 10:28:09.892812 27891 solver.cpp:238]     Train net output #57: loss61 = 928.084 (* 1 = 928.084 loss)
I0726 10:28:09.892822 27891 solver.cpp:238]     Train net output #58: loss62 = 930.514 (* 1 = 930.514 loss)
I0726 10:28:09.892849 27891 solver.cpp:238]     Train net output #59: loss63 = 1009.76 (* 1 = 1009.76 loss)
I0726 10:28:09.892860 27891 solver.cpp:238]     Train net output #60: loss64 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892873 27891 solver.cpp:238]     Train net output #61: loss7 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892884 27891 solver.cpp:238]     Train net output #62: loss8 = 951.748 (* 1 = 951.748 loss)
I0726 10:28:09.892894 27891 solver.cpp:238]     Train net output #63: loss9 = 927.656 (* 1 = 927.656 loss)
I0726 10:28:09.892905 27891 sgd_solver.cpp:105] Iteration 21600, lr = 1e-09
I0726 10:37:04.279774 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:37:04.305259 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:37:04.675799 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_27000.caffemodel
I0726 10:37:04.923384 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_27000.solverstate
I0726 10:37:05.040161 27891 solver.cpp:331] Iteration 27000, Testing net (#0)
I0726 10:37:20.408236 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:37:20.409420 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:37:20.873919 27891 solver.cpp:398]     Test net output #0: mae = 94.734 (* 1 = 94.734 loss)
I0726 10:37:20.873944 27891 solver.cpp:398]     Test net output #1: mse = 17224.4 (* 1 = 17224.4 loss)
I0726 10:37:20.998417 27891 solver.cpp:219] Iteration 27000 (9.79866 iter/s, 551.096s/5400 iters), loss = 53687.9
I0726 10:37:20.998464 27891 solver.cpp:238]     Train net output #0: loss1 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998476 27891 solver.cpp:238]     Train net output #1: loss10 = 847.378 (* 1 = 847.378 loss)
I0726 10:37:20.998486 27891 solver.cpp:238]     Train net output #2: loss11 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998495 27891 solver.cpp:238]     Train net output #3: loss12 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998504 27891 solver.cpp:238]     Train net output #4: loss13 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998514 27891 solver.cpp:238]     Train net output #5: loss14 = 852.115 (* 1 = 852.115 loss)
I0726 10:37:20.998524 27891 solver.cpp:238]     Train net output #6: loss15 = 842.33 (* 1 = 842.33 loss)
I0726 10:37:20.998534 27891 solver.cpp:238]     Train net output #7: loss16 = 859.834 (* 1 = 859.834 loss)
I0726 10:37:20.998546 27891 solver.cpp:238]     Train net output #8: loss17 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998558 27891 solver.cpp:238]     Train net output #9: loss18 = 855.718 (* 1 = 855.718 loss)
I0726 10:37:20.998570 27891 solver.cpp:238]     Train net output #10: loss19 = 870.025 (* 1 = 870.025 loss)
I0726 10:37:20.998582 27891 solver.cpp:238]     Train net output #11: loss2 = 843.811 (* 1 = 843.811 loss)
I0726 10:37:20.998594 27891 solver.cpp:238]     Train net output #12: loss20 = 882.762 (* 1 = 882.762 loss)
I0726 10:37:20.998605 27891 solver.cpp:238]     Train net output #13: loss21 = 840.116 (* 1 = 840.116 loss)
I0726 10:37:20.998616 27891 solver.cpp:238]     Train net output #14: loss22 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998627 27891 solver.cpp:238]     Train net output #15: loss23 = 820.273 (* 1 = 820.273 loss)
I0726 10:37:20.998638 27891 solver.cpp:238]     Train net output #16: loss24 = 821.941 (* 1 = 821.941 loss)
I0726 10:37:20.998649 27891 solver.cpp:238]     Train net output #17: loss25 = 858.094 (* 1 = 858.094 loss)
I0726 10:37:20.998661 27891 solver.cpp:238]     Train net output #18: loss26 = 826.513 (* 1 = 826.513 loss)
I0726 10:37:20.998672 27891 solver.cpp:238]     Train net output #19: loss27 = 823.799 (* 1 = 823.799 loss)
I0726 10:37:20.998682 27891 solver.cpp:238]     Train net output #20: loss28 = 827.709 (* 1 = 827.709 loss)
I0726 10:37:20.998693 27891 solver.cpp:238]     Train net output #21: loss29 = 872.652 (* 1 = 872.652 loss)
I0726 10:37:20.998705 27891 solver.cpp:238]     Train net output #22: loss3 = 848.478 (* 1 = 848.478 loss)
I0726 10:37:20.998716 27891 solver.cpp:238]     Train net output #23: loss30 = 875.588 (* 1 = 875.588 loss)
I0726 10:37:20.998728 27891 solver.cpp:238]     Train net output #24: loss31 = 825.172 (* 1 = 825.172 loss)
I0726 10:37:20.998739 27891 solver.cpp:238]     Train net output #25: loss32 = 854.285 (* 1 = 854.285 loss)
I0726 10:37:20.998749 27891 solver.cpp:238]     Train net output #26: loss33 = 853.091 (* 1 = 853.091 loss)
I0726 10:37:20.998760 27891 solver.cpp:238]     Train net output #27: loss34 = 874.165 (* 1 = 874.165 loss)
I0726 10:37:20.998771 27891 solver.cpp:238]     Train net output #28: loss35 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998782 27891 solver.cpp:238]     Train net output #29: loss36 = 845.5 (* 1 = 845.5 loss)
I0726 10:37:20.998834 27891 solver.cpp:238]     Train net output #30: loss37 = 829.523 (* 1 = 829.523 loss)
I0726 10:37:20.998845 27891 solver.cpp:238]     Train net output #31: loss38 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998857 27891 solver.cpp:238]     Train net output #32: loss39 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998868 27891 solver.cpp:238]     Train net output #33: loss4 = 820.279 (* 1 = 820.279 loss)
I0726 10:37:20.998884 27891 solver.cpp:238]     Train net output #34: loss40 = 819.667 (* 1 = 819.667 loss)
I0726 10:37:20.998896 27891 solver.cpp:238]     Train net output #35: loss41 = 861.235 (* 1 = 861.235 loss)
I0726 10:37:20.998908 27891 solver.cpp:238]     Train net output #36: loss42 = 837.161 (* 1 = 837.161 loss)
I0726 10:37:20.998920 27891 solver.cpp:238]     Train net output #37: loss43 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998930 27891 solver.cpp:238]     Train net output #38: loss44 = 826.597 (* 1 = 826.597 loss)
I0726 10:37:20.998942 27891 solver.cpp:238]     Train net output #39: loss45 = 834.537 (* 1 = 834.537 loss)
I0726 10:37:20.998953 27891 solver.cpp:238]     Train net output #40: loss46 = 836.311 (* 1 = 836.311 loss)
I0726 10:37:20.998965 27891 solver.cpp:238]     Train net output #41: loss47 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998976 27891 solver.cpp:238]     Train net output #42: loss48 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.998987 27891 solver.cpp:238]     Train net output #43: loss49 = 869.323 (* 1 = 869.323 loss)
I0726 10:37:20.998999 27891 solver.cpp:238]     Train net output #44: loss5 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999011 27891 solver.cpp:238]     Train net output #45: loss50 = 901.774 (* 1 = 901.774 loss)
I0726 10:37:20.999022 27891 solver.cpp:238]     Train net output #46: loss51 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999033 27891 solver.cpp:238]     Train net output #47: loss52 = 853.182 (* 1 = 853.182 loss)
I0726 10:37:20.999045 27891 solver.cpp:238]     Train net output #48: loss53 = 822.19 (* 1 = 822.19 loss)
I0726 10:37:20.999056 27891 solver.cpp:238]     Train net output #49: loss54 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999068 27891 solver.cpp:238]     Train net output #50: loss55 = 825.013 (* 1 = 825.013 loss)
I0726 10:37:20.999078 27891 solver.cpp:238]     Train net output #51: loss56 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999089 27891 solver.cpp:238]     Train net output #52: loss57 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999100 27891 solver.cpp:238]     Train net output #53: loss58 = 835.252 (* 1 = 835.252 loss)
I0726 10:37:20.999111 27891 solver.cpp:238]     Train net output #54: loss59 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999122 27891 solver.cpp:238]     Train net output #55: loss6 = 865.024 (* 1 = 865.024 loss)
I0726 10:37:20.999133 27891 solver.cpp:238]     Train net output #56: loss60 = 907.963 (* 1 = 907.963 loss)
I0726 10:37:20.999145 27891 solver.cpp:238]     Train net output #57: loss61 = 820.663 (* 1 = 820.663 loss)
I0726 10:37:20.999155 27891 solver.cpp:238]     Train net output #58: loss62 = 823.328 (* 1 = 823.328 loss)
I0726 10:37:20.999167 27891 solver.cpp:238]     Train net output #59: loss63 = 883.412 (* 1 = 883.412 loss)
I0726 10:37:20.999178 27891 solver.cpp:238]     Train net output #60: loss64 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999191 27891 solver.cpp:238]     Train net output #61: loss7 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999202 27891 solver.cpp:238]     Train net output #62: loss8 = 842.145 (* 1 = 842.145 loss)
I0726 10:37:20.999212 27891 solver.cpp:238]     Train net output #63: loss9 = 820.254 (* 1 = 820.254 loss)
I0726 10:37:20.999223 27891 sgd_solver.cpp:105] Iteration 27000, lr = 1e-09
I0726 10:46:13.883399 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:46:13.886948 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:46:14.298574 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_32400.caffemodel
I0726 10:46:14.558436 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_32400.solverstate
I0726 10:46:14.652827 27891 solver.cpp:331] Iteration 32400, Testing net (#0)
I0726 10:46:30.111490 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:46:30.131997 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:46:30.576463 27891 solver.cpp:398]     Test net output #0: mae = 91.3512 (* 1 = 91.3512 loss)
I0726 10:46:30.576488 27891 solver.cpp:398]     Test net output #1: mse = 16373.7 (* 1 = 16373.7 loss)
I0726 10:46:30.701407 27891 solver.cpp:219] Iteration 32400 (9.82367 iter/s, 549.693s/5400 iters), loss = 48973.6
I0726 10:46:30.701455 27891 solver.cpp:238]     Train net output #0: loss1 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701462 27891 solver.cpp:238]     Train net output #1: loss10 = 773.24 (* 1 = 773.24 loss)
I0726 10:46:30.701467 27891 solver.cpp:238]     Train net output #2: loss11 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701474 27891 solver.cpp:238]     Train net output #3: loss12 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701481 27891 solver.cpp:238]     Train net output #4: loss13 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701488 27891 solver.cpp:238]     Train net output #5: loss14 = 779.489 (* 1 = 779.489 loss)
I0726 10:46:30.701494 27891 solver.cpp:238]     Train net output #6: loss15 = 766.214 (* 1 = 766.214 loss)
I0726 10:46:30.701500 27891 solver.cpp:238]     Train net output #7: loss16 = 785.999 (* 1 = 785.999 loss)
I0726 10:46:30.701506 27891 solver.cpp:238]     Train net output #8: loss17 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701514 27891 solver.cpp:238]     Train net output #9: loss18 = 775.347 (* 1 = 775.347 loss)
I0726 10:46:30.701520 27891 solver.cpp:238]     Train net output #10: loss19 = 793.717 (* 1 = 793.717 loss)
I0726 10:46:30.701527 27891 solver.cpp:238]     Train net output #11: loss2 = 768.076 (* 1 = 768.076 loss)
I0726 10:46:30.701534 27891 solver.cpp:238]     Train net output #12: loss20 = 809.979 (* 1 = 809.979 loss)
I0726 10:46:30.701539 27891 solver.cpp:238]     Train net output #13: loss21 = 766.053 (* 1 = 766.053 loss)
I0726 10:46:30.701545 27891 solver.cpp:238]     Train net output #14: loss22 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701551 27891 solver.cpp:238]     Train net output #15: loss23 = 749.217 (* 1 = 749.217 loss)
I0726 10:46:30.701558 27891 solver.cpp:238]     Train net output #16: loss24 = 751.191 (* 1 = 751.191 loss)
I0726 10:46:30.701565 27891 solver.cpp:238]     Train net output #17: loss25 = 779.425 (* 1 = 779.425 loss)
I0726 10:46:30.701570 27891 solver.cpp:238]     Train net output #18: loss26 = 753.954 (* 1 = 753.954 loss)
I0726 10:46:30.701576 27891 solver.cpp:238]     Train net output #19: loss27 = 750.933 (* 1 = 750.933 loss)
I0726 10:46:30.701582 27891 solver.cpp:238]     Train net output #20: loss28 = 754.626 (* 1 = 754.626 loss)
I0726 10:46:30.701588 27891 solver.cpp:238]     Train net output #21: loss29 = 793.216 (* 1 = 793.216 loss)
I0726 10:46:30.701594 27891 solver.cpp:238]     Train net output #22: loss3 = 771.271 (* 1 = 771.271 loss)
I0726 10:46:30.701601 27891 solver.cpp:238]     Train net output #23: loss30 = 798.138 (* 1 = 798.138 loss)
I0726 10:46:30.701606 27891 solver.cpp:238]     Train net output #24: loss31 = 754.633 (* 1 = 754.633 loss)
I0726 10:46:30.701611 27891 solver.cpp:238]     Train net output #25: loss32 = 776.016 (* 1 = 776.016 loss)
I0726 10:46:30.701617 27891 solver.cpp:238]     Train net output #26: loss33 = 778.26 (* 1 = 778.26 loss)
I0726 10:46:30.701623 27891 solver.cpp:238]     Train net output #27: loss34 = 798.03 (* 1 = 798.03 loss)
I0726 10:46:30.701629 27891 solver.cpp:238]     Train net output #28: loss35 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701635 27891 solver.cpp:238]     Train net output #29: loss36 = 772.934 (* 1 = 772.934 loss)
I0726 10:46:30.701678 27891 solver.cpp:238]     Train net output #30: loss37 = 757.178 (* 1 = 757.178 loss)
I0726 10:46:30.701685 27891 solver.cpp:238]     Train net output #31: loss38 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701692 27891 solver.cpp:238]     Train net output #32: loss39 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701699 27891 solver.cpp:238]     Train net output #33: loss4 = 749.207 (* 1 = 749.207 loss)
I0726 10:46:30.701706 27891 solver.cpp:238]     Train net output #34: loss40 = 746.63 (* 1 = 746.63 loss)
I0726 10:46:30.701716 27891 solver.cpp:238]     Train net output #35: loss41 = 784.235 (* 1 = 784.235 loss)
I0726 10:46:30.701727 27891 solver.cpp:238]     Train net output #36: loss42 = 761.159 (* 1 = 761.159 loss)
I0726 10:46:30.701738 27891 solver.cpp:238]     Train net output #37: loss43 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701750 27891 solver.cpp:238]     Train net output #38: loss44 = 756.323 (* 1 = 756.323 loss)
I0726 10:46:30.701758 27891 solver.cpp:238]     Train net output #39: loss45 = 761.443 (* 1 = 761.443 loss)
I0726 10:46:30.701764 27891 solver.cpp:238]     Train net output #40: loss46 = 761.033 (* 1 = 761.033 loss)
I0726 10:46:30.701771 27891 solver.cpp:238]     Train net output #41: loss47 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701776 27891 solver.cpp:238]     Train net output #42: loss48 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701782 27891 solver.cpp:238]     Train net output #43: loss49 = 789.399 (* 1 = 789.399 loss)
I0726 10:46:30.701789 27891 solver.cpp:238]     Train net output #44: loss5 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701795 27891 solver.cpp:238]     Train net output #45: loss50 = 815.269 (* 1 = 815.269 loss)
I0726 10:46:30.701802 27891 solver.cpp:238]     Train net output #46: loss51 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701807 27891 solver.cpp:238]     Train net output #47: loss52 = 772.353 (* 1 = 772.353 loss)
I0726 10:46:30.701814 27891 solver.cpp:238]     Train net output #48: loss53 = 749.029 (* 1 = 749.029 loss)
I0726 10:46:30.701820 27891 solver.cpp:238]     Train net output #49: loss54 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701827 27891 solver.cpp:238]     Train net output #50: loss55 = 755.701 (* 1 = 755.701 loss)
I0726 10:46:30.701833 27891 solver.cpp:238]     Train net output #51: loss56 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701839 27891 solver.cpp:238]     Train net output #52: loss57 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701845 27891 solver.cpp:238]     Train net output #53: loss58 = 765.883 (* 1 = 765.883 loss)
I0726 10:46:30.701851 27891 solver.cpp:238]     Train net output #54: loss59 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701858 27891 solver.cpp:238]     Train net output #55: loss6 = 785.585 (* 1 = 785.585 loss)
I0726 10:46:30.701864 27891 solver.cpp:238]     Train net output #56: loss60 = 830.443 (* 1 = 830.443 loss)
I0726 10:46:30.701870 27891 solver.cpp:238]     Train net output #57: loss61 = 749.533 (* 1 = 749.533 loss)
I0726 10:46:30.701876 27891 solver.cpp:238]     Train net output #58: loss62 = 751.934 (* 1 = 751.934 loss)
I0726 10:46:30.701882 27891 solver.cpp:238]     Train net output #59: loss63 = 803.605 (* 1 = 803.605 loss)
I0726 10:46:30.701889 27891 solver.cpp:238]     Train net output #60: loss64 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701894 27891 solver.cpp:238]     Train net output #61: loss7 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701900 27891 solver.cpp:238]     Train net output #62: loss8 = 767.353 (* 1 = 767.353 loss)
I0726 10:46:30.701907 27891 solver.cpp:238]     Train net output #63: loss9 = 749.197 (* 1 = 749.197 loss)
I0726 10:46:30.701915 27891 sgd_solver.cpp:105] Iteration 32400, lr = 1e-09
I0726 10:55:24.606319 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:55:24.607470 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:55:24.995839 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_37800.caffemodel
I0726 10:55:25.255964 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_37800.solverstate
I0726 10:55:25.345479 27891 solver.cpp:331] Iteration 37800, Testing net (#0)
I0726 10:55:40.731654 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:55:40.752189 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 10:55:41.195749 27891 solver.cpp:398]     Test net output #0: mae = 88.3075 (* 1 = 88.3075 loss)
I0726 10:55:41.195775 27891 solver.cpp:398]     Test net output #1: mse = 15649.2 (* 1 = 15649.2 loss)
I0726 10:55:41.320155 27891 solver.cpp:219] Iteration 37800 (9.80733 iter/s, 550.609s/5400 iters), loss = 45198.1
I0726 10:55:41.320202 27891 solver.cpp:238]     Train net output #0: loss1 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320212 27891 solver.cpp:238]     Train net output #1: loss10 = 714.827 (* 1 = 714.827 loss)
I0726 10:55:41.320221 27891 solver.cpp:238]     Train net output #2: loss11 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320226 27891 solver.cpp:238]     Train net output #3: loss12 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320231 27891 solver.cpp:238]     Train net output #4: loss13 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320236 27891 solver.cpp:238]     Train net output #5: loss14 = 720.947 (* 1 = 720.947 loss)
I0726 10:55:41.320242 27891 solver.cpp:238]     Train net output #6: loss15 = 705.535 (* 1 = 705.535 loss)
I0726 10:55:41.320248 27891 solver.cpp:238]     Train net output #7: loss16 = 725.687 (* 1 = 725.687 loss)
I0726 10:55:41.320255 27891 solver.cpp:238]     Train net output #8: loss17 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320261 27891 solver.cpp:238]     Train net output #9: loss18 = 711.905 (* 1 = 711.905 loss)
I0726 10:55:41.320267 27891 solver.cpp:238]     Train net output #10: loss19 = 732.015 (* 1 = 732.015 loss)
I0726 10:55:41.320273 27891 solver.cpp:238]     Train net output #11: loss2 = 708.29 (* 1 = 708.29 loss)
I0726 10:55:41.320278 27891 solver.cpp:238]     Train net output #12: loss20 = 751.078 (* 1 = 751.078 loss)
I0726 10:55:41.320284 27891 solver.cpp:238]     Train net output #13: loss21 = 706.348 (* 1 = 706.348 loss)
I0726 10:55:41.320291 27891 solver.cpp:238]     Train net output #14: loss22 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320297 27891 solver.cpp:238]     Train net output #15: loss23 = 692.347 (* 1 = 692.347 loss)
I0726 10:55:41.320302 27891 solver.cpp:238]     Train net output #16: loss24 = 694.248 (* 1 = 694.248 loss)
I0726 10:55:41.320308 27891 solver.cpp:238]     Train net output #17: loss25 = 717.937 (* 1 = 717.937 loss)
I0726 10:55:41.320314 27891 solver.cpp:238]     Train net output #18: loss26 = 696.433 (* 1 = 696.433 loss)
I0726 10:55:41.320320 27891 solver.cpp:238]     Train net output #19: loss27 = 692.812 (* 1 = 692.812 loss)
I0726 10:55:41.320327 27891 solver.cpp:238]     Train net output #20: loss28 = 695.957 (* 1 = 695.957 loss)
I0726 10:55:41.320333 27891 solver.cpp:238]     Train net output #21: loss29 = 729.124 (* 1 = 729.124 loss)
I0726 10:55:41.320339 27891 solver.cpp:238]     Train net output #22: loss3 = 709.417 (* 1 = 709.417 loss)
I0726 10:55:41.320344 27891 solver.cpp:238]     Train net output #23: loss30 = 735.758 (* 1 = 735.758 loss)
I0726 10:55:41.320350 27891 solver.cpp:238]     Train net output #24: loss31 = 698.157 (* 1 = 698.157 loss)
I0726 10:55:41.320356 27891 solver.cpp:238]     Train net output #25: loss32 = 714.323 (* 1 = 714.323 loss)
I0726 10:55:41.320363 27891 solver.cpp:238]     Train net output #26: loss33 = 717.913 (* 1 = 717.913 loss)
I0726 10:55:41.320374 27891 solver.cpp:238]     Train net output #27: loss34 = 735.894 (* 1 = 735.894 loss)
I0726 10:55:41.320381 27891 solver.cpp:238]     Train net output #28: loss35 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320387 27891 solver.cpp:238]     Train net output #29: loss36 = 714.824 (* 1 = 714.824 loss)
I0726 10:55:41.320432 27891 solver.cpp:238]     Train net output #30: loss37 = 700.472 (* 1 = 700.472 loss)
I0726 10:55:41.320439 27891 solver.cpp:238]     Train net output #31: loss38 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320446 27891 solver.cpp:238]     Train net output #32: loss39 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320451 27891 solver.cpp:238]     Train net output #33: loss4 = 692.335 (* 1 = 692.335 loss)
I0726 10:55:41.320461 27891 solver.cpp:238]     Train net output #34: loss40 = 688.019 (* 1 = 688.019 loss)
I0726 10:55:41.320471 27891 solver.cpp:238]     Train net output #35: loss41 = 721.895 (* 1 = 721.895 loss)
I0726 10:55:41.320479 27891 solver.cpp:238]     Train net output #36: loss42 = 700.683 (* 1 = 700.683 loss)
I0726 10:55:41.320489 27891 solver.cpp:238]     Train net output #37: loss43 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320499 27891 solver.cpp:238]     Train net output #38: loss44 = 699.66 (* 1 = 699.66 loss)
I0726 10:55:41.320510 27891 solver.cpp:238]     Train net output #39: loss45 = 704.204 (* 1 = 704.204 loss)
I0726 10:55:41.320521 27891 solver.cpp:238]     Train net output #40: loss46 = 701.625 (* 1 = 701.625 loss)
I0726 10:55:41.320528 27891 solver.cpp:238]     Train net output #41: loss47 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320534 27891 solver.cpp:238]     Train net output #42: loss48 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320541 27891 solver.cpp:238]     Train net output #43: loss49 = 726.533 (* 1 = 726.533 loss)
I0726 10:55:41.320549 27891 solver.cpp:238]     Train net output #44: loss5 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320555 27891 solver.cpp:238]     Train net output #45: loss50 = 746.106 (* 1 = 746.106 loss)
I0726 10:55:41.320561 27891 solver.cpp:238]     Train net output #46: loss51 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320569 27891 solver.cpp:238]     Train net output #47: loss52 = 709.694 (* 1 = 709.694 loss)
I0726 10:55:41.320576 27891 solver.cpp:238]     Train net output #48: loss53 = 691.275 (* 1 = 691.275 loss)
I0726 10:55:41.320583 27891 solver.cpp:238]     Train net output #49: loss54 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320590 27891 solver.cpp:238]     Train net output #50: loss55 = 699.299 (* 1 = 699.299 loss)
I0726 10:55:41.320597 27891 solver.cpp:238]     Train net output #51: loss56 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320605 27891 solver.cpp:238]     Train net output #52: loss57 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320611 27891 solver.cpp:238]     Train net output #53: loss58 = 709.459 (* 1 = 709.459 loss)
I0726 10:55:41.320617 27891 solver.cpp:238]     Train net output #54: loss59 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320624 27891 solver.cpp:238]     Train net output #55: loss6 = 722.538 (* 1 = 722.538 loss)
I0726 10:55:41.320631 27891 solver.cpp:238]     Train net output #56: loss60 = 765.69 (* 1 = 765.69 loss)
I0726 10:55:41.320638 27891 solver.cpp:238]     Train net output #57: loss61 = 692.654 (* 1 = 692.654 loss)
I0726 10:55:41.320646 27891 solver.cpp:238]     Train net output #58: loss62 = 694.831 (* 1 = 694.831 loss)
I0726 10:55:41.320652 27891 solver.cpp:238]     Train net output #59: loss63 = 740.993 (* 1 = 740.993 loss)
I0726 10:55:41.320659 27891 solver.cpp:238]     Train net output #60: loss64 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320667 27891 solver.cpp:238]     Train net output #61: loss7 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320673 27891 solver.cpp:238]     Train net output #62: loss8 = 704.316 (* 1 = 704.316 loss)
I0726 10:55:41.320679 27891 solver.cpp:238]     Train net output #63: loss9 = 692.318 (* 1 = 692.318 loss)
I0726 10:55:41.320686 27891 sgd_solver.cpp:105] Iteration 37800, lr = 1e-09
I0726 11:04:33.914950 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:04:33.916141 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:04:34.278579 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_43200.caffemodel
I0726 11:04:34.534641 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_43200.solverstate
I0726 11:04:34.619560 27891 solver.cpp:331] Iteration 43200, Testing net (#0)
I0726 11:04:50.273458 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:04:50.275163 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:04:50.751406 27891 solver.cpp:398]     Test net output #0: mae = 85.6841 (* 1 = 85.6841 loss)
I0726 11:04:50.751436 27891 solver.cpp:398]     Test net output #1: mse = 15072 (* 1 = 15072 loss)
I0726 11:04:50.877657 27891 solver.cpp:219] Iteration 43200 (9.82626 iter/s, 549.548s/5400 iters), loss = 42385.5
I0726 11:04:50.877710 27891 solver.cpp:238]     Train net output #0: loss1 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877722 27891 solver.cpp:238]     Train net output #1: loss10 = 671.486 (* 1 = 671.486 loss)
I0726 11:04:50.877732 27891 solver.cpp:238]     Train net output #2: loss11 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877741 27891 solver.cpp:238]     Train net output #3: loss12 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877751 27891 solver.cpp:238]     Train net output #4: loss13 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877761 27891 solver.cpp:238]     Train net output #5: loss14 = 677.795 (* 1 = 677.795 loss)
I0726 11:04:50.877771 27891 solver.cpp:238]     Train net output #6: loss15 = 661.598 (* 1 = 661.598 loss)
I0726 11:04:50.877780 27891 solver.cpp:238]     Train net output #7: loss16 = 679.816 (* 1 = 679.816 loss)
I0726 11:04:50.877790 27891 solver.cpp:238]     Train net output #8: loss17 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877799 27891 solver.cpp:238]     Train net output #9: loss18 = 664.841 (* 1 = 664.841 loss)
I0726 11:04:50.877810 27891 solver.cpp:238]     Train net output #10: loss19 = 685.312 (* 1 = 685.312 loss)
I0726 11:04:50.877820 27891 solver.cpp:238]     Train net output #11: loss2 = 664.23 (* 1 = 664.23 loss)
I0726 11:04:50.877828 27891 solver.cpp:238]     Train net output #12: loss20 = 706.687 (* 1 = 706.687 loss)
I0726 11:04:50.877843 27891 solver.cpp:238]     Train net output #13: loss21 = 661.304 (* 1 = 661.304 loss)
I0726 11:04:50.877852 27891 solver.cpp:238]     Train net output #14: loss22 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877862 27891 solver.cpp:238]     Train net output #15: loss23 = 650.027 (* 1 = 650.027 loss)
I0726 11:04:50.877871 27891 solver.cpp:238]     Train net output #16: loss24 = 652.01 (* 1 = 652.01 loss)
I0726 11:04:50.877882 27891 solver.cpp:238]     Train net output #17: loss25 = 673.907 (* 1 = 673.907 loss)
I0726 11:04:50.877890 27891 solver.cpp:238]     Train net output #18: loss26 = 653.979 (* 1 = 653.979 loss)
I0726 11:04:50.877900 27891 solver.cpp:238]     Train net output #19: loss27 = 649.789 (* 1 = 649.789 loss)
I0726 11:04:50.877909 27891 solver.cpp:238]     Train net output #20: loss28 = 652.466 (* 1 = 652.466 loss)
I0726 11:04:50.877919 27891 solver.cpp:238]     Train net output #21: loss29 = 681.949 (* 1 = 681.949 loss)
I0726 11:04:50.877929 27891 solver.cpp:238]     Train net output #22: loss3 = 663.323 (* 1 = 663.323 loss)
I0726 11:04:50.877938 27891 solver.cpp:238]     Train net output #23: loss30 = 687.998 (* 1 = 687.998 loss)
I0726 11:04:50.877948 27891 solver.cpp:238]     Train net output #24: loss31 = 655.847 (* 1 = 655.847 loss)
I0726 11:04:50.877959 27891 solver.cpp:238]     Train net output #25: loss32 = 668.875 (* 1 = 668.875 loss)
I0726 11:04:50.877967 27891 solver.cpp:238]     Train net output #26: loss33 = 673.592 (* 1 = 673.592 loss)
I0726 11:04:50.877977 27891 solver.cpp:238]     Train net output #27: loss34 = 688.836 (* 1 = 688.836 loss)
I0726 11:04:50.877987 27891 solver.cpp:238]     Train net output #28: loss35 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.877996 27891 solver.cpp:238]     Train net output #29: loss36 = 671.848 (* 1 = 671.848 loss)
I0726 11:04:50.878342 27891 solver.cpp:238]     Train net output #30: loss37 = 658.717 (* 1 = 658.717 loss)
I0726 11:04:50.878357 27891 solver.cpp:238]     Train net output #31: loss38 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878368 27891 solver.cpp:238]     Train net output #32: loss39 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878378 27891 solver.cpp:238]     Train net output #33: loss4 = 650.01 (* 1 = 650.01 loss)
I0726 11:04:50.878387 27891 solver.cpp:238]     Train net output #34: loss40 = 644.39 (* 1 = 644.39 loss)
I0726 11:04:50.878397 27891 solver.cpp:238]     Train net output #35: loss41 = 675.322 (* 1 = 675.322 loss)
I0726 11:04:50.878407 27891 solver.cpp:238]     Train net output #36: loss42 = 655.551 (* 1 = 655.551 loss)
I0726 11:04:50.878417 27891 solver.cpp:238]     Train net output #37: loss43 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878427 27891 solver.cpp:238]     Train net output #38: loss44 = 657.181 (* 1 = 657.181 loss)
I0726 11:04:50.878435 27891 solver.cpp:238]     Train net output #39: loss45 = 661.929 (* 1 = 661.929 loss)
I0726 11:04:50.878445 27891 solver.cpp:238]     Train net output #40: loss46 = 657.521 (* 1 = 657.521 loss)
I0726 11:04:50.878455 27891 solver.cpp:238]     Train net output #41: loss47 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878464 27891 solver.cpp:238]     Train net output #42: loss48 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878474 27891 solver.cpp:238]     Train net output #43: loss49 = 680.036 (* 1 = 680.036 loss)
I0726 11:04:50.878484 27891 solver.cpp:238]     Train net output #44: loss5 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878494 27891 solver.cpp:238]     Train net output #45: loss50 = 695.214 (* 1 = 695.214 loss)
I0726 11:04:50.878504 27891 solver.cpp:238]     Train net output #46: loss51 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878512 27891 solver.cpp:238]     Train net output #47: loss52 = 663.057 (* 1 = 663.057 loss)
I0726 11:04:50.878522 27891 solver.cpp:238]     Train net output #48: loss53 = 649.242 (* 1 = 649.242 loss)
I0726 11:04:50.878532 27891 solver.cpp:238]     Train net output #49: loss54 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878541 27891 solver.cpp:238]     Train net output #50: loss55 = 656.851 (* 1 = 656.851 loss)
I0726 11:04:50.878551 27891 solver.cpp:238]     Train net output #51: loss56 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878561 27891 solver.cpp:238]     Train net output #52: loss57 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878571 27891 solver.cpp:238]     Train net output #53: loss58 = 667.828 (* 1 = 667.828 loss)
I0726 11:04:50.878579 27891 solver.cpp:238]     Train net output #54: loss59 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878589 27891 solver.cpp:238]     Train net output #55: loss6 = 675.251 (* 1 = 675.251 loss)
I0726 11:04:50.878598 27891 solver.cpp:238]     Train net output #56: loss60 = 714.947 (* 1 = 714.947 loss)
I0726 11:04:50.878608 27891 solver.cpp:238]     Train net output #57: loss61 = 650.368 (* 1 = 650.368 loss)
I0726 11:04:50.878618 27891 solver.cpp:238]     Train net output #58: loss62 = 652.407 (* 1 = 652.407 loss)
I0726 11:04:50.878628 27891 solver.cpp:238]     Train net output #59: loss63 = 693.494 (* 1 = 693.494 loss)
I0726 11:04:50.878638 27891 solver.cpp:238]     Train net output #60: loss64 = 650.132 (* 1 = 650.132 loss)
I0726 11:04:50.878646 27891 solver.cpp:238]     Train net output #61: loss7 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878656 27891 solver.cpp:238]     Train net output #62: loss8 = 657.29 (* 1 = 657.29 loss)
I0726 11:04:50.878665 27891 solver.cpp:238]     Train net output #63: loss9 = 649.993 (* 1 = 649.993 loss)
I0726 11:04:50.878674 27891 sgd_solver.cpp:105] Iteration 43200, lr = 1e-09
I0726 11:13:44.240458 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:13:44.241958 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:13:44.637063 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_48600.caffemodel
I0726 11:13:44.866698 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_48600.solverstate
I0726 11:13:44.967581 27891 solver.cpp:331] Iteration 48600, Testing net (#0)
I0726 11:14:00.698277 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:14:00.701027 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:14:01.170450 27891 solver.cpp:398]     Test net output #0: mae = 84.3834 (* 1 = 84.3834 loss)
I0726 11:14:01.170476 27891 solver.cpp:398]     Test net output #1: mse = 14731.9 (* 1 = 14731.9 loss)
I0726 11:14:01.295397 27891 solver.cpp:219] Iteration 48600 (9.81091 iter/s, 550.408s/5400 iters), loss = 40688.4
I0726 11:14:01.295456 27891 solver.cpp:238]     Train net output #0: loss1 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295469 27891 solver.cpp:238]     Train net output #1: loss10 = 645.005 (* 1 = 645.005 loss)
I0726 11:14:01.295478 27891 solver.cpp:238]     Train net output #2: loss11 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295488 27891 solver.cpp:238]     Train net output #3: loss12 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295498 27891 solver.cpp:238]     Train net output #4: loss13 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295508 27891 solver.cpp:238]     Train net output #5: loss14 = 651.565 (* 1 = 651.565 loss)
I0726 11:14:01.295517 27891 solver.cpp:238]     Train net output #6: loss15 = 635.195 (* 1 = 635.195 loss)
I0726 11:14:01.295527 27891 solver.cpp:238]     Train net output #7: loss16 = 650.964 (* 1 = 650.964 loss)
I0726 11:14:01.295537 27891 solver.cpp:238]     Train net output #8: loss17 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295547 27891 solver.cpp:238]     Train net output #9: loss18 = 636.549 (* 1 = 636.549 loss)
I0726 11:14:01.295557 27891 solver.cpp:238]     Train net output #10: loss19 = 655.782 (* 1 = 655.782 loss)
I0726 11:14:01.295567 27891 solver.cpp:238]     Train net output #11: loss2 = 637.357 (* 1 = 637.357 loss)
I0726 11:14:01.295575 27891 solver.cpp:238]     Train net output #12: loss20 = 680.192 (* 1 = 680.192 loss)
I0726 11:14:01.295585 27891 solver.cpp:238]     Train net output #13: loss21 = 633.168 (* 1 = 633.168 loss)
I0726 11:14:01.295594 27891 solver.cpp:238]     Train net output #14: loss22 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295604 27891 solver.cpp:238]     Train net output #15: loss23 = 624.261 (* 1 = 624.261 loss)
I0726 11:14:01.295614 27891 solver.cpp:238]     Train net output #16: loss24 = 626.355 (* 1 = 626.355 loss)
I0726 11:14:01.295624 27891 solver.cpp:238]     Train net output #17: loss25 = 648.937 (* 1 = 648.937 loss)
I0726 11:14:01.295634 27891 solver.cpp:238]     Train net output #18: loss26 = 628.469 (* 1 = 628.469 loss)
I0726 11:14:01.295644 27891 solver.cpp:238]     Train net output #19: loss27 = 623.721 (* 1 = 623.721 loss)
I0726 11:14:01.295652 27891 solver.cpp:238]     Train net output #20: loss28 = 626.002 (* 1 = 626.002 loss)
I0726 11:14:01.295662 27891 solver.cpp:238]     Train net output #21: loss29 = 653.506 (* 1 = 653.506 loss)
I0726 11:14:01.295672 27891 solver.cpp:238]     Train net output #22: loss3 = 635.511 (* 1 = 635.511 loss)
I0726 11:14:01.295681 27891 solver.cpp:238]     Train net output #23: loss30 = 656.9 (* 1 = 656.9 loss)
I0726 11:14:01.295691 27891 solver.cpp:238]     Train net output #24: loss31 = 630.022 (* 1 = 630.022 loss)
I0726 11:14:01.295701 27891 solver.cpp:238]     Train net output #25: loss32 = 640.814 (* 1 = 640.814 loss)
I0726 11:14:01.295711 27891 solver.cpp:238]     Train net output #26: loss33 = 647.193 (* 1 = 647.193 loss)
I0726 11:14:01.295720 27891 solver.cpp:238]     Train net output #27: loss34 = 659.297 (* 1 = 659.297 loss)
I0726 11:14:01.295730 27891 solver.cpp:238]     Train net output #28: loss35 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295740 27891 solver.cpp:238]     Train net output #29: loss36 = 646.386 (* 1 = 646.386 loss)
I0726 11:14:01.295840 27891 solver.cpp:238]     Train net output #30: loss37 = 633.685 (* 1 = 633.685 loss)
I0726 11:14:01.295851 27891 solver.cpp:238]     Train net output #31: loss38 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295861 27891 solver.cpp:238]     Train net output #32: loss39 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295871 27891 solver.cpp:238]     Train net output #33: loss4 = 624.236 (* 1 = 624.236 loss)
I0726 11:14:01.295881 27891 solver.cpp:238]     Train net output #34: loss40 = 617.777 (* 1 = 617.777 loss)
I0726 11:14:01.295891 27891 solver.cpp:238]     Train net output #35: loss41 = 646.783 (* 1 = 646.783 loss)
I0726 11:14:01.295900 27891 solver.cpp:238]     Train net output #36: loss42 = 628.007 (* 1 = 628.007 loss)
I0726 11:14:01.295909 27891 solver.cpp:238]     Train net output #37: loss43 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295918 27891 solver.cpp:238]     Train net output #38: loss44 = 638.338 (* 1 = 638.338 loss)
I0726 11:14:01.295928 27891 solver.cpp:238]     Train net output #39: loss45 = 636.396 (* 1 = 636.396 loss)
I0726 11:14:01.295938 27891 solver.cpp:238]     Train net output #40: loss46 = 630.453 (* 1 = 630.453 loss)
I0726 11:14:01.295948 27891 solver.cpp:238]     Train net output #41: loss47 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295956 27891 solver.cpp:238]     Train net output #42: loss48 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295966 27891 solver.cpp:238]     Train net output #43: loss49 = 652.918 (* 1 = 652.918 loss)
I0726 11:14:01.295975 27891 solver.cpp:238]     Train net output #44: loss5 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.295985 27891 solver.cpp:238]     Train net output #45: loss50 = 664.492 (* 1 = 664.492 loss)
I0726 11:14:01.295995 27891 solver.cpp:238]     Train net output #46: loss51 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296005 27891 solver.cpp:238]     Train net output #47: loss52 = 634.854 (* 1 = 634.854 loss)
I0726 11:14:01.296015 27891 solver.cpp:238]     Train net output #48: loss53 = 624.075 (* 1 = 624.075 loss)
I0726 11:14:01.296023 27891 solver.cpp:238]     Train net output #49: loss54 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296033 27891 solver.cpp:238]     Train net output #50: loss55 = 630.58 (* 1 = 630.58 loss)
I0726 11:14:01.296042 27891 solver.cpp:238]     Train net output #51: loss56 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296052 27891 solver.cpp:238]     Train net output #52: loss57 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296061 27891 solver.cpp:238]     Train net output #53: loss58 = 642.608 (* 1 = 642.608 loss)
I0726 11:14:01.296072 27891 solver.cpp:238]     Train net output #54: loss59 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296082 27891 solver.cpp:238]     Train net output #55: loss6 = 645.998 (* 1 = 645.998 loss)
I0726 11:14:01.296090 27891 solver.cpp:238]     Train net output #56: loss60 = 682.194 (* 1 = 682.194 loss)
I0726 11:14:01.296100 27891 solver.cpp:238]     Train net output #57: loss61 = 624.614 (* 1 = 624.614 loss)
I0726 11:14:01.296109 27891 solver.cpp:238]     Train net output #58: loss62 = 626.776 (* 1 = 626.776 loss)
I0726 11:14:01.296119 27891 solver.cpp:238]     Train net output #59: loss63 = 663.948 (* 1 = 663.948 loss)
I0726 11:14:01.296139 27891 solver.cpp:238]     Train net output #60: loss64 = 625.029 (* 1 = 625.029 loss)
I0726 11:14:01.296147 27891 solver.cpp:238]     Train net output #61: loss7 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296157 27891 solver.cpp:238]     Train net output #62: loss8 = 630.235 (* 1 = 630.235 loss)
I0726 11:14:01.296166 27891 solver.cpp:238]     Train net output #63: loss9 = 624.22 (* 1 = 624.22 loss)
I0726 11:14:01.296175 27891 sgd_solver.cpp:105] Iteration 48600, lr = 1e-09
I0726 11:22:54.336776 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:22:54.340075 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:22:54.738476 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_54000.caffemodel
I0726 11:22:55.351594 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_54000.solverstate
I0726 11:22:55.435739 27891 solver.cpp:331] Iteration 54000, Testing net (#0)
I0726 11:23:10.692587 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:23:10.714215 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:23:11.169481 27891 solver.cpp:398]     Test net output #0: mae = 83.123 (* 1 = 83.123 loss)
I0726 11:23:11.169504 27891 solver.cpp:398]     Test net output #1: mse = 14407.7 (* 1 = 14407.7 loss)
I0726 11:23:11.294500 27891 solver.cpp:219] Iteration 54000 (9.81838 iter/s, 549.989s/5400 iters), loss = 39213.1
I0726 11:23:11.294556 27891 solver.cpp:238]     Train net output #0: loss1 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294569 27891 solver.cpp:238]     Train net output #1: loss10 = 621.803 (* 1 = 621.803 loss)
I0726 11:23:11.294579 27891 solver.cpp:238]     Train net output #2: loss11 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294589 27891 solver.cpp:238]     Train net output #3: loss12 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294597 27891 solver.cpp:238]     Train net output #4: loss13 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294607 27891 solver.cpp:238]     Train net output #5: loss14 = 627.793 (* 1 = 627.793 loss)
I0726 11:23:11.294617 27891 solver.cpp:238]     Train net output #6: loss15 = 611.887 (* 1 = 611.887 loss)
I0726 11:23:11.294626 27891 solver.cpp:238]     Train net output #7: loss16 = 626.121 (* 1 = 626.121 loss)
I0726 11:23:11.294636 27891 solver.cpp:238]     Train net output #8: loss17 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294646 27891 solver.cpp:238]     Train net output #9: loss18 = 612.344 (* 1 = 612.344 loss)
I0726 11:23:11.294656 27891 solver.cpp:238]     Train net output #10: loss19 = 629.215 (* 1 = 629.215 loss)
I0726 11:23:11.294665 27891 solver.cpp:238]     Train net output #11: loss2 = 614.398 (* 1 = 614.398 loss)
I0726 11:23:11.294674 27891 solver.cpp:238]     Train net output #12: loss20 = 656.692 (* 1 = 656.692 loss)
I0726 11:23:11.294684 27891 solver.cpp:238]     Train net output #13: loss21 = 608.572 (* 1 = 608.572 loss)
I0726 11:23:11.294693 27891 solver.cpp:238]     Train net output #14: loss22 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294703 27891 solver.cpp:238]     Train net output #15: loss23 = 601.909 (* 1 = 601.909 loss)
I0726 11:23:11.294713 27891 solver.cpp:238]     Train net output #16: loss24 = 604.149 (* 1 = 604.149 loss)
I0726 11:23:11.294723 27891 solver.cpp:238]     Train net output #17: loss25 = 626.893 (* 1 = 626.893 loss)
I0726 11:23:11.294731 27891 solver.cpp:238]     Train net output #18: loss26 = 606.379 (* 1 = 606.379 loss)
I0726 11:23:11.294741 27891 solver.cpp:238]     Train net output #19: loss27 = 601.425 (* 1 = 601.425 loss)
I0726 11:23:11.294750 27891 solver.cpp:238]     Train net output #20: loss28 = 603.12 (* 1 = 603.12 loss)
I0726 11:23:11.294760 27891 solver.cpp:238]     Train net output #21: loss29 = 630.549 (* 1 = 630.549 loss)
I0726 11:23:11.294770 27891 solver.cpp:238]     Train net output #22: loss3 = 611.249 (* 1 = 611.249 loss)
I0726 11:23:11.294780 27891 solver.cpp:238]     Train net output #23: loss30 = 629.086 (* 1 = 629.086 loss)
I0726 11:23:11.294790 27891 solver.cpp:238]     Train net output #24: loss31 = 607.303 (* 1 = 607.303 loss)
I0726 11:23:11.294800 27891 solver.cpp:238]     Train net output #25: loss32 = 617.084 (* 1 = 617.084 loss)
I0726 11:23:11.294808 27891 solver.cpp:238]     Train net output #26: loss33 = 624.225 (* 1 = 624.225 loss)
I0726 11:23:11.294818 27891 solver.cpp:238]     Train net output #27: loss34 = 633.414 (* 1 = 633.414 loss)
I0726 11:23:11.294828 27891 solver.cpp:238]     Train net output #28: loss35 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294837 27891 solver.cpp:238]     Train net output #29: loss36 = 623.374 (* 1 = 623.374 loss)
I0726 11:23:11.294894 27891 solver.cpp:238]     Train net output #30: loss37 = 611.458 (* 1 = 611.458 loss)
I0726 11:23:11.294904 27891 solver.cpp:238]     Train net output #31: loss38 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294914 27891 solver.cpp:238]     Train net output #32: loss39 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294924 27891 solver.cpp:238]     Train net output #33: loss4 = 601.838 (* 1 = 601.838 loss)
I0726 11:23:11.294934 27891 solver.cpp:238]     Train net output #34: loss40 = 594.849 (* 1 = 594.849 loss)
I0726 11:23:11.294944 27891 solver.cpp:238]     Train net output #35: loss41 = 623.311 (* 1 = 623.311 loss)
I0726 11:23:11.294952 27891 solver.cpp:238]     Train net output #36: loss42 = 604.375 (* 1 = 604.375 loss)
I0726 11:23:11.294961 27891 solver.cpp:238]     Train net output #37: loss43 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.294971 27891 solver.cpp:238]     Train net output #38: loss44 = 619.381 (* 1 = 619.381 loss)
I0726 11:23:11.294981 27891 solver.cpp:238]     Train net output #39: loss45 = 613.738 (* 1 = 613.738 loss)
I0726 11:23:11.294991 27891 solver.cpp:238]     Train net output #40: loss46 = 607.185 (* 1 = 607.185 loss)
I0726 11:23:11.294999 27891 solver.cpp:238]     Train net output #41: loss47 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295008 27891 solver.cpp:238]     Train net output #42: loss48 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295018 27891 solver.cpp:238]     Train net output #43: loss49 = 629.841 (* 1 = 629.841 loss)
I0726 11:23:11.295027 27891 solver.cpp:238]     Train net output #44: loss5 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295037 27891 solver.cpp:238]     Train net output #45: loss50 = 637.754 (* 1 = 637.754 loss)
I0726 11:23:11.295047 27891 solver.cpp:238]     Train net output #46: loss51 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295056 27891 solver.cpp:238]     Train net output #47: loss52 = 610.311 (* 1 = 610.311 loss)
I0726 11:23:11.295065 27891 solver.cpp:238]     Train net output #48: loss53 = 602.395 (* 1 = 602.395 loss)
I0726 11:23:11.295075 27891 solver.cpp:238]     Train net output #49: loss54 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295084 27891 solver.cpp:238]     Train net output #50: loss55 = 607.53 (* 1 = 607.53 loss)
I0726 11:23:11.295094 27891 solver.cpp:238]     Train net output #51: loss56 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295104 27891 solver.cpp:238]     Train net output #52: loss57 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295112 27891 solver.cpp:238]     Train net output #53: loss58 = 620.643 (* 1 = 620.643 loss)
I0726 11:23:11.295122 27891 solver.cpp:238]     Train net output #54: loss59 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295131 27891 solver.cpp:238]     Train net output #55: loss6 = 620.437 (* 1 = 620.437 loss)
I0726 11:23:11.295141 27891 solver.cpp:238]     Train net output #56: loss60 = 653.753 (* 1 = 653.753 loss)
I0726 11:23:11.295150 27891 solver.cpp:238]     Train net output #57: loss61 = 602.132 (* 1 = 602.132 loss)
I0726 11:23:11.295161 27891 solver.cpp:238]     Train net output #58: loss62 = 604.288 (* 1 = 604.288 loss)
I0726 11:23:11.295169 27891 solver.cpp:238]     Train net output #59: loss63 = 637.45 (* 1 = 637.45 loss)
I0726 11:23:11.295179 27891 solver.cpp:238]     Train net output #60: loss64 = 603.641 (* 1 = 603.641 loss)
I0726 11:23:11.295188 27891 solver.cpp:238]     Train net output #61: loss7 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295197 27891 solver.cpp:238]     Train net output #62: loss8 = 607.342 (* 1 = 607.342 loss)
I0726 11:23:11.295207 27891 solver.cpp:238]     Train net output #63: loss9 = 601.825 (* 1 = 601.825 loss)
I0726 11:23:11.295217 27891 sgd_solver.cpp:105] Iteration 54000, lr = 1e-09
I0726 11:32:05.619524 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:32:05.622568 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:32:06.020238 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_59400.caffemodel
I0726 11:32:06.287009 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_59400.solverstate
I0726 11:32:06.372675 27891 solver.cpp:331] Iteration 59400, Testing net (#0)
I0726 11:32:21.560181 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:32:21.580761 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:32:22.024601 27891 solver.cpp:398]     Test net output #0: mae = 82.6481 (* 1 = 82.6481 loss)
I0726 11:32:22.024626 27891 solver.cpp:398]     Test net output #1: mse = 14228.9 (* 1 = 14228.9 loss)
I0726 11:32:22.149545 27891 solver.cpp:219] Iteration 59400 (9.80313 iter/s, 550.845s/5400 iters), loss = 38104.5
I0726 11:32:22.149592 27891 solver.cpp:238]     Train net output #0: loss1 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149602 27891 solver.cpp:238]     Train net output #1: loss10 = 604.015 (* 1 = 604.015 loss)
I0726 11:32:22.149610 27891 solver.cpp:238]     Train net output #2: loss11 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149616 27891 solver.cpp:238]     Train net output #3: loss12 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149622 27891 solver.cpp:238]     Train net output #4: loss13 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149629 27891 solver.cpp:238]     Train net output #5: loss14 = 610.151 (* 1 = 610.151 loss)
I0726 11:32:22.149636 27891 solver.cpp:238]     Train net output #6: loss15 = 594.518 (* 1 = 594.518 loss)
I0726 11:32:22.149642 27891 solver.cpp:238]     Train net output #7: loss16 = 607.417 (* 1 = 607.417 loss)
I0726 11:32:22.149649 27891 solver.cpp:238]     Train net output #8: loss17 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149657 27891 solver.cpp:238]     Train net output #9: loss18 = 595.033 (* 1 = 595.033 loss)
I0726 11:32:22.149662 27891 solver.cpp:238]     Train net output #10: loss19 = 608.379 (* 1 = 608.379 loss)
I0726 11:32:22.149669 27891 solver.cpp:238]     Train net output #11: loss2 = 597.256 (* 1 = 597.256 loss)
I0726 11:32:22.149675 27891 solver.cpp:238]     Train net output #12: loss20 = 639.287 (* 1 = 639.287 loss)
I0726 11:32:22.149682 27891 solver.cpp:238]     Train net output #13: loss21 = 590.139 (* 1 = 590.139 loss)
I0726 11:32:22.149688 27891 solver.cpp:238]     Train net output #14: loss22 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149695 27891 solver.cpp:238]     Train net output #15: loss23 = 585.206 (* 1 = 585.206 loss)
I0726 11:32:22.149703 27891 solver.cpp:238]     Train net output #16: loss24 = 587.647 (* 1 = 587.647 loss)
I0726 11:32:22.149709 27891 solver.cpp:238]     Train net output #17: loss25 = 610.406 (* 1 = 610.406 loss)
I0726 11:32:22.149715 27891 solver.cpp:238]     Train net output #18: loss26 = 589.927 (* 1 = 589.927 loss)
I0726 11:32:22.149722 27891 solver.cpp:238]     Train net output #19: loss27 = 584.795 (* 1 = 584.795 loss)
I0726 11:32:22.149729 27891 solver.cpp:238]     Train net output #20: loss28 = 586.112 (* 1 = 586.112 loss)
I0726 11:32:22.149735 27891 solver.cpp:238]     Train net output #21: loss29 = 613.585 (* 1 = 613.585 loss)
I0726 11:32:22.149741 27891 solver.cpp:238]     Train net output #22: loss3 = 593.717 (* 1 = 593.717 loss)
I0726 11:32:22.149749 27891 solver.cpp:238]     Train net output #23: loss30 = 607.46 (* 1 = 607.46 loss)
I0726 11:32:22.149755 27891 solver.cpp:238]     Train net output #24: loss31 = 590.346 (* 1 = 590.346 loss)
I0726 11:32:22.149761 27891 solver.cpp:238]     Train net output #25: loss32 = 599.73 (* 1 = 599.73 loss)
I0726 11:32:22.149768 27891 solver.cpp:238]     Train net output #26: loss33 = 607.846 (* 1 = 607.846 loss)
I0726 11:32:22.149775 27891 solver.cpp:238]     Train net output #27: loss34 = 613.931 (* 1 = 613.931 loss)
I0726 11:32:22.149780 27891 solver.cpp:238]     Train net output #28: loss35 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149787 27891 solver.cpp:238]     Train net output #29: loss36 = 605.575 (* 1 = 605.575 loss)
I0726 11:32:22.149835 27891 solver.cpp:238]     Train net output #30: loss37 = 595.018 (* 1 = 595.018 loss)
I0726 11:32:22.149843 27891 solver.cpp:238]     Train net output #31: loss38 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149850 27891 solver.cpp:238]     Train net output #32: loss39 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149858 27891 solver.cpp:238]     Train net output #33: loss4 = 584.98 (* 1 = 584.98 loss)
I0726 11:32:22.149874 27891 solver.cpp:238]     Train net output #34: loss40 = 577.557 (* 1 = 577.557 loss)
I0726 11:32:22.149881 27891 solver.cpp:238]     Train net output #35: loss41 = 606.242 (* 1 = 606.242 loss)
I0726 11:32:22.149888 27891 solver.cpp:238]     Train net output #36: loss42 = 586.95 (* 1 = 586.95 loss)
I0726 11:32:22.149896 27891 solver.cpp:238]     Train net output #37: loss43 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149904 27891 solver.cpp:238]     Train net output #38: loss44 = 603.471 (* 1 = 603.471 loss)
I0726 11:32:22.149914 27891 solver.cpp:238]     Train net output #39: loss45 = 596.418 (* 1 = 596.418 loss)
I0726 11:32:22.149924 27891 solver.cpp:238]     Train net output #40: loss46 = 589.43 (* 1 = 589.43 loss)
I0726 11:32:22.149933 27891 solver.cpp:238]     Train net output #41: loss47 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149943 27891 solver.cpp:238]     Train net output #42: loss48 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149958 27891 solver.cpp:238]     Train net output #43: loss49 = 612.451 (* 1 = 612.451 loss)
I0726 11:32:22.149971 27891 solver.cpp:238]     Train net output #44: loss5 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149981 27891 solver.cpp:238]     Train net output #45: loss50 = 618.18 (* 1 = 618.18 loss)
I0726 11:32:22.149987 27891 solver.cpp:238]     Train net output #46: loss51 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.149994 27891 solver.cpp:238]     Train net output #47: loss52 = 592.359 (* 1 = 592.359 loss)
I0726 11:32:22.150002 27891 solver.cpp:238]     Train net output #48: loss53 = 586.149 (* 1 = 586.149 loss)
I0726 11:32:22.150008 27891 solver.cpp:238]     Train net output #49: loss54 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150015 27891 solver.cpp:238]     Train net output #50: loss55 = 590.378 (* 1 = 590.378 loss)
I0726 11:32:22.150022 27891 solver.cpp:238]     Train net output #51: loss56 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150028 27891 solver.cpp:238]     Train net output #52: loss57 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150037 27891 solver.cpp:238]     Train net output #53: loss58 = 604.529 (* 1 = 604.529 loss)
I0726 11:32:22.150043 27891 solver.cpp:238]     Train net output #54: loss59 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150050 27891 solver.cpp:238]     Train net output #55: loss6 = 601.118 (* 1 = 601.118 loss)
I0726 11:32:22.150056 27891 solver.cpp:238]     Train net output #56: loss60 = 632.833 (* 1 = 632.833 loss)
I0726 11:32:22.150063 27891 solver.cpp:238]     Train net output #57: loss61 = 586.094 (* 1 = 586.094 loss)
I0726 11:32:22.150069 27891 solver.cpp:238]     Train net output #58: loss62 = 587.43 (* 1 = 587.43 loss)
I0726 11:32:22.150075 27891 solver.cpp:238]     Train net output #59: loss63 = 617.827 (* 1 = 617.827 loss)
I0726 11:32:22.150082 27891 solver.cpp:238]     Train net output #60: loss64 = 587.701 (* 1 = 587.701 loss)
I0726 11:32:22.150089 27891 solver.cpp:238]     Train net output #61: loss7 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150095 27891 solver.cpp:238]     Train net output #62: loss8 = 590.961 (* 1 = 590.961 loss)
I0726 11:32:22.150102 27891 solver.cpp:238]     Train net output #63: loss9 = 584.969 (* 1 = 584.969 loss)
I0726 11:32:22.150110 27891 sgd_solver.cpp:105] Iteration 59400, lr = 1e-09
I0726 11:41:26.294567 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:41:26.297674 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:41:26.693085 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_64800.caffemodel
I0726 11:41:26.932020 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_64800.solverstate
I0726 11:41:27.034788 27891 solver.cpp:331] Iteration 64800, Testing net (#0)
I0726 11:41:42.214249 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:41:42.256678 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:41:42.679476 27891 solver.cpp:398]     Test net output #0: mae = 81.5854 (* 1 = 81.5854 loss)
I0726 11:41:42.679500 27891 solver.cpp:398]     Test net output #1: mse = 13999 (* 1 = 13999 loss)
I0726 11:41:42.803789 27891 solver.cpp:219] Iteration 64800 (9.63179 iter/s, 560.644s/5400 iters), loss = 37496.1
I0726 11:41:42.803831 27891 solver.cpp:238]     Train net output #0: loss1 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803843 27891 solver.cpp:238]     Train net output #1: loss10 = 594.551 (* 1 = 594.551 loss)
I0726 11:41:42.803850 27891 solver.cpp:238]     Train net output #2: loss11 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803858 27891 solver.cpp:238]     Train net output #3: loss12 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803865 27891 solver.cpp:238]     Train net output #4: loss13 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803874 27891 solver.cpp:238]     Train net output #5: loss14 = 599.257 (* 1 = 599.257 loss)
I0726 11:41:42.803881 27891 solver.cpp:238]     Train net output #6: loss15 = 585.493 (* 1 = 585.493 loss)
I0726 11:41:42.803889 27891 solver.cpp:238]     Train net output #7: loss16 = 597.35 (* 1 = 597.35 loss)
I0726 11:41:42.803896 27891 solver.cpp:238]     Train net output #8: loss17 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803905 27891 solver.cpp:238]     Train net output #9: loss18 = 586.372 (* 1 = 586.372 loss)
I0726 11:41:42.803913 27891 solver.cpp:238]     Train net output #10: loss19 = 596.489 (* 1 = 596.489 loss)
I0726 11:41:42.803920 27891 solver.cpp:238]     Train net output #11: loss2 = 588.261 (* 1 = 588.261 loss)
I0726 11:41:42.803928 27891 solver.cpp:238]     Train net output #12: loss20 = 629.175 (* 1 = 629.175 loss)
I0726 11:41:42.803936 27891 solver.cpp:238]     Train net output #13: loss21 = 580.429 (* 1 = 580.429 loss)
I0726 11:41:42.803944 27891 solver.cpp:238]     Train net output #14: loss22 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.803952 27891 solver.cpp:238]     Train net output #15: loss23 = 576.227 (* 1 = 576.227 loss)
I0726 11:41:42.803959 27891 solver.cpp:238]     Train net output #16: loss24 = 578.425 (* 1 = 578.425 loss)
I0726 11:41:42.803966 27891 solver.cpp:238]     Train net output #17: loss25 = 602.412 (* 1 = 602.412 loss)
I0726 11:41:42.803972 27891 solver.cpp:238]     Train net output #18: loss26 = 581.183 (* 1 = 581.183 loss)
I0726 11:41:42.803977 27891 solver.cpp:238]     Train net output #19: loss27 = 575.472 (* 1 = 575.472 loss)
I0726 11:41:42.803983 27891 solver.cpp:238]     Train net output #20: loss28 = 577.541 (* 1 = 577.541 loss)
I0726 11:41:42.803990 27891 solver.cpp:238]     Train net output #21: loss29 = 604.406 (* 1 = 604.406 loss)
I0726 11:41:42.803997 27891 solver.cpp:238]     Train net output #22: loss3 = 584.959 (* 1 = 584.959 loss)
I0726 11:41:42.804003 27891 solver.cpp:238]     Train net output #23: loss30 = 594.849 (* 1 = 594.849 loss)
I0726 11:41:42.804008 27891 solver.cpp:238]     Train net output #24: loss31 = 580.532 (* 1 = 580.532 loss)
I0726 11:41:42.804014 27891 solver.cpp:238]     Train net output #25: loss32 = 590.499 (* 1 = 590.499 loss)
I0726 11:41:42.804020 27891 solver.cpp:238]     Train net output #26: loss33 = 599.061 (* 1 = 599.061 loss)
I0726 11:41:42.804026 27891 solver.cpp:238]     Train net output #27: loss34 = 602.535 (* 1 = 602.535 loss)
I0726 11:41:42.804033 27891 solver.cpp:238]     Train net output #28: loss35 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804039 27891 solver.cpp:238]     Train net output #29: loss36 = 596.093 (* 1 = 596.093 loss)
I0726 11:41:42.804082 27891 solver.cpp:238]     Train net output #30: loss37 = 586.435 (* 1 = 586.435 loss)
I0726 11:41:42.804093 27891 solver.cpp:238]     Train net output #31: loss38 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804105 27891 solver.cpp:238]     Train net output #32: loss39 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804113 27891 solver.cpp:238]     Train net output #33: loss4 = 575.634 (* 1 = 575.634 loss)
I0726 11:41:42.804121 27891 solver.cpp:238]     Train net output #34: loss40 = 567.929 (* 1 = 567.929 loss)
I0726 11:41:42.804127 27891 solver.cpp:238]     Train net output #35: loss41 = 596.758 (* 1 = 596.758 loss)
I0726 11:41:42.804133 27891 solver.cpp:238]     Train net output #36: loss42 = 577.61 (* 1 = 577.61 loss)
I0726 11:41:42.804138 27891 solver.cpp:238]     Train net output #37: loss43 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804144 27891 solver.cpp:238]     Train net output #38: loss44 = 595.116 (* 1 = 595.116 loss)
I0726 11:41:42.804150 27891 solver.cpp:238]     Train net output #39: loss45 = 587.316 (* 1 = 587.316 loss)
I0726 11:41:42.804157 27891 solver.cpp:238]     Train net output #40: loss46 = 580.487 (* 1 = 580.487 loss)
I0726 11:41:42.804162 27891 solver.cpp:238]     Train net output #41: loss47 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804168 27891 solver.cpp:238]     Train net output #42: loss48 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804174 27891 solver.cpp:238]     Train net output #43: loss49 = 603.531 (* 1 = 603.531 loss)
I0726 11:41:42.804180 27891 solver.cpp:238]     Train net output #44: loss5 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804185 27891 solver.cpp:238]     Train net output #45: loss50 = 606.897 (* 1 = 606.897 loss)
I0726 11:41:42.804191 27891 solver.cpp:238]     Train net output #46: loss51 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804198 27891 solver.cpp:238]     Train net output #47: loss52 = 582.646 (* 1 = 582.646 loss)
I0726 11:41:42.804203 27891 solver.cpp:238]     Train net output #48: loss53 = 577.431 (* 1 = 577.431 loss)
I0726 11:41:42.804209 27891 solver.cpp:238]     Train net output #49: loss54 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804215 27891 solver.cpp:238]     Train net output #50: loss55 = 580.771 (* 1 = 580.771 loss)
I0726 11:41:42.804221 27891 solver.cpp:238]     Train net output #51: loss56 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804229 27891 solver.cpp:238]     Train net output #52: loss57 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804234 27891 solver.cpp:238]     Train net output #53: loss58 = 596.3 (* 1 = 596.3 loss)
I0726 11:41:42.804240 27891 solver.cpp:238]     Train net output #54: loss59 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804246 27891 solver.cpp:238]     Train net output #55: loss6 = 590.859 (* 1 = 590.859 loss)
I0726 11:41:42.804251 27891 solver.cpp:238]     Train net output #56: loss60 = 620.645 (* 1 = 620.645 loss)
I0726 11:41:42.804257 27891 solver.cpp:238]     Train net output #57: loss61 = 575.629 (* 1 = 575.629 loss)
I0726 11:41:42.804263 27891 solver.cpp:238]     Train net output #58: loss62 = 578.336 (* 1 = 578.336 loss)
I0726 11:41:42.804270 27891 solver.cpp:238]     Train net output #59: loss63 = 607.471 (* 1 = 607.471 loss)
I0726 11:41:42.804275 27891 solver.cpp:238]     Train net output #60: loss64 = 579.05 (* 1 = 579.05 loss)
I0726 11:41:42.804281 27891 solver.cpp:238]     Train net output #61: loss7 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804287 27891 solver.cpp:238]     Train net output #62: loss8 = 582.47 (* 1 = 582.47 loss)
I0726 11:41:42.804292 27891 solver.cpp:238]     Train net output #63: loss9 = 575.615 (* 1 = 575.615 loss)
I0726 11:41:42.804298 27891 sgd_solver.cpp:105] Iteration 64800, lr = 1e-09
I0726 11:50:44.323721 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:50:44.324841 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:50:44.711786 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_70200.caffemodel
I0726 11:50:44.935971 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_70200.solverstate
I0726 11:50:45.018807 27891 solver.cpp:331] Iteration 70200, Testing net (#0)
I0726 11:51:00.234213 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:51:00.353794 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 11:51:00.699791 27891 solver.cpp:398]     Test net output #0: mae = 81.5715 (* 1 = 81.5715 loss)
I0726 11:51:00.699818 27891 solver.cpp:398]     Test net output #1: mse = 13959.3 (* 1 = 13959.3 loss)
I0726 11:51:00.824636 27891 solver.cpp:219] Iteration 70200 (9.67724 iter/s, 558.01s/5400 iters), loss = 37338.2
I0726 11:51:00.824681 27891 solver.cpp:238]     Train net output #0: loss1 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824690 27891 solver.cpp:238]     Train net output #1: loss10 = 591.522 (* 1 = 591.522 loss)
I0726 11:51:00.824697 27891 solver.cpp:238]     Train net output #2: loss11 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824703 27891 solver.cpp:238]     Train net output #3: loss12 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824709 27891 solver.cpp:238]     Train net output #4: loss13 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824715 27891 solver.cpp:238]     Train net output #5: loss14 = 594.805 (* 1 = 594.805 loss)
I0726 11:51:00.824723 27891 solver.cpp:238]     Train net output #6: loss15 = 583.003 (* 1 = 583.003 loss)
I0726 11:51:00.824728 27891 solver.cpp:238]     Train net output #7: loss16 = 593.275 (* 1 = 593.275 loss)
I0726 11:51:00.824734 27891 solver.cpp:238]     Train net output #8: loss17 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824740 27891 solver.cpp:238]     Train net output #9: loss18 = 584.597 (* 1 = 584.597 loss)
I0726 11:51:00.824746 27891 solver.cpp:238]     Train net output #10: loss19 = 591.585 (* 1 = 591.585 loss)
I0726 11:51:00.824753 27891 solver.cpp:238]     Train net output #11: loss2 = 585.795 (* 1 = 585.795 loss)
I0726 11:51:00.824760 27891 solver.cpp:238]     Train net output #12: loss20 = 626.237 (* 1 = 626.237 loss)
I0726 11:51:00.824767 27891 solver.cpp:238]     Train net output #13: loss21 = 577.94 (* 1 = 577.94 loss)
I0726 11:51:00.824774 27891 solver.cpp:238]     Train net output #14: loss22 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824779 27891 solver.cpp:238]     Train net output #15: loss23 = 573.851 (* 1 = 573.851 loss)
I0726 11:51:00.824786 27891 solver.cpp:238]     Train net output #16: loss24 = 576.081 (* 1 = 576.081 loss)
I0726 11:51:00.824792 27891 solver.cpp:238]     Train net output #17: loss25 = 601.365 (* 1 = 601.365 loss)
I0726 11:51:00.824798 27891 solver.cpp:238]     Train net output #18: loss26 = 578.941 (* 1 = 578.941 loss)
I0726 11:51:00.824805 27891 solver.cpp:238]     Train net output #19: loss27 = 572.709 (* 1 = 572.709 loss)
I0726 11:51:00.824811 27891 solver.cpp:238]     Train net output #20: loss28 = 575.817 (* 1 = 575.817 loss)
I0726 11:51:00.824817 27891 solver.cpp:238]     Train net output #21: loss29 = 602.953 (* 1 = 602.953 loss)
I0726 11:51:00.824825 27891 solver.cpp:238]     Train net output #22: loss3 = 582.9 (* 1 = 582.9 loss)
I0726 11:51:00.824831 27891 solver.cpp:238]     Train net output #23: loss30 = 589.345 (* 1 = 589.345 loss)
I0726 11:51:00.824837 27891 solver.cpp:238]     Train net output #24: loss31 = 577.368 (* 1 = 577.368 loss)
I0726 11:51:00.824843 27891 solver.cpp:238]     Train net output #25: loss32 = 587.698 (* 1 = 587.698 loss)
I0726 11:51:00.824849 27891 solver.cpp:238]     Train net output #26: loss33 = 597.128 (* 1 = 597.128 loss)
I0726 11:51:00.824856 27891 solver.cpp:238]     Train net output #27: loss34 = 598.167 (* 1 = 598.167 loss)
I0726 11:51:00.824862 27891 solver.cpp:238]     Train net output #28: loss35 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824868 27891 solver.cpp:238]     Train net output #29: loss36 = 592.811 (* 1 = 592.811 loss)
I0726 11:51:00.824915 27891 solver.cpp:238]     Train net output #30: loss37 = 584.532 (* 1 = 584.532 loss)
I0726 11:51:00.824928 27891 solver.cpp:238]     Train net output #31: loss38 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824937 27891 solver.cpp:238]     Train net output #32: loss39 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.824949 27891 solver.cpp:238]     Train net output #33: loss4 = 577.645 (* 1 = 577.645 loss)
I0726 11:51:00.824959 27891 solver.cpp:238]     Train net output #34: loss40 = 564.988 (* 1 = 564.988 loss)
I0726 11:51:00.824968 27891 solver.cpp:238]     Train net output #35: loss41 = 594.335 (* 1 = 594.335 loss)
I0726 11:51:00.824978 27891 solver.cpp:238]     Train net output #36: loss42 = 574.874 (* 1 = 574.874 loss)
I0726 11:51:00.824988 27891 solver.cpp:238]     Train net output #37: loss43 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825000 27891 solver.cpp:238]     Train net output #38: loss44 = 592.817 (* 1 = 592.817 loss)
I0726 11:51:00.825011 27891 solver.cpp:238]     Train net output #39: loss45 = 584.633 (* 1 = 584.633 loss)
I0726 11:51:00.825019 27891 solver.cpp:238]     Train net output #40: loss46 = 578.04 (* 1 = 578.04 loss)
I0726 11:51:00.825026 27891 solver.cpp:238]     Train net output #41: loss47 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825031 27891 solver.cpp:238]     Train net output #42: loss48 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825038 27891 solver.cpp:238]     Train net output #43: loss49 = 601.618 (* 1 = 601.618 loss)
I0726 11:51:00.825044 27891 solver.cpp:238]     Train net output #44: loss5 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825052 27891 solver.cpp:238]     Train net output #45: loss50 = 602.867 (* 1 = 602.867 loss)
I0726 11:51:00.825057 27891 solver.cpp:238]     Train net output #46: loss51 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825063 27891 solver.cpp:238]     Train net output #47: loss52 = 589.189 (* 1 = 589.189 loss)
I0726 11:51:00.825070 27891 solver.cpp:238]     Train net output #48: loss53 = 574.956 (* 1 = 574.956 loss)
I0726 11:51:00.825076 27891 solver.cpp:238]     Train net output #49: loss54 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825083 27891 solver.cpp:238]     Train net output #50: loss55 = 578.122 (* 1 = 578.122 loss)
I0726 11:51:00.825089 27891 solver.cpp:238]     Train net output #51: loss56 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825095 27891 solver.cpp:238]     Train net output #52: loss57 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825101 27891 solver.cpp:238]     Train net output #53: loss58 = 595.045 (* 1 = 595.045 loss)
I0726 11:51:00.825107 27891 solver.cpp:238]     Train net output #54: loss59 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825114 27891 solver.cpp:238]     Train net output #55: loss6 = 586.569 (* 1 = 586.569 loss)
I0726 11:51:00.825120 27891 solver.cpp:238]     Train net output #56: loss60 = 615.683 (* 1 = 615.683 loss)
I0726 11:51:00.825127 27891 solver.cpp:238]     Train net output #57: loss61 = 572.944 (* 1 = 572.944 loss)
I0726 11:51:00.825134 27891 solver.cpp:238]     Train net output #58: loss62 = 575.823 (* 1 = 575.823 loss)
I0726 11:51:00.825139 27891 solver.cpp:238]     Train net output #59: loss63 = 603.482 (* 1 = 603.482 loss)
I0726 11:51:00.825146 27891 solver.cpp:238]     Train net output #60: loss64 = 576.741 (* 1 = 576.741 loss)
I0726 11:51:00.825152 27891 solver.cpp:238]     Train net output #61: loss7 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825160 27891 solver.cpp:238]     Train net output #62: loss8 = 580.528 (* 1 = 580.528 loss)
I0726 11:51:00.825165 27891 solver.cpp:238]     Train net output #63: loss9 = 572.882 (* 1 = 572.882 loss)
I0726 11:51:00.825172 27891 sgd_solver.cpp:105] Iteration 70200, lr = 1e-09
I0726 12:00:04.314093 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:00:04.315484 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:00:04.714833 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_75600.caffemodel
I0726 12:00:04.962258 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_75600.solverstate
I0726 12:00:05.045241 27891 solver.cpp:331] Iteration 75600, Testing net (#0)
I0726 12:00:20.253417 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:00:20.280030 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:00:20.718180 27891 solver.cpp:398]     Test net output #0: mae = 80.8376 (* 1 = 80.8376 loss)
I0726 12:00:20.718207 27891 solver.cpp:398]     Test net output #1: mse = 13830.1 (* 1 = 13830.1 loss)
I0726 12:00:20.842857 27891 solver.cpp:219] Iteration 75600 (9.64272 iter/s, 560.008s/5400 iters), loss = 36795.1
I0726 12:00:20.842896 27891 solver.cpp:238]     Train net output #0: loss1 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.842906 27891 solver.cpp:238]     Train net output #1: loss10 = 582.581 (* 1 = 582.581 loss)
I0726 12:00:20.842913 27891 solver.cpp:238]     Train net output #2: loss11 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.842919 27891 solver.cpp:238]     Train net output #3: loss12 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.842926 27891 solver.cpp:238]     Train net output #4: loss13 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.842932 27891 solver.cpp:238]     Train net output #5: loss14 = 584.726 (* 1 = 584.726 loss)
I0726 12:00:20.842941 27891 solver.cpp:238]     Train net output #6: loss15 = 574.911 (* 1 = 574.911 loss)
I0726 12:00:20.842948 27891 solver.cpp:238]     Train net output #7: loss16 = 583.334 (* 1 = 583.334 loss)
I0726 12:00:20.842955 27891 solver.cpp:238]     Train net output #8: loss17 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.842962 27891 solver.cpp:238]     Train net output #9: loss18 = 576.72 (* 1 = 576.72 loss)
I0726 12:00:20.842968 27891 solver.cpp:238]     Train net output #10: loss19 = 581.403 (* 1 = 581.403 loss)
I0726 12:00:20.842975 27891 solver.cpp:238]     Train net output #11: loss2 = 577.647 (* 1 = 577.647 loss)
I0726 12:00:20.842981 27891 solver.cpp:238]     Train net output #12: loss20 = 616.816 (* 1 = 616.816 loss)
I0726 12:00:20.842988 27891 solver.cpp:238]     Train net output #13: loss21 = 569.269 (* 1 = 569.269 loss)
I0726 12:00:20.842995 27891 solver.cpp:238]     Train net output #14: loss22 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843011 27891 solver.cpp:238]     Train net output #15: loss23 = 566.015 (* 1 = 566.015 loss)
I0726 12:00:20.843019 27891 solver.cpp:238]     Train net output #16: loss24 = 568.35 (* 1 = 568.35 loss)
I0726 12:00:20.843025 27891 solver.cpp:238]     Train net output #17: loss25 = 593.847 (* 1 = 593.847 loss)
I0726 12:00:20.843032 27891 solver.cpp:238]     Train net output #18: loss26 = 570.738 (* 1 = 570.738 loss)
I0726 12:00:20.843039 27891 solver.cpp:238]     Train net output #19: loss27 = 564.734 (* 1 = 564.734 loss)
I0726 12:00:20.843045 27891 solver.cpp:238]     Train net output #20: loss28 = 568.079 (* 1 = 568.079 loss)
I0726 12:00:20.843052 27891 solver.cpp:238]     Train net output #21: loss29 = 594.607 (* 1 = 594.607 loss)
I0726 12:00:20.843060 27891 solver.cpp:238]     Train net output #22: loss3 = 575.302 (* 1 = 575.302 loss)
I0726 12:00:20.843065 27891 solver.cpp:238]     Train net output #23: loss30 = 578.662 (* 1 = 578.662 loss)
I0726 12:00:20.843072 27891 solver.cpp:238]     Train net output #24: loss31 = 568.811 (* 1 = 568.811 loss)
I0726 12:00:20.843080 27891 solver.cpp:238]     Train net output #25: loss32 = 579.013 (* 1 = 579.013 loss)
I0726 12:00:20.843086 27891 solver.cpp:238]     Train net output #26: loss33 = 588.874 (* 1 = 588.874 loss)
I0726 12:00:20.843092 27891 solver.cpp:238]     Train net output #27: loss34 = 588.101 (* 1 = 588.101 loss)
I0726 12:00:20.843098 27891 solver.cpp:238]     Train net output #28: loss35 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843106 27891 solver.cpp:238]     Train net output #29: loss36 = 583.731 (* 1 = 583.731 loss)
I0726 12:00:20.843158 27891 solver.cpp:238]     Train net output #30: loss37 = 576.615 (* 1 = 576.615 loss)
I0726 12:00:20.843165 27891 solver.cpp:238]     Train net output #31: loss38 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843173 27891 solver.cpp:238]     Train net output #32: loss39 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843179 27891 solver.cpp:238]     Train net output #33: loss4 = 573.593 (* 1 = 573.593 loss)
I0726 12:00:20.843185 27891 solver.cpp:238]     Train net output #34: loss40 = 556.559 (* 1 = 556.559 loss)
I0726 12:00:20.843194 27891 solver.cpp:238]     Train net output #35: loss41 = 585.983 (* 1 = 585.983 loss)
I0726 12:00:20.843205 27891 solver.cpp:238]     Train net output #36: loss42 = 566.564 (* 1 = 566.564 loss)
I0726 12:00:20.843221 27891 solver.cpp:238]     Train net output #37: loss43 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843231 27891 solver.cpp:238]     Train net output #38: loss44 = 584.199 (* 1 = 584.199 loss)
I0726 12:00:20.843241 27891 solver.cpp:238]     Train net output #39: loss45 = 575.837 (* 1 = 575.837 loss)
I0726 12:00:20.843252 27891 solver.cpp:238]     Train net output #40: loss46 = 570.065 (* 1 = 570.065 loss)
I0726 12:00:20.843266 27891 solver.cpp:238]     Train net output #41: loss47 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843276 27891 solver.cpp:238]     Train net output #42: loss48 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843282 27891 solver.cpp:238]     Train net output #43: loss49 = 592.959 (* 1 = 592.959 loss)
I0726 12:00:20.843288 27891 solver.cpp:238]     Train net output #44: loss5 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843296 27891 solver.cpp:238]     Train net output #45: loss50 = 592.964 (* 1 = 592.964 loss)
I0726 12:00:20.843302 27891 solver.cpp:238]     Train net output #46: loss51 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843309 27891 solver.cpp:238]     Train net output #47: loss52 = 583.27 (* 1 = 583.27 loss)
I0726 12:00:20.843317 27891 solver.cpp:238]     Train net output #48: loss53 = 567.016 (* 1 = 567.016 loss)
I0726 12:00:20.843323 27891 solver.cpp:238]     Train net output #49: loss54 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843329 27891 solver.cpp:238]     Train net output #50: loss55 = 569.974 (* 1 = 569.974 loss)
I0726 12:00:20.843335 27891 solver.cpp:238]     Train net output #51: loss56 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843343 27891 solver.cpp:238]     Train net output #52: loss57 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843350 27891 solver.cpp:238]     Train net output #53: loss58 = 587.664 (* 1 = 587.664 loss)
I0726 12:00:20.843356 27891 solver.cpp:238]     Train net output #54: loss59 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843364 27891 solver.cpp:238]     Train net output #55: loss6 = 577.397 (* 1 = 577.397 loss)
I0726 12:00:20.843369 27891 solver.cpp:238]     Train net output #56: loss60 = 604.585 (* 1 = 604.585 loss)
I0726 12:00:20.843376 27891 solver.cpp:238]     Train net output #57: loss61 = 564.712 (* 1 = 564.712 loss)
I0726 12:00:20.843382 27891 solver.cpp:238]     Train net output #58: loss62 = 567.573 (* 1 = 567.573 loss)
I0726 12:00:20.843389 27891 solver.cpp:238]     Train net output #59: loss63 = 593.326 (* 1 = 593.326 loss)
I0726 12:00:20.843397 27891 solver.cpp:238]     Train net output #60: loss64 = 568.893 (* 1 = 568.893 loss)
I0726 12:00:20.843405 27891 solver.cpp:238]     Train net output #61: loss7 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843410 27891 solver.cpp:238]     Train net output #62: loss8 = 572.815 (* 1 = 572.815 loss)
I0726 12:00:20.843417 27891 solver.cpp:238]     Train net output #63: loss9 = 564.68 (* 1 = 564.68 loss)
I0726 12:00:20.843425 27891 sgd_solver.cpp:105] Iteration 75600, lr = 1e-09
I0726 12:09:22.010177 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:09:22.013598 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:09:22.415357 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_81000.caffemodel
I0726 12:09:22.661481 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_81000.solverstate
I0726 12:09:22.743980 27891 solver.cpp:331] Iteration 81000, Testing net (#0)
I0726 12:09:37.947283 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:09:37.996325 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:09:38.413837 27891 solver.cpp:398]     Test net output #0: mae = 80.1772 (* 1 = 80.1772 loss)
I0726 12:09:38.413868 27891 solver.cpp:398]     Test net output #1: mse = 13717.2 (* 1 = 13717.2 loss)
I0726 12:09:38.538976 27891 solver.cpp:219] Iteration 81000 (9.68287 iter/s, 557.686s/5400 iters), loss = 36464.2
I0726 12:09:38.539016 27891 solver.cpp:238]     Train net output #0: loss1 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539026 27891 solver.cpp:238]     Train net output #1: loss10 = 577.176 (* 1 = 577.176 loss)
I0726 12:09:38.539032 27891 solver.cpp:238]     Train net output #2: loss11 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539038 27891 solver.cpp:238]     Train net output #3: loss12 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539046 27891 solver.cpp:238]     Train net output #4: loss13 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539052 27891 solver.cpp:238]     Train net output #5: loss14 = 578.345 (* 1 = 578.345 loss)
I0726 12:09:38.539058 27891 solver.cpp:238]     Train net output #6: loss15 = 570.088 (* 1 = 570.088 loss)
I0726 12:09:38.539065 27891 solver.cpp:238]     Train net output #7: loss16 = 577.457 (* 1 = 577.457 loss)
I0726 12:09:38.539072 27891 solver.cpp:238]     Train net output #8: loss17 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539078 27891 solver.cpp:238]     Train net output #9: loss18 = 572.419 (* 1 = 572.419 loss)
I0726 12:09:38.539085 27891 solver.cpp:238]     Train net output #10: loss19 = 575.043 (* 1 = 575.043 loss)
I0726 12:09:38.539091 27891 solver.cpp:238]     Train net output #11: loss2 = 572.854 (* 1 = 572.854 loss)
I0726 12:09:38.539098 27891 solver.cpp:238]     Train net output #12: loss20 = 611.138 (* 1 = 611.138 loss)
I0726 12:09:38.539103 27891 solver.cpp:238]     Train net output #13: loss21 = 564.474 (* 1 = 564.474 loss)
I0726 12:09:38.539110 27891 solver.cpp:238]     Train net output #14: loss22 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539115 27891 solver.cpp:238]     Train net output #15: loss23 = 561.678 (* 1 = 561.678 loss)
I0726 12:09:38.539122 27891 solver.cpp:238]     Train net output #16: loss24 = 563.762 (* 1 = 563.762 loss)
I0726 12:09:38.539132 27891 solver.cpp:238]     Train net output #17: loss25 = 589.814 (* 1 = 589.814 loss)
I0726 12:09:38.539137 27891 solver.cpp:238]     Train net output #18: loss26 = 565.916 (* 1 = 565.916 loss)
I0726 12:09:38.539144 27891 solver.cpp:238]     Train net output #19: loss27 = 559.651 (* 1 = 559.651 loss)
I0726 12:09:38.539150 27891 solver.cpp:238]     Train net output #20: loss28 = 563.822 (* 1 = 563.822 loss)
I0726 12:09:38.539156 27891 solver.cpp:238]     Train net output #21: loss29 = 589.928 (* 1 = 589.928 loss)
I0726 12:09:38.539163 27891 solver.cpp:238]     Train net output #22: loss3 = 570.794 (* 1 = 570.794 loss)
I0726 12:09:38.539170 27891 solver.cpp:238]     Train net output #23: loss30 = 572.097 (* 1 = 572.097 loss)
I0726 12:09:38.539176 27891 solver.cpp:238]     Train net output #24: loss31 = 563.532 (* 1 = 563.532 loss)
I0726 12:09:38.539183 27891 solver.cpp:238]     Train net output #25: loss32 = 574.218 (* 1 = 574.218 loss)
I0726 12:09:38.539189 27891 solver.cpp:238]     Train net output #26: loss33 = 584.29 (* 1 = 584.29 loss)
I0726 12:09:38.539196 27891 solver.cpp:238]     Train net output #27: loss34 = 581.931 (* 1 = 581.931 loss)
I0726 12:09:38.539202 27891 solver.cpp:238]     Train net output #28: loss35 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539209 27891 solver.cpp:238]     Train net output #29: loss36 = 578.433 (* 1 = 578.433 loss)
I0726 12:09:38.539255 27891 solver.cpp:238]     Train net output #30: loss37 = 571.853 (* 1 = 571.853 loss)
I0726 12:09:38.539263 27891 solver.cpp:238]     Train net output #31: loss38 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539270 27891 solver.cpp:238]     Train net output #32: loss39 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539276 27891 solver.cpp:238]     Train net output #33: loss4 = 569.648 (* 1 = 569.648 loss)
I0726 12:09:38.539288 27891 solver.cpp:238]     Train net output #34: loss40 = 551.442 (* 1 = 551.442 loss)
I0726 12:09:38.539299 27891 solver.cpp:238]     Train net output #35: loss41 = 581.063 (* 1 = 581.063 loss)
I0726 12:09:38.539309 27891 solver.cpp:238]     Train net output #36: loss42 = 561.835 (* 1 = 561.835 loss)
I0726 12:09:38.539317 27891 solver.cpp:238]     Train net output #37: loss43 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539327 27891 solver.cpp:238]     Train net output #38: loss44 = 579.097 (* 1 = 579.097 loss)
I0726 12:09:38.539338 27891 solver.cpp:238]     Train net output #39: loss45 = 570.676 (* 1 = 570.676 loss)
I0726 12:09:38.539350 27891 solver.cpp:238]     Train net output #40: loss46 = 565.279 (* 1 = 565.279 loss)
I0726 12:09:38.539361 27891 solver.cpp:238]     Train net output #41: loss47 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539367 27891 solver.cpp:238]     Train net output #42: loss48 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539374 27891 solver.cpp:238]     Train net output #43: loss49 = 587.449 (* 1 = 587.449 loss)
I0726 12:09:38.539381 27891 solver.cpp:238]     Train net output #44: loss5 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539387 27891 solver.cpp:238]     Train net output #45: loss50 = 586.862 (* 1 = 586.862 loss)
I0726 12:09:38.539393 27891 solver.cpp:238]     Train net output #46: loss51 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539400 27891 solver.cpp:238]     Train net output #47: loss52 = 578.643 (* 1 = 578.643 loss)
I0726 12:09:38.539407 27891 solver.cpp:238]     Train net output #48: loss53 = 562.144 (* 1 = 562.144 loss)
I0726 12:09:38.539414 27891 solver.cpp:238]     Train net output #49: loss54 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539420 27891 solver.cpp:238]     Train net output #50: loss55 = 564.967 (* 1 = 564.967 loss)
I0726 12:09:38.539427 27891 solver.cpp:238]     Train net output #51: loss56 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539434 27891 solver.cpp:238]     Train net output #52: loss57 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539441 27891 solver.cpp:238]     Train net output #53: loss58 = 583.643 (* 1 = 583.643 loss)
I0726 12:09:38.539448 27891 solver.cpp:238]     Train net output #54: loss59 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539454 27891 solver.cpp:238]     Train net output #55: loss6 = 571.649 (* 1 = 571.649 loss)
I0726 12:09:38.539461 27891 solver.cpp:238]     Train net output #56: loss60 = 598.245 (* 1 = 598.245 loss)
I0726 12:09:38.539468 27891 solver.cpp:238]     Train net output #57: loss61 = 559.768 (* 1 = 559.768 loss)
I0726 12:09:38.539474 27891 solver.cpp:238]     Train net output #58: loss62 = 562.664 (* 1 = 562.664 loss)
I0726 12:09:38.539481 27891 solver.cpp:238]     Train net output #59: loss63 = 586.984 (* 1 = 586.984 loss)
I0726 12:09:38.539489 27891 solver.cpp:238]     Train net output #60: loss64 = 563.928 (* 1 = 563.928 loss)
I0726 12:09:38.539495 27891 solver.cpp:238]     Train net output #61: loss7 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539502 27891 solver.cpp:238]     Train net output #62: loss8 = 568.369 (* 1 = 568.369 loss)
I0726 12:09:38.539508 27891 solver.cpp:238]     Train net output #63: loss9 = 559.61 (* 1 = 559.61 loss)
I0726 12:09:38.539515 27891 sgd_solver.cpp:105] Iteration 81000, lr = 1e-09
I0726 12:18:39.803757 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:18:39.806977 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:18:40.200028 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_86400.caffemodel
I0726 12:18:40.595204 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_86400.solverstate
I0726 12:18:40.677772 27891 solver.cpp:331] Iteration 86400, Testing net (#0)
I0726 12:18:55.888597 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:18:55.904088 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:18:56.354111 27891 solver.cpp:398]     Test net output #0: mae = 80.1065 (* 1 = 80.1065 loss)
I0726 12:18:56.354136 27891 solver.cpp:398]     Test net output #1: mse = 13690.1 (* 1 = 13690.1 loss)
I0726 12:18:56.479255 27891 solver.cpp:219] Iteration 86400 (9.67863 iter/s, 557.93s/5400 iters), loss = 36238.9
I0726 12:18:56.479293 27891 solver.cpp:238]     Train net output #0: loss1 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479301 27891 solver.cpp:238]     Train net output #1: loss10 = 573.213 (* 1 = 573.213 loss)
I0726 12:18:56.479307 27891 solver.cpp:238]     Train net output #2: loss11 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479315 27891 solver.cpp:238]     Train net output #3: loss12 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479322 27891 solver.cpp:238]     Train net output #4: loss13 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479329 27891 solver.cpp:238]     Train net output #5: loss14 = 573.457 (* 1 = 573.457 loss)
I0726 12:18:56.479336 27891 solver.cpp:238]     Train net output #6: loss15 = 566.87 (* 1 = 566.87 loss)
I0726 12:18:56.479341 27891 solver.cpp:238]     Train net output #7: loss16 = 573.208 (* 1 = 573.208 loss)
I0726 12:18:56.479348 27891 solver.cpp:238]     Train net output #8: loss17 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479356 27891 solver.cpp:238]     Train net output #9: loss18 = 569.718 (* 1 = 569.718 loss)
I0726 12:18:56.479362 27891 solver.cpp:238]     Train net output #10: loss19 = 570.606 (* 1 = 570.606 loss)
I0726 12:18:56.479368 27891 solver.cpp:238]     Train net output #11: loss2 = 569.631 (* 1 = 569.631 loss)
I0726 12:18:56.479374 27891 solver.cpp:238]     Train net output #12: loss20 = 606.318 (* 1 = 606.318 loss)
I0726 12:18:56.479380 27891 solver.cpp:238]     Train net output #13: loss21 = 561.449 (* 1 = 561.449 loss)
I0726 12:18:56.479387 27891 solver.cpp:238]     Train net output #14: loss22 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479395 27891 solver.cpp:238]     Train net output #15: loss23 = 558.789 (* 1 = 558.789 loss)
I0726 12:18:56.479401 27891 solver.cpp:238]     Train net output #16: loss24 = 560.614 (* 1 = 560.614 loss)
I0726 12:18:56.479408 27891 solver.cpp:238]     Train net output #17: loss25 = 587.435 (* 1 = 587.435 loss)
I0726 12:18:56.479415 27891 solver.cpp:238]     Train net output #18: loss26 = 562.55 (* 1 = 562.55 loss)
I0726 12:18:56.479423 27891 solver.cpp:238]     Train net output #19: loss27 = 556.318 (* 1 = 556.318 loss)
I0726 12:18:56.479429 27891 solver.cpp:238]     Train net output #20: loss28 = 561.033 (* 1 = 561.033 loss)
I0726 12:18:56.479435 27891 solver.cpp:238]     Train net output #21: loss29 = 586.724 (* 1 = 586.724 loss)
I0726 12:18:56.479442 27891 solver.cpp:238]     Train net output #22: loss3 = 567.985 (* 1 = 567.985 loss)
I0726 12:18:56.479449 27891 solver.cpp:238]     Train net output #23: loss30 = 567.536 (* 1 = 567.536 loss)
I0726 12:18:56.479456 27891 solver.cpp:238]     Train net output #24: loss31 = 559.683 (* 1 = 559.683 loss)
I0726 12:18:56.479463 27891 solver.cpp:238]     Train net output #25: loss32 = 571.147 (* 1 = 571.147 loss)
I0726 12:18:56.479471 27891 solver.cpp:238]     Train net output #26: loss33 = 581.028 (* 1 = 581.028 loss)
I0726 12:18:56.479477 27891 solver.cpp:238]     Train net output #27: loss34 = 577.521 (* 1 = 577.521 loss)
I0726 12:18:56.479485 27891 solver.cpp:238]     Train net output #28: loss35 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479491 27891 solver.cpp:238]     Train net output #29: loss36 = 574.783 (* 1 = 574.783 loss)
I0726 12:18:56.479537 27891 solver.cpp:238]     Train net output #30: loss37 = 568.442 (* 1 = 568.442 loss)
I0726 12:18:56.479545 27891 solver.cpp:238]     Train net output #31: loss38 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479552 27891 solver.cpp:238]     Train net output #32: loss39 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479558 27891 solver.cpp:238]     Train net output #33: loss4 = 567.061 (* 1 = 567.061 loss)
I0726 12:18:56.479565 27891 solver.cpp:238]     Train net output #34: loss40 = 547.868 (* 1 = 547.868 loss)
I0726 12:18:56.479571 27891 solver.cpp:238]     Train net output #35: loss41 = 577.736 (* 1 = 577.736 loss)
I0726 12:18:56.479578 27891 solver.cpp:238]     Train net output #36: loss42 = 558.805 (* 1 = 558.805 loss)
I0726 12:18:56.479583 27891 solver.cpp:238]     Train net output #37: loss43 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479591 27891 solver.cpp:238]     Train net output #38: loss44 = 575.643 (* 1 = 575.643 loss)
I0726 12:18:56.479599 27891 solver.cpp:238]     Train net output #39: loss45 = 567.217 (* 1 = 567.217 loss)
I0726 12:18:56.479609 27891 solver.cpp:238]     Train net output #40: loss46 = 562.088 (* 1 = 562.088 loss)
I0726 12:18:56.479620 27891 solver.cpp:238]     Train net output #41: loss47 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479627 27891 solver.cpp:238]     Train net output #42: loss48 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479635 27891 solver.cpp:238]     Train net output #43: loss49 = 584.011 (* 1 = 584.011 loss)
I0726 12:18:56.479640 27891 solver.cpp:238]     Train net output #44: loss5 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479647 27891 solver.cpp:238]     Train net output #45: loss50 = 582.291 (* 1 = 582.291 loss)
I0726 12:18:56.479655 27891 solver.cpp:238]     Train net output #46: loss51 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479661 27891 solver.cpp:238]     Train net output #47: loss52 = 574.917 (* 1 = 574.917 loss)
I0726 12:18:56.479667 27891 solver.cpp:238]     Train net output #48: loss53 = 558.909 (* 1 = 558.909 loss)
I0726 12:18:56.479674 27891 solver.cpp:238]     Train net output #49: loss54 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479681 27891 solver.cpp:238]     Train net output #50: loss55 = 561.639 (* 1 = 561.639 loss)
I0726 12:18:56.479687 27891 solver.cpp:238]     Train net output #51: loss56 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479694 27891 solver.cpp:238]     Train net output #52: loss57 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479701 27891 solver.cpp:238]     Train net output #53: loss58 = 580.995 (* 1 = 580.995 loss)
I0726 12:18:56.479707 27891 solver.cpp:238]     Train net output #54: loss59 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479714 27891 solver.cpp:238]     Train net output #55: loss6 = 567.588 (* 1 = 567.588 loss)
I0726 12:18:56.479720 27891 solver.cpp:238]     Train net output #56: loss60 = 593.678 (* 1 = 593.678 loss)
I0726 12:18:56.479727 27891 solver.cpp:238]     Train net output #57: loss61 = 556.555 (* 1 = 556.555 loss)
I0726 12:18:56.479734 27891 solver.cpp:238]     Train net output #58: loss62 = 559.244 (* 1 = 559.244 loss)
I0726 12:18:56.479740 27891 solver.cpp:238]     Train net output #59: loss63 = 582.468 (* 1 = 582.468 loss)
I0726 12:18:56.479748 27891 solver.cpp:238]     Train net output #60: loss64 = 560.579 (* 1 = 560.579 loss)
I0726 12:18:56.479754 27891 solver.cpp:238]     Train net output #61: loss7 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479760 27891 solver.cpp:238]     Train net output #62: loss8 = 565.691 (* 1 = 565.691 loss)
I0726 12:18:56.479768 27891 solver.cpp:238]     Train net output #63: loss9 = 556.025 (* 1 = 556.025 loss)
I0726 12:18:56.479774 27891 sgd_solver.cpp:105] Iteration 86400, lr = 1e-09
I0726 12:28:00.398288 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:28:00.399960 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:28:00.790051 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_91800.caffemodel
I0726 12:28:01.200376 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_91800.solverstate
I0726 12:28:01.282737 27891 solver.cpp:331] Iteration 91800, Testing net (#0)
I0726 12:28:16.487109 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:28:16.513864 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:28:16.951611 27891 solver.cpp:398]     Test net output #0: mae = 79.8953 (* 1 = 79.8953 loss)
I0726 12:28:16.951637 27891 solver.cpp:398]     Test net output #1: mse = 13620.7 (* 1 = 13620.7 loss)
I0726 12:28:17.076221 27891 solver.cpp:219] Iteration 91800 (9.63277 iter/s, 560.587s/5400 iters), loss = 36044.4
I0726 12:28:17.076257 27891 solver.cpp:238]     Train net output #0: loss1 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076266 27891 solver.cpp:238]     Train net output #1: loss10 = 569.608 (* 1 = 569.608 loss)
I0726 12:28:17.076272 27891 solver.cpp:238]     Train net output #2: loss11 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076279 27891 solver.cpp:238]     Train net output #3: loss12 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076285 27891 solver.cpp:238]     Train net output #4: loss13 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076292 27891 solver.cpp:238]     Train net output #5: loss14 = 569.048 (* 1 = 569.048 loss)
I0726 12:28:17.076297 27891 solver.cpp:238]     Train net output #6: loss15 = 564.126 (* 1 = 564.126 loss)
I0726 12:28:17.076303 27891 solver.cpp:238]     Train net output #7: loss16 = 569.704 (* 1 = 569.704 loss)
I0726 12:28:17.076309 27891 solver.cpp:238]     Train net output #8: loss17 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076316 27891 solver.cpp:238]     Train net output #9: loss18 = 567.469 (* 1 = 567.469 loss)
I0726 12:28:17.076323 27891 solver.cpp:238]     Train net output #10: loss19 = 566.727 (* 1 = 566.727 loss)
I0726 12:28:17.076330 27891 solver.cpp:238]     Train net output #11: loss2 = 567.034 (* 1 = 567.034 loss)
I0726 12:28:17.076340 27891 solver.cpp:238]     Train net output #12: loss20 = 602.109 (* 1 = 602.109 loss)
I0726 12:28:17.076351 27891 solver.cpp:238]     Train net output #13: loss21 = 558.876 (* 1 = 558.876 loss)
I0726 12:28:17.076359 27891 solver.cpp:238]     Train net output #14: loss22 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076367 27891 solver.cpp:238]     Train net output #15: loss23 = 556.24 (* 1 = 556.24 loss)
I0726 12:28:17.076372 27891 solver.cpp:238]     Train net output #16: loss24 = 558.069 (* 1 = 558.069 loss)
I0726 12:28:17.076380 27891 solver.cpp:238]     Train net output #17: loss25 = 584.978 (* 1 = 584.978 loss)
I0726 12:28:17.076386 27891 solver.cpp:238]     Train net output #18: loss26 = 559.678 (* 1 = 559.678 loss)
I0726 12:28:17.076392 27891 solver.cpp:238]     Train net output #19: loss27 = 553.339 (* 1 = 553.339 loss)
I0726 12:28:17.076400 27891 solver.cpp:238]     Train net output #20: loss28 = 558.751 (* 1 = 558.751 loss)
I0726 12:28:17.076406 27891 solver.cpp:238]     Train net output #21: loss29 = 583.69 (* 1 = 583.69 loss)
I0726 12:28:17.076413 27891 solver.cpp:238]     Train net output #22: loss3 = 565.502 (* 1 = 565.502 loss)
I0726 12:28:17.076421 27891 solver.cpp:238]     Train net output #23: loss30 = 563.614 (* 1 = 563.614 loss)
I0726 12:28:17.076426 27891 solver.cpp:238]     Train net output #24: loss31 = 556.378 (* 1 = 556.378 loss)
I0726 12:28:17.076433 27891 solver.cpp:238]     Train net output #25: loss32 = 568.584 (* 1 = 568.584 loss)
I0726 12:28:17.076441 27891 solver.cpp:238]     Train net output #26: loss33 = 578.181 (* 1 = 578.181 loss)
I0726 12:28:17.076447 27891 solver.cpp:238]     Train net output #27: loss34 = 573.65 (* 1 = 573.65 loss)
I0726 12:28:17.076454 27891 solver.cpp:238]     Train net output #28: loss35 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076462 27891 solver.cpp:238]     Train net output #29: loss36 = 571.574 (* 1 = 571.574 loss)
I0726 12:28:17.076510 27891 solver.cpp:238]     Train net output #30: loss37 = 565.47 (* 1 = 565.47 loss)
I0726 12:28:17.076522 27891 solver.cpp:238]     Train net output #31: loss38 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076534 27891 solver.cpp:238]     Train net output #32: loss39 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076540 27891 solver.cpp:238]     Train net output #33: loss4 = 566.151 (* 1 = 566.151 loss)
I0726 12:28:17.076547 27891 solver.cpp:238]     Train net output #34: loss40 = 544.732 (* 1 = 544.732 loss)
I0726 12:28:17.076555 27891 solver.cpp:238]     Train net output #35: loss41 = 574.823 (* 1 = 574.823 loss)
I0726 12:28:17.076562 27891 solver.cpp:238]     Train net output #36: loss42 = 556.493 (* 1 = 556.493 loss)
I0726 12:28:17.076568 27891 solver.cpp:238]     Train net output #37: loss43 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076575 27891 solver.cpp:238]     Train net output #38: loss44 = 572.907 (* 1 = 572.907 loss)
I0726 12:28:17.076581 27891 solver.cpp:238]     Train net output #39: loss45 = 564.158 (* 1 = 564.158 loss)
I0726 12:28:17.076587 27891 solver.cpp:238]     Train net output #40: loss46 = 559.408 (* 1 = 559.408 loss)
I0726 12:28:17.076593 27891 solver.cpp:238]     Train net output #41: loss47 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076601 27891 solver.cpp:238]     Train net output #42: loss48 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076606 27891 solver.cpp:238]     Train net output #43: loss49 = 580.792 (* 1 = 580.792 loss)
I0726 12:28:17.076613 27891 solver.cpp:238]     Train net output #44: loss5 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076622 27891 solver.cpp:238]     Train net output #45: loss50 = 578.339 (* 1 = 578.339 loss)
I0726 12:28:17.076627 27891 solver.cpp:238]     Train net output #46: loss51 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076639 27891 solver.cpp:238]     Train net output #47: loss52 = 571.317 (* 1 = 571.317 loss)
I0726 12:28:17.076645 27891 solver.cpp:238]     Train net output #48: loss53 = 556.155 (* 1 = 556.155 loss)
I0726 12:28:17.076652 27891 solver.cpp:238]     Train net output #49: loss54 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076659 27891 solver.cpp:238]     Train net output #50: loss55 = 558.861 (* 1 = 558.861 loss)
I0726 12:28:17.076665 27891 solver.cpp:238]     Train net output #51: loss56 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076671 27891 solver.cpp:238]     Train net output #52: loss57 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076678 27891 solver.cpp:238]     Train net output #53: loss58 = 578.499 (* 1 = 578.499 loss)
I0726 12:28:17.076684 27891 solver.cpp:238]     Train net output #54: loss59 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076690 27891 solver.cpp:238]     Train net output #55: loss6 = 564.102 (* 1 = 564.102 loss)
I0726 12:28:17.076696 27891 solver.cpp:238]     Train net output #56: loss60 = 589.294 (* 1 = 589.294 loss)
I0726 12:28:17.076704 27891 solver.cpp:238]     Train net output #57: loss61 = 553.864 (* 1 = 553.864 loss)
I0726 12:28:17.076709 27891 solver.cpp:238]     Train net output #58: loss62 = 556.307 (* 1 = 556.307 loss)
I0726 12:28:17.076716 27891 solver.cpp:238]     Train net output #59: loss63 = 578.679 (* 1 = 578.679 loss)
I0726 12:28:17.076722 27891 solver.cpp:238]     Train net output #60: loss64 = 557.66 (* 1 = 557.66 loss)
I0726 12:28:17.076730 27891 solver.cpp:238]     Train net output #61: loss7 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076735 27891 solver.cpp:238]     Train net output #62: loss8 = 563.387 (* 1 = 563.387 loss)
I0726 12:28:17.076741 27891 solver.cpp:238]     Train net output #63: loss9 = 552.972 (* 1 = 552.972 loss)
I0726 12:28:17.076748 27891 sgd_solver.cpp:105] Iteration 91800, lr = 1e-09
I0726 12:37:17.371505 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:37:17.375619 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:37:17.773877 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_97200.caffemodel
I0726 12:37:18.277328 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_97200.solverstate
I0726 12:37:18.362489 27891 solver.cpp:331] Iteration 97200, Testing net (#0)
I0726 12:37:33.560928 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:37:33.630856 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:37:34.025300 27891 solver.cpp:398]     Test net output #0: mae = 79.7098 (* 1 = 79.7098 loss)
I0726 12:37:34.025344 27891 solver.cpp:398]     Test net output #1: mse = 13585.8 (* 1 = 13585.8 loss)
I0726 12:37:34.154696 27891 solver.cpp:219] Iteration 97200 (9.69358 iter/s, 557.069s/5400 iters), loss = 35700.2
I0726 12:37:34.154748 27891 solver.cpp:238]     Train net output #0: loss1 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154763 27891 solver.cpp:238]     Train net output #1: loss10 = 563.824 (* 1 = 563.824 loss)
I0726 12:37:34.154777 27891 solver.cpp:238]     Train net output #2: loss11 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154788 27891 solver.cpp:238]     Train net output #3: loss12 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154800 27891 solver.cpp:238]     Train net output #4: loss13 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154813 27891 solver.cpp:238]     Train net output #5: loss14 = 562.484 (* 1 = 562.484 loss)
I0726 12:37:34.154826 27891 solver.cpp:238]     Train net output #6: loss15 = 559.255 (* 1 = 559.255 loss)
I0726 12:37:34.154842 27891 solver.cpp:238]     Train net output #7: loss16 = 563.949 (* 1 = 563.949 loss)
I0726 12:37:34.154857 27891 solver.cpp:238]     Train net output #8: loss17 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154872 27891 solver.cpp:238]     Train net output #9: loss18 = 562.893 (* 1 = 562.893 loss)
I0726 12:37:34.154887 27891 solver.cpp:238]     Train net output #10: loss19 = 560.725 (* 1 = 560.725 loss)
I0726 12:37:34.154902 27891 solver.cpp:238]     Train net output #11: loss2 = 562.048 (* 1 = 562.048 loss)
I0726 12:37:34.154917 27891 solver.cpp:238]     Train net output #12: loss20 = 595.187 (* 1 = 595.187 loss)
I0726 12:37:34.154932 27891 solver.cpp:238]     Train net output #13: loss21 = 553.685 (* 1 = 553.685 loss)
I0726 12:37:34.154947 27891 solver.cpp:238]     Train net output #14: loss22 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.154960 27891 solver.cpp:238]     Train net output #15: loss23 = 551.523 (* 1 = 551.523 loss)
I0726 12:37:34.154975 27891 solver.cpp:238]     Train net output #16: loss24 = 553.003 (* 1 = 553.003 loss)
I0726 12:37:34.154990 27891 solver.cpp:238]     Train net output #17: loss25 = 580.053 (* 1 = 580.053 loss)
I0726 12:37:34.155005 27891 solver.cpp:238]     Train net output #18: loss26 = 554.506 (* 1 = 554.506 loss)
I0726 12:37:34.155019 27891 solver.cpp:238]     Train net output #19: loss27 = 548.356 (* 1 = 548.356 loss)
I0726 12:37:34.155035 27891 solver.cpp:238]     Train net output #20: loss28 = 554.215 (* 1 = 554.215 loss)
I0726 12:37:34.155050 27891 solver.cpp:238]     Train net output #21: loss29 = 578.365 (* 1 = 578.365 loss)
I0726 12:37:34.155064 27891 solver.cpp:238]     Train net output #22: loss3 = 560.764 (* 1 = 560.764 loss)
I0726 12:37:34.155078 27891 solver.cpp:238]     Train net output #23: loss30 = 557.84 (* 1 = 557.84 loss)
I0726 12:37:34.155093 27891 solver.cpp:238]     Train net output #24: loss31 = 550.809 (* 1 = 550.809 loss)
I0726 12:37:34.155108 27891 solver.cpp:238]     Train net output #25: loss32 = 563.63 (* 1 = 563.63 loss)
I0726 12:37:34.155122 27891 solver.cpp:238]     Train net output #26: loss33 = 573.129 (* 1 = 573.129 loss)
I0726 12:37:34.155136 27891 solver.cpp:238]     Train net output #27: loss34 = 567.608 (* 1 = 567.608 loss)
I0726 12:37:34.155151 27891 solver.cpp:238]     Train net output #28: loss35 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155165 27891 solver.cpp:238]     Train net output #29: loss36 = 566.209 (* 1 = 566.209 loss)
I0726 12:37:34.155222 27891 solver.cpp:238]     Train net output #30: loss37 = 560.091 (* 1 = 560.091 loss)
I0726 12:37:34.155241 27891 solver.cpp:238]     Train net output #31: loss38 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155256 27891 solver.cpp:238]     Train net output #32: loss39 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155270 27891 solver.cpp:238]     Train net output #33: loss4 = 561.405 (* 1 = 561.405 loss)
I0726 12:37:34.155284 27891 solver.cpp:238]     Train net output #34: loss40 = 539.547 (* 1 = 539.547 loss)
I0726 12:37:34.155300 27891 solver.cpp:238]     Train net output #35: loss41 = 569.748 (* 1 = 569.748 loss)
I0726 12:37:34.155313 27891 solver.cpp:238]     Train net output #36: loss42 = 551.893 (* 1 = 551.893 loss)
I0726 12:37:34.155326 27891 solver.cpp:238]     Train net output #37: loss43 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155340 27891 solver.cpp:238]     Train net output #38: loss44 = 567.655 (* 1 = 567.655 loss)
I0726 12:37:34.155355 27891 solver.cpp:238]     Train net output #39: loss45 = 558.924 (* 1 = 558.924 loss)
I0726 12:37:34.155371 27891 solver.cpp:238]     Train net output #40: loss46 = 554.597 (* 1 = 554.597 loss)
I0726 12:37:34.155386 27891 solver.cpp:238]     Train net output #41: loss47 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155402 27891 solver.cpp:238]     Train net output #42: loss48 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155416 27891 solver.cpp:238]     Train net output #43: loss49 = 575.775 (* 1 = 575.775 loss)
I0726 12:37:34.155432 27891 solver.cpp:238]     Train net output #44: loss5 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155447 27891 solver.cpp:238]     Train net output #45: loss50 = 572.025 (* 1 = 572.025 loss)
I0726 12:37:34.155463 27891 solver.cpp:238]     Train net output #46: loss51 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155478 27891 solver.cpp:238]     Train net output #47: loss52 = 565.443 (* 1 = 565.443 loss)
I0726 12:37:34.155493 27891 solver.cpp:238]     Train net output #48: loss53 = 551.203 (* 1 = 551.203 loss)
I0726 12:37:34.155508 27891 solver.cpp:238]     Train net output #49: loss54 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155524 27891 solver.cpp:238]     Train net output #50: loss55 = 553.825 (* 1 = 553.825 loss)
I0726 12:37:34.155539 27891 solver.cpp:238]     Train net output #51: loss56 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155555 27891 solver.cpp:238]     Train net output #52: loss57 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155575 27891 solver.cpp:238]     Train net output #53: loss58 = 573.425 (* 1 = 573.425 loss)
I0726 12:37:34.155591 27891 solver.cpp:238]     Train net output #54: loss59 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155606 27891 solver.cpp:238]     Train net output #55: loss6 = 558.573 (* 1 = 558.573 loss)
I0726 12:37:34.155620 27891 solver.cpp:238]     Train net output #56: loss60 = 582.904 (* 1 = 582.904 loss)
I0726 12:37:34.155634 27891 solver.cpp:238]     Train net output #57: loss61 = 548.86 (* 1 = 548.86 loss)
I0726 12:37:34.155650 27891 solver.cpp:238]     Train net output #58: loss62 = 551.236 (* 1 = 551.236 loss)
I0726 12:37:34.155665 27891 solver.cpp:238]     Train net output #59: loss63 = 572.763 (* 1 = 572.763 loss)
I0726 12:37:34.155681 27891 solver.cpp:238]     Train net output #60: loss64 = 552.163 (* 1 = 552.163 loss)
I0726 12:37:34.155696 27891 solver.cpp:238]     Train net output #61: loss7 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155711 27891 solver.cpp:238]     Train net output #62: loss8 = 558.524 (* 1 = 558.524 loss)
I0726 12:37:34.155726 27891 solver.cpp:238]     Train net output #63: loss9 = 547.727 (* 1 = 547.727 loss)
I0726 12:37:34.155740 27891 sgd_solver.cpp:105] Iteration 97200, lr = 1e-09
I0726 12:46:33.324378 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:46:33.328013 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:46:33.712277 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_102600.caffemodel
I0726 12:46:34.154031 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_102600.solverstate
I0726 12:46:34.234899 27891 solver.cpp:331] Iteration 102600, Testing net (#0)
I0726 12:46:49.450991 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:46:49.549167 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:46:49.916352 27891 solver.cpp:398]     Test net output #0: mae = 79.5622 (* 1 = 79.5622 loss)
I0726 12:46:49.916383 27891 solver.cpp:398]     Test net output #1: mse = 13526.6 (* 1 = 13526.6 loss)
I0726 12:46:50.041270 27891 solver.cpp:219] Iteration 102600 (9.71434 iter/s, 555.88s/5400 iters), loss = 35532.2
I0726 12:46:50.041318 27891 solver.cpp:238]     Train net output #0: loss1 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041327 27891 solver.cpp:238]     Train net output #1: loss10 = 560.671 (* 1 = 560.671 loss)
I0726 12:46:50.041334 27891 solver.cpp:238]     Train net output #2: loss11 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041340 27891 solver.cpp:238]     Train net output #3: loss12 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041347 27891 solver.cpp:238]     Train net output #4: loss13 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041352 27891 solver.cpp:238]     Train net output #5: loss14 = 558.854 (* 1 = 558.854 loss)
I0726 12:46:50.041359 27891 solver.cpp:238]     Train net output #6: loss15 = 557.404 (* 1 = 557.404 loss)
I0726 12:46:50.041365 27891 solver.cpp:238]     Train net output #7: loss16 = 560.87 (* 1 = 560.87 loss)
I0726 12:46:50.041371 27891 solver.cpp:238]     Train net output #8: loss17 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041378 27891 solver.cpp:238]     Train net output #9: loss18 = 560.857 (* 1 = 560.857 loss)
I0726 12:46:50.041383 27891 solver.cpp:238]     Train net output #10: loss19 = 557.547 (* 1 = 557.547 loss)
I0726 12:46:50.041394 27891 solver.cpp:238]     Train net output #11: loss2 = 559.88 (* 1 = 559.88 loss)
I0726 12:46:50.041400 27891 solver.cpp:238]     Train net output #12: loss20 = 591.383 (* 1 = 591.383 loss)
I0726 12:46:50.041407 27891 solver.cpp:238]     Train net output #13: loss21 = 551.711 (* 1 = 551.711 loss)
I0726 12:46:50.041414 27891 solver.cpp:238]     Train net output #14: loss22 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041419 27891 solver.cpp:238]     Train net output #15: loss23 = 549.719 (* 1 = 549.719 loss)
I0726 12:46:50.041425 27891 solver.cpp:238]     Train net output #16: loss24 = 550.58 (* 1 = 550.58 loss)
I0726 12:46:50.041431 27891 solver.cpp:238]     Train net output #17: loss25 = 578.148 (* 1 = 578.148 loss)
I0726 12:46:50.041438 27891 solver.cpp:238]     Train net output #18: loss26 = 552.024 (* 1 = 552.024 loss)
I0726 12:46:50.041445 27891 solver.cpp:238]     Train net output #19: loss27 = 545.944 (* 1 = 545.944 loss)
I0726 12:46:50.041450 27891 solver.cpp:238]     Train net output #20: loss28 = 552.226 (* 1 = 552.226 loss)
I0726 12:46:50.041456 27891 solver.cpp:238]     Train net output #21: loss29 = 576.001 (* 1 = 576.001 loss)
I0726 12:46:50.041463 27891 solver.cpp:238]     Train net output #22: loss3 = 558.932 (* 1 = 558.932 loss)
I0726 12:46:50.041470 27891 solver.cpp:238]     Train net output #23: loss30 = 554.687 (* 1 = 554.687 loss)
I0726 12:46:50.041476 27891 solver.cpp:238]     Train net output #24: loss31 = 547.807 (* 1 = 547.807 loss)
I0726 12:46:50.041481 27891 solver.cpp:238]     Train net output #25: loss32 = 561.433 (* 1 = 561.433 loss)
I0726 12:46:50.041487 27891 solver.cpp:238]     Train net output #26: loss33 = 570.771 (* 1 = 570.771 loss)
I0726 12:46:50.041493 27891 solver.cpp:238]     Train net output #27: loss34 = 564.43 (* 1 = 564.43 loss)
I0726 12:46:50.041499 27891 solver.cpp:238]     Train net output #28: loss35 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041505 27891 solver.cpp:238]     Train net output #29: loss36 = 563.368 (* 1 = 563.368 loss)
I0726 12:46:50.041549 27891 solver.cpp:238]     Train net output #30: loss37 = 557.488 (* 1 = 557.488 loss)
I0726 12:46:50.041558 27891 solver.cpp:238]     Train net output #31: loss38 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041565 27891 solver.cpp:238]     Train net output #32: loss39 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041576 27891 solver.cpp:238]     Train net output #33: loss4 = 558.56 (* 1 = 558.56 loss)
I0726 12:46:50.041585 27891 solver.cpp:238]     Train net output #34: loss40 = 537.006 (* 1 = 537.006 loss)
I0726 12:46:50.041591 27891 solver.cpp:238]     Train net output #35: loss41 = 567.344 (* 1 = 567.344 loss)
I0726 12:46:50.041599 27891 solver.cpp:238]     Train net output #36: loss42 = 550.322 (* 1 = 550.322 loss)
I0726 12:46:50.041604 27891 solver.cpp:238]     Train net output #37: loss43 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041611 27891 solver.cpp:238]     Train net output #38: loss44 = 564.994 (* 1 = 564.994 loss)
I0726 12:46:50.041620 27891 solver.cpp:238]     Train net output #39: loss45 = 556.349 (* 1 = 556.349 loss)
I0726 12:46:50.041625 27891 solver.cpp:238]     Train net output #40: loss46 = 552.157 (* 1 = 552.157 loss)
I0726 12:46:50.041632 27891 solver.cpp:238]     Train net output #41: loss47 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041640 27891 solver.cpp:238]     Train net output #42: loss48 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041646 27891 solver.cpp:238]     Train net output #43: loss49 = 573.608 (* 1 = 573.608 loss)
I0726 12:46:50.041653 27891 solver.cpp:238]     Train net output #44: loss5 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041661 27891 solver.cpp:238]     Train net output #45: loss50 = 568.535 (* 1 = 568.535 loss)
I0726 12:46:50.041668 27891 solver.cpp:238]     Train net output #46: loss51 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041674 27891 solver.cpp:238]     Train net output #47: loss52 = 562.212 (* 1 = 562.212 loss)
I0726 12:46:50.041682 27891 solver.cpp:238]     Train net output #48: loss53 = 548.849 (* 1 = 548.849 loss)
I0726 12:46:50.041688 27891 solver.cpp:238]     Train net output #49: loss54 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041695 27891 solver.cpp:238]     Train net output #50: loss55 = 551.388 (* 1 = 551.388 loss)
I0726 12:46:50.041702 27891 solver.cpp:238]     Train net output #51: loss56 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041708 27891 solver.cpp:238]     Train net output #52: loss57 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041714 27891 solver.cpp:238]     Train net output #53: loss58 = 571.273 (* 1 = 571.273 loss)
I0726 12:46:50.041721 27891 solver.cpp:238]     Train net output #54: loss59 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041728 27891 solver.cpp:238]     Train net output #55: loss6 = 555.656 (* 1 = 555.656 loss)
I0726 12:46:50.041734 27891 solver.cpp:238]     Train net output #56: loss60 = 579.454 (* 1 = 579.454 loss)
I0726 12:46:50.041740 27891 solver.cpp:238]     Train net output #57: loss61 = 546.422 (* 1 = 546.422 loss)
I0726 12:46:50.041748 27891 solver.cpp:238]     Train net output #58: loss62 = 548.805 (* 1 = 548.805 loss)
I0726 12:46:50.041754 27891 solver.cpp:238]     Train net output #59: loss63 = 569.607 (* 1 = 569.607 loss)
I0726 12:46:50.041761 27891 solver.cpp:238]     Train net output #60: loss64 = 549.46 (* 1 = 549.46 loss)
I0726 12:46:50.041767 27891 solver.cpp:238]     Train net output #61: loss7 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041774 27891 solver.cpp:238]     Train net output #62: loss8 = 556.549 (* 1 = 556.549 loss)
I0726 12:46:50.041781 27891 solver.cpp:238]     Train net output #63: loss9 = 545.073 (* 1 = 545.073 loss)
I0726 12:46:50.041787 27891 sgd_solver.cpp:105] Iteration 102600, lr = 1e-09
I0726 12:55:52.656131 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:55:52.659468 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:55:53.044245 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_108000.caffemodel
I0726 12:55:53.698885 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_108000.solverstate
I0726 12:55:53.782137 27891 solver.cpp:331] Iteration 108000, Testing net (#0)
I0726 12:56:08.978806 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:56:09.076186 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 12:56:09.443598 27891 solver.cpp:398]     Test net output #0: mae = 79.4841 (* 1 = 79.4841 loss)
I0726 12:56:09.443624 27891 solver.cpp:398]     Test net output #1: mse = 13477.8 (* 1 = 13477.8 loss)
I0726 12:56:09.567934 27891 solver.cpp:219] Iteration 108000 (9.65117 iter/s, 559.518s/5400 iters), loss = 35323.6
I0726 12:56:09.567975 27891 solver.cpp:238]     Train net output #0: loss1 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.567982 27891 solver.cpp:238]     Train net output #1: loss10 = 556.773 (* 1 = 556.773 loss)
I0726 12:56:09.567989 27891 solver.cpp:238]     Train net output #2: loss11 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.567996 27891 solver.cpp:238]     Train net output #3: loss12 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568001 27891 solver.cpp:238]     Train net output #4: loss13 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568007 27891 solver.cpp:238]     Train net output #5: loss14 = 554.839 (* 1 = 554.839 loss)
I0726 12:56:09.568014 27891 solver.cpp:238]     Train net output #6: loss15 = 554.584 (* 1 = 554.584 loss)
I0726 12:56:09.568020 27891 solver.cpp:238]     Train net output #7: loss16 = 557.225 (* 1 = 557.225 loss)
I0726 12:56:09.568027 27891 solver.cpp:238]     Train net output #8: loss17 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568032 27891 solver.cpp:238]     Train net output #9: loss18 = 558.279 (* 1 = 558.279 loss)
I0726 12:56:09.568038 27891 solver.cpp:238]     Train net output #10: loss19 = 553.657 (* 1 = 553.657 loss)
I0726 12:56:09.568044 27891 solver.cpp:238]     Train net output #11: loss2 = 556.779 (* 1 = 556.779 loss)
I0726 12:56:09.568050 27891 solver.cpp:238]     Train net output #12: loss20 = 586.862 (* 1 = 586.862 loss)
I0726 12:56:09.568056 27891 solver.cpp:238]     Train net output #13: loss21 = 549.032 (* 1 = 549.032 loss)
I0726 12:56:09.568063 27891 solver.cpp:238]     Train net output #14: loss22 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568068 27891 solver.cpp:238]     Train net output #15: loss23 = 547.487 (* 1 = 547.487 loss)
I0726 12:56:09.568074 27891 solver.cpp:238]     Train net output #16: loss24 = 547.408 (* 1 = 547.408 loss)
I0726 12:56:09.568079 27891 solver.cpp:238]     Train net output #17: loss25 = 575.576 (* 1 = 575.576 loss)
I0726 12:56:09.568085 27891 solver.cpp:238]     Train net output #18: loss26 = 548.8 (* 1 = 548.8 loss)
I0726 12:56:09.568091 27891 solver.cpp:238]     Train net output #19: loss27 = 542.801 (* 1 = 542.801 loss)
I0726 12:56:09.568097 27891 solver.cpp:238]     Train net output #20: loss28 = 549.517 (* 1 = 549.517 loss)
I0726 12:56:09.568104 27891 solver.cpp:238]     Train net output #21: loss29 = 572.842 (* 1 = 572.842 loss)
I0726 12:56:09.568110 27891 solver.cpp:238]     Train net output #22: loss3 = 556.42 (* 1 = 556.42 loss)
I0726 12:56:09.568116 27891 solver.cpp:238]     Train net output #23: loss30 = 550.792 (* 1 = 550.792 loss)
I0726 12:56:09.568122 27891 solver.cpp:238]     Train net output #24: loss31 = 544.074 (* 1 = 544.074 loss)
I0726 12:56:09.568128 27891 solver.cpp:238]     Train net output #25: loss32 = 558.389 (* 1 = 558.389 loss)
I0726 12:56:09.568135 27891 solver.cpp:238]     Train net output #26: loss33 = 567.704 (* 1 = 567.704 loss)
I0726 12:56:09.568140 27891 solver.cpp:238]     Train net output #27: loss34 = 560.691 (* 1 = 560.691 loss)
I0726 12:56:09.568146 27891 solver.cpp:238]     Train net output #28: loss35 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568153 27891 solver.cpp:238]     Train net output #29: loss36 = 559.608 (* 1 = 559.608 loss)
I0726 12:56:09.568193 27891 solver.cpp:238]     Train net output #30: loss37 = 554.306 (* 1 = 554.306 loss)
I0726 12:56:09.568200 27891 solver.cpp:238]     Train net output #31: loss38 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568207 27891 solver.cpp:238]     Train net output #32: loss39 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568213 27891 solver.cpp:238]     Train net output #33: loss4 = 554.829 (* 1 = 554.829 loss)
I0726 12:56:09.568219 27891 solver.cpp:238]     Train net output #34: loss40 = 533.877 (* 1 = 533.877 loss)
I0726 12:56:09.568225 27891 solver.cpp:238]     Train net output #35: loss41 = 564.319 (* 1 = 564.319 loss)
I0726 12:56:09.568231 27891 solver.cpp:238]     Train net output #36: loss42 = 548.261 (* 1 = 548.261 loss)
I0726 12:56:09.568238 27891 solver.cpp:238]     Train net output #37: loss43 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568243 27891 solver.cpp:238]     Train net output #38: loss44 = 561.467 (* 1 = 561.467 loss)
I0726 12:56:09.568249 27891 solver.cpp:238]     Train net output #39: loss45 = 553.026 (* 1 = 553.026 loss)
I0726 12:56:09.568255 27891 solver.cpp:238]     Train net output #40: loss46 = 548.963 (* 1 = 548.963 loss)
I0726 12:56:09.568261 27891 solver.cpp:238]     Train net output #41: loss47 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568267 27891 solver.cpp:238]     Train net output #42: loss48 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568274 27891 solver.cpp:238]     Train net output #43: loss49 = 570.577 (* 1 = 570.577 loss)
I0726 12:56:09.568279 27891 solver.cpp:238]     Train net output #44: loss5 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568285 27891 solver.cpp:238]     Train net output #45: loss50 = 564.852 (* 1 = 564.852 loss)
I0726 12:56:09.568295 27891 solver.cpp:238]     Train net output #46: loss51 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568301 27891 solver.cpp:238]     Train net output #47: loss52 = 558.164 (* 1 = 558.164 loss)
I0726 12:56:09.568307 27891 solver.cpp:238]     Train net output #48: loss53 = 545.89 (* 1 = 545.89 loss)
I0726 12:56:09.568313 27891 solver.cpp:238]     Train net output #49: loss54 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568318 27891 solver.cpp:238]     Train net output #50: loss55 = 548.376 (* 1 = 548.376 loss)
I0726 12:56:09.568325 27891 solver.cpp:238]     Train net output #51: loss56 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568331 27891 solver.cpp:238]     Train net output #52: loss57 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568336 27891 solver.cpp:238]     Train net output #53: loss58 = 568.415 (* 1 = 568.415 loss)
I0726 12:56:09.568342 27891 solver.cpp:238]     Train net output #54: loss59 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568348 27891 solver.cpp:238]     Train net output #55: loss6 = 552.173 (* 1 = 552.173 loss)
I0726 12:56:09.568353 27891 solver.cpp:238]     Train net output #56: loss60 = 575.423 (* 1 = 575.423 loss)
I0726 12:56:09.568359 27891 solver.cpp:238]     Train net output #57: loss61 = 543.526 (* 1 = 543.526 loss)
I0726 12:56:09.568366 27891 solver.cpp:238]     Train net output #58: loss62 = 545.768 (* 1 = 545.768 loss)
I0726 12:56:09.568372 27891 solver.cpp:238]     Train net output #59: loss63 = 566.006 (* 1 = 566.006 loss)
I0726 12:56:09.568378 27891 solver.cpp:238]     Train net output #60: loss64 = 547.771 (* 1 = 547.771 loss)
I0726 12:56:09.568385 27891 solver.cpp:238]     Train net output #61: loss7 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568392 27891 solver.cpp:238]     Train net output #62: loss8 = 553.703 (* 1 = 553.703 loss)
I0726 12:56:09.568397 27891 solver.cpp:238]     Train net output #63: loss9 = 541.728 (* 1 = 541.728 loss)
I0726 12:56:09.568403 27891 sgd_solver.cpp:105] Iteration 108000, lr = 1e-09
I0726 13:05:11.395653 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:05:11.396877 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:05:11.796744 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_113400.caffemodel
I0726 13:05:12.337438 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_113400.solverstate
I0726 13:05:12.463553 27891 solver.cpp:331] Iteration 113400, Testing net (#0)
I0726 13:05:27.674006 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:05:27.771252 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:05:28.140161 27891 solver.cpp:398]     Test net output #0: mae = 79.1969 (* 1 = 79.1969 loss)
I0726 13:05:28.140184 27891 solver.cpp:398]     Test net output #1: mse = 13433 (* 1 = 13433 loss)
I0726 13:05:28.265017 27891 solver.cpp:219] Iteration 113400 (9.66551 iter/s, 558.688s/5400 iters), loss = 34983.1
I0726 13:05:28.265054 27891 solver.cpp:238]     Train net output #0: loss1 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265061 27891 solver.cpp:238]     Train net output #1: loss10 = 550.679 (* 1 = 550.679 loss)
I0726 13:05:28.265069 27891 solver.cpp:238]     Train net output #2: loss11 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265076 27891 solver.cpp:238]     Train net output #3: loss12 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265082 27891 solver.cpp:238]     Train net output #4: loss13 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265089 27891 solver.cpp:238]     Train net output #5: loss14 = 548.059 (* 1 = 548.059 loss)
I0726 13:05:28.265094 27891 solver.cpp:238]     Train net output #6: loss15 = 549.264 (* 1 = 549.264 loss)
I0726 13:05:28.265101 27891 solver.cpp:238]     Train net output #7: loss16 = 551.356 (* 1 = 551.356 loss)
I0726 13:05:28.265106 27891 solver.cpp:238]     Train net output #8: loss17 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265113 27891 solver.cpp:238]     Train net output #9: loss18 = 553.045 (* 1 = 553.045 loss)
I0726 13:05:28.265118 27891 solver.cpp:238]     Train net output #10: loss19 = 547.609 (* 1 = 547.609 loss)
I0726 13:05:28.265125 27891 solver.cpp:238]     Train net output #11: loss2 = 551.319 (* 1 = 551.319 loss)
I0726 13:05:28.265132 27891 solver.cpp:238]     Train net output #12: loss20 = 579.503 (* 1 = 579.503 loss)
I0726 13:05:28.265138 27891 solver.cpp:238]     Train net output #13: loss21 = 543.98 (* 1 = 543.98 loss)
I0726 13:05:28.265143 27891 solver.cpp:238]     Train net output #14: loss22 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265149 27891 solver.cpp:238]     Train net output #15: loss23 = 542.941 (* 1 = 542.941 loss)
I0726 13:05:28.265156 27891 solver.cpp:238]     Train net output #16: loss24 = 541.967 (* 1 = 541.967 loss)
I0726 13:05:28.265161 27891 solver.cpp:238]     Train net output #17: loss25 = 570.113 (* 1 = 570.113 loss)
I0726 13:05:28.265167 27891 solver.cpp:238]     Train net output #18: loss26 = 543.442 (* 1 = 543.442 loss)
I0726 13:05:28.265173 27891 solver.cpp:238]     Train net output #19: loss27 = 537.446 (* 1 = 537.446 loss)
I0726 13:05:28.265179 27891 solver.cpp:238]     Train net output #20: loss28 = 544.459 (* 1 = 544.459 loss)
I0726 13:05:28.265185 27891 solver.cpp:238]     Train net output #21: loss29 = 566.699 (* 1 = 566.699 loss)
I0726 13:05:28.265192 27891 solver.cpp:238]     Train net output #22: loss3 = 551.579 (* 1 = 551.579 loss)
I0726 13:05:28.265197 27891 solver.cpp:238]     Train net output #23: loss30 = 544.869 (* 1 = 544.869 loss)
I0726 13:05:28.265203 27891 solver.cpp:238]     Train net output #24: loss31 = 538.324 (* 1 = 538.324 loss)
I0726 13:05:28.265209 27891 solver.cpp:238]     Train net output #25: loss32 = 553.062 (* 1 = 553.062 loss)
I0726 13:05:28.265215 27891 solver.cpp:238]     Train net output #26: loss33 = 561.962 (* 1 = 561.962 loss)
I0726 13:05:28.265220 27891 solver.cpp:238]     Train net output #27: loss34 = 554.782 (* 1 = 554.782 loss)
I0726 13:05:28.265226 27891 solver.cpp:238]     Train net output #28: loss35 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265233 27891 solver.cpp:238]     Train net output #29: loss36 = 553.563 (* 1 = 553.563 loss)
I0726 13:05:28.265274 27891 solver.cpp:238]     Train net output #30: loss37 = 548.728 (* 1 = 548.728 loss)
I0726 13:05:28.265281 27891 solver.cpp:238]     Train net output #31: loss38 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265287 27891 solver.cpp:238]     Train net output #32: loss39 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265293 27891 solver.cpp:238]     Train net output #33: loss4 = 548.936 (* 1 = 548.936 loss)
I0726 13:05:28.265300 27891 solver.cpp:238]     Train net output #34: loss40 = 528.551 (* 1 = 528.551 loss)
I0726 13:05:28.265312 27891 solver.cpp:238]     Train net output #35: loss41 = 558.882 (* 1 = 558.882 loss)
I0726 13:05:28.265321 27891 solver.cpp:238]     Train net output #36: loss42 = 543.656 (* 1 = 543.656 loss)
I0726 13:05:28.265326 27891 solver.cpp:238]     Train net output #37: loss43 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265332 27891 solver.cpp:238]     Train net output #38: loss44 = 555.641 (* 1 = 555.641 loss)
I0726 13:05:28.265338 27891 solver.cpp:238]     Train net output #39: loss45 = 547.314 (* 1 = 547.314 loss)
I0726 13:05:28.265346 27891 solver.cpp:238]     Train net output #40: loss46 = 543.83 (* 1 = 543.83 loss)
I0726 13:05:28.265352 27891 solver.cpp:238]     Train net output #41: loss47 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265358 27891 solver.cpp:238]     Train net output #42: loss48 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265364 27891 solver.cpp:238]     Train net output #43: loss49 = 564.967 (* 1 = 564.967 loss)
I0726 13:05:28.265372 27891 solver.cpp:238]     Train net output #44: loss5 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265377 27891 solver.cpp:238]     Train net output #45: loss50 = 558.857 (* 1 = 558.857 loss)
I0726 13:05:28.265383 27891 solver.cpp:238]     Train net output #46: loss51 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265389 27891 solver.cpp:238]     Train net output #47: loss52 = 551.829 (* 1 = 551.829 loss)
I0726 13:05:28.265396 27891 solver.cpp:238]     Train net output #48: loss53 = 540.794 (* 1 = 540.794 loss)
I0726 13:05:28.265403 27891 solver.cpp:238]     Train net output #49: loss54 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265408 27891 solver.cpp:238]     Train net output #50: loss55 = 543.139 (* 1 = 543.139 loss)
I0726 13:05:28.265414 27891 solver.cpp:238]     Train net output #51: loss56 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265420 27891 solver.cpp:238]     Train net output #52: loss57 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265427 27891 solver.cpp:238]     Train net output #53: loss58 = 562.776 (* 1 = 562.776 loss)
I0726 13:05:28.265434 27891 solver.cpp:238]     Train net output #54: loss59 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265440 27891 solver.cpp:238]     Train net output #55: loss6 = 546.661 (* 1 = 546.661 loss)
I0726 13:05:28.265447 27891 solver.cpp:238]     Train net output #56: loss60 = 569.207 (* 1 = 569.207 loss)
I0726 13:05:28.265453 27891 solver.cpp:238]     Train net output #57: loss61 = 538.147 (* 1 = 538.147 loss)
I0726 13:05:28.265458 27891 solver.cpp:238]     Train net output #58: loss62 = 540.414 (* 1 = 540.414 loss)
I0726 13:05:28.265465 27891 solver.cpp:238]     Train net output #59: loss63 = 559.795 (* 1 = 559.795 loss)
I0726 13:05:28.265471 27891 solver.cpp:238]     Train net output #60: loss64 = 544.461 (* 1 = 544.461 loss)
I0726 13:05:28.265477 27891 solver.cpp:238]     Train net output #61: loss7 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265483 27891 solver.cpp:238]     Train net output #62: loss8 = 548.235 (* 1 = 548.235 loss)
I0726 13:05:28.265489 27891 solver.cpp:238]     Train net output #63: loss9 = 536.283 (* 1 = 536.283 loss)
I0726 13:05:28.265496 27891 sgd_solver.cpp:105] Iteration 113400, lr = 1e-09
I0726 13:10:59.315198 27891 blocking_queue.cpp:49] Waiting for data
I0726 13:14:31.062783 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:14:31.063776 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:14:31.455058 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_118800.caffemodel
I0726 13:14:31.691633 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_118800.solverstate
I0726 13:14:31.773197 27891 solver.cpp:331] Iteration 118800, Testing net (#0)
I0726 13:14:47.099755 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:14:47.315084 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:14:47.564834 27891 solver.cpp:398]     Test net output #0: mae = 79.1365 (* 1 = 79.1365 loss)
I0726 13:14:47.564863 27891 solver.cpp:398]     Test net output #1: mse = 13398.6 (* 1 = 13398.6 loss)
I0726 13:14:47.689915 27891 solver.cpp:219] Iteration 118800 (9.65293 iter/s, 559.415s/5400 iters), loss = 34920
I0726 13:14:47.689962 27891 solver.cpp:238]     Train net output #0: loss1 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.689972 27891 solver.cpp:238]     Train net output #1: loss10 = 549.092 (* 1 = 549.092 loss)
I0726 13:14:47.689980 27891 solver.cpp:238]     Train net output #2: loss11 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.689986 27891 solver.cpp:238]     Train net output #3: loss12 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.689992 27891 solver.cpp:238]     Train net output #4: loss13 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.689998 27891 solver.cpp:238]     Train net output #5: loss14 = 546.267 (* 1 = 546.267 loss)
I0726 13:14:47.690004 27891 solver.cpp:238]     Train net output #6: loss15 = 548.478 (* 1 = 548.478 loss)
I0726 13:14:47.690009 27891 solver.cpp:238]     Train net output #7: loss16 = 549.902 (* 1 = 549.902 loss)
I0726 13:14:47.690016 27891 solver.cpp:238]     Train net output #8: loss17 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690021 27891 solver.cpp:238]     Train net output #9: loss18 = 552.282 (* 1 = 552.282 loss)
I0726 13:14:47.690026 27891 solver.cpp:238]     Train net output #10: loss19 = 546.038 (* 1 = 546.038 loss)
I0726 13:14:47.690032 27891 solver.cpp:238]     Train net output #11: loss2 = 550.448 (* 1 = 550.448 loss)
I0726 13:14:47.690038 27891 solver.cpp:238]     Train net output #12: loss20 = 577.609 (* 1 = 577.609 loss)
I0726 13:14:47.690043 27891 solver.cpp:238]     Train net output #13: loss21 = 543.327 (* 1 = 543.327 loss)
I0726 13:14:47.690049 27891 solver.cpp:238]     Train net output #14: loss22 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690054 27891 solver.cpp:238]     Train net output #15: loss23 = 542.661 (* 1 = 542.661 loss)
I0726 13:14:47.690060 27891 solver.cpp:238]     Train net output #16: loss24 = 540.923 (* 1 = 540.923 loss)
I0726 13:14:47.690065 27891 solver.cpp:238]     Train net output #17: loss25 = 569.269 (* 1 = 569.269 loss)
I0726 13:14:47.690071 27891 solver.cpp:238]     Train net output #18: loss26 = 542.415 (* 1 = 542.415 loss)
I0726 13:14:47.690078 27891 solver.cpp:238]     Train net output #19: loss27 = 536.552 (* 1 = 536.552 loss)
I0726 13:14:47.690083 27891 solver.cpp:238]     Train net output #20: loss28 = 543.789 (* 1 = 543.789 loss)
I0726 13:14:47.690090 27891 solver.cpp:238]     Train net output #21: loss29 = 565.728 (* 1 = 565.728 loss)
I0726 13:14:47.690095 27891 solver.cpp:238]     Train net output #22: loss3 = 551.024 (* 1 = 551.024 loss)
I0726 13:14:47.690100 27891 solver.cpp:238]     Train net output #23: loss30 = 543.404 (* 1 = 543.404 loss)
I0726 13:14:47.690106 27891 solver.cpp:238]     Train net output #24: loss31 = 536.85 (* 1 = 536.85 loss)
I0726 13:14:47.690114 27891 solver.cpp:238]     Train net output #25: loss32 = 552.262 (* 1 = 552.262 loss)
I0726 13:14:47.690119 27891 solver.cpp:238]     Train net output #26: loss33 = 561.154 (* 1 = 561.154 loss)
I0726 13:14:47.690125 27891 solver.cpp:238]     Train net output #27: loss34 = 553.678 (* 1 = 553.678 loss)
I0726 13:14:47.690130 27891 solver.cpp:238]     Train net output #28: loss35 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690136 27891 solver.cpp:238]     Train net output #29: loss36 = 551.908 (* 1 = 551.908 loss)
I0726 13:14:47.690174 27891 solver.cpp:238]     Train net output #30: loss37 = 547.426 (* 1 = 547.426 loss)
I0726 13:14:47.690181 27891 solver.cpp:238]     Train net output #31: loss38 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690186 27891 solver.cpp:238]     Train net output #32: loss39 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690192 27891 solver.cpp:238]     Train net output #33: loss4 = 547.501 (* 1 = 547.501 loss)
I0726 13:14:47.690198 27891 solver.cpp:238]     Train net output #34: loss40 = 527.483 (* 1 = 527.483 loss)
I0726 13:14:47.690204 27891 solver.cpp:238]     Train net output #35: loss41 = 557.866 (* 1 = 557.866 loss)
I0726 13:14:47.690209 27891 solver.cpp:238]     Train net output #36: loss42 = 543.623 (* 1 = 543.623 loss)
I0726 13:14:47.690215 27891 solver.cpp:238]     Train net output #37: loss43 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690222 27891 solver.cpp:238]     Train net output #38: loss44 = 554.378 (* 1 = 554.378 loss)
I0726 13:14:47.690227 27891 solver.cpp:238]     Train net output #39: loss45 = 546.155 (* 1 = 546.155 loss)
I0726 13:14:47.690232 27891 solver.cpp:238]     Train net output #40: loss46 = 542.875 (* 1 = 542.875 loss)
I0726 13:14:47.690238 27891 solver.cpp:238]     Train net output #41: loss47 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690244 27891 solver.cpp:238]     Train net output #42: loss48 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690249 27891 solver.cpp:238]     Train net output #43: loss49 = 564.052 (* 1 = 564.052 loss)
I0726 13:14:47.690255 27891 solver.cpp:238]     Train net output #44: loss5 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690261 27891 solver.cpp:238]     Train net output #45: loss50 = 557.404 (* 1 = 557.404 loss)
I0726 13:14:47.690268 27891 solver.cpp:238]     Train net output #46: loss51 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690274 27891 solver.cpp:238]     Train net output #47: loss52 = 550.23 (* 1 = 550.23 loss)
I0726 13:14:47.690279 27891 solver.cpp:238]     Train net output #48: loss53 = 540.01 (* 1 = 540.01 loss)
I0726 13:14:47.690285 27891 solver.cpp:238]     Train net output #49: loss54 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690290 27891 solver.cpp:238]     Train net output #50: loss55 = 542.289 (* 1 = 542.289 loss)
I0726 13:14:47.690296 27891 solver.cpp:238]     Train net output #51: loss56 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690302 27891 solver.cpp:238]     Train net output #52: loss57 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690309 27891 solver.cpp:238]     Train net output #53: loss58 = 562.069 (* 1 = 562.069 loss)
I0726 13:14:47.690313 27891 solver.cpp:238]     Train net output #54: loss59 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690320 27891 solver.cpp:238]     Train net output #55: loss6 = 545.604 (* 1 = 545.604 loss)
I0726 13:14:47.690325 27891 solver.cpp:238]     Train net output #56: loss60 = 567.78 (* 1 = 567.78 loss)
I0726 13:14:47.690331 27891 solver.cpp:238]     Train net output #57: loss61 = 537.211 (* 1 = 537.211 loss)
I0726 13:14:47.690337 27891 solver.cpp:238]     Train net output #58: loss62 = 539.504 (* 1 = 539.504 loss)
I0726 13:14:47.690343 27891 solver.cpp:238]     Train net output #59: loss63 = 558.381 (* 1 = 558.381 loss)
I0726 13:14:47.690349 27891 solver.cpp:238]     Train net output #60: loss64 = 544.018 (* 1 = 544.018 loss)
I0726 13:14:47.690354 27891 solver.cpp:238]     Train net output #61: loss7 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690361 27891 solver.cpp:238]     Train net output #62: loss8 = 547.307 (* 1 = 547.307 loss)
I0726 13:14:47.690366 27891 solver.cpp:238]     Train net output #63: loss9 = 535.108 (* 1 = 535.108 loss)
I0726 13:14:47.690372 27891 sgd_solver.cpp:105] Iteration 118800, lr = 1e-09
I0726 13:23:50.453235 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:23:50.454623 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:23:50.852052 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_124200.caffemodel
I0726 13:23:51.079005 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_124200.solverstate
I0726 13:23:51.162397 27891 solver.cpp:331] Iteration 124200, Testing net (#0)
I0726 13:24:06.412590 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:24:06.651321 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:24:06.877547 27891 solver.cpp:398]     Test net output #0: mae = 79.1163 (* 1 = 79.1163 loss)
I0726 13:24:06.877581 27891 solver.cpp:398]     Test net output #1: mse = 13382.8 (* 1 = 13382.8 loss)
I0726 13:24:07.003648 27891 solver.cpp:219] Iteration 124200 (9.65485 iter/s, 559.304s/5400 iters), loss = 34857.5
I0726 13:24:07.003696 27891 solver.cpp:238]     Train net output #0: loss1 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003705 27891 solver.cpp:238]     Train net output #1: loss10 = 547.681 (* 1 = 547.681 loss)
I0726 13:24:07.003711 27891 solver.cpp:238]     Train net output #2: loss11 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003717 27891 solver.cpp:238]     Train net output #3: loss12 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003723 27891 solver.cpp:238]     Train net output #4: loss13 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003729 27891 solver.cpp:238]     Train net output #5: loss14 = 544.359 (* 1 = 544.359 loss)
I0726 13:24:07.003736 27891 solver.cpp:238]     Train net output #6: loss15 = 547.835 (* 1 = 547.835 loss)
I0726 13:24:07.003742 27891 solver.cpp:238]     Train net output #7: loss16 = 548.705 (* 1 = 548.705 loss)
I0726 13:24:07.003749 27891 solver.cpp:238]     Train net output #8: loss17 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003756 27891 solver.cpp:238]     Train net output #9: loss18 = 551.802 (* 1 = 551.802 loss)
I0726 13:24:07.003762 27891 solver.cpp:238]     Train net output #10: loss19 = 544.615 (* 1 = 544.615 loss)
I0726 13:24:07.003767 27891 solver.cpp:238]     Train net output #11: loss2 = 549.566 (* 1 = 549.566 loss)
I0726 13:24:07.003773 27891 solver.cpp:238]     Train net output #12: loss20 = 575.696 (* 1 = 575.696 loss)
I0726 13:24:07.003779 27891 solver.cpp:238]     Train net output #13: loss21 = 542.798 (* 1 = 542.798 loss)
I0726 13:24:07.003785 27891 solver.cpp:238]     Train net output #14: loss22 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003793 27891 solver.cpp:238]     Train net output #15: loss23 = 542.494 (* 1 = 542.494 loss)
I0726 13:24:07.003798 27891 solver.cpp:238]     Train net output #16: loss24 = 540.085 (* 1 = 540.085 loss)
I0726 13:24:07.003804 27891 solver.cpp:238]     Train net output #17: loss25 = 568.434 (* 1 = 568.434 loss)
I0726 13:24:07.003810 27891 solver.cpp:238]     Train net output #18: loss26 = 541.606 (* 1 = 541.606 loss)
I0726 13:24:07.003816 27891 solver.cpp:238]     Train net output #19: loss27 = 535.82 (* 1 = 535.82 loss)
I0726 13:24:07.003823 27891 solver.cpp:238]     Train net output #20: loss28 = 543.265 (* 1 = 543.265 loss)
I0726 13:24:07.003829 27891 solver.cpp:238]     Train net output #21: loss29 = 564.534 (* 1 = 564.534 loss)
I0726 13:24:07.003834 27891 solver.cpp:238]     Train net output #22: loss3 = 550.571 (* 1 = 550.571 loss)
I0726 13:24:07.003840 27891 solver.cpp:238]     Train net output #23: loss30 = 542.098 (* 1 = 542.098 loss)
I0726 13:24:07.003846 27891 solver.cpp:238]     Train net output #24: loss31 = 535.61 (* 1 = 535.61 loss)
I0726 13:24:07.003854 27891 solver.cpp:238]     Train net output #25: loss32 = 551.602 (* 1 = 551.602 loss)
I0726 13:24:07.003859 27891 solver.cpp:238]     Train net output #26: loss33 = 560.454 (* 1 = 560.454 loss)
I0726 13:24:07.003865 27891 solver.cpp:238]     Train net output #27: loss34 = 552.657 (* 1 = 552.657 loss)
I0726 13:24:07.003870 27891 solver.cpp:238]     Train net output #28: loss35 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003876 27891 solver.cpp:238]     Train net output #29: loss36 = 550.329 (* 1 = 550.329 loss)
I0726 13:24:07.003927 27891 solver.cpp:238]     Train net output #30: loss37 = 546.39 (* 1 = 546.39 loss)
I0726 13:24:07.003937 27891 solver.cpp:238]     Train net output #31: loss38 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003943 27891 solver.cpp:238]     Train net output #32: loss39 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003949 27891 solver.cpp:238]     Train net output #33: loss4 = 546.355 (* 1 = 546.355 loss)
I0726 13:24:07.003958 27891 solver.cpp:238]     Train net output #34: loss40 = 526.588 (* 1 = 526.588 loss)
I0726 13:24:07.003968 27891 solver.cpp:238]     Train net output #35: loss41 = 556.933 (* 1 = 556.933 loss)
I0726 13:24:07.003978 27891 solver.cpp:238]     Train net output #36: loss42 = 543.701 (* 1 = 543.701 loss)
I0726 13:24:07.003986 27891 solver.cpp:238]     Train net output #37: loss43 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.003995 27891 solver.cpp:238]     Train net output #38: loss44 = 553.371 (* 1 = 553.371 loss)
I0726 13:24:07.004004 27891 solver.cpp:238]     Train net output #39: loss45 = 545.222 (* 1 = 545.222 loss)
I0726 13:24:07.004015 27891 solver.cpp:238]     Train net output #40: loss46 = 541.943 (* 1 = 541.943 loss)
I0726 13:24:07.004026 27891 solver.cpp:238]     Train net output #41: loss47 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004035 27891 solver.cpp:238]     Train net output #42: loss48 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004042 27891 solver.cpp:238]     Train net output #43: loss49 = 563.078 (* 1 = 563.078 loss)
I0726 13:24:07.004048 27891 solver.cpp:238]     Train net output #44: loss5 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004055 27891 solver.cpp:238]     Train net output #45: loss50 = 556.173 (* 1 = 556.173 loss)
I0726 13:24:07.004060 27891 solver.cpp:238]     Train net output #46: loss51 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004066 27891 solver.cpp:238]     Train net output #47: loss52 = 548.645 (* 1 = 548.645 loss)
I0726 13:24:07.004073 27891 solver.cpp:238]     Train net output #48: loss53 = 539.367 (* 1 = 539.367 loss)
I0726 13:24:07.004079 27891 solver.cpp:238]     Train net output #49: loss54 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004086 27891 solver.cpp:238]     Train net output #50: loss55 = 541.688 (* 1 = 541.688 loss)
I0726 13:24:07.004091 27891 solver.cpp:238]     Train net output #51: loss56 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004097 27891 solver.cpp:238]     Train net output #52: loss57 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004102 27891 solver.cpp:238]     Train net output #53: loss58 = 561.369 (* 1 = 561.369 loss)
I0726 13:24:07.004107 27891 solver.cpp:238]     Train net output #54: loss59 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004113 27891 solver.cpp:238]     Train net output #55: loss6 = 544.681 (* 1 = 544.681 loss)
I0726 13:24:07.004119 27891 solver.cpp:238]     Train net output #56: loss60 = 566.347 (* 1 = 566.347 loss)
I0726 13:24:07.004125 27891 solver.cpp:238]     Train net output #57: loss61 = 536.712 (* 1 = 536.712 loss)
I0726 13:24:07.004132 27891 solver.cpp:238]     Train net output #58: loss62 = 538.698 (* 1 = 538.698 loss)
I0726 13:24:07.004137 27891 solver.cpp:238]     Train net output #59: loss63 = 557.205 (* 1 = 557.205 loss)
I0726 13:24:07.004144 27891 solver.cpp:238]     Train net output #60: loss64 = 543.612 (* 1 = 543.612 loss)
I0726 13:24:07.004150 27891 solver.cpp:238]     Train net output #61: loss7 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004158 27891 solver.cpp:238]     Train net output #62: loss8 = 546.53 (* 1 = 546.53 loss)
I0726 13:24:07.004163 27891 solver.cpp:238]     Train net output #63: loss9 = 534.091 (* 1 = 534.091 loss)
I0726 13:24:07.004169 27891 sgd_solver.cpp:105] Iteration 124200, lr = 1e-09
I0726 13:33:04.639083 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:33:04.639093 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:33:05.024651 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_129600.caffemodel
I0726 13:33:05.526880 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_129600.solverstate
I0726 13:33:05.615058 27891 solver.cpp:331] Iteration 129600, Testing net (#0)
I0726 13:33:20.964277 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:33:21.054914 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:33:21.429576 27891 solver.cpp:398]     Test net output #0: mae = 78.9769 (* 1 = 78.9769 loss)
I0726 13:33:21.429957 27891 solver.cpp:398]     Test net output #1: mse = 13355.4 (* 1 = 13355.4 loss)
I0726 13:33:21.556509 27891 solver.cpp:219] Iteration 129600 (9.73774 iter/s, 554.543s/5400 iters), loss = 34694.8
I0726 13:33:21.556572 27891 solver.cpp:238]     Train net output #0: loss1 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556584 27891 solver.cpp:238]     Train net output #1: loss10 = 544.833 (* 1 = 544.833 loss)
I0726 13:33:21.556594 27891 solver.cpp:238]     Train net output #2: loss11 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556604 27891 solver.cpp:238]     Train net output #3: loss12 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556614 27891 solver.cpp:238]     Train net output #4: loss13 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556624 27891 solver.cpp:238]     Train net output #5: loss14 = 541.128 (* 1 = 541.128 loss)
I0726 13:33:21.556633 27891 solver.cpp:238]     Train net output #6: loss15 = 545.642 (* 1 = 545.642 loss)
I0726 13:33:21.556643 27891 solver.cpp:238]     Train net output #7: loss16 = 546.005 (* 1 = 546.005 loss)
I0726 13:33:21.556653 27891 solver.cpp:238]     Train net output #8: loss17 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556661 27891 solver.cpp:238]     Train net output #9: loss18 = 549.226 (* 1 = 549.226 loss)
I0726 13:33:21.556671 27891 solver.cpp:238]     Train net output #10: loss19 = 541.798 (* 1 = 541.798 loss)
I0726 13:33:21.556680 27891 solver.cpp:238]     Train net output #11: loss2 = 547.036 (* 1 = 547.036 loss)
I0726 13:33:21.556690 27891 solver.cpp:238]     Train net output #12: loss20 = 572.002 (* 1 = 572.002 loss)
I0726 13:33:21.556699 27891 solver.cpp:238]     Train net output #13: loss21 = 540.627 (* 1 = 540.627 loss)
I0726 13:33:21.556710 27891 solver.cpp:238]     Train net output #14: loss22 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.556718 27891 solver.cpp:238]     Train net output #15: loss23 = 540.605 (* 1 = 540.605 loss)
I0726 13:33:21.556727 27891 solver.cpp:238]     Train net output #16: loss24 = 537.641 (* 1 = 537.641 loss)
I0726 13:33:21.556737 27891 solver.cpp:238]     Train net output #17: loss25 = 565.489 (* 1 = 565.489 loss)
I0726 13:33:21.556746 27891 solver.cpp:238]     Train net output #18: loss26 = 539.131 (* 1 = 539.131 loss)
I0726 13:33:21.556756 27891 solver.cpp:238]     Train net output #19: loss27 = 533.468 (* 1 = 533.468 loss)
I0726 13:33:21.556766 27891 solver.cpp:238]     Train net output #20: loss28 = 540.924 (* 1 = 540.924 loss)
I0726 13:33:21.556776 27891 solver.cpp:238]     Train net output #21: loss29 = 561.543 (* 1 = 561.543 loss)
I0726 13:33:21.556785 27891 solver.cpp:238]     Train net output #22: loss3 = 548.411 (* 1 = 548.411 loss)
I0726 13:33:21.556794 27891 solver.cpp:238]     Train net output #23: loss30 = 539.395 (* 1 = 539.395 loss)
I0726 13:33:21.556803 27891 solver.cpp:238]     Train net output #24: loss31 = 532.875 (* 1 = 532.875 loss)
I0726 13:33:21.556813 27891 solver.cpp:238]     Train net output #25: loss32 = 549.316 (* 1 = 549.316 loss)
I0726 13:33:21.556823 27891 solver.cpp:238]     Train net output #26: loss33 = 557.891 (* 1 = 557.891 loss)
I0726 13:33:21.556833 27891 solver.cpp:238]     Train net output #27: loss34 = 549.958 (* 1 = 549.958 loss)
I0726 13:33:21.556841 27891 solver.cpp:238]     Train net output #28: loss35 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559692 27891 solver.cpp:238]     Train net output #29: loss36 = 547.328 (* 1 = 547.328 loss)
I0726 13:33:21.559710 27891 solver.cpp:238]     Train net output #30: loss37 = 543.606 (* 1 = 543.606 loss)
I0726 13:33:21.559715 27891 solver.cpp:238]     Train net output #31: loss38 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559722 27891 solver.cpp:238]     Train net output #32: loss39 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559728 27891 solver.cpp:238]     Train net output #33: loss4 = 543.467 (* 1 = 543.467 loss)
I0726 13:33:21.559736 27891 solver.cpp:238]     Train net output #34: loss40 = 524.175 (* 1 = 524.175 loss)
I0726 13:33:21.559742 27891 solver.cpp:238]     Train net output #35: loss41 = 554.212 (* 1 = 554.212 loss)
I0726 13:33:21.559748 27891 solver.cpp:238]     Train net output #36: loss42 = 541.791 (* 1 = 541.791 loss)
I0726 13:33:21.559754 27891 solver.cpp:238]     Train net output #37: loss43 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559761 27891 solver.cpp:238]     Train net output #38: loss44 = 550.799 (* 1 = 550.799 loss)
I0726 13:33:21.559767 27891 solver.cpp:238]     Train net output #39: loss45 = 542.812 (* 1 = 542.812 loss)
I0726 13:33:21.559773 27891 solver.cpp:238]     Train net output #40: loss46 = 539.696 (* 1 = 539.696 loss)
I0726 13:33:21.559779 27891 solver.cpp:238]     Train net output #41: loss47 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559785 27891 solver.cpp:238]     Train net output #42: loss48 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559792 27891 solver.cpp:238]     Train net output #43: loss49 = 559.816 (* 1 = 559.816 loss)
I0726 13:33:21.559801 27891 solver.cpp:238]     Train net output #44: loss5 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559808 27891 solver.cpp:238]     Train net output #45: loss50 = 553.068 (* 1 = 553.068 loss)
I0726 13:33:21.559813 27891 solver.cpp:238]     Train net output #46: loss51 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559819 27891 solver.cpp:238]     Train net output #47: loss52 = 545.663 (* 1 = 545.663 loss)
I0726 13:33:21.559825 27891 solver.cpp:238]     Train net output #48: loss53 = 537.056 (* 1 = 537.056 loss)
I0726 13:33:21.559831 27891 solver.cpp:238]     Train net output #49: loss54 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559837 27891 solver.cpp:238]     Train net output #50: loss55 = 539.32 (* 1 = 539.32 loss)
I0726 13:33:21.559844 27891 solver.cpp:238]     Train net output #51: loss56 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559849 27891 solver.cpp:238]     Train net output #52: loss57 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559856 27891 solver.cpp:238]     Train net output #53: loss58 = 558.749 (* 1 = 558.749 loss)
I0726 13:33:21.559862 27891 solver.cpp:238]     Train net output #54: loss59 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559869 27891 solver.cpp:238]     Train net output #55: loss6 = 542.211 (* 1 = 542.211 loss)
I0726 13:33:21.559873 27891 solver.cpp:238]     Train net output #56: loss60 = 563.298 (* 1 = 563.298 loss)
I0726 13:33:21.559880 27891 solver.cpp:238]     Train net output #57: loss61 = 534.416 (* 1 = 534.416 loss)
I0726 13:33:21.559886 27891 solver.cpp:238]     Train net output #58: loss62 = 536.26 (* 1 = 536.26 loss)
I0726 13:33:21.559892 27891 solver.cpp:238]     Train net output #59: loss63 = 554.353 (* 1 = 554.353 loss)
I0726 13:33:21.559898 27891 solver.cpp:238]     Train net output #60: loss64 = 541.416 (* 1 = 541.416 loss)
I0726 13:33:21.559904 27891 solver.cpp:238]     Train net output #61: loss7 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559911 27891 solver.cpp:238]     Train net output #62: loss8 = 544.126 (* 1 = 544.126 loss)
I0726 13:33:21.559916 27891 solver.cpp:238]     Train net output #63: loss9 = 531.567 (* 1 = 531.567 loss)
I0726 13:33:21.559923 27891 sgd_solver.cpp:105] Iteration 129600, lr = 1e-09
I0726 13:42:22.648813 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:42:22.650436 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:42:23.037914 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_135000.caffemodel
I0726 13:42:23.444092 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_135000.solverstate
I0726 13:42:23.526978 27891 solver.cpp:331] Iteration 135000, Testing net (#0)
I0726 13:42:38.919812 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:42:39.138710 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:42:39.385793 27891 solver.cpp:398]     Test net output #0: mae = 78.6201 (* 1 = 78.6201 loss)
I0726 13:42:39.386128 27891 solver.cpp:398]     Test net output #1: mse = 13305.5 (* 1 = 13305.5 loss)
I0726 13:42:39.511737 27891 solver.cpp:219] Iteration 135000 (9.67836 iter/s, 557.946s/5400 iters), loss = 34463.5
I0726 13:42:39.511801 27891 solver.cpp:238]     Train net output #0: loss1 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511811 27891 solver.cpp:238]     Train net output #1: loss10 = 540.876 (* 1 = 540.876 loss)
I0726 13:42:39.511817 27891 solver.cpp:238]     Train net output #2: loss11 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511823 27891 solver.cpp:238]     Train net output #3: loss12 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511829 27891 solver.cpp:238]     Train net output #4: loss13 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511835 27891 solver.cpp:238]     Train net output #5: loss14 = 536.855 (* 1 = 536.855 loss)
I0726 13:42:39.511842 27891 solver.cpp:238]     Train net output #6: loss15 = 542.297 (* 1 = 542.297 loss)
I0726 13:42:39.511849 27891 solver.cpp:238]     Train net output #7: loss16 = 542.095 (* 1 = 542.095 loss)
I0726 13:42:39.511857 27891 solver.cpp:238]     Train net output #8: loss17 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511862 27891 solver.cpp:238]     Train net output #9: loss18 = 545.769 (* 1 = 545.769 loss)
I0726 13:42:39.511868 27891 solver.cpp:238]     Train net output #10: loss19 = 537.904 (* 1 = 537.904 loss)
I0726 13:42:39.511874 27891 solver.cpp:238]     Train net output #11: loss2 = 543.464 (* 1 = 543.464 loss)
I0726 13:42:39.511880 27891 solver.cpp:238]     Train net output #12: loss20 = 567.44 (* 1 = 567.44 loss)
I0726 13:42:39.511888 27891 solver.cpp:238]     Train net output #13: loss21 = 537.256 (* 1 = 537.256 loss)
I0726 13:42:39.511893 27891 solver.cpp:238]     Train net output #14: loss22 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511899 27891 solver.cpp:238]     Train net output #15: loss23 = 537.62 (* 1 = 537.62 loss)
I0726 13:42:39.511905 27891 solver.cpp:238]     Train net output #16: loss24 = 534.139 (* 1 = 534.139 loss)
I0726 13:42:39.511912 27891 solver.cpp:238]     Train net output #17: loss25 = 561.707 (* 1 = 561.707 loss)
I0726 13:42:39.511919 27891 solver.cpp:238]     Train net output #18: loss26 = 535.61 (* 1 = 535.61 loss)
I0726 13:42:39.511925 27891 solver.cpp:238]     Train net output #19: loss27 = 530.054 (* 1 = 530.054 loss)
I0726 13:42:39.511931 27891 solver.cpp:238]     Train net output #20: loss28 = 537.54 (* 1 = 537.54 loss)
I0726 13:42:39.511940 27891 solver.cpp:238]     Train net output #21: loss29 = 557.595 (* 1 = 557.595 loss)
I0726 13:42:39.511945 27891 solver.cpp:238]     Train net output #22: loss3 = 545.072 (* 1 = 545.072 loss)
I0726 13:42:39.511951 27891 solver.cpp:238]     Train net output #23: loss30 = 535.705 (* 1 = 535.705 loss)
I0726 13:42:39.511957 27891 solver.cpp:238]     Train net output #24: loss31 = 529.202 (* 1 = 529.202 loss)
I0726 13:42:39.511963 27891 solver.cpp:238]     Train net output #25: loss32 = 545.964 (* 1 = 545.964 loss)
I0726 13:42:39.511970 27891 solver.cpp:238]     Train net output #26: loss33 = 554.384 (* 1 = 554.384 loss)
I0726 13:42:39.511976 27891 solver.cpp:238]     Train net output #27: loss34 = 546.146 (* 1 = 546.146 loss)
I0726 13:42:39.511981 27891 solver.cpp:238]     Train net output #28: loss35 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.511987 27891 solver.cpp:238]     Train net output #29: loss36 = 543.214 (* 1 = 543.214 loss)
I0726 13:42:39.512169 27891 solver.cpp:238]     Train net output #30: loss37 = 539.707 (* 1 = 539.707 loss)
I0726 13:42:39.512193 27891 solver.cpp:238]     Train net output #31: loss38 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512200 27891 solver.cpp:238]     Train net output #32: loss39 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512207 27891 solver.cpp:238]     Train net output #33: loss4 = 539.623 (* 1 = 539.623 loss)
I0726 13:42:39.512213 27891 solver.cpp:238]     Train net output #34: loss40 = 520.726 (* 1 = 520.726 loss)
I0726 13:42:39.512219 27891 solver.cpp:238]     Train net output #35: loss41 = 550.524 (* 1 = 550.524 loss)
I0726 13:42:39.512226 27891 solver.cpp:238]     Train net output #36: loss42 = 538.728 (* 1 = 538.728 loss)
I0726 13:42:39.512233 27891 solver.cpp:238]     Train net output #37: loss43 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512239 27891 solver.cpp:238]     Train net output #38: loss44 = 546.977 (* 1 = 546.977 loss)
I0726 13:42:39.512244 27891 solver.cpp:238]     Train net output #39: loss45 = 539.355 (* 1 = 539.355 loss)
I0726 13:42:39.512251 27891 solver.cpp:238]     Train net output #40: loss46 = 536.335 (* 1 = 536.335 loss)
I0726 13:42:39.512256 27891 solver.cpp:238]     Train net output #41: loss47 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512264 27891 solver.cpp:238]     Train net output #42: loss48 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512269 27891 solver.cpp:238]     Train net output #43: loss49 = 555.686 (* 1 = 555.686 loss)
I0726 13:42:39.512275 27891 solver.cpp:238]     Train net output #44: loss5 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512282 27891 solver.cpp:238]     Train net output #45: loss50 = 549.11 (* 1 = 549.11 loss)
I0726 13:42:39.512289 27891 solver.cpp:238]     Train net output #46: loss51 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512295 27891 solver.cpp:238]     Train net output #47: loss52 = 541.456 (* 1 = 541.456 loss)
I0726 13:42:39.512300 27891 solver.cpp:238]     Train net output #48: loss53 = 533.708 (* 1 = 533.708 loss)
I0726 13:42:39.512307 27891 solver.cpp:238]     Train net output #49: loss54 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512320 27891 solver.cpp:238]     Train net output #50: loss55 = 535.881 (* 1 = 535.881 loss)
I0726 13:42:39.512327 27891 solver.cpp:238]     Train net output #51: loss56 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512334 27891 solver.cpp:238]     Train net output #52: loss57 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512341 27891 solver.cpp:238]     Train net output #53: loss58 = 555.076 (* 1 = 555.076 loss)
I0726 13:42:39.512346 27891 solver.cpp:238]     Train net output #54: loss59 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512352 27891 solver.cpp:238]     Train net output #55: loss6 = 538.624 (* 1 = 538.624 loss)
I0726 13:42:39.512358 27891 solver.cpp:238]     Train net output #56: loss60 = 559.075 (* 1 = 559.075 loss)
I0726 13:42:39.512365 27891 solver.cpp:238]     Train net output #57: loss61 = 531.269 (* 1 = 531.269 loss)
I0726 13:42:39.512372 27891 solver.cpp:238]     Train net output #58: loss62 = 532.911 (* 1 = 532.911 loss)
I0726 13:42:39.512377 27891 solver.cpp:238]     Train net output #59: loss63 = 550.356 (* 1 = 550.356 loss)
I0726 13:42:39.512383 27891 solver.cpp:238]     Train net output #60: loss64 = 538.232 (* 1 = 538.232 loss)
I0726 13:42:39.512390 27891 solver.cpp:238]     Train net output #61: loss7 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512397 27891 solver.cpp:238]     Train net output #62: loss8 = 540.509 (* 1 = 540.509 loss)
I0726 13:42:39.512403 27891 solver.cpp:238]     Train net output #63: loss9 = 528.059 (* 1 = 528.059 loss)
I0726 13:42:39.512413 27891 sgd_solver.cpp:105] Iteration 135000, lr = 1e-09
I0726 13:51:42.933231 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:51:42.936970 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:51:43.336894 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_140400.caffemodel
I0726 13:51:43.577198 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_140400.solverstate
I0726 13:51:43.660997 27891 solver.cpp:331] Iteration 140400, Testing net (#0)
I0726 13:51:58.885030 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:51:58.915230 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 13:51:59.351027 27891 solver.cpp:398]     Test net output #0: mae = 77.8929 (* 1 = 77.8929 loss)
I0726 13:51:59.351058 27891 solver.cpp:398]     Test net output #1: mse = 13244.9 (* 1 = 13244.9 loss)
I0726 13:51:59.476022 27891 solver.cpp:219] Iteration 140400 (9.64378 iter/s, 559.947s/5400 iters), loss = 34252.9
I0726 13:51:59.476058 27891 solver.cpp:238]     Train net output #0: loss1 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476065 27891 solver.cpp:238]     Train net output #1: loss10 = 537.3 (* 1 = 537.3 loss)
I0726 13:51:59.476070 27891 solver.cpp:238]     Train net output #2: loss11 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476081 27891 solver.cpp:238]     Train net output #3: loss12 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476089 27891 solver.cpp:238]     Train net output #4: loss13 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476094 27891 solver.cpp:238]     Train net output #5: loss14 = 532.798 (* 1 = 532.798 loss)
I0726 13:51:59.476100 27891 solver.cpp:238]     Train net output #6: loss15 = 539.148 (* 1 = 539.148 loss)
I0726 13:51:59.476107 27891 solver.cpp:238]     Train net output #7: loss16 = 538.708 (* 1 = 538.708 loss)
I0726 13:51:59.476114 27891 solver.cpp:238]     Train net output #8: loss17 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476120 27891 solver.cpp:238]     Train net output #9: loss18 = 542.42 (* 1 = 542.42 loss)
I0726 13:51:59.476126 27891 solver.cpp:238]     Train net output #10: loss19 = 534.351 (* 1 = 534.351 loss)
I0726 13:51:59.476135 27891 solver.cpp:238]     Train net output #11: loss2 = 540.072 (* 1 = 540.072 loss)
I0726 13:51:59.476140 27891 solver.cpp:238]     Train net output #12: loss20 = 563.249 (* 1 = 563.249 loss)
I0726 13:51:59.476146 27891 solver.cpp:238]     Train net output #13: loss21 = 534.083 (* 1 = 534.083 loss)
I0726 13:51:59.476152 27891 solver.cpp:238]     Train net output #14: loss22 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476158 27891 solver.cpp:238]     Train net output #15: loss23 = 534.701 (* 1 = 534.701 loss)
I0726 13:51:59.476164 27891 solver.cpp:238]     Train net output #16: loss24 = 530.886 (* 1 = 530.886 loss)
I0726 13:51:59.476171 27891 solver.cpp:238]     Train net output #17: loss25 = 557.964 (* 1 = 557.964 loss)
I0726 13:51:59.476178 27891 solver.cpp:238]     Train net output #18: loss26 = 532.206 (* 1 = 532.206 loss)
I0726 13:51:59.476184 27891 solver.cpp:238]     Train net output #19: loss27 = 527.045 (* 1 = 527.045 loss)
I0726 13:51:59.476191 27891 solver.cpp:238]     Train net output #20: loss28 = 534.366 (* 1 = 534.366 loss)
I0726 13:51:59.476198 27891 solver.cpp:238]     Train net output #21: loss29 = 553.709 (* 1 = 553.709 loss)
I0726 13:51:59.476205 27891 solver.cpp:238]     Train net output #22: loss3 = 541.995 (* 1 = 541.995 loss)
I0726 13:51:59.476212 27891 solver.cpp:238]     Train net output #23: loss30 = 532.333 (* 1 = 532.333 loss)
I0726 13:51:59.476219 27891 solver.cpp:238]     Train net output #24: loss31 = 525.802 (* 1 = 525.802 loss)
I0726 13:51:59.476225 27891 solver.cpp:238]     Train net output #25: loss32 = 542.777 (* 1 = 542.777 loss)
I0726 13:51:59.476233 27891 solver.cpp:238]     Train net output #26: loss33 = 551.101 (* 1 = 551.101 loss)
I0726 13:51:59.476239 27891 solver.cpp:238]     Train net output #27: loss34 = 542.678 (* 1 = 542.678 loss)
I0726 13:51:59.476245 27891 solver.cpp:238]     Train net output #28: loss35 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476253 27891 solver.cpp:238]     Train net output #29: loss36 = 539.421 (* 1 = 539.421 loss)
I0726 13:51:59.476297 27891 solver.cpp:238]     Train net output #30: loss37 = 535.949 (* 1 = 535.949 loss)
I0726 13:51:59.476305 27891 solver.cpp:238]     Train net output #31: loss38 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476312 27891 solver.cpp:238]     Train net output #32: loss39 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476318 27891 solver.cpp:238]     Train net output #33: loss4 = 535.975 (* 1 = 535.975 loss)
I0726 13:51:59.476325 27891 solver.cpp:238]     Train net output #34: loss40 = 517.542 (* 1 = 517.542 loss)
I0726 13:51:59.476331 27891 solver.cpp:238]     Train net output #35: loss41 = 547.071 (* 1 = 547.071 loss)
I0726 13:51:59.476341 27891 solver.cpp:238]     Train net output #36: loss42 = 535.777 (* 1 = 535.777 loss)
I0726 13:51:59.476351 27891 solver.cpp:238]     Train net output #37: loss43 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476361 27891 solver.cpp:238]     Train net output #38: loss44 = 543.59 (* 1 = 543.59 loss)
I0726 13:51:59.476369 27891 solver.cpp:238]     Train net output #39: loss45 = 536.08 (* 1 = 536.08 loss)
I0726 13:51:59.476379 27891 solver.cpp:238]     Train net output #40: loss46 = 533.227 (* 1 = 533.227 loss)
I0726 13:51:59.476388 27891 solver.cpp:238]     Train net output #41: loss47 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476398 27891 solver.cpp:238]     Train net output #42: loss48 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476410 27891 solver.cpp:238]     Train net output #43: loss49 = 551.675 (* 1 = 551.675 loss)
I0726 13:51:59.476423 27891 solver.cpp:238]     Train net output #44: loss5 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476431 27891 solver.cpp:238]     Train net output #45: loss50 = 545.262 (* 1 = 545.262 loss)
I0726 13:51:59.476438 27891 solver.cpp:238]     Train net output #46: loss51 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476444 27891 solver.cpp:238]     Train net output #47: loss52 = 537.807 (* 1 = 537.807 loss)
I0726 13:51:59.476450 27891 solver.cpp:238]     Train net output #48: loss53 = 530.571 (* 1 = 530.571 loss)
I0726 13:51:59.476456 27891 solver.cpp:238]     Train net output #49: loss54 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476464 27891 solver.cpp:238]     Train net output #50: loss55 = 532.494 (* 1 = 532.494 loss)
I0726 13:51:59.476469 27891 solver.cpp:238]     Train net output #51: loss56 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476475 27891 solver.cpp:238]     Train net output #52: loss57 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476482 27891 solver.cpp:238]     Train net output #53: loss58 = 551.577 (* 1 = 551.577 loss)
I0726 13:51:59.476490 27891 solver.cpp:238]     Train net output #54: loss59 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476495 27891 solver.cpp:238]     Train net output #55: loss6 = 535.397 (* 1 = 535.397 loss)
I0726 13:51:59.476502 27891 solver.cpp:238]     Train net output #56: loss60 = 555.048 (* 1 = 555.048 loss)
I0726 13:51:59.476510 27891 solver.cpp:238]     Train net output #57: loss61 = 528.207 (* 1 = 528.207 loss)
I0726 13:51:59.476516 27891 solver.cpp:238]     Train net output #58: loss62 = 529.841 (* 1 = 529.841 loss)
I0726 13:51:59.476521 27891 solver.cpp:238]     Train net output #59: loss63 = 546.456 (* 1 = 546.456 loss)
I0726 13:51:59.476528 27891 solver.cpp:238]     Train net output #60: loss64 = 535.232 (* 1 = 535.232 loss)
I0726 13:51:59.476536 27891 solver.cpp:238]     Train net output #61: loss7 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476541 27891 solver.cpp:238]     Train net output #62: loss8 = 537.003 (* 1 = 537.003 loss)
I0726 13:51:59.476547 27891 solver.cpp:238]     Train net output #63: loss9 = 524.865 (* 1 = 524.865 loss)
I0726 13:51:59.476554 27891 sgd_solver.cpp:105] Iteration 140400, lr = 1e-09
I0726 14:01:02.419555 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:01:02.420774 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:01:02.807265 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_145800.caffemodel
I0726 14:01:03.028095 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_145800.solverstate
I0726 14:01:03.118361 27891 solver.cpp:331] Iteration 145800, Testing net (#0)
I0726 14:01:18.350471 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:01:18.365350 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:01:18.814626 27891 solver.cpp:398]     Test net output #0: mae = 77.5508 (* 1 = 77.5508 loss)
I0726 14:01:18.814656 27891 solver.cpp:398]     Test net output #1: mse = 13208.1 (* 1 = 13208.1 loss)
I0726 14:01:18.939497 27891 solver.cpp:219] Iteration 145800 (9.65235 iter/s, 559.449s/5400 iters), loss = 34170.4
I0726 14:01:18.939532 27891 solver.cpp:238]     Train net output #0: loss1 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939539 27891 solver.cpp:238]     Train net output #1: loss10 = 535.727 (* 1 = 535.727 loss)
I0726 14:01:18.939544 27891 solver.cpp:238]     Train net output #2: loss11 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939549 27891 solver.cpp:238]     Train net output #3: loss12 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939555 27891 solver.cpp:238]     Train net output #4: loss13 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939560 27891 solver.cpp:238]     Train net output #5: loss14 = 530.936 (* 1 = 530.936 loss)
I0726 14:01:18.939566 27891 solver.cpp:238]     Train net output #6: loss15 = 538.043 (* 1 = 538.043 loss)
I0726 14:01:18.939573 27891 solver.cpp:238]     Train net output #7: loss16 = 537.304 (* 1 = 537.304 loss)
I0726 14:01:18.939579 27891 solver.cpp:238]     Train net output #8: loss17 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939584 27891 solver.cpp:238]     Train net output #9: loss18 = 541.257 (* 1 = 541.257 loss)
I0726 14:01:18.939591 27891 solver.cpp:238]     Train net output #10: loss19 = 532.774 (* 1 = 532.774 loss)
I0726 14:01:18.939597 27891 solver.cpp:238]     Train net output #11: loss2 = 538.911 (* 1 = 538.911 loss)
I0726 14:01:18.939604 27891 solver.cpp:238]     Train net output #12: loss20 = 561.461 (* 1 = 561.461 loss)
I0726 14:01:18.939610 27891 solver.cpp:238]     Train net output #13: loss21 = 533.098 (* 1 = 533.098 loss)
I0726 14:01:18.939615 27891 solver.cpp:238]     Train net output #14: loss22 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939621 27891 solver.cpp:238]     Train net output #15: loss23 = 533.726 (* 1 = 533.726 loss)
I0726 14:01:18.939627 27891 solver.cpp:238]     Train net output #16: loss24 = 529.666 (* 1 = 529.666 loss)
I0726 14:01:18.939633 27891 solver.cpp:238]     Train net output #17: loss25 = 556.546 (* 1 = 556.546 loss)
I0726 14:01:18.939640 27891 solver.cpp:238]     Train net output #18: loss26 = 530.912 (* 1 = 530.912 loss)
I0726 14:01:18.939646 27891 solver.cpp:238]     Train net output #19: loss27 = 525.904 (* 1 = 525.904 loss)
I0726 14:01:18.939651 27891 solver.cpp:238]     Train net output #20: loss28 = 533.222 (* 1 = 533.222 loss)
I0726 14:01:18.939656 27891 solver.cpp:238]     Train net output #21: loss29 = 552.277 (* 1 = 552.277 loss)
I0726 14:01:18.939662 27891 solver.cpp:238]     Train net output #22: loss3 = 541.175 (* 1 = 541.175 loss)
I0726 14:01:18.939667 27891 solver.cpp:238]     Train net output #23: loss30 = 530.884 (* 1 = 530.884 loss)
I0726 14:01:18.939673 27891 solver.cpp:238]     Train net output #24: loss31 = 524.34 (* 1 = 524.34 loss)
I0726 14:01:18.939680 27891 solver.cpp:238]     Train net output #25: loss32 = 541.804 (* 1 = 541.804 loss)
I0726 14:01:18.939685 27891 solver.cpp:238]     Train net output #26: loss33 = 550.183 (* 1 = 550.183 loss)
I0726 14:01:18.939692 27891 solver.cpp:238]     Train net output #27: loss34 = 541.372 (* 1 = 541.372 loss)
I0726 14:01:18.939697 27891 solver.cpp:238]     Train net output #28: loss35 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939745 27891 solver.cpp:238]     Train net output #29: loss36 = 537.554 (* 1 = 537.554 loss)
I0726 14:01:18.939754 27891 solver.cpp:238]     Train net output #30: loss37 = 534.46 (* 1 = 534.46 loss)
I0726 14:01:18.939762 27891 solver.cpp:238]     Train net output #31: loss38 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939769 27891 solver.cpp:238]     Train net output #32: loss39 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939775 27891 solver.cpp:238]     Train net output #33: loss4 = 534.4 (* 1 = 534.4 loss)
I0726 14:01:18.939780 27891 solver.cpp:238]     Train net output #34: loss40 = 516.429 (* 1 = 516.429 loss)
I0726 14:01:18.939786 27891 solver.cpp:238]     Train net output #35: loss41 = 545.832 (* 1 = 545.832 loss)
I0726 14:01:18.939792 27891 solver.cpp:238]     Train net output #36: loss42 = 535.057 (* 1 = 535.057 loss)
I0726 14:01:18.939800 27891 solver.cpp:238]     Train net output #37: loss43 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939805 27891 solver.cpp:238]     Train net output #38: loss44 = 542.066 (* 1 = 542.066 loss)
I0726 14:01:18.939812 27891 solver.cpp:238]     Train net output #39: loss45 = 534.817 (* 1 = 534.817 loss)
I0726 14:01:18.939818 27891 solver.cpp:238]     Train net output #40: loss46 = 532.248 (* 1 = 532.248 loss)
I0726 14:01:18.939826 27891 solver.cpp:238]     Train net output #41: loss47 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939832 27891 solver.cpp:238]     Train net output #42: loss48 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939838 27891 solver.cpp:238]     Train net output #43: loss49 = 550.092 (* 1 = 550.092 loss)
I0726 14:01:18.939844 27891 solver.cpp:238]     Train net output #44: loss5 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939851 27891 solver.cpp:238]     Train net output #45: loss50 = 543.633 (* 1 = 543.633 loss)
I0726 14:01:18.939857 27891 solver.cpp:238]     Train net output #46: loss51 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939862 27891 solver.cpp:238]     Train net output #47: loss52 = 536.324 (* 1 = 536.324 loss)
I0726 14:01:18.939868 27891 solver.cpp:238]     Train net output #48: loss53 = 529.459 (* 1 = 529.459 loss)
I0726 14:01:18.939874 27891 solver.cpp:238]     Train net output #49: loss54 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939880 27891 solver.cpp:238]     Train net output #50: loss55 = 531.382 (* 1 = 531.382 loss)
I0726 14:01:18.939887 27891 solver.cpp:238]     Train net output #51: loss56 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939893 27891 solver.cpp:238]     Train net output #52: loss57 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939898 27891 solver.cpp:238]     Train net output #53: loss58 = 550.333 (* 1 = 550.333 loss)
I0726 14:01:18.939904 27891 solver.cpp:238]     Train net output #54: loss59 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939911 27891 solver.cpp:238]     Train net output #55: loss6 = 534.169 (* 1 = 534.169 loss)
I0726 14:01:18.939918 27891 solver.cpp:238]     Train net output #56: loss60 = 553.33 (* 1 = 553.33 loss)
I0726 14:01:18.939923 27891 solver.cpp:238]     Train net output #57: loss61 = 527.178 (* 1 = 527.178 loss)
I0726 14:01:18.939929 27891 solver.cpp:238]     Train net output #58: loss62 = 528.72 (* 1 = 528.72 loss)
I0726 14:01:18.939934 27891 solver.cpp:238]     Train net output #59: loss63 = 545.066 (* 1 = 545.066 loss)
I0726 14:01:18.939940 27891 solver.cpp:238]     Train net output #60: loss64 = 534.323 (* 1 = 534.323 loss)
I0726 14:01:18.939947 27891 solver.cpp:238]     Train net output #61: loss7 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939952 27891 solver.cpp:238]     Train net output #62: loss8 = 535.772 (* 1 = 535.772 loss)
I0726 14:01:18.939959 27891 solver.cpp:238]     Train net output #63: loss9 = 523.569 (* 1 = 523.569 loss)
I0726 14:01:18.939965 27891 sgd_solver.cpp:105] Iteration 145800, lr = 1e-09
I0726 14:10:22.699475 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:10:22.702740 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:10:23.088044 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_151200.caffemodel
I0726 14:10:23.367588 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_151200.solverstate
I0726 14:10:23.454071 27891 solver.cpp:331] Iteration 151200, Testing net (#0)
I0726 14:10:38.657477 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:10:38.683501 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:10:39.123034 27891 solver.cpp:398]     Test net output #0: mae = 76.8735 (* 1 = 76.8735 loss)
I0726 14:10:39.123059 27891 solver.cpp:398]     Test net output #1: mse = 13190.1 (* 1 = 13190.1 loss)
I0726 14:10:39.248463 27891 solver.cpp:219] Iteration 151200 (9.63775 iter/s, 560.297s/5400 iters), loss = 33988.5
I0726 14:10:39.248510 27891 solver.cpp:238]     Train net output #0: loss1 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248520 27891 solver.cpp:238]     Train net output #1: loss10 = 532.674 (* 1 = 532.674 loss)
I0726 14:10:39.248528 27891 solver.cpp:238]     Train net output #2: loss11 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248534 27891 solver.cpp:238]     Train net output #3: loss12 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248541 27891 solver.cpp:238]     Train net output #4: loss13 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248548 27891 solver.cpp:238]     Train net output #5: loss14 = 527.483 (* 1 = 527.483 loss)
I0726 14:10:39.248554 27891 solver.cpp:238]     Train net output #6: loss15 = 535.354 (* 1 = 535.354 loss)
I0726 14:10:39.248561 27891 solver.cpp:238]     Train net output #7: loss16 = 534.307 (* 1 = 534.307 loss)
I0726 14:10:39.248569 27891 solver.cpp:238]     Train net output #8: loss17 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248574 27891 solver.cpp:238]     Train net output #9: loss18 = 538.451 (* 1 = 538.451 loss)
I0726 14:10:39.248581 27891 solver.cpp:238]     Train net output #10: loss19 = 529.725 (* 1 = 529.725 loss)
I0726 14:10:39.248587 27891 solver.cpp:238]     Train net output #11: loss2 = 536.1 (* 1 = 536.1 loss)
I0726 14:10:39.248594 27891 solver.cpp:238]     Train net output #12: loss20 = 557.953 (* 1 = 557.953 loss)
I0726 14:10:39.248600 27891 solver.cpp:238]     Train net output #13: loss21 = 531.065 (* 1 = 531.065 loss)
I0726 14:10:39.248607 27891 solver.cpp:238]     Train net output #14: loss22 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248615 27891 solver.cpp:238]     Train net output #15: loss23 = 531.099 (* 1 = 531.099 loss)
I0726 14:10:39.248620 27891 solver.cpp:238]     Train net output #16: loss24 = 526.863 (* 1 = 526.863 loss)
I0726 14:10:39.248627 27891 solver.cpp:238]     Train net output #17: loss25 = 553.468 (* 1 = 553.468 loss)
I0726 14:10:39.248634 27891 solver.cpp:238]     Train net output #18: loss26 = 528.042 (* 1 = 528.042 loss)
I0726 14:10:39.248641 27891 solver.cpp:238]     Train net output #19: loss27 = 523.331 (* 1 = 523.331 loss)
I0726 14:10:39.248648 27891 solver.cpp:238]     Train net output #20: loss28 = 530.497 (* 1 = 530.497 loss)
I0726 14:10:39.248654 27891 solver.cpp:238]     Train net output #21: loss29 = 548.991 (* 1 = 548.991 loss)
I0726 14:10:39.248661 27891 solver.cpp:238]     Train net output #22: loss3 = 538.702 (* 1 = 538.702 loss)
I0726 14:10:39.248672 27891 solver.cpp:238]     Train net output #23: loss30 = 527.984 (* 1 = 527.984 loss)
I0726 14:10:39.248682 27891 solver.cpp:238]     Train net output #24: loss31 = 521.42 (* 1 = 521.42 loss)
I0726 14:10:39.248689 27891 solver.cpp:238]     Train net output #25: loss32 = 539.048 (* 1 = 539.048 loss)
I0726 14:10:39.248697 27891 solver.cpp:238]     Train net output #26: loss33 = 547.666 (* 1 = 547.666 loss)
I0726 14:10:39.248703 27891 solver.cpp:238]     Train net output #27: loss34 = 538.561 (* 1 = 538.561 loss)
I0726 14:10:39.248710 27891 solver.cpp:238]     Train net output #28: loss35 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248718 27891 solver.cpp:238]     Train net output #29: loss36 = 534.219 (* 1 = 534.219 loss)
I0726 14:10:39.248775 27891 solver.cpp:238]     Train net output #30: loss37 = 531.302 (* 1 = 531.302 loss)
I0726 14:10:39.248785 27891 solver.cpp:238]     Train net output #31: loss38 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248792 27891 solver.cpp:238]     Train net output #32: loss39 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248800 27891 solver.cpp:238]     Train net output #33: loss4 = 531.293 (* 1 = 531.293 loss)
I0726 14:10:39.248806 27891 solver.cpp:238]     Train net output #34: loss40 = 513.885 (* 1 = 513.885 loss)
I0726 14:10:39.248827 27891 solver.cpp:238]     Train net output #35: loss41 = 543.112 (* 1 = 543.112 loss)
I0726 14:10:39.248836 27891 solver.cpp:238]     Train net output #36: loss42 = 532.482 (* 1 = 532.482 loss)
I0726 14:10:39.248849 27891 solver.cpp:238]     Train net output #37: loss43 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248857 27891 solver.cpp:238]     Train net output #38: loss44 = 539.006 (* 1 = 539.006 loss)
I0726 14:10:39.248867 27891 solver.cpp:238]     Train net output #39: loss45 = 532.178 (* 1 = 532.178 loss)
I0726 14:10:39.248875 27891 solver.cpp:238]     Train net output #40: loss46 = 529.701 (* 1 = 529.701 loss)
I0726 14:10:39.248884 27891 solver.cpp:238]     Train net output #41: loss47 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248893 27891 solver.cpp:238]     Train net output #42: loss48 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248900 27891 solver.cpp:238]     Train net output #43: loss49 = 546.848 (* 1 = 546.848 loss)
I0726 14:10:39.248909 27891 solver.cpp:238]     Train net output #44: loss5 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248917 27891 solver.cpp:238]     Train net output #45: loss50 = 540.406 (* 1 = 540.406 loss)
I0726 14:10:39.248925 27891 solver.cpp:238]     Train net output #46: loss51 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248934 27891 solver.cpp:238]     Train net output #47: loss52 = 533.257 (* 1 = 533.257 loss)
I0726 14:10:39.248942 27891 solver.cpp:238]     Train net output #48: loss53 = 526.799 (* 1 = 526.799 loss)
I0726 14:10:39.248951 27891 solver.cpp:238]     Train net output #49: loss54 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248960 27891 solver.cpp:238]     Train net output #50: loss55 = 528.361 (* 1 = 528.361 loss)
I0726 14:10:39.248968 27891 solver.cpp:238]     Train net output #51: loss56 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248977 27891 solver.cpp:238]     Train net output #52: loss57 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.248986 27891 solver.cpp:238]     Train net output #53: loss58 = 547.189 (* 1 = 547.189 loss)
I0726 14:10:39.248994 27891 solver.cpp:238]     Train net output #54: loss59 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.249002 27891 solver.cpp:238]     Train net output #55: loss6 = 531.483 (* 1 = 531.483 loss)
I0726 14:10:39.249011 27891 solver.cpp:238]     Train net output #56: loss60 = 549.913 (* 1 = 549.913 loss)
I0726 14:10:39.249019 27891 solver.cpp:238]     Train net output #57: loss61 = 524.547 (* 1 = 524.547 loss)
I0726 14:10:39.249028 27891 solver.cpp:238]     Train net output #58: loss62 = 526.099 (* 1 = 526.099 loss)
I0726 14:10:39.249037 27891 solver.cpp:238]     Train net output #59: loss63 = 542.034 (* 1 = 542.034 loss)
I0726 14:10:39.249045 27891 solver.cpp:238]     Train net output #60: loss64 = 531.644 (* 1 = 531.644 loss)
I0726 14:10:39.249053 27891 solver.cpp:238]     Train net output #61: loss7 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.249063 27891 solver.cpp:238]     Train net output #62: loss8 = 532.842 (* 1 = 532.842 loss)
I0726 14:10:39.249070 27891 solver.cpp:238]     Train net output #63: loss9 = 520.866 (* 1 = 520.866 loss)
I0726 14:10:39.249079 27891 sgd_solver.cpp:105] Iteration 151200, lr = 1e-09
I0726 14:19:41.746347 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:19:41.748546 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:19:42.143182 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_156600.caffemodel
I0726 14:19:43.296864 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_156600.solverstate
I0726 14:19:43.376332 27891 solver.cpp:331] Iteration 156600, Testing net (#0)
I0726 14:19:58.565966 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:19:58.591845 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:19:59.031245 27891 solver.cpp:398]     Test net output #0: mae = 76.0699 (* 1 = 76.0699 loss)
I0726 14:19:59.031273 27891 solver.cpp:398]     Test net output #1: mse = 13223.3 (* 1 = 13223.3 loss)
I0726 14:19:59.156108 27891 solver.cpp:219] Iteration 156600 (9.64461 iter/s, 559.898s/5400 iters), loss = 33599.8
I0726 14:19:59.156148 27891 solver.cpp:238]     Train net output #0: loss1 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156160 27891 solver.cpp:238]     Train net output #1: loss10 = 526.579 (* 1 = 526.579 loss)
I0726 14:19:59.156168 27891 solver.cpp:238]     Train net output #2: loss11 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156177 27891 solver.cpp:238]     Train net output #3: loss12 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156185 27891 solver.cpp:238]     Train net output #4: loss13 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156193 27891 solver.cpp:238]     Train net output #5: loss14 = 520.661 (* 1 = 520.661 loss)
I0726 14:19:59.156201 27891 solver.cpp:238]     Train net output #6: loss15 = 529.474 (* 1 = 529.474 loss)
I0726 14:19:59.156210 27891 solver.cpp:238]     Train net output #7: loss16 = 528.446 (* 1 = 528.446 loss)
I0726 14:19:59.156219 27891 solver.cpp:238]     Train net output #8: loss17 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156225 27891 solver.cpp:238]     Train net output #9: loss18 = 531.962 (* 1 = 531.962 loss)
I0726 14:19:59.156235 27891 solver.cpp:238]     Train net output #10: loss19 = 523.639 (* 1 = 523.639 loss)
I0726 14:19:59.156244 27891 solver.cpp:238]     Train net output #11: loss2 = 530.03 (* 1 = 530.03 loss)
I0726 14:19:59.156253 27891 solver.cpp:238]     Train net output #12: loss20 = 550.811 (* 1 = 550.811 loss)
I0726 14:19:59.156261 27891 solver.cpp:238]     Train net output #13: loss21 = 524.449 (* 1 = 524.449 loss)
I0726 14:19:59.156270 27891 solver.cpp:238]     Train net output #14: loss22 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156278 27891 solver.cpp:238]     Train net output #15: loss23 = 525.115 (* 1 = 525.115 loss)
I0726 14:19:59.156286 27891 solver.cpp:238]     Train net output #16: loss24 = 520.993 (* 1 = 520.993 loss)
I0726 14:19:59.156294 27891 solver.cpp:238]     Train net output #17: loss25 = 546.613 (* 1 = 546.613 loss)
I0726 14:19:59.156303 27891 solver.cpp:238]     Train net output #18: loss26 = 521.911 (* 1 = 521.911 loss)
I0726 14:19:59.156311 27891 solver.cpp:238]     Train net output #19: loss27 = 517.559 (* 1 = 517.559 loss)
I0726 14:19:59.156319 27891 solver.cpp:238]     Train net output #20: loss28 = 524.444 (* 1 = 524.444 loss)
I0726 14:19:59.156327 27891 solver.cpp:238]     Train net output #21: loss29 = 541.604 (* 1 = 541.604 loss)
I0726 14:19:59.156335 27891 solver.cpp:238]     Train net output #22: loss3 = 532.588 (* 1 = 532.588 loss)
I0726 14:19:59.156343 27891 solver.cpp:238]     Train net output #23: loss30 = 522.188 (* 1 = 522.188 loss)
I0726 14:19:59.156352 27891 solver.cpp:238]     Train net output #24: loss31 = 515.552 (* 1 = 515.552 loss)
I0726 14:19:59.156359 27891 solver.cpp:238]     Train net output #25: loss32 = 533.157 (* 1 = 533.157 loss)
I0726 14:19:59.156368 27891 solver.cpp:238]     Train net output #26: loss33 = 541.152 (* 1 = 541.152 loss)
I0726 14:19:59.156376 27891 solver.cpp:238]     Train net output #27: loss34 = 532.299 (* 1 = 532.299 loss)
I0726 14:19:59.156384 27891 solver.cpp:238]     Train net output #28: loss35 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156435 27891 solver.cpp:238]     Train net output #29: loss36 = 527.856 (* 1 = 527.856 loss)
I0726 14:19:59.156443 27891 solver.cpp:238]     Train net output #30: loss37 = 524.69 (* 1 = 524.69 loss)
I0726 14:19:59.156452 27891 solver.cpp:238]     Train net output #31: loss38 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156460 27891 solver.cpp:238]     Train net output #32: loss39 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156468 27891 solver.cpp:238]     Train net output #33: loss4 = 525.161 (* 1 = 525.161 loss)
I0726 14:19:59.156476 27891 solver.cpp:238]     Train net output #34: loss40 = 508.082 (* 1 = 508.082 loss)
I0726 14:19:59.156483 27891 solver.cpp:238]     Train net output #35: loss41 = 536.961 (* 1 = 536.961 loss)
I0726 14:19:59.156491 27891 solver.cpp:238]     Train net output #36: loss42 = 526.325 (* 1 = 526.325 loss)
I0726 14:19:59.156503 27891 solver.cpp:238]     Train net output #37: loss43 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156514 27891 solver.cpp:238]     Train net output #38: loss44 = 532.904 (* 1 = 532.904 loss)
I0726 14:19:59.156532 27891 solver.cpp:238]     Train net output #39: loss45 = 526.529 (* 1 = 526.529 loss)
I0726 14:19:59.156541 27891 solver.cpp:238]     Train net output #40: loss46 = 524.063 (* 1 = 524.063 loss)
I0726 14:19:59.156551 27891 solver.cpp:238]     Train net output #41: loss47 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156561 27891 solver.cpp:238]     Train net output #42: loss48 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156572 27891 solver.cpp:238]     Train net output #43: loss49 = 540.122 (* 1 = 540.122 loss)
I0726 14:19:59.156584 27891 solver.cpp:238]     Train net output #44: loss5 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156591 27891 solver.cpp:238]     Train net output #45: loss50 = 533.703 (* 1 = 533.703 loss)
I0726 14:19:59.156599 27891 solver.cpp:238]     Train net output #46: loss51 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156607 27891 solver.cpp:238]     Train net output #47: loss52 = 526.997 (* 1 = 526.997 loss)
I0726 14:19:59.156615 27891 solver.cpp:238]     Train net output #48: loss53 = 520.805 (* 1 = 520.805 loss)
I0726 14:19:59.156623 27891 solver.cpp:238]     Train net output #49: loss54 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156632 27891 solver.cpp:238]     Train net output #50: loss55 = 521.98 (* 1 = 521.98 loss)
I0726 14:19:59.156641 27891 solver.cpp:238]     Train net output #51: loss56 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156649 27891 solver.cpp:238]     Train net output #52: loss57 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156657 27891 solver.cpp:238]     Train net output #53: loss58 = 540.094 (* 1 = 540.094 loss)
I0726 14:19:59.156666 27891 solver.cpp:238]     Train net output #54: loss59 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156673 27891 solver.cpp:238]     Train net output #55: loss6 = 525.679 (* 1 = 525.679 loss)
I0726 14:19:59.156682 27891 solver.cpp:238]     Train net output #56: loss60 = 543.013 (* 1 = 543.013 loss)
I0726 14:19:59.156689 27891 solver.cpp:238]     Train net output #57: loss61 = 518.642 (* 1 = 518.642 loss)
I0726 14:19:59.156697 27891 solver.cpp:238]     Train net output #58: loss62 = 520.18 (* 1 = 520.18 loss)
I0726 14:19:59.156705 27891 solver.cpp:238]     Train net output #59: loss63 = 535.066 (* 1 = 535.066 loss)
I0726 14:19:59.156713 27891 solver.cpp:238]     Train net output #60: loss64 = 525.933 (* 1 = 525.933 loss)
I0726 14:19:59.156721 27891 solver.cpp:238]     Train net output #61: loss7 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156729 27891 solver.cpp:238]     Train net output #62: loss8 = 526.37 (* 1 = 526.37 loss)
I0726 14:19:59.156738 27891 solver.cpp:238]     Train net output #63: loss9 = 515.166 (* 1 = 515.166 loss)
I0726 14:19:59.156745 27891 sgd_solver.cpp:105] Iteration 156600, lr = 1e-09
I0726 14:29:01.849320 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:29:01.850164 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:29:02.237970 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_162000.caffemodel
I0726 14:29:02.484737 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_162000.solverstate
I0726 14:29:02.568332 27891 solver.cpp:331] Iteration 162000, Testing net (#0)
I0726 14:29:17.770469 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:29:17.984094 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:29:18.236791 27891 solver.cpp:398]     Test net output #0: mae = 75.7746 (* 1 = 75.7746 loss)
I0726 14:29:18.236822 27891 solver.cpp:398]     Test net output #1: mse = 13314 (* 1 = 13314 loss)
I0726 14:29:18.362061 27891 solver.cpp:219] Iteration 162000 (9.65665 iter/s, 559.2s/5400 iters), loss = 33433.9
I0726 14:29:18.362097 27891 solver.cpp:238]     Train net output #0: loss1 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362103 27891 solver.cpp:238]     Train net output #1: loss10 = 523.797 (* 1 = 523.797 loss)
I0726 14:29:18.362108 27891 solver.cpp:238]     Train net output #2: loss11 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362113 27891 solver.cpp:238]     Train net output #3: loss12 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362119 27891 solver.cpp:238]     Train net output #4: loss13 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362125 27891 solver.cpp:238]     Train net output #5: loss14 = 517.652 (* 1 = 517.652 loss)
I0726 14:29:18.362131 27891 solver.cpp:238]     Train net output #6: loss15 = 526.975 (* 1 = 526.975 loss)
I0726 14:29:18.362136 27891 solver.cpp:238]     Train net output #7: loss16 = 525.997 (* 1 = 525.997 loss)
I0726 14:29:18.362143 27891 solver.cpp:238]     Train net output #8: loss17 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362149 27891 solver.cpp:238]     Train net output #9: loss18 = 529.078 (* 1 = 529.078 loss)
I0726 14:29:18.362154 27891 solver.cpp:238]     Train net output #10: loss19 = 520.856 (* 1 = 520.856 loss)
I0726 14:29:18.362159 27891 solver.cpp:238]     Train net output #11: loss2 = 527.414 (* 1 = 527.414 loss)
I0726 14:29:18.362165 27891 solver.cpp:238]     Train net output #12: loss20 = 547.456 (* 1 = 547.456 loss)
I0726 14:29:18.362171 27891 solver.cpp:238]     Train net output #13: loss21 = 521.95 (* 1 = 521.95 loss)
I0726 14:29:18.362177 27891 solver.cpp:238]     Train net output #14: loss22 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362184 27891 solver.cpp:238]     Train net output #15: loss23 = 522.786 (* 1 = 522.786 loss)
I0726 14:29:18.362190 27891 solver.cpp:238]     Train net output #16: loss24 = 518.429 (* 1 = 518.429 loss)
I0726 14:29:18.362195 27891 solver.cpp:238]     Train net output #17: loss25 = 543.229 (* 1 = 543.229 loss)
I0726 14:29:18.362202 27891 solver.cpp:238]     Train net output #18: loss26 = 519.269 (* 1 = 519.269 loss)
I0726 14:29:18.362208 27891 solver.cpp:238]     Train net output #19: loss27 = 515.26 (* 1 = 515.26 loss)
I0726 14:29:18.362215 27891 solver.cpp:238]     Train net output #20: loss28 = 521.79 (* 1 = 521.79 loss)
I0726 14:29:18.362221 27891 solver.cpp:238]     Train net output #21: loss29 = 538.28 (* 1 = 538.28 loss)
I0726 14:29:18.362226 27891 solver.cpp:238]     Train net output #22: loss3 = 529.851 (* 1 = 529.851 loss)
I0726 14:29:18.362233 27891 solver.cpp:238]     Train net output #23: loss30 = 519.659 (* 1 = 519.659 loss)
I0726 14:29:18.362238 27891 solver.cpp:238]     Train net output #24: loss31 = 512.987 (* 1 = 512.987 loss)
I0726 14:29:18.362244 27891 solver.cpp:238]     Train net output #25: loss32 = 530.64 (* 1 = 530.64 loss)
I0726 14:29:18.362251 27891 solver.cpp:238]     Train net output #26: loss33 = 538.331 (* 1 = 538.331 loss)
I0726 14:29:18.362257 27891 solver.cpp:238]     Train net output #27: loss34 = 529.543 (* 1 = 529.543 loss)
I0726 14:29:18.362263 27891 solver.cpp:238]     Train net output #28: loss35 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362270 27891 solver.cpp:238]     Train net output #29: loss36 = 524.736 (* 1 = 524.736 loss)
I0726 14:29:18.362306 27891 solver.cpp:238]     Train net output #30: loss37 = 521.535 (* 1 = 521.535 loss)
I0726 14:29:18.362314 27891 solver.cpp:238]     Train net output #31: loss38 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362320 27891 solver.cpp:238]     Train net output #32: loss39 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362326 27891 solver.cpp:238]     Train net output #33: loss4 = 522.473 (* 1 = 522.473 loss)
I0726 14:29:18.362332 27891 solver.cpp:238]     Train net output #34: loss40 = 505.849 (* 1 = 505.849 loss)
I0726 14:29:18.362339 27891 solver.cpp:238]     Train net output #35: loss41 = 534.154 (* 1 = 534.154 loss)
I0726 14:29:18.362344 27891 solver.cpp:238]     Train net output #36: loss42 = 523.922 (* 1 = 523.922 loss)
I0726 14:29:18.362349 27891 solver.cpp:238]     Train net output #37: loss43 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362355 27891 solver.cpp:238]     Train net output #38: loss44 = 530.239 (* 1 = 530.239 loss)
I0726 14:29:18.362361 27891 solver.cpp:238]     Train net output #39: loss45 = 524.214 (* 1 = 524.214 loss)
I0726 14:29:18.362367 27891 solver.cpp:238]     Train net output #40: loss46 = 521.669 (* 1 = 521.669 loss)
I0726 14:29:18.362372 27891 solver.cpp:238]     Train net output #41: loss47 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362378 27891 solver.cpp:238]     Train net output #42: loss48 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362385 27891 solver.cpp:238]     Train net output #43: loss49 = 536.885 (* 1 = 536.885 loss)
I0726 14:29:18.362390 27891 solver.cpp:238]     Train net output #44: loss5 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362396 27891 solver.cpp:238]     Train net output #45: loss50 = 530.683 (* 1 = 530.683 loss)
I0726 14:29:18.362401 27891 solver.cpp:238]     Train net output #46: loss51 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362406 27891 solver.cpp:238]     Train net output #47: loss52 = 524.002 (* 1 = 524.002 loss)
I0726 14:29:18.362411 27891 solver.cpp:238]     Train net output #48: loss53 = 518.253 (* 1 = 518.253 loss)
I0726 14:29:18.362417 27891 solver.cpp:238]     Train net output #49: loss54 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362423 27891 solver.cpp:238]     Train net output #50: loss55 = 519.259 (* 1 = 519.259 loss)
I0726 14:29:18.362428 27891 solver.cpp:238]     Train net output #51: loss56 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362434 27891 solver.cpp:238]     Train net output #52: loss57 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362440 27891 solver.cpp:238]     Train net output #53: loss58 = 536.681 (* 1 = 536.681 loss)
I0726 14:29:18.362447 27891 solver.cpp:238]     Train net output #54: loss59 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362452 27891 solver.cpp:238]     Train net output #55: loss6 = 523.234 (* 1 = 523.234 loss)
I0726 14:29:18.362457 27891 solver.cpp:238]     Train net output #56: loss60 = 539.84 (* 1 = 539.84 loss)
I0726 14:29:18.362463 27891 solver.cpp:238]     Train net output #57: loss61 = 516.159 (* 1 = 516.159 loss)
I0726 14:29:18.362469 27891 solver.cpp:238]     Train net output #58: loss62 = 517.605 (* 1 = 517.605 loss)
I0726 14:29:18.362474 27891 solver.cpp:238]     Train net output #59: loss63 = 531.963 (* 1 = 531.963 loss)
I0726 14:29:18.362480 27891 solver.cpp:238]     Train net output #60: loss64 = 523.858 (* 1 = 523.858 loss)
I0726 14:29:18.362485 27891 solver.cpp:238]     Train net output #61: loss7 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362491 27891 solver.cpp:238]     Train net output #62: loss8 = 523.39 (* 1 = 523.39 loss)
I0726 14:29:18.362496 27891 solver.cpp:238]     Train net output #63: loss9 = 512.734 (* 1 = 512.734 loss)
I0726 14:29:18.362502 27891 sgd_solver.cpp:105] Iteration 162000, lr = 1e-09
I0726 14:38:22.414453 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:38:22.416637 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:38:22.817587 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_167400.caffemodel
I0726 14:38:23.438298 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_167400.solverstate
I0726 14:38:23.541060 27891 solver.cpp:331] Iteration 167400, Testing net (#0)
I0726 14:38:38.735728 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:38:38.974037 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:38:39.201117 27891 solver.cpp:398]     Test net output #0: mae = 75.7527 (* 1 = 75.7527 loss)
I0726 14:38:39.201143 27891 solver.cpp:398]     Test net output #1: mse = 13439.1 (* 1 = 13439.1 loss)
I0726 14:38:39.327266 27891 solver.cpp:219] Iteration 167400 (9.62641 iter/s, 560.957s/5400 iters), loss = 33379.4
I0726 14:38:39.327303 27891 solver.cpp:238]     Train net output #0: loss1 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327311 27891 solver.cpp:238]     Train net output #1: loss10 = 522.674 (* 1 = 522.674 loss)
I0726 14:38:39.327316 27891 solver.cpp:238]     Train net output #2: loss11 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327323 27891 solver.cpp:238]     Train net output #3: loss12 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327328 27891 solver.cpp:238]     Train net output #4: loss13 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327334 27891 solver.cpp:238]     Train net output #5: loss14 = 516.713 (* 1 = 516.713 loss)
I0726 14:38:39.327340 27891 solver.cpp:238]     Train net output #6: loss15 = 526.198 (* 1 = 526.198 loss)
I0726 14:38:39.327347 27891 solver.cpp:238]     Train net output #7: loss16 = 525.035 (* 1 = 525.035 loss)
I0726 14:38:39.327353 27891 solver.cpp:238]     Train net output #8: loss17 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327359 27891 solver.cpp:238]     Train net output #9: loss18 = 528.053 (* 1 = 528.053 loss)
I0726 14:38:39.327366 27891 solver.cpp:238]     Train net output #10: loss19 = 519.8 (* 1 = 519.8 loss)
I0726 14:38:39.327373 27891 solver.cpp:238]     Train net output #11: loss2 = 526.544 (* 1 = 526.544 loss)
I0726 14:38:39.327378 27891 solver.cpp:238]     Train net output #12: loss20 = 546.315 (* 1 = 546.315 loss)
I0726 14:38:39.327385 27891 solver.cpp:238]     Train net output #13: loss21 = 521.255 (* 1 = 521.255 loss)
I0726 14:38:39.327391 27891 solver.cpp:238]     Train net output #14: loss22 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327397 27891 solver.cpp:238]     Train net output #15: loss23 = 522.504 (* 1 = 522.504 loss)
I0726 14:38:39.327404 27891 solver.cpp:238]     Train net output #16: loss24 = 517.733 (* 1 = 517.733 loss)
I0726 14:38:39.327410 27891 solver.cpp:238]     Train net output #17: loss25 = 542.006 (* 1 = 542.006 loss)
I0726 14:38:39.327416 27891 solver.cpp:238]     Train net output #18: loss26 = 518.617 (* 1 = 518.617 loss)
I0726 14:38:39.327422 27891 solver.cpp:238]     Train net output #19: loss27 = 514.83 (* 1 = 514.83 loss)
I0726 14:38:39.327430 27891 solver.cpp:238]     Train net output #20: loss28 = 520.947 (* 1 = 520.947 loss)
I0726 14:38:39.327435 27891 solver.cpp:238]     Train net output #21: loss29 = 537.282 (* 1 = 537.282 loss)
I0726 14:38:39.327441 27891 solver.cpp:238]     Train net output #22: loss3 = 529.062 (* 1 = 529.062 loss)
I0726 14:38:39.327448 27891 solver.cpp:238]     Train net output #23: loss30 = 518.677 (* 1 = 518.677 loss)
I0726 14:38:39.327455 27891 solver.cpp:238]     Train net output #24: loss31 = 512.16 (* 1 = 512.16 loss)
I0726 14:38:39.327461 27891 solver.cpp:238]     Train net output #25: loss32 = 530.019 (* 1 = 530.019 loss)
I0726 14:38:39.327467 27891 solver.cpp:238]     Train net output #26: loss33 = 537.74 (* 1 = 537.74 loss)
I0726 14:38:39.327473 27891 solver.cpp:238]     Train net output #27: loss34 = 528.597 (* 1 = 528.597 loss)
I0726 14:38:39.327479 27891 solver.cpp:238]     Train net output #28: loss35 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327486 27891 solver.cpp:238]     Train net output #29: loss36 = 523.57 (* 1 = 523.57 loss)
I0726 14:38:39.327527 27891 solver.cpp:238]     Train net output #30: loss37 = 520.464 (* 1 = 520.464 loss)
I0726 14:38:39.327534 27891 solver.cpp:238]     Train net output #31: loss38 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327544 27891 solver.cpp:238]     Train net output #32: loss39 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327550 27891 solver.cpp:238]     Train net output #33: loss4 = 521.661 (* 1 = 521.661 loss)
I0726 14:38:39.327558 27891 solver.cpp:238]     Train net output #34: loss40 = 505.44 (* 1 = 505.44 loss)
I0726 14:38:39.327565 27891 solver.cpp:238]     Train net output #35: loss41 = 533.24 (* 1 = 533.24 loss)
I0726 14:38:39.327572 27891 solver.cpp:238]     Train net output #36: loss42 = 523.643 (* 1 = 523.643 loss)
I0726 14:38:39.327594 27891 solver.cpp:238]     Train net output #37: loss43 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327605 27891 solver.cpp:238]     Train net output #38: loss44 = 529.156 (* 1 = 529.156 loss)
I0726 14:38:39.327615 27891 solver.cpp:238]     Train net output #39: loss45 = 523.387 (* 1 = 523.387 loss)
I0726 14:38:39.327627 27891 solver.cpp:238]     Train net output #40: loss46 = 520.992 (* 1 = 520.992 loss)
I0726 14:38:39.327636 27891 solver.cpp:238]     Train net output #41: loss47 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327642 27891 solver.cpp:238]     Train net output #42: loss48 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327648 27891 solver.cpp:238]     Train net output #43: loss49 = 535.505 (* 1 = 535.505 loss)
I0726 14:38:39.327654 27891 solver.cpp:238]     Train net output #44: loss5 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327661 27891 solver.cpp:238]     Train net output #45: loss50 = 529.529 (* 1 = 529.529 loss)
I0726 14:38:39.327667 27891 solver.cpp:238]     Train net output #46: loss51 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327673 27891 solver.cpp:238]     Train net output #47: loss52 = 522.908 (* 1 = 522.908 loss)
I0726 14:38:39.327680 27891 solver.cpp:238]     Train net output #48: loss53 = 517.629 (* 1 = 517.629 loss)
I0726 14:38:39.327687 27891 solver.cpp:238]     Train net output #49: loss54 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327692 27891 solver.cpp:238]     Train net output #50: loss55 = 518.344 (* 1 = 518.344 loss)
I0726 14:38:39.327698 27891 solver.cpp:238]     Train net output #51: loss56 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327704 27891 solver.cpp:238]     Train net output #52: loss57 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327711 27891 solver.cpp:238]     Train net output #53: loss58 = 535.617 (* 1 = 535.617 loss)
I0726 14:38:39.327718 27891 solver.cpp:238]     Train net output #54: loss59 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327723 27891 solver.cpp:238]     Train net output #55: loss6 = 522.498 (* 1 = 522.498 loss)
I0726 14:38:39.327730 27891 solver.cpp:238]     Train net output #56: loss60 = 538.418 (* 1 = 538.418 loss)
I0726 14:38:39.327736 27891 solver.cpp:238]     Train net output #57: loss61 = 515.465 (* 1 = 515.465 loss)
I0726 14:38:39.327742 27891 solver.cpp:238]     Train net output #58: loss62 = 516.887 (* 1 = 516.887 loss)
I0726 14:38:39.327749 27891 solver.cpp:238]     Train net output #59: loss63 = 530.921 (* 1 = 530.921 loss)
I0726 14:38:39.327755 27891 solver.cpp:238]     Train net output #60: loss64 = 523.606 (* 1 = 523.606 loss)
I0726 14:38:39.327761 27891 solver.cpp:238]     Train net output #61: loss7 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327769 27891 solver.cpp:238]     Train net output #62: loss8 = 522.381 (* 1 = 522.381 loss)
I0726 14:38:39.327775 27891 solver.cpp:238]     Train net output #63: loss9 = 511.992 (* 1 = 511.992 loss)
I0726 14:38:39.327780 27891 sgd_solver.cpp:105] Iteration 167400, lr = 1e-09
I0726 14:47:43.524044 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:47:43.528076 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:47:43.924350 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_172800.caffemodel
I0726 14:47:44.519042 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_172800.solverstate
I0726 14:47:44.608217 27891 solver.cpp:331] Iteration 172800, Testing net (#0)
I0726 14:47:59.809556 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:47:59.836278 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:48:00.285148 27891 solver.cpp:398]     Test net output #0: mae = 75.6509 (* 1 = 75.6509 loss)
I0726 14:48:00.285177 27891 solver.cpp:398]     Test net output #1: mse = 13438.1 (* 1 = 13438.1 loss)
I0726 14:48:00.409997 27891 solver.cpp:219] Iteration 172800 (9.62441 iter/s, 561.073s/5400 iters), loss = 33344.4
I0726 14:48:00.410042 27891 solver.cpp:238]     Train net output #0: loss1 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410053 27891 solver.cpp:238]     Train net output #1: loss10 = 521.891 (* 1 = 521.891 loss)
I0726 14:48:00.410063 27891 solver.cpp:238]     Train net output #2: loss11 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410070 27891 solver.cpp:238]     Train net output #3: loss12 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410079 27891 solver.cpp:238]     Train net output #4: loss13 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410086 27891 solver.cpp:238]     Train net output #5: loss14 = 516.21 (* 1 = 516.21 loss)
I0726 14:48:00.410096 27891 solver.cpp:238]     Train net output #6: loss15 = 525.558 (* 1 = 525.558 loss)
I0726 14:48:00.410104 27891 solver.cpp:238]     Train net output #7: loss16 = 524.128 (* 1 = 524.128 loss)
I0726 14:48:00.410115 27891 solver.cpp:238]     Train net output #8: loss17 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410122 27891 solver.cpp:238]     Train net output #9: loss18 = 527.574 (* 1 = 527.574 loss)
I0726 14:48:00.410130 27891 solver.cpp:238]     Train net output #10: loss19 = 518.928 (* 1 = 518.928 loss)
I0726 14:48:00.410138 27891 solver.cpp:238]     Train net output #11: loss2 = 526.117 (* 1 = 526.117 loss)
I0726 14:48:00.410146 27891 solver.cpp:238]     Train net output #12: loss20 = 545.405 (* 1 = 545.405 loss)
I0726 14:48:00.410156 27891 solver.cpp:238]     Train net output #13: loss21 = 520.927 (* 1 = 520.927 loss)
I0726 14:48:00.410166 27891 solver.cpp:238]     Train net output #14: loss22 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410173 27891 solver.cpp:238]     Train net output #15: loss23 = 522.403 (* 1 = 522.403 loss)
I0726 14:48:00.410181 27891 solver.cpp:238]     Train net output #16: loss24 = 517.236 (* 1 = 517.236 loss)
I0726 14:48:00.410187 27891 solver.cpp:238]     Train net output #17: loss25 = 541.278 (* 1 = 541.278 loss)
I0726 14:48:00.410192 27891 solver.cpp:238]     Train net output #18: loss26 = 518.126 (* 1 = 518.126 loss)
I0726 14:48:00.410198 27891 solver.cpp:238]     Train net output #19: loss27 = 514.445 (* 1 = 514.445 loss)
I0726 14:48:00.410205 27891 solver.cpp:238]     Train net output #20: loss28 = 520.461 (* 1 = 520.461 loss)
I0726 14:48:00.410212 27891 solver.cpp:238]     Train net output #21: loss29 = 536.784 (* 1 = 536.784 loss)
I0726 14:48:00.410219 27891 solver.cpp:238]     Train net output #22: loss3 = 528.796 (* 1 = 528.796 loss)
I0726 14:48:00.410228 27891 solver.cpp:238]     Train net output #23: loss30 = 517.964 (* 1 = 517.964 loss)
I0726 14:48:00.410233 27891 solver.cpp:238]     Train net output #24: loss31 = 511.508 (* 1 = 511.508 loss)
I0726 14:48:00.410240 27891 solver.cpp:238]     Train net output #25: loss32 = 529.712 (* 1 = 529.712 loss)
I0726 14:48:00.410246 27891 solver.cpp:238]     Train net output #26: loss33 = 537.319 (* 1 = 537.319 loss)
I0726 14:48:00.410253 27891 solver.cpp:238]     Train net output #27: loss34 = 528.033 (* 1 = 528.033 loss)
I0726 14:48:00.410259 27891 solver.cpp:238]     Train net output #28: loss35 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410305 27891 solver.cpp:238]     Train net output #29: loss36 = 522.599 (* 1 = 522.599 loss)
I0726 14:48:00.410318 27891 solver.cpp:238]     Train net output #30: loss37 = 519.676 (* 1 = 519.676 loss)
I0726 14:48:00.410329 27891 solver.cpp:238]     Train net output #31: loss38 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410339 27891 solver.cpp:238]     Train net output #32: loss39 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410347 27891 solver.cpp:238]     Train net output #33: loss4 = 521.064 (* 1 = 521.064 loss)
I0726 14:48:00.410356 27891 solver.cpp:238]     Train net output #34: loss40 = 505.082 (* 1 = 505.082 loss)
I0726 14:48:00.410362 27891 solver.cpp:238]     Train net output #35: loss41 = 532.575 (* 1 = 532.575 loss)
I0726 14:48:00.410367 27891 solver.cpp:238]     Train net output #36: loss42 = 523.412 (* 1 = 523.412 loss)
I0726 14:48:00.410373 27891 solver.cpp:238]     Train net output #37: loss43 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410379 27891 solver.cpp:238]     Train net output #38: loss44 = 528.256 (* 1 = 528.256 loss)
I0726 14:48:00.410385 27891 solver.cpp:238]     Train net output #39: loss45 = 522.887 (* 1 = 522.887 loss)
I0726 14:48:00.410392 27891 solver.cpp:238]     Train net output #40: loss46 = 520.594 (* 1 = 520.594 loss)
I0726 14:48:00.410398 27891 solver.cpp:238]     Train net output #41: loss47 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410404 27891 solver.cpp:238]     Train net output #42: loss48 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410410 27891 solver.cpp:238]     Train net output #43: loss49 = 534.769 (* 1 = 534.769 loss)
I0726 14:48:00.410416 27891 solver.cpp:238]     Train net output #44: loss5 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410423 27891 solver.cpp:238]     Train net output #45: loss50 = 528.882 (* 1 = 528.882 loss)
I0726 14:48:00.410429 27891 solver.cpp:238]     Train net output #46: loss51 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410435 27891 solver.cpp:238]     Train net output #47: loss52 = 522.292 (* 1 = 522.292 loss)
I0726 14:48:00.410441 27891 solver.cpp:238]     Train net output #48: loss53 = 517.176 (* 1 = 517.176 loss)
I0726 14:48:00.410447 27891 solver.cpp:238]     Train net output #49: loss54 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410454 27891 solver.cpp:238]     Train net output #50: loss55 = 517.678 (* 1 = 517.678 loss)
I0726 14:48:00.410459 27891 solver.cpp:238]     Train net output #51: loss56 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410465 27891 solver.cpp:238]     Train net output #52: loss57 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410471 27891 solver.cpp:238]     Train net output #53: loss58 = 535.008 (* 1 = 535.008 loss)
I0726 14:48:00.410477 27891 solver.cpp:238]     Train net output #54: loss59 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410483 27891 solver.cpp:238]     Train net output #55: loss6 = 521.99 (* 1 = 521.99 loss)
I0726 14:48:00.410490 27891 solver.cpp:238]     Train net output #56: loss60 = 537.462 (* 1 = 537.462 loss)
I0726 14:48:00.410496 27891 solver.cpp:238]     Train net output #57: loss61 = 515.016 (* 1 = 515.016 loss)
I0726 14:48:00.410502 27891 solver.cpp:238]     Train net output #58: loss62 = 516.426 (* 1 = 516.426 loss)
I0726 14:48:00.410508 27891 solver.cpp:238]     Train net output #59: loss63 = 530.255 (* 1 = 530.255 loss)
I0726 14:48:00.410514 27891 solver.cpp:238]     Train net output #60: loss64 = 523.535 (* 1 = 523.535 loss)
I0726 14:48:00.410521 27891 solver.cpp:238]     Train net output #61: loss7 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410526 27891 solver.cpp:238]     Train net output #62: loss8 = 521.845 (* 1 = 521.845 loss)
I0726 14:48:00.410532 27891 solver.cpp:238]     Train net output #63: loss9 = 511.416 (* 1 = 511.416 loss)
I0726 14:48:00.410539 27891 sgd_solver.cpp:105] Iteration 172800, lr = 1e-09
I0726 14:57:01.962911 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:57:01.962911 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:57:02.329726 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_178200.caffemodel
I0726 14:57:03.169797 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_178200.solverstate
I0726 14:57:03.428506 27891 solver.cpp:331] Iteration 178200, Testing net (#0)
I0726 14:57:18.988332 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:57:19.071197 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 14:57:19.445581 27891 solver.cpp:398]     Test net output #0: mae = 75.5466 (* 1 = 75.5466 loss)
I0726 14:57:19.445613 27891 solver.cpp:398]     Test net output #1: mse = 13400 (* 1 = 13400 loss)
I0726 14:57:19.570067 27891 solver.cpp:219] Iteration 178200 (9.65754 iter/s, 559.149s/5400 iters), loss = 33299.9
I0726 14:57:19.570125 27891 solver.cpp:238]     Train net output #0: loss1 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570135 27891 solver.cpp:238]     Train net output #1: loss10 = 520.965 (* 1 = 520.965 loss)
I0726 14:57:19.570142 27891 solver.cpp:238]     Train net output #2: loss11 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570147 27891 solver.cpp:238]     Train net output #3: loss12 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570153 27891 solver.cpp:238]     Train net output #4: loss13 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570159 27891 solver.cpp:238]     Train net output #5: loss14 = 515.418 (* 1 = 515.418 loss)
I0726 14:57:19.570166 27891 solver.cpp:238]     Train net output #6: loss15 = 524.754 (* 1 = 524.754 loss)
I0726 14:57:19.570173 27891 solver.cpp:238]     Train net output #7: loss16 = 523.086 (* 1 = 523.086 loss)
I0726 14:57:19.570178 27891 solver.cpp:238]     Train net output #8: loss17 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570185 27891 solver.cpp:238]     Train net output #9: loss18 = 527.07 (* 1 = 527.07 loss)
I0726 14:57:19.570190 27891 solver.cpp:238]     Train net output #10: loss19 = 517.976 (* 1 = 517.976 loss)
I0726 14:57:19.570196 27891 solver.cpp:238]     Train net output #11: loss2 = 525.534 (* 1 = 525.534 loss)
I0726 14:57:19.570204 27891 solver.cpp:238]     Train net output #12: loss20 = 544.626 (* 1 = 544.626 loss)
I0726 14:57:19.570209 27891 solver.cpp:238]     Train net output #13: loss21 = 520.573 (* 1 = 520.573 loss)
I0726 14:57:19.570215 27891 solver.cpp:238]     Train net output #14: loss22 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570221 27891 solver.cpp:238]     Train net output #15: loss23 = 522.132 (* 1 = 522.132 loss)
I0726 14:57:19.570227 27891 solver.cpp:238]     Train net output #16: loss24 = 516.59 (* 1 = 516.59 loss)
I0726 14:57:19.570233 27891 solver.cpp:238]     Train net output #17: loss25 = 540.688 (* 1 = 540.688 loss)
I0726 14:57:19.570240 27891 solver.cpp:238]     Train net output #18: loss26 = 517.642 (* 1 = 517.642 loss)
I0726 14:57:19.570245 27891 solver.cpp:238]     Train net output #19: loss27 = 514.029 (* 1 = 514.029 loss)
I0726 14:57:19.570251 27891 solver.cpp:238]     Train net output #20: loss28 = 519.979 (* 1 = 519.979 loss)
I0726 14:57:19.570258 27891 solver.cpp:238]     Train net output #21: loss29 = 536.16 (* 1 = 536.16 loss)
I0726 14:57:19.570264 27891 solver.cpp:238]     Train net output #22: loss3 = 528.424 (* 1 = 528.424 loss)
I0726 14:57:19.570271 27891 solver.cpp:238]     Train net output #23: loss30 = 517.181 (* 1 = 517.181 loss)
I0726 14:57:19.570276 27891 solver.cpp:238]     Train net output #24: loss31 = 510.793 (* 1 = 510.793 loss)
I0726 14:57:19.570282 27891 solver.cpp:238]     Train net output #25: loss32 = 529.255 (* 1 = 529.255 loss)
I0726 14:57:19.570288 27891 solver.cpp:238]     Train net output #26: loss33 = 537.04 (* 1 = 537.04 loss)
I0726 14:57:19.570294 27891 solver.cpp:238]     Train net output #27: loss34 = 527.445 (* 1 = 527.445 loss)
I0726 14:57:19.570300 27891 solver.cpp:238]     Train net output #28: loss35 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570307 27891 solver.cpp:238]     Train net output #29: loss36 = 521.578 (* 1 = 521.578 loss)
I0726 14:57:19.570461 27891 solver.cpp:238]     Train net output #30: loss37 = 518.808 (* 1 = 518.808 loss)
I0726 14:57:19.570473 27891 solver.cpp:238]     Train net output #31: loss38 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570483 27891 solver.cpp:238]     Train net output #32: loss39 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570494 27891 solver.cpp:238]     Train net output #33: loss4 = 520.405 (* 1 = 520.405 loss)
I0726 14:57:19.570504 27891 solver.cpp:238]     Train net output #34: loss40 = 504.573 (* 1 = 504.573 loss)
I0726 14:57:19.570513 27891 solver.cpp:238]     Train net output #35: loss41 = 531.908 (* 1 = 531.908 loss)
I0726 14:57:19.570523 27891 solver.cpp:238]     Train net output #36: loss42 = 522.963 (* 1 = 522.963 loss)
I0726 14:57:19.570530 27891 solver.cpp:238]     Train net output #37: loss43 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570540 27891 solver.cpp:238]     Train net output #38: loss44 = 527.276 (* 1 = 527.276 loss)
I0726 14:57:19.570549 27891 solver.cpp:238]     Train net output #39: loss45 = 522.21 (* 1 = 522.21 loss)
I0726 14:57:19.570560 27891 solver.cpp:238]     Train net output #40: loss46 = 520.2 (* 1 = 520.2 loss)
I0726 14:57:19.570571 27891 solver.cpp:238]     Train net output #41: loss47 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570578 27891 solver.cpp:238]     Train net output #42: loss48 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570585 27891 solver.cpp:238]     Train net output #43: loss49 = 534.109 (* 1 = 534.109 loss)
I0726 14:57:19.570591 27891 solver.cpp:238]     Train net output #44: loss5 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570597 27891 solver.cpp:238]     Train net output #45: loss50 = 528.094 (* 1 = 528.094 loss)
I0726 14:57:19.570603 27891 solver.cpp:238]     Train net output #46: loss51 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570610 27891 solver.cpp:238]     Train net output #47: loss52 = 521.618 (* 1 = 521.618 loss)
I0726 14:57:19.570616 27891 solver.cpp:238]     Train net output #48: loss53 = 516.717 (* 1 = 516.717 loss)
I0726 14:57:19.570621 27891 solver.cpp:238]     Train net output #49: loss54 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570627 27891 solver.cpp:238]     Train net output #50: loss55 = 517.054 (* 1 = 517.054 loss)
I0726 14:57:19.570633 27891 solver.cpp:238]     Train net output #51: loss56 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570639 27891 solver.cpp:238]     Train net output #52: loss57 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570646 27891 solver.cpp:238]     Train net output #53: loss58 = 534.238 (* 1 = 534.238 loss)
I0726 14:57:19.570652 27891 solver.cpp:238]     Train net output #54: loss59 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570657 27891 solver.cpp:238]     Train net output #55: loss6 = 521.445 (* 1 = 521.445 loss)
I0726 14:57:19.570663 27891 solver.cpp:238]     Train net output #56: loss60 = 536.771 (* 1 = 536.771 loss)
I0726 14:57:19.570669 27891 solver.cpp:238]     Train net output #57: loss61 = 514.522 (* 1 = 514.522 loss)
I0726 14:57:19.570675 27891 solver.cpp:238]     Train net output #58: loss62 = 515.926 (* 1 = 515.926 loss)
I0726 14:57:19.570682 27891 solver.cpp:238]     Train net output #59: loss63 = 529.606 (* 1 = 529.606 loss)
I0726 14:57:19.570688 27891 solver.cpp:238]     Train net output #60: loss64 = 523.361 (* 1 = 523.361 loss)
I0726 14:57:19.570693 27891 solver.cpp:238]     Train net output #61: loss7 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570700 27891 solver.cpp:238]     Train net output #62: loss8 = 521.264 (* 1 = 521.264 loss)
I0726 14:57:19.570706 27891 solver.cpp:238]     Train net output #63: loss9 = 510.746 (* 1 = 510.746 loss)
I0726 14:57:19.570715 27891 sgd_solver.cpp:105] Iteration 178200, lr = 1e-09
I0726 15:06:16.825512 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:06:16.824529 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:06:17.192376 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_183600.caffemodel
I0726 15:06:17.896723 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_183600.solverstate
I0726 15:06:18.059528 27891 solver.cpp:331] Iteration 183600, Testing net (#0)
I0726 15:06:33.476521 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:06:33.570533 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:06:33.942418 27891 solver.cpp:398]     Test net output #0: mae = 75.4664 (* 1 = 75.4664 loss)
I0726 15:06:33.942447 27891 solver.cpp:398]     Test net output #1: mse = 13311.8 (* 1 = 13311.8 loss)
I0726 15:06:34.067821 27891 solver.cpp:219] Iteration 183600 (9.73874 iter/s, 554.487s/5400 iters), loss = 33360.6
I0726 15:06:34.067878 27891 solver.cpp:238]     Train net output #0: loss1 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.067890 27891 solver.cpp:238]     Train net output #1: loss10 = 521.596 (* 1 = 521.596 loss)
I0726 15:06:34.067900 27891 solver.cpp:238]     Train net output #2: loss11 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.067910 27891 solver.cpp:238]     Train net output #3: loss12 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.067919 27891 solver.cpp:238]     Train net output #4: loss13 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.067929 27891 solver.cpp:238]     Train net output #5: loss14 = 516.345 (* 1 = 516.345 loss)
I0726 15:06:34.067939 27891 solver.cpp:238]     Train net output #6: loss15 = 525.546 (* 1 = 525.546 loss)
I0726 15:06:34.067948 27891 solver.cpp:238]     Train net output #7: loss16 = 523.591 (* 1 = 523.591 loss)
I0726 15:06:34.067957 27891 solver.cpp:238]     Train net output #8: loss17 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.067967 27891 solver.cpp:238]     Train net output #9: loss18 = 528.237 (* 1 = 528.237 loss)
I0726 15:06:34.067977 27891 solver.cpp:238]     Train net output #10: loss19 = 518.615 (* 1 = 518.615 loss)
I0726 15:06:34.067987 27891 solver.cpp:238]     Train net output #11: loss2 = 526.471 (* 1 = 526.471 loss)
I0726 15:06:34.067996 27891 solver.cpp:238]     Train net output #12: loss20 = 545.715 (* 1 = 545.715 loss)
I0726 15:06:34.068006 27891 solver.cpp:238]     Train net output #13: loss21 = 521.856 (* 1 = 521.856 loss)
I0726 15:06:34.068017 27891 solver.cpp:238]     Train net output #14: loss22 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.068025 27891 solver.cpp:238]     Train net output #15: loss23 = 523.461 (* 1 = 523.461 loss)
I0726 15:06:34.068035 27891 solver.cpp:238]     Train net output #16: loss24 = 517.513 (* 1 = 517.513 loss)
I0726 15:06:34.068045 27891 solver.cpp:238]     Train net output #17: loss25 = 541.893 (* 1 = 541.893 loss)
I0726 15:06:34.068054 27891 solver.cpp:238]     Train net output #18: loss26 = 518.676 (* 1 = 518.676 loss)
I0726 15:06:34.068064 27891 solver.cpp:238]     Train net output #19: loss27 = 515.13 (* 1 = 515.13 loss)
I0726 15:06:34.068073 27891 solver.cpp:238]     Train net output #20: loss28 = 521.14 (* 1 = 521.14 loss)
I0726 15:06:34.068084 27891 solver.cpp:238]     Train net output #21: loss29 = 537.297 (* 1 = 537.297 loss)
I0726 15:06:34.068094 27891 solver.cpp:238]     Train net output #22: loss3 = 529.789 (* 1 = 529.789 loss)
I0726 15:06:34.068102 27891 solver.cpp:238]     Train net output #23: loss30 = 517.959 (* 1 = 517.959 loss)
I0726 15:06:34.068112 27891 solver.cpp:238]     Train net output #24: loss31 = 511.554 (* 1 = 511.554 loss)
I0726 15:06:34.068121 27891 solver.cpp:238]     Train net output #25: loss32 = 530.457 (* 1 = 530.457 loss)
I0726 15:06:34.068131 27891 solver.cpp:238]     Train net output #26: loss33 = 538.509 (* 1 = 538.509 loss)
I0726 15:06:34.068141 27891 solver.cpp:238]     Train net output #27: loss34 = 528.44 (* 1 = 528.44 loss)
I0726 15:06:34.068150 27891 solver.cpp:238]     Train net output #28: loss35 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.068159 27891 solver.cpp:238]     Train net output #29: loss36 = 522.245 (* 1 = 522.245 loss)
I0726 15:06:34.087533 27891 solver.cpp:238]     Train net output #30: loss37 = 519.57 (* 1 = 519.57 loss)
I0726 15:06:34.087553 27891 solver.cpp:238]     Train net output #31: loss38 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087563 27891 solver.cpp:238]     Train net output #32: loss39 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087572 27891 solver.cpp:238]     Train net output #33: loss4 = 521.267 (* 1 = 521.267 loss)
I0726 15:06:34.087581 27891 solver.cpp:238]     Train net output #34: loss40 = 505.646 (* 1 = 505.646 loss)
I0726 15:06:34.087590 27891 solver.cpp:238]     Train net output #35: loss41 = 532.85 (* 1 = 532.85 loss)
I0726 15:06:34.087599 27891 solver.cpp:238]     Train net output #36: loss42 = 524.073 (* 1 = 524.073 loss)
I0726 15:06:34.087606 27891 solver.cpp:238]     Train net output #37: loss43 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087615 27891 solver.cpp:238]     Train net output #38: loss44 = 528.041 (* 1 = 528.041 loss)
I0726 15:06:34.087622 27891 solver.cpp:238]     Train net output #39: loss45 = 523.119 (* 1 = 523.119 loss)
I0726 15:06:34.087631 27891 solver.cpp:238]     Train net output #40: loss46 = 521.305 (* 1 = 521.305 loss)
I0726 15:06:34.087638 27891 solver.cpp:238]     Train net output #41: loss47 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087646 27891 solver.cpp:238]     Train net output #42: loss48 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087654 27891 solver.cpp:238]     Train net output #43: loss49 = 534.963 (* 1 = 534.963 loss)
I0726 15:06:34.087662 27891 solver.cpp:238]     Train net output #44: loss5 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087671 27891 solver.cpp:238]     Train net output #45: loss50 = 529.075 (* 1 = 529.075 loss)
I0726 15:06:34.087678 27891 solver.cpp:238]     Train net output #46: loss51 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087687 27891 solver.cpp:238]     Train net output #47: loss52 = 522.653 (* 1 = 522.653 loss)
I0726 15:06:34.087694 27891 solver.cpp:238]     Train net output #48: loss53 = 517.737 (* 1 = 517.737 loss)
I0726 15:06:34.087702 27891 solver.cpp:238]     Train net output #49: loss54 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087709 27891 solver.cpp:238]     Train net output #50: loss55 = 518.158 (* 1 = 518.158 loss)
I0726 15:06:34.087718 27891 solver.cpp:238]     Train net output #51: loss56 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087725 27891 solver.cpp:238]     Train net output #52: loss57 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087738 27891 solver.cpp:238]     Train net output #53: loss58 = 535.273 (* 1 = 535.273 loss)
I0726 15:06:34.087745 27891 solver.cpp:238]     Train net output #54: loss59 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087754 27891 solver.cpp:238]     Train net output #55: loss6 = 522.531 (* 1 = 522.531 loss)
I0726 15:06:34.087761 27891 solver.cpp:238]     Train net output #56: loss60 = 537.837 (* 1 = 537.837 loss)
I0726 15:06:34.087769 27891 solver.cpp:238]     Train net output #57: loss61 = 515.608 (* 1 = 515.608 loss)
I0726 15:06:34.087777 27891 solver.cpp:238]     Train net output #58: loss62 = 516.983 (* 1 = 516.983 loss)
I0726 15:06:34.087785 27891 solver.cpp:238]     Train net output #59: loss63 = 530.774 (* 1 = 530.774 loss)
I0726 15:06:34.087793 27891 solver.cpp:238]     Train net output #60: loss64 = 524.666 (* 1 = 524.666 loss)
I0726 15:06:34.087801 27891 solver.cpp:238]     Train net output #61: loss7 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087810 27891 solver.cpp:238]     Train net output #62: loss8 = 522.286 (* 1 = 522.286 loss)
I0726 15:06:34.087817 27891 solver.cpp:238]     Train net output #63: loss9 = 511.566 (* 1 = 511.566 loss)
I0726 15:06:34.087829 27891 sgd_solver.cpp:105] Iteration 183600, lr = 1e-09
I0726 15:15:30.544495 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:15:30.544494 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:15:30.933046 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_189000.caffemodel
I0726 15:15:31.834168 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_189000.solverstate
I0726 15:15:32.100708 27891 solver.cpp:331] Iteration 189000, Testing net (#0)
I0726 15:15:47.450831 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:15:47.543673 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:15:47.924918 27891 solver.cpp:398]     Test net output #0: mae = 75.3739 (* 1 = 75.3739 loss)
I0726 15:15:47.925256 27891 solver.cpp:398]     Test net output #1: mse = 13313.7 (* 1 = 13313.7 loss)
I0726 15:15:48.049540 27891 solver.cpp:219] Iteration 189000 (9.7478 iter/s, 553.971s/5400 iters), loss = 33342.5
I0726 15:15:48.049595 27891 solver.cpp:238]     Train net output #0: loss1 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049607 27891 solver.cpp:238]     Train net output #1: loss10 = 521.25 (* 1 = 521.25 loss)
I0726 15:15:48.049618 27891 solver.cpp:238]     Train net output #2: loss11 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049626 27891 solver.cpp:238]     Train net output #3: loss12 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049635 27891 solver.cpp:238]     Train net output #4: loss13 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049644 27891 solver.cpp:238]     Train net output #5: loss14 = 516.051 (* 1 = 516.051 loss)
I0726 15:15:48.049654 27891 solver.cpp:238]     Train net output #6: loss15 = 525.253 (* 1 = 525.253 loss)
I0726 15:15:48.049664 27891 solver.cpp:238]     Train net output #7: loss16 = 523.062 (* 1 = 523.062 loss)
I0726 15:15:48.049672 27891 solver.cpp:238]     Train net output #8: loss17 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049681 27891 solver.cpp:238]     Train net output #9: loss18 = 528.154 (* 1 = 528.154 loss)
I0726 15:15:48.049690 27891 solver.cpp:238]     Train net output #10: loss19 = 518.254 (* 1 = 518.254 loss)
I0726 15:15:48.049700 27891 solver.cpp:238]     Train net output #11: loss2 = 526.167 (* 1 = 526.167 loss)
I0726 15:15:48.049710 27891 solver.cpp:238]     Train net output #12: loss20 = 545.409 (* 1 = 545.409 loss)
I0726 15:15:48.049718 27891 solver.cpp:238]     Train net output #13: loss21 = 521.938 (* 1 = 521.938 loss)
I0726 15:15:48.049727 27891 solver.cpp:238]     Train net output #14: loss22 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.049737 27891 solver.cpp:238]     Train net output #15: loss23 = 523.642 (* 1 = 523.642 loss)
I0726 15:15:48.049746 27891 solver.cpp:238]     Train net output #16: loss24 = 517.347 (* 1 = 517.347 loss)
I0726 15:15:48.049756 27891 solver.cpp:238]     Train net output #17: loss25 = 541.578 (* 1 = 541.578 loss)
I0726 15:15:48.049764 27891 solver.cpp:238]     Train net output #18: loss26 = 518.534 (* 1 = 518.534 loss)
I0726 15:15:48.049778 27891 solver.cpp:238]     Train net output #19: loss27 = 514.988 (* 1 = 514.988 loss)
I0726 15:15:48.049787 27891 solver.cpp:238]     Train net output #20: loss28 = 521.076 (* 1 = 521.076 loss)
I0726 15:15:48.049796 27891 solver.cpp:238]     Train net output #21: loss29 = 536.862 (* 1 = 536.862 loss)
I0726 15:15:48.049805 27891 solver.cpp:238]     Train net output #22: loss3 = 529.846 (* 1 = 529.846 loss)
I0726 15:15:48.049815 27891 solver.cpp:238]     Train net output #23: loss30 = 517.761 (* 1 = 517.761 loss)
I0726 15:15:48.049824 27891 solver.cpp:238]     Train net output #24: loss31 = 511.282 (* 1 = 511.282 loss)
I0726 15:15:48.049834 27891 solver.cpp:238]     Train net output #25: loss32 = 530.474 (* 1 = 530.474 loss)
I0726 15:15:48.049842 27891 solver.cpp:238]     Train net output #26: loss33 = 538.637 (* 1 = 538.637 loss)
I0726 15:15:48.049852 27891 solver.cpp:238]     Train net output #27: loss34 = 528.293 (* 1 = 528.293 loss)
I0726 15:15:48.049861 27891 solver.cpp:238]     Train net output #28: loss35 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050017 27891 solver.cpp:238]     Train net output #29: loss36 = 521.839 (* 1 = 521.839 loss)
I0726 15:15:48.050029 27891 solver.cpp:238]     Train net output #30: loss37 = 519.077 (* 1 = 519.077 loss)
I0726 15:15:48.050037 27891 solver.cpp:238]     Train net output #31: loss38 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050046 27891 solver.cpp:238]     Train net output #32: loss39 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050056 27891 solver.cpp:238]     Train net output #33: loss4 = 521.008 (* 1 = 521.008 loss)
I0726 15:15:48.050065 27891 solver.cpp:238]     Train net output #34: loss40 = 505.47 (* 1 = 505.47 loss)
I0726 15:15:48.050074 27891 solver.cpp:238]     Train net output #35: loss41 = 532.579 (* 1 = 532.579 loss)
I0726 15:15:48.050083 27891 solver.cpp:238]     Train net output #36: loss42 = 523.883 (* 1 = 523.883 loss)
I0726 15:15:48.050092 27891 solver.cpp:238]     Train net output #37: loss43 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050102 27891 solver.cpp:238]     Train net output #38: loss44 = 527.719 (* 1 = 527.719 loss)
I0726 15:15:48.050112 27891 solver.cpp:238]     Train net output #39: loss45 = 523.09 (* 1 = 523.09 loss)
I0726 15:15:48.050120 27891 solver.cpp:238]     Train net output #40: loss46 = 521.319 (* 1 = 521.319 loss)
I0726 15:15:48.050129 27891 solver.cpp:238]     Train net output #41: loss47 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050138 27891 solver.cpp:238]     Train net output #42: loss48 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050148 27891 solver.cpp:238]     Train net output #43: loss49 = 534.596 (* 1 = 534.596 loss)
I0726 15:15:48.050158 27891 solver.cpp:238]     Train net output #44: loss5 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050166 27891 solver.cpp:238]     Train net output #45: loss50 = 528.785 (* 1 = 528.785 loss)
I0726 15:15:48.050173 27891 solver.cpp:238]     Train net output #46: loss51 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050179 27891 solver.cpp:238]     Train net output #47: loss52 = 522.517 (* 1 = 522.517 loss)
I0726 15:15:48.050185 27891 solver.cpp:238]     Train net output #48: loss53 = 517.602 (* 1 = 517.602 loss)
I0726 15:15:48.050191 27891 solver.cpp:238]     Train net output #49: loss54 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050197 27891 solver.cpp:238]     Train net output #50: loss55 = 517.913 (* 1 = 517.913 loss)
I0726 15:15:48.050204 27891 solver.cpp:238]     Train net output #51: loss56 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050210 27891 solver.cpp:238]     Train net output #52: loss57 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050216 27891 solver.cpp:238]     Train net output #53: loss58 = 534.931 (* 1 = 534.931 loss)
I0726 15:15:48.050222 27891 solver.cpp:238]     Train net output #54: loss59 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050228 27891 solver.cpp:238]     Train net output #55: loss6 = 522.561 (* 1 = 522.561 loss)
I0726 15:15:48.050235 27891 solver.cpp:238]     Train net output #56: loss60 = 537.511 (* 1 = 537.511 loss)
I0726 15:15:48.050242 27891 solver.cpp:238]     Train net output #57: loss61 = 515.517 (* 1 = 515.517 loss)
I0726 15:15:48.050252 27891 solver.cpp:238]     Train net output #58: loss62 = 516.91 (* 1 = 516.91 loss)
I0726 15:15:48.050261 27891 solver.cpp:238]     Train net output #59: loss63 = 530.555 (* 1 = 530.555 loss)
I0726 15:15:48.050271 27891 solver.cpp:238]     Train net output #60: loss64 = 524.678 (* 1 = 524.678 loss)
I0726 15:15:48.050281 27891 solver.cpp:238]     Train net output #61: loss7 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050289 27891 solver.cpp:238]     Train net output #62: loss8 = 522.145 (* 1 = 522.145 loss)
I0726 15:15:48.050307 27891 solver.cpp:238]     Train net output #63: loss9 = 511.367 (* 1 = 511.367 loss)
I0726 15:15:48.050318 27891 sgd_solver.cpp:105] Iteration 189000, lr = 1e-09
I0726 15:24:44.510979 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:24:44.514106 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:24:44.897189 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_194400.caffemodel
I0726 15:24:45.161051 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_194400.solverstate
I0726 15:24:45.252931 27891 solver.cpp:331] Iteration 194400, Testing net (#0)
I0726 15:25:01.097677 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:25:01.198077 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:25:01.567932 27891 solver.cpp:398]     Test net output #0: mae = 75.2878 (* 1 = 75.2878 loss)
I0726 15:25:01.567976 27891 solver.cpp:398]     Test net output #1: mse = 13214.3 (* 1 = 13214.3 loss)
I0726 15:25:01.693588 27891 solver.cpp:219] Iteration 194400 (9.75374 iter/s, 553.634s/5400 iters), loss = 33427.1
I0726 15:25:01.693660 27891 solver.cpp:238]     Train net output #0: loss1 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693677 27891 solver.cpp:238]     Train net output #1: loss10 = 522.203 (* 1 = 522.203 loss)
I0726 15:25:01.693694 27891 solver.cpp:238]     Train net output #2: loss11 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693707 27891 solver.cpp:238]     Train net output #3: loss12 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693723 27891 solver.cpp:238]     Train net output #4: loss13 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693739 27891 solver.cpp:238]     Train net output #5: loss14 = 517.113 (* 1 = 517.113 loss)
I0726 15:25:01.693753 27891 solver.cpp:238]     Train net output #6: loss15 = 526.315 (* 1 = 526.315 loss)
I0726 15:25:01.693765 27891 solver.cpp:238]     Train net output #7: loss16 = 523.8 (* 1 = 523.8 loss)
I0726 15:25:01.693780 27891 solver.cpp:238]     Train net output #8: loss17 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693796 27891 solver.cpp:238]     Train net output #9: loss18 = 529.612 (* 1 = 529.612 loss)
I0726 15:25:01.693809 27891 solver.cpp:238]     Train net output #10: loss19 = 519.173 (* 1 = 519.173 loss)
I0726 15:25:01.693822 27891 solver.cpp:238]     Train net output #11: loss2 = 527.378 (* 1 = 527.378 loss)
I0726 15:25:01.693835 27891 solver.cpp:238]     Train net output #12: loss20 = 546.74 (* 1 = 546.74 loss)
I0726 15:25:01.693850 27891 solver.cpp:238]     Train net output #13: loss21 = 523.542 (* 1 = 523.542 loss)
I0726 15:25:01.693866 27891 solver.cpp:238]     Train net output #14: loss22 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.693881 27891 solver.cpp:238]     Train net output #15: loss23 = 525.243 (* 1 = 525.243 loss)
I0726 15:25:01.693893 27891 solver.cpp:238]     Train net output #16: loss24 = 518.6 (* 1 = 518.6 loss)
I0726 15:25:01.693907 27891 solver.cpp:238]     Train net output #17: loss25 = 543.3 (* 1 = 543.3 loss)
I0726 15:25:01.693920 27891 solver.cpp:238]     Train net output #18: loss26 = 519.822 (* 1 = 519.822 loss)
I0726 15:25:01.693934 27891 solver.cpp:238]     Train net output #19: loss27 = 516.237 (* 1 = 516.237 loss)
I0726 15:25:01.693948 27891 solver.cpp:238]     Train net output #20: loss28 = 522.566 (* 1 = 522.566 loss)
I0726 15:25:01.693960 27891 solver.cpp:238]     Train net output #21: loss29 = 538.358 (* 1 = 538.358 loss)
I0726 15:25:01.693974 27891 solver.cpp:238]     Train net output #22: loss3 = 531.634 (* 1 = 531.634 loss)
I0726 15:25:01.693987 27891 solver.cpp:238]     Train net output #23: loss30 = 518.826 (* 1 = 518.826 loss)
I0726 15:25:01.694000 27891 solver.cpp:238]     Train net output #24: loss31 = 512.28 (* 1 = 512.28 loss)
I0726 15:25:01.694013 27891 solver.cpp:238]     Train net output #25: loss32 = 532.094 (* 1 = 532.094 loss)
I0726 15:25:01.694027 27891 solver.cpp:238]     Train net output #26: loss33 = 540.546 (* 1 = 540.546 loss)
I0726 15:25:01.694041 27891 solver.cpp:238]     Train net output #27: loss34 = 529.665 (* 1 = 529.665 loss)
I0726 15:25:01.694053 27891 solver.cpp:238]     Train net output #28: loss35 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.694067 27891 solver.cpp:238]     Train net output #29: loss36 = 522.787 (* 1 = 522.787 loss)
I0726 15:25:01.695936 27891 solver.cpp:238]     Train net output #30: loss37 = 520.116 (* 1 = 520.116 loss)
I0726 15:25:01.695956 27891 solver.cpp:238]     Train net output #31: loss38 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.695968 27891 solver.cpp:238]     Train net output #32: loss39 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.695979 27891 solver.cpp:238]     Train net output #33: loss4 = 522.195 (* 1 = 522.195 loss)
I0726 15:25:01.695989 27891 solver.cpp:238]     Train net output #34: loss40 = 506.68 (* 1 = 506.68 loss)
I0726 15:25:01.695999 27891 solver.cpp:238]     Train net output #35: loss41 = 533.757 (* 1 = 533.757 loss)
I0726 15:25:01.696009 27891 solver.cpp:238]     Train net output #36: loss42 = 525.349 (* 1 = 525.349 loss)
I0726 15:25:01.696029 27891 solver.cpp:238]     Train net output #37: loss43 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696043 27891 solver.cpp:238]     Train net output #38: loss44 = 528.739 (* 1 = 528.739 loss)
I0726 15:25:01.696053 27891 solver.cpp:238]     Train net output #39: loss45 = 524.302 (* 1 = 524.302 loss)
I0726 15:25:01.696063 27891 solver.cpp:238]     Train net output #40: loss46 = 522.763 (* 1 = 522.763 loss)
I0726 15:25:01.696074 27891 solver.cpp:238]     Train net output #41: loss47 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696084 27891 solver.cpp:238]     Train net output #42: loss48 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696094 27891 solver.cpp:238]     Train net output #43: loss49 = 535.792 (* 1 = 535.792 loss)
I0726 15:25:01.696105 27891 solver.cpp:238]     Train net output #44: loss5 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696116 27891 solver.cpp:238]     Train net output #45: loss50 = 530.057 (* 1 = 530.057 loss)
I0726 15:25:01.696126 27891 solver.cpp:238]     Train net output #46: loss51 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696138 27891 solver.cpp:238]     Train net output #47: loss52 = 523.875 (* 1 = 523.875 loss)
I0726 15:25:01.696148 27891 solver.cpp:238]     Train net output #48: loss53 = 518.816 (* 1 = 518.816 loss)
I0726 15:25:01.696158 27891 solver.cpp:238]     Train net output #49: loss54 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696169 27891 solver.cpp:238]     Train net output #50: loss55 = 519.288 (* 1 = 519.288 loss)
I0726 15:25:01.696182 27891 solver.cpp:238]     Train net output #51: loss56 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696189 27891 solver.cpp:238]     Train net output #52: loss57 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696195 27891 solver.cpp:238]     Train net output #53: loss58 = 536.288 (* 1 = 536.288 loss)
I0726 15:25:01.696202 27891 solver.cpp:238]     Train net output #54: loss59 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696208 27891 solver.cpp:238]     Train net output #55: loss6 = 523.905 (* 1 = 523.905 loss)
I0726 15:25:01.696214 27891 solver.cpp:238]     Train net output #56: loss60 = 539.027 (* 1 = 539.027 loss)
I0726 15:25:01.696223 27891 solver.cpp:238]     Train net output #57: loss61 = 516.988 (* 1 = 516.988 loss)
I0726 15:25:01.696233 27891 solver.cpp:238]     Train net output #58: loss62 = 518.201 (* 1 = 518.201 loss)
I0726 15:25:01.696243 27891 solver.cpp:238]     Train net output #59: loss63 = 531.861 (* 1 = 531.861 loss)
I0726 15:25:01.696251 27891 solver.cpp:238]     Train net output #60: loss64 = 526.201 (* 1 = 526.201 loss)
I0726 15:25:01.696260 27891 solver.cpp:238]     Train net output #61: loss7 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696270 27891 solver.cpp:238]     Train net output #62: loss8 = 523.497 (* 1 = 523.497 loss)
I0726 15:25:01.696280 27891 solver.cpp:238]     Train net output #63: loss9 = 512.448 (* 1 = 512.448 loss)
I0726 15:25:01.696290 27891 sgd_solver.cpp:105] Iteration 194400, lr = 1e-09
I0726 15:33:54.736098 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:33:54.737473 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:33:55.127974 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_199800.caffemodel
I0726 15:33:55.810526 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_199800.solverstate
I0726 15:33:56.137719 27891 solver.cpp:331] Iteration 199800, Testing net (#0)
I0726 15:34:11.890552 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:34:11.916596 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:34:12.356653 27891 solver.cpp:398]     Test net output #0: mae = 75.2421 (* 1 = 75.2421 loss)
I0726 15:34:12.356691 27891 solver.cpp:398]     Test net output #1: mse = 13175.1 (* 1 = 13175.1 loss)
I0726 15:34:12.480931 27891 solver.cpp:219] Iteration 199800 (9.80435 iter/s, 550.776s/5400 iters), loss = 33481.1
I0726 15:34:12.481091 27891 solver.cpp:238]     Train net output #0: loss1 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481108 27891 solver.cpp:238]     Train net output #1: loss10 = 522.862 (* 1 = 522.862 loss)
I0726 15:34:12.481119 27891 solver.cpp:238]     Train net output #2: loss11 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481129 27891 solver.cpp:238]     Train net output #3: loss12 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481140 27891 solver.cpp:238]     Train net output #4: loss13 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481150 27891 solver.cpp:238]     Train net output #5: loss14 = 517.863 (* 1 = 517.863 loss)
I0726 15:34:12.481160 27891 solver.cpp:238]     Train net output #6: loss15 = 527.067 (* 1 = 527.067 loss)
I0726 15:34:12.481171 27891 solver.cpp:238]     Train net output #7: loss16 = 524.134 (* 1 = 524.134 loss)
I0726 15:34:12.481181 27891 solver.cpp:238]     Train net output #8: loss17 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481191 27891 solver.cpp:238]     Train net output #9: loss18 = 530.661 (* 1 = 530.661 loss)
I0726 15:34:12.481201 27891 solver.cpp:238]     Train net output #10: loss19 = 519.837 (* 1 = 519.837 loss)
I0726 15:34:12.481212 27891 solver.cpp:238]     Train net output #11: loss2 = 528.204 (* 1 = 528.204 loss)
I0726 15:34:12.481222 27891 solver.cpp:238]     Train net output #12: loss20 = 547.393 (* 1 = 547.393 loss)
I0726 15:34:12.481232 27891 solver.cpp:238]     Train net output #13: loss21 = 524.619 (* 1 = 524.619 loss)
I0726 15:34:12.481241 27891 solver.cpp:238]     Train net output #14: loss22 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481251 27891 solver.cpp:238]     Train net output #15: loss23 = 526.337 (* 1 = 526.337 loss)
I0726 15:34:12.481261 27891 solver.cpp:238]     Train net output #16: loss24 = 519.507 (* 1 = 519.507 loss)
I0726 15:34:12.481271 27891 solver.cpp:238]     Train net output #17: loss25 = 544.231 (* 1 = 544.231 loss)
I0726 15:34:12.481281 27891 solver.cpp:238]     Train net output #18: loss26 = 520.691 (* 1 = 520.691 loss)
I0726 15:34:12.481290 27891 solver.cpp:238]     Train net output #19: loss27 = 517.129 (* 1 = 517.129 loss)
I0726 15:34:12.481300 27891 solver.cpp:238]     Train net output #20: loss28 = 523.552 (* 1 = 523.552 loss)
I0726 15:34:12.481318 27891 solver.cpp:238]     Train net output #21: loss29 = 539.13 (* 1 = 539.13 loss)
I0726 15:34:12.481329 27891 solver.cpp:238]     Train net output #22: loss3 = 532.675 (* 1 = 532.675 loss)
I0726 15:34:12.481340 27891 solver.cpp:238]     Train net output #23: loss30 = 519.613 (* 1 = 519.613 loss)
I0726 15:34:12.481350 27891 solver.cpp:238]     Train net output #24: loss31 = 513.023 (* 1 = 513.023 loss)
I0726 15:34:12.481360 27891 solver.cpp:238]     Train net output #25: loss32 = 533.102 (* 1 = 533.102 loss)
I0726 15:34:12.481370 27891 solver.cpp:238]     Train net output #26: loss33 = 541.741 (* 1 = 541.741 loss)
I0726 15:34:12.481380 27891 solver.cpp:238]     Train net output #27: loss34 = 530.643 (* 1 = 530.643 loss)
I0726 15:34:12.481390 27891 solver.cpp:238]     Train net output #28: loss35 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481835 27891 solver.cpp:238]     Train net output #29: loss36 = 523.473 (* 1 = 523.473 loss)
I0726 15:34:12.481850 27891 solver.cpp:238]     Train net output #30: loss37 = 520.644 (* 1 = 520.644 loss)
I0726 15:34:12.481861 27891 solver.cpp:238]     Train net output #31: loss38 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481873 27891 solver.cpp:238]     Train net output #32: loss39 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481884 27891 solver.cpp:238]     Train net output #33: loss4 = 523.078 (* 1 = 523.078 loss)
I0726 15:34:12.481894 27891 solver.cpp:238]     Train net output #34: loss40 = 507.506 (* 1 = 507.506 loss)
I0726 15:34:12.481904 27891 solver.cpp:238]     Train net output #35: loss41 = 534.669 (* 1 = 534.669 loss)
I0726 15:34:12.481915 27891 solver.cpp:238]     Train net output #36: loss42 = 526.31 (* 1 = 526.31 loss)
I0726 15:34:12.481925 27891 solver.cpp:238]     Train net output #37: loss43 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481935 27891 solver.cpp:238]     Train net output #38: loss44 = 529.545 (* 1 = 529.545 loss)
I0726 15:34:12.481946 27891 solver.cpp:238]     Train net output #39: loss45 = 525.158 (* 1 = 525.158 loss)
I0726 15:34:12.481956 27891 solver.cpp:238]     Train net output #40: loss46 = 523.868 (* 1 = 523.868 loss)
I0726 15:34:12.481967 27891 solver.cpp:238]     Train net output #41: loss47 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481977 27891 solver.cpp:238]     Train net output #42: loss48 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.481988 27891 solver.cpp:238]     Train net output #43: loss49 = 536.588 (* 1 = 536.588 loss)
I0726 15:34:12.481998 27891 solver.cpp:238]     Train net output #44: loss5 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482009 27891 solver.cpp:238]     Train net output #45: loss50 = 530.9 (* 1 = 530.9 loss)
I0726 15:34:12.482019 27891 solver.cpp:238]     Train net output #46: loss51 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482030 27891 solver.cpp:238]     Train net output #47: loss52 = 524.767 (* 1 = 524.767 loss)
I0726 15:34:12.482041 27891 solver.cpp:238]     Train net output #48: loss53 = 519.656 (* 1 = 519.656 loss)
I0726 15:34:12.482051 27891 solver.cpp:238]     Train net output #49: loss54 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482061 27891 solver.cpp:238]     Train net output #50: loss55 = 520.282 (* 1 = 520.282 loss)
I0726 15:34:12.482072 27891 solver.cpp:238]     Train net output #51: loss56 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482082 27891 solver.cpp:238]     Train net output #52: loss57 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482094 27891 solver.cpp:238]     Train net output #53: loss58 = 537.081 (* 1 = 537.081 loss)
I0726 15:34:12.482103 27891 solver.cpp:238]     Train net output #54: loss59 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482115 27891 solver.cpp:238]     Train net output #55: loss6 = 524.917 (* 1 = 524.917 loss)
I0726 15:34:12.482125 27891 solver.cpp:238]     Train net output #56: loss60 = 540.001 (* 1 = 540.001 loss)
I0726 15:34:12.482136 27891 solver.cpp:238]     Train net output #57: loss61 = 517.957 (* 1 = 517.957 loss)
I0726 15:34:12.482146 27891 solver.cpp:238]     Train net output #58: loss62 = 519.119 (* 1 = 519.119 loss)
I0726 15:34:12.482156 27891 solver.cpp:238]     Train net output #59: loss63 = 532.654 (* 1 = 532.654 loss)
I0726 15:34:12.482167 27891 solver.cpp:238]     Train net output #60: loss64 = 527.196 (* 1 = 527.196 loss)
I0726 15:34:12.482177 27891 solver.cpp:238]     Train net output #61: loss7 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482187 27891 solver.cpp:238]     Train net output #62: loss8 = 524.345 (* 1 = 524.345 loss)
I0726 15:34:12.482197 27891 solver.cpp:238]     Train net output #63: loss9 = 513.219 (* 1 = 513.219 loss)
I0726 15:34:12.482208 27891 sgd_solver.cpp:105] Iteration 199800, lr = 1e-09
I0726 15:43:07.276899 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:43:07.276899 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:43:07.663163 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_205200.caffemodel
I0726 15:43:07.986322 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_205200.solverstate
I0726 15:43:08.183274 27891 solver.cpp:331] Iteration 205200, Testing net (#0)
I0726 15:43:23.892125 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:43:23.990398 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:43:24.360990 27891 solver.cpp:398]     Test net output #0: mae = 75.253 (* 1 = 75.253 loss)
I0726 15:43:24.361299 27891 solver.cpp:398]     Test net output #1: mse = 13112.2 (* 1 = 13112.2 loss)
I0726 15:43:24.485986 27891 solver.cpp:219] Iteration 205200 (9.78271 iter/s, 551.994s/5400 iters), loss = 33569.1
I0726 15:43:24.486047 27891 solver.cpp:238]     Train net output #0: loss1 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486065 27891 solver.cpp:238]     Train net output #1: loss10 = 524.142 (* 1 = 524.142 loss)
I0726 15:43:24.486078 27891 solver.cpp:238]     Train net output #2: loss11 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486091 27891 solver.cpp:238]     Train net output #3: loss12 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486104 27891 solver.cpp:238]     Train net output #4: loss13 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486114 27891 solver.cpp:238]     Train net output #5: loss14 = 519.224 (* 1 = 519.224 loss)
I0726 15:43:24.486125 27891 solver.cpp:238]     Train net output #6: loss15 = 528.452 (* 1 = 528.452 loss)
I0726 15:43:24.486135 27891 solver.cpp:238]     Train net output #7: loss16 = 525.07 (* 1 = 525.07 loss)
I0726 15:43:24.486145 27891 solver.cpp:238]     Train net output #8: loss17 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486153 27891 solver.cpp:238]     Train net output #9: loss18 = 532.32 (* 1 = 532.32 loss)
I0726 15:43:24.486162 27891 solver.cpp:238]     Train net output #10: loss19 = 521.107 (* 1 = 521.107 loss)
I0726 15:43:24.486171 27891 solver.cpp:238]     Train net output #11: loss2 = 529.609 (* 1 = 529.609 loss)
I0726 15:43:24.486181 27891 solver.cpp:238]     Train net output #12: loss20 = 548.841 (* 1 = 548.841 loss)
I0726 15:43:24.486189 27891 solver.cpp:238]     Train net output #13: loss21 = 526.876 (* 1 = 526.876 loss)
I0726 15:43:24.486199 27891 solver.cpp:238]     Train net output #14: loss22 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486207 27891 solver.cpp:238]     Train net output #15: loss23 = 528.088 (* 1 = 528.088 loss)
I0726 15:43:24.486217 27891 solver.cpp:238]     Train net output #16: loss24 = 520.937 (* 1 = 520.937 loss)
I0726 15:43:24.486225 27891 solver.cpp:238]     Train net output #17: loss25 = 546.079 (* 1 = 546.079 loss)
I0726 15:43:24.486234 27891 solver.cpp:238]     Train net output #18: loss26 = 522.273 (* 1 = 522.273 loss)
I0726 15:43:24.486244 27891 solver.cpp:238]     Train net output #19: loss27 = 518.559 (* 1 = 518.559 loss)
I0726 15:43:24.486253 27891 solver.cpp:238]     Train net output #20: loss28 = 525.172 (* 1 = 525.172 loss)
I0726 15:43:24.486263 27891 solver.cpp:238]     Train net output #21: loss29 = 540.568 (* 1 = 540.568 loss)
I0726 15:43:24.486271 27891 solver.cpp:238]     Train net output #22: loss3 = 534.446 (* 1 = 534.446 loss)
I0726 15:43:24.486280 27891 solver.cpp:238]     Train net output #23: loss30 = 520.973 (* 1 = 520.973 loss)
I0726 15:43:24.486289 27891 solver.cpp:238]     Train net output #24: loss31 = 514.335 (* 1 = 514.335 loss)
I0726 15:43:24.486299 27891 solver.cpp:238]     Train net output #25: loss32 = 534.735 (* 1 = 534.735 loss)
I0726 15:43:24.486307 27891 solver.cpp:238]     Train net output #26: loss33 = 543.713 (* 1 = 543.713 loss)
I0726 15:43:24.486316 27891 solver.cpp:238]     Train net output #27: loss34 = 532.126 (* 1 = 532.126 loss)
I0726 15:43:24.486325 27891 solver.cpp:238]     Train net output #28: loss35 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486335 27891 solver.cpp:238]     Train net output #29: loss36 = 524.765 (* 1 = 524.765 loss)
I0726 15:43:24.486526 27891 solver.cpp:238]     Train net output #30: loss37 = 521.891 (* 1 = 521.891 loss)
I0726 15:43:24.486539 27891 solver.cpp:238]     Train net output #31: loss38 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486549 27891 solver.cpp:238]     Train net output #32: loss39 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486560 27891 solver.cpp:238]     Train net output #33: loss4 = 524.485 (* 1 = 524.485 loss)
I0726 15:43:24.486572 27891 solver.cpp:238]     Train net output #34: loss40 = 508.872 (* 1 = 508.872 loss)
I0726 15:43:24.486582 27891 solver.cpp:238]     Train net output #35: loss41 = 536.26 (* 1 = 536.26 loss)
I0726 15:43:24.486591 27891 solver.cpp:238]     Train net output #36: loss42 = 527.93 (* 1 = 527.93 loss)
I0726 15:43:24.486601 27891 solver.cpp:238]     Train net output #37: loss43 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486611 27891 solver.cpp:238]     Train net output #38: loss44 = 530.917 (* 1 = 530.917 loss)
I0726 15:43:24.486621 27891 solver.cpp:238]     Train net output #39: loss45 = 526.651 (* 1 = 526.651 loss)
I0726 15:43:24.486630 27891 solver.cpp:238]     Train net output #40: loss46 = 525.478 (* 1 = 525.478 loss)
I0726 15:43:24.486639 27891 solver.cpp:238]     Train net output #41: loss47 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486644 27891 solver.cpp:238]     Train net output #42: loss48 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486647 27891 solver.cpp:238]     Train net output #43: loss49 = 538.082 (* 1 = 538.082 loss)
I0726 15:43:24.486652 27891 solver.cpp:238]     Train net output #44: loss5 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486657 27891 solver.cpp:238]     Train net output #45: loss50 = 532.52 (* 1 = 532.52 loss)
I0726 15:43:24.486661 27891 solver.cpp:238]     Train net output #46: loss51 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486666 27891 solver.cpp:238]     Train net output #47: loss52 = 526.271 (* 1 = 526.271 loss)
I0726 15:43:24.486671 27891 solver.cpp:238]     Train net output #48: loss53 = 521.159 (* 1 = 521.159 loss)
I0726 15:43:24.486676 27891 solver.cpp:238]     Train net output #49: loss54 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486680 27891 solver.cpp:238]     Train net output #50: loss55 = 521.911 (* 1 = 521.911 loss)
I0726 15:43:24.486685 27891 solver.cpp:238]     Train net output #51: loss56 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486690 27891 solver.cpp:238]     Train net output #52: loss57 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486695 27891 solver.cpp:238]     Train net output #53: loss58 = 538.546 (* 1 = 538.546 loss)
I0726 15:43:24.486699 27891 solver.cpp:238]     Train net output #54: loss59 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486706 27891 solver.cpp:238]     Train net output #55: loss6 = 526.457 (* 1 = 526.457 loss)
I0726 15:43:24.486711 27891 solver.cpp:238]     Train net output #56: loss60 = 541.787 (* 1 = 541.787 loss)
I0726 15:43:24.486717 27891 solver.cpp:238]     Train net output #57: loss61 = 519.607 (* 1 = 519.607 loss)
I0726 15:43:24.486723 27891 solver.cpp:238]     Train net output #58: loss62 = 520.64 (* 1 = 520.64 loss)
I0726 15:43:24.486729 27891 solver.cpp:238]     Train net output #59: loss63 = 534.199 (* 1 = 534.199 loss)
I0726 15:43:24.486734 27891 solver.cpp:238]     Train net output #60: loss64 = 528.885 (* 1 = 528.885 loss)
I0726 15:43:24.486740 27891 solver.cpp:238]     Train net output #61: loss7 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486747 27891 solver.cpp:238]     Train net output #62: loss8 = 525.76 (* 1 = 525.76 loss)
I0726 15:43:24.486752 27891 solver.cpp:238]     Train net output #63: loss9 = 514.554 (* 1 = 514.554 loss)
I0726 15:43:24.486759 27891 sgd_solver.cpp:105] Iteration 205200, lr = 1e-09
I0726 15:52:20.963923 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:52:20.972858 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:52:21.343272 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_210600.caffemodel
I0726 15:52:22.871994 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_210600.solverstate
I0726 15:52:23.295289 27891 solver.cpp:331] Iteration 210600, Testing net (#0)
I0726 15:52:38.624799 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:52:38.717640 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 15:52:39.109133 27891 solver.cpp:398]     Test net output #0: mae = 75.2357 (* 1 = 75.2357 loss)
I0726 15:52:39.109464 27891 solver.cpp:398]     Test net output #1: mse = 13072.5 (* 1 = 13072.5 loss)
I0726 15:52:39.235507 27891 solver.cpp:219] Iteration 210600 (9.73431 iter/s, 554.739s/5400 iters), loss = 33651.4
I0726 15:52:39.235647 27891 solver.cpp:238]     Train net output #0: loss1 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235689 27891 solver.cpp:238]     Train net output #1: loss10 = 525.315 (* 1 = 525.315 loss)
I0726 15:52:39.235702 27891 solver.cpp:238]     Train net output #2: loss11 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235713 27891 solver.cpp:238]     Train net output #3: loss12 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235721 27891 solver.cpp:238]     Train net output #4: loss13 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235731 27891 solver.cpp:238]     Train net output #5: loss14 = 520.536 (* 1 = 520.536 loss)
I0726 15:52:39.235741 27891 solver.cpp:238]     Train net output #6: loss15 = 529.749 (* 1 = 529.749 loss)
I0726 15:52:39.235751 27891 solver.cpp:238]     Train net output #7: loss16 = 525.791 (* 1 = 525.791 loss)
I0726 15:52:39.235761 27891 solver.cpp:238]     Train net output #8: loss17 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235771 27891 solver.cpp:238]     Train net output #9: loss18 = 533.83 (* 1 = 533.83 loss)
I0726 15:52:39.235780 27891 solver.cpp:238]     Train net output #10: loss19 = 522.256 (* 1 = 522.256 loss)
I0726 15:52:39.235790 27891 solver.cpp:238]     Train net output #11: loss2 = 530.911 (* 1 = 530.911 loss)
I0726 15:52:39.235800 27891 solver.cpp:238]     Train net output #12: loss20 = 550.198 (* 1 = 550.198 loss)
I0726 15:52:39.235810 27891 solver.cpp:238]     Train net output #13: loss21 = 529.021 (* 1 = 529.021 loss)
I0726 15:52:39.235819 27891 solver.cpp:238]     Train net output #14: loss22 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235829 27891 solver.cpp:238]     Train net output #15: loss23 = 529.71 (* 1 = 529.71 loss)
I0726 15:52:39.235839 27891 solver.cpp:238]     Train net output #16: loss24 = 522.328 (* 1 = 522.328 loss)
I0726 15:52:39.235848 27891 solver.cpp:238]     Train net output #17: loss25 = 547.513 (* 1 = 547.513 loss)
I0726 15:52:39.235858 27891 solver.cpp:238]     Train net output #18: loss26 = 523.709 (* 1 = 523.709 loss)
I0726 15:52:39.235868 27891 solver.cpp:238]     Train net output #19: loss27 = 520.006 (* 1 = 520.006 loss)
I0726 15:52:39.235878 27891 solver.cpp:238]     Train net output #20: loss28 = 526.643 (* 1 = 526.643 loss)
I0726 15:52:39.235888 27891 solver.cpp:238]     Train net output #21: loss29 = 541.953 (* 1 = 541.953 loss)
I0726 15:52:39.235898 27891 solver.cpp:238]     Train net output #22: loss3 = 536.021 (* 1 = 536.021 loss)
I0726 15:52:39.235906 27891 solver.cpp:238]     Train net output #23: loss30 = 522.188 (* 1 = 522.188 loss)
I0726 15:52:39.235916 27891 solver.cpp:238]     Train net output #24: loss31 = 515.637 (* 1 = 515.637 loss)
I0726 15:52:39.235926 27891 solver.cpp:238]     Train net output #25: loss32 = 536.409 (* 1 = 536.409 loss)
I0726 15:52:39.235935 27891 solver.cpp:238]     Train net output #26: loss33 = 545.488 (* 1 = 545.488 loss)
I0726 15:52:39.235945 27891 solver.cpp:238]     Train net output #27: loss34 = 533.534 (* 1 = 533.534 loss)
I0726 15:52:39.235955 27891 solver.cpp:238]     Train net output #28: loss35 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.235965 27891 solver.cpp:238]     Train net output #29: loss36 = 525.929 (* 1 = 525.929 loss)
I0726 15:52:39.236644 27891 solver.cpp:238]     Train net output #30: loss37 = 523.076 (* 1 = 523.076 loss)
I0726 15:52:39.236657 27891 solver.cpp:238]     Train net output #31: loss38 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236670 27891 solver.cpp:238]     Train net output #32: loss39 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236680 27891 solver.cpp:238]     Train net output #33: loss4 = 525.803 (* 1 = 525.803 loss)
I0726 15:52:39.236690 27891 solver.cpp:238]     Train net output #34: loss40 = 510.19 (* 1 = 510.19 loss)
I0726 15:52:39.236701 27891 solver.cpp:238]     Train net output #35: loss41 = 537.641 (* 1 = 537.641 loss)
I0726 15:52:39.236711 27891 solver.cpp:238]     Train net output #36: loss42 = 529.512 (* 1 = 529.512 loss)
I0726 15:52:39.236721 27891 solver.cpp:238]     Train net output #37: loss43 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236730 27891 solver.cpp:238]     Train net output #38: loss44 = 532.108 (* 1 = 532.108 loss)
I0726 15:52:39.236739 27891 solver.cpp:238]     Train net output #39: loss45 = 528.025 (* 1 = 528.025 loss)
I0726 15:52:39.236749 27891 solver.cpp:238]     Train net output #40: loss46 = 527 (* 1 = 527 loss)
I0726 15:52:39.236759 27891 solver.cpp:238]     Train net output #41: loss47 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236769 27891 solver.cpp:238]     Train net output #42: loss48 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236778 27891 solver.cpp:238]     Train net output #43: loss49 = 539.414 (* 1 = 539.414 loss)
I0726 15:52:39.236788 27891 solver.cpp:238]     Train net output #44: loss5 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236799 27891 solver.cpp:238]     Train net output #45: loss50 = 533.909 (* 1 = 533.909 loss)
I0726 15:52:39.236809 27891 solver.cpp:238]     Train net output #46: loss51 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236817 27891 solver.cpp:238]     Train net output #47: loss52 = 527.711 (* 1 = 527.711 loss)
I0726 15:52:39.236827 27891 solver.cpp:238]     Train net output #48: loss53 = 522.57 (* 1 = 522.57 loss)
I0726 15:52:39.236837 27891 solver.cpp:238]     Train net output #49: loss54 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236847 27891 solver.cpp:238]     Train net output #50: loss55 = 523.291 (* 1 = 523.291 loss)
I0726 15:52:39.236856 27891 solver.cpp:238]     Train net output #51: loss56 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236866 27891 solver.cpp:238]     Train net output #52: loss57 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236876 27891 solver.cpp:238]     Train net output #53: loss58 = 539.776 (* 1 = 539.776 loss)
I0726 15:52:39.236886 27891 solver.cpp:238]     Train net output #54: loss59 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236896 27891 solver.cpp:238]     Train net output #55: loss6 = 527.932 (* 1 = 527.932 loss)
I0726 15:52:39.236905 27891 solver.cpp:238]     Train net output #56: loss60 = 543.292 (* 1 = 543.292 loss)
I0726 15:52:39.236915 27891 solver.cpp:238]     Train net output #57: loss61 = 521.145 (* 1 = 521.145 loss)
I0726 15:52:39.236925 27891 solver.cpp:238]     Train net output #58: loss62 = 522.012 (* 1 = 522.012 loss)
I0726 15:52:39.236935 27891 solver.cpp:238]     Train net output #59: loss63 = 535.543 (* 1 = 535.543 loss)
I0726 15:52:39.236945 27891 solver.cpp:238]     Train net output #60: loss64 = 530.382 (* 1 = 530.382 loss)
I0726 15:52:39.236954 27891 solver.cpp:238]     Train net output #61: loss7 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236964 27891 solver.cpp:238]     Train net output #62: loss8 = 527.127 (* 1 = 527.127 loss)
I0726 15:52:39.236974 27891 solver.cpp:238]     Train net output #63: loss9 = 515.823 (* 1 = 515.823 loss)
I0726 15:52:39.236984 27891 sgd_solver.cpp:105] Iteration 210600, lr = 1e-09
I0726 16:01:38.409960 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:01:38.412091 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:01:38.814870 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_216000.caffemodel
I0726 16:01:39.088415 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_216000.solverstate
I0726 16:01:39.178231 27891 solver.cpp:331] Iteration 216000, Testing net (#0)
I0726 16:01:54.377516 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:01:54.473664 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:01:54.843189 27891 solver.cpp:398]     Test net output #0: mae = 75.178 (* 1 = 75.178 loss)
I0726 16:01:54.843230 27891 solver.cpp:398]     Test net output #1: mse = 13022.5 (* 1 = 13022.5 loss)
I0726 16:01:54.968008 27891 solver.cpp:219] Iteration 216000 (9.71707 iter/s, 555.723s/5400 iters), loss = 33776.5
I0726 16:01:54.968049 27891 solver.cpp:238]     Train net output #0: loss1 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968060 27891 solver.cpp:238]     Train net output #1: loss10 = 527.049 (* 1 = 527.049 loss)
I0726 16:01:54.968070 27891 solver.cpp:238]     Train net output #2: loss11 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968077 27891 solver.cpp:238]     Train net output #3: loss12 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968086 27891 solver.cpp:238]     Train net output #4: loss13 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968096 27891 solver.cpp:238]     Train net output #5: loss14 = 522.307 (* 1 = 522.307 loss)
I0726 16:01:54.968104 27891 solver.cpp:238]     Train net output #6: loss15 = 531.679 (* 1 = 531.679 loss)
I0726 16:01:54.968114 27891 solver.cpp:238]     Train net output #7: loss16 = 527.163 (* 1 = 527.163 loss)
I0726 16:01:54.968122 27891 solver.cpp:238]     Train net output #8: loss17 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968132 27891 solver.cpp:238]     Train net output #9: loss18 = 535.829 (* 1 = 535.829 loss)
I0726 16:01:54.968140 27891 solver.cpp:238]     Train net output #10: loss19 = 523.945 (* 1 = 523.945 loss)
I0726 16:01:54.968149 27891 solver.cpp:238]     Train net output #11: loss2 = 532.714 (* 1 = 532.714 loss)
I0726 16:01:54.968158 27891 solver.cpp:238]     Train net output #12: loss20 = 552.164 (* 1 = 552.164 loss)
I0726 16:01:54.968166 27891 solver.cpp:238]     Train net output #13: loss21 = 531.786 (* 1 = 531.786 loss)
I0726 16:01:54.968175 27891 solver.cpp:238]     Train net output #14: loss22 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968183 27891 solver.cpp:238]     Train net output #15: loss23 = 531.891 (* 1 = 531.891 loss)
I0726 16:01:54.968192 27891 solver.cpp:238]     Train net output #16: loss24 = 524.284 (* 1 = 524.284 loss)
I0726 16:01:54.968200 27891 solver.cpp:238]     Train net output #17: loss25 = 549.572 (* 1 = 549.572 loss)
I0726 16:01:54.968209 27891 solver.cpp:238]     Train net output #18: loss26 = 525.767 (* 1 = 525.767 loss)
I0726 16:01:54.968219 27891 solver.cpp:238]     Train net output #19: loss27 = 522.113 (* 1 = 522.113 loss)
I0726 16:01:54.968227 27891 solver.cpp:238]     Train net output #20: loss28 = 528.68 (* 1 = 528.68 loss)
I0726 16:01:54.968235 27891 solver.cpp:238]     Train net output #21: loss29 = 543.794 (* 1 = 543.794 loss)
I0726 16:01:54.968245 27891 solver.cpp:238]     Train net output #22: loss3 = 538.241 (* 1 = 538.241 loss)
I0726 16:01:54.968253 27891 solver.cpp:238]     Train net output #23: loss30 = 523.951 (* 1 = 523.951 loss)
I0726 16:01:54.968262 27891 solver.cpp:238]     Train net output #24: loss31 = 517.514 (* 1 = 517.514 loss)
I0726 16:01:54.968271 27891 solver.cpp:238]     Train net output #25: loss32 = 538.411 (* 1 = 538.411 loss)
I0726 16:01:54.968279 27891 solver.cpp:238]     Train net output #26: loss33 = 547.803 (* 1 = 547.803 loss)
I0726 16:01:54.968288 27891 solver.cpp:238]     Train net output #27: loss34 = 535.547 (* 1 = 535.547 loss)
I0726 16:01:54.968297 27891 solver.cpp:238]     Train net output #28: loss35 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968305 27891 solver.cpp:238]     Train net output #29: loss36 = 527.675 (* 1 = 527.675 loss)
I0726 16:01:54.968353 27891 solver.cpp:238]     Train net output #30: loss37 = 524.765 (* 1 = 524.765 loss)
I0726 16:01:54.968364 27891 solver.cpp:238]     Train net output #31: loss38 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968372 27891 solver.cpp:238]     Train net output #32: loss39 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968382 27891 solver.cpp:238]     Train net output #33: loss4 = 527.68 (* 1 = 527.68 loss)
I0726 16:01:54.968391 27891 solver.cpp:238]     Train net output #34: loss40 = 512.03 (* 1 = 512.03 loss)
I0726 16:01:54.968401 27891 solver.cpp:238]     Train net output #35: loss41 = 539.586 (* 1 = 539.586 loss)
I0726 16:01:54.968410 27891 solver.cpp:238]     Train net output #36: loss42 = 531.667 (* 1 = 531.667 loss)
I0726 16:01:54.968420 27891 solver.cpp:238]     Train net output #37: loss43 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968427 27891 solver.cpp:238]     Train net output #38: loss44 = 533.955 (* 1 = 533.955 loss)
I0726 16:01:54.968437 27891 solver.cpp:238]     Train net output #39: loss45 = 529.876 (* 1 = 529.876 loss)
I0726 16:01:54.968446 27891 solver.cpp:238]     Train net output #40: loss46 = 529.021 (* 1 = 529.021 loss)
I0726 16:01:54.968454 27891 solver.cpp:238]     Train net output #41: loss47 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968462 27891 solver.cpp:238]     Train net output #42: loss48 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968472 27891 solver.cpp:238]     Train net output #43: loss49 = 541.341 (* 1 = 541.341 loss)
I0726 16:01:54.968480 27891 solver.cpp:238]     Train net output #44: loss5 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968489 27891 solver.cpp:238]     Train net output #45: loss50 = 535.964 (* 1 = 535.964 loss)
I0726 16:01:54.968497 27891 solver.cpp:238]     Train net output #46: loss51 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968506 27891 solver.cpp:238]     Train net output #47: loss52 = 529.677 (* 1 = 529.677 loss)
I0726 16:01:54.968514 27891 solver.cpp:238]     Train net output #48: loss53 = 524.528 (* 1 = 524.528 loss)
I0726 16:01:54.968523 27891 solver.cpp:238]     Train net output #49: loss54 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968533 27891 solver.cpp:238]     Train net output #50: loss55 = 525.329 (* 1 = 525.329 loss)
I0726 16:01:54.968540 27891 solver.cpp:238]     Train net output #51: loss56 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968549 27891 solver.cpp:238]     Train net output #52: loss57 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968559 27891 solver.cpp:238]     Train net output #53: loss58 = 541.505 (* 1 = 541.505 loss)
I0726 16:01:54.968566 27891 solver.cpp:238]     Train net output #54: loss59 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968575 27891 solver.cpp:238]     Train net output #55: loss6 = 530.028 (* 1 = 530.028 loss)
I0726 16:01:54.968585 27891 solver.cpp:238]     Train net output #56: loss60 = 545.34 (* 1 = 545.34 loss)
I0726 16:01:54.968592 27891 solver.cpp:238]     Train net output #57: loss61 = 523.26 (* 1 = 523.26 loss)
I0726 16:01:54.968600 27891 solver.cpp:238]     Train net output #58: loss62 = 523.908 (* 1 = 523.908 loss)
I0726 16:01:54.968608 27891 solver.cpp:238]     Train net output #59: loss63 = 537.495 (* 1 = 537.495 loss)
I0726 16:01:54.968616 27891 solver.cpp:238]     Train net output #60: loss64 = 532.457 (* 1 = 532.457 loss)
I0726 16:01:54.968624 27891 solver.cpp:238]     Train net output #61: loss7 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968634 27891 solver.cpp:238]     Train net output #62: loss8 = 528.911 (* 1 = 528.911 loss)
I0726 16:01:54.968641 27891 solver.cpp:238]     Train net output #63: loss9 = 517.649 (* 1 = 517.649 loss)
I0726 16:01:54.968648 27891 sgd_solver.cpp:105] Iteration 216000, lr = 1e-09
I0726 16:10:58.830356 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:10:58.832229 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:10:59.223074 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_221400.caffemodel
I0726 16:10:59.722905 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_221400.solverstate
I0726 16:10:59.805857 27891 solver.cpp:331] Iteration 221400, Testing net (#0)
I0726 16:11:15.007752 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:11:15.049325 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:11:15.473103 27891 solver.cpp:398]     Test net output #0: mae = 75.1892 (* 1 = 75.1892 loss)
I0726 16:11:15.473132 27891 solver.cpp:398]     Test net output #1: mse = 12953.4 (* 1 = 12953.4 loss)
I0726 16:11:15.598145 27891 solver.cpp:219] Iteration 221400 (9.63211 iter/s, 560.625s/5400 iters), loss = 33854.8
I0726 16:11:15.598188 27891 solver.cpp:238]     Train net output #0: loss1 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598199 27891 solver.cpp:238]     Train net output #1: loss10 = 528.126 (* 1 = 528.126 loss)
I0726 16:11:15.598206 27891 solver.cpp:238]     Train net output #2: loss11 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598212 27891 solver.cpp:238]     Train net output #3: loss12 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598219 27891 solver.cpp:238]     Train net output #4: loss13 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598225 27891 solver.cpp:238]     Train net output #5: loss14 = 523.533 (* 1 = 523.533 loss)
I0726 16:11:15.598232 27891 solver.cpp:238]     Train net output #6: loss15 = 532.926 (* 1 = 532.926 loss)
I0726 16:11:15.598238 27891 solver.cpp:238]     Train net output #7: loss16 = 527.825 (* 1 = 527.825 loss)
I0726 16:11:15.598244 27891 solver.cpp:238]     Train net output #8: loss17 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598251 27891 solver.cpp:238]     Train net output #9: loss18 = 537.086 (* 1 = 537.086 loss)
I0726 16:11:15.598258 27891 solver.cpp:238]     Train net output #10: loss19 = 524.955 (* 1 = 524.955 loss)
I0726 16:11:15.598264 27891 solver.cpp:238]     Train net output #11: loss2 = 533.818 (* 1 = 533.818 loss)
I0726 16:11:15.598270 27891 solver.cpp:238]     Train net output #12: loss20 = 553.34 (* 1 = 553.34 loss)
I0726 16:11:15.598276 27891 solver.cpp:238]     Train net output #13: loss21 = 533.476 (* 1 = 533.476 loss)
I0726 16:11:15.598284 27891 solver.cpp:238]     Train net output #14: loss22 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598289 27891 solver.cpp:238]     Train net output #15: loss23 = 533.258 (* 1 = 533.258 loss)
I0726 16:11:15.598296 27891 solver.cpp:238]     Train net output #16: loss24 = 525.51 (* 1 = 525.51 loss)
I0726 16:11:15.598304 27891 solver.cpp:238]     Train net output #17: loss25 = 550.92 (* 1 = 550.92 loss)
I0726 16:11:15.598309 27891 solver.cpp:238]     Train net output #18: loss26 = 527.081 (* 1 = 527.081 loss)
I0726 16:11:15.598316 27891 solver.cpp:238]     Train net output #19: loss27 = 523.467 (* 1 = 523.467 loss)
I0726 16:11:15.598322 27891 solver.cpp:238]     Train net output #20: loss28 = 529.983 (* 1 = 529.983 loss)
I0726 16:11:15.598330 27891 solver.cpp:238]     Train net output #21: loss29 = 545.023 (* 1 = 545.023 loss)
I0726 16:11:15.598335 27891 solver.cpp:238]     Train net output #22: loss3 = 539.62 (* 1 = 539.62 loss)
I0726 16:11:15.598341 27891 solver.cpp:238]     Train net output #23: loss30 = 525.051 (* 1 = 525.051 loss)
I0726 16:11:15.598348 27891 solver.cpp:238]     Train net output #24: loss31 = 518.647 (* 1 = 518.647 loss)
I0726 16:11:15.598354 27891 solver.cpp:238]     Train net output #25: loss32 = 539.839 (* 1 = 539.839 loss)
I0726 16:11:15.598361 27891 solver.cpp:238]     Train net output #26: loss33 = 549.39 (* 1 = 549.39 loss)
I0726 16:11:15.598368 27891 solver.cpp:238]     Train net output #27: loss34 = 536.786 (* 1 = 536.786 loss)
I0726 16:11:15.598374 27891 solver.cpp:238]     Train net output #28: loss35 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598381 27891 solver.cpp:238]     Train net output #29: loss36 = 528.768 (* 1 = 528.768 loss)
I0726 16:11:15.598424 27891 solver.cpp:238]     Train net output #30: loss37 = 525.809 (* 1 = 525.809 loss)
I0726 16:11:15.598433 27891 solver.cpp:238]     Train net output #31: loss38 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598439 27891 solver.cpp:238]     Train net output #32: loss39 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598445 27891 solver.cpp:238]     Train net output #33: loss4 = 528.854 (* 1 = 528.854 loss)
I0726 16:11:15.598451 27891 solver.cpp:238]     Train net output #34: loss40 = 513.195 (* 1 = 513.195 loss)
I0726 16:11:15.598459 27891 solver.cpp:238]     Train net output #35: loss41 = 540.809 (* 1 = 540.809 loss)
I0726 16:11:15.598465 27891 solver.cpp:238]     Train net output #36: loss42 = 533.13 (* 1 = 533.13 loss)
I0726 16:11:15.598479 27891 solver.cpp:238]     Train net output #37: loss43 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598485 27891 solver.cpp:238]     Train net output #38: loss44 = 535.03 (* 1 = 535.03 loss)
I0726 16:11:15.598492 27891 solver.cpp:238]     Train net output #39: loss45 = 531.159 (* 1 = 531.159 loss)
I0726 16:11:15.598498 27891 solver.cpp:238]     Train net output #40: loss46 = 530.309 (* 1 = 530.309 loss)
I0726 16:11:15.598505 27891 solver.cpp:238]     Train net output #41: loss47 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598511 27891 solver.cpp:238]     Train net output #42: loss48 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598518 27891 solver.cpp:238]     Train net output #43: loss49 = 542.535 (* 1 = 542.535 loss)
I0726 16:11:15.598525 27891 solver.cpp:238]     Train net output #44: loss5 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598531 27891 solver.cpp:238]     Train net output #45: loss50 = 537.265 (* 1 = 537.265 loss)
I0726 16:11:15.598536 27891 solver.cpp:238]     Train net output #46: loss51 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598543 27891 solver.cpp:238]     Train net output #47: loss52 = 530.907 (* 1 = 530.907 loss)
I0726 16:11:15.598549 27891 solver.cpp:238]     Train net output #48: loss53 = 525.767 (* 1 = 525.767 loss)
I0726 16:11:15.598556 27891 solver.cpp:238]     Train net output #49: loss54 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598562 27891 solver.cpp:238]     Train net output #50: loss55 = 526.682 (* 1 = 526.682 loss)
I0726 16:11:15.598568 27891 solver.cpp:238]     Train net output #51: loss56 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598574 27891 solver.cpp:238]     Train net output #52: loss57 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598580 27891 solver.cpp:238]     Train net output #53: loss58 = 542.603 (* 1 = 542.603 loss)
I0726 16:11:15.598587 27891 solver.cpp:238]     Train net output #54: loss59 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598593 27891 solver.cpp:238]     Train net output #55: loss6 = 531.295 (* 1 = 531.295 loss)
I0726 16:11:15.598599 27891 solver.cpp:238]     Train net output #56: loss60 = 546.659 (* 1 = 546.659 loss)
I0726 16:11:15.598605 27891 solver.cpp:238]     Train net output #57: loss61 = 524.497 (* 1 = 524.497 loss)
I0726 16:11:15.598613 27891 solver.cpp:238]     Train net output #58: loss62 = 525.155 (* 1 = 525.155 loss)
I0726 16:11:15.598618 27891 solver.cpp:238]     Train net output #59: loss63 = 538.825 (* 1 = 538.825 loss)
I0726 16:11:15.598624 27891 solver.cpp:238]     Train net output #60: loss64 = 533.895 (* 1 = 533.895 loss)
I0726 16:11:15.598631 27891 solver.cpp:238]     Train net output #61: loss7 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598637 27891 solver.cpp:238]     Train net output #62: loss8 = 530.026 (* 1 = 530.026 loss)
I0726 16:11:15.598644 27891 solver.cpp:238]     Train net output #63: loss9 = 518.773 (* 1 = 518.773 loss)
I0726 16:11:15.598651 27891 sgd_solver.cpp:105] Iteration 221400, lr = 1e-09
I0726 16:20:19.322118 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:20:19.324139 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:20:19.710384 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_226800.caffemodel
I0726 16:20:20.262620 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_226800.solverstate
I0726 16:20:20.346204 27891 solver.cpp:331] Iteration 226800, Testing net (#0)
I0726 16:20:35.531808 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:20:35.648262 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:20:35.996953 27891 solver.cpp:398]     Test net output #0: mae = 75.2146 (* 1 = 75.2146 loss)
I0726 16:20:35.996978 27891 solver.cpp:398]     Test net output #1: mse = 12916.1 (* 1 = 12916.1 loss)
I0726 16:20:36.121453 27891 solver.cpp:219] Iteration 226800 (9.63399 iter/s, 560.515s/5400 iters), loss = 33940.6
I0726 16:20:36.121490 27891 solver.cpp:238]     Train net output #0: loss1 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121496 27891 solver.cpp:238]     Train net output #1: loss10 = 529.411 (* 1 = 529.411 loss)
I0726 16:20:36.121502 27891 solver.cpp:238]     Train net output #2: loss11 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121510 27891 solver.cpp:238]     Train net output #3: loss12 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121518 27891 solver.cpp:238]     Train net output #4: loss13 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121525 27891 solver.cpp:238]     Train net output #5: loss14 = 524.957 (* 1 = 524.957 loss)
I0726 16:20:36.121531 27891 solver.cpp:238]     Train net output #6: loss15 = 534.308 (* 1 = 534.308 loss)
I0726 16:20:36.121537 27891 solver.cpp:238]     Train net output #7: loss16 = 528.597 (* 1 = 528.597 loss)
I0726 16:20:36.121542 27891 solver.cpp:238]     Train net output #8: loss17 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121547 27891 solver.cpp:238]     Train net output #9: loss18 = 538.551 (* 1 = 538.551 loss)
I0726 16:20:36.121554 27891 solver.cpp:238]     Train net output #10: loss19 = 526.22 (* 1 = 526.22 loss)
I0726 16:20:36.121563 27891 solver.cpp:238]     Train net output #11: loss2 = 535.137 (* 1 = 535.137 loss)
I0726 16:20:36.121570 27891 solver.cpp:238]     Train net output #12: loss20 = 554.668 (* 1 = 554.668 loss)
I0726 16:20:36.121577 27891 solver.cpp:238]     Train net output #13: loss21 = 535.206 (* 1 = 535.206 loss)
I0726 16:20:36.121582 27891 solver.cpp:238]     Train net output #14: loss22 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121588 27891 solver.cpp:238]     Train net output #15: loss23 = 534.837 (* 1 = 534.837 loss)
I0726 16:20:36.121595 27891 solver.cpp:238]     Train net output #16: loss24 = 526.911 (* 1 = 526.911 loss)
I0726 16:20:36.121600 27891 solver.cpp:238]     Train net output #17: loss25 = 552.257 (* 1 = 552.257 loss)
I0726 16:20:36.121606 27891 solver.cpp:238]     Train net output #18: loss26 = 528.57 (* 1 = 528.57 loss)
I0726 16:20:36.121613 27891 solver.cpp:238]     Train net output #19: loss27 = 525.031 (* 1 = 525.031 loss)
I0726 16:20:36.121618 27891 solver.cpp:238]     Train net output #20: loss28 = 531.497 (* 1 = 531.497 loss)
I0726 16:20:36.121624 27891 solver.cpp:238]     Train net output #21: loss29 = 546.242 (* 1 = 546.242 loss)
I0726 16:20:36.121631 27891 solver.cpp:238]     Train net output #22: loss3 = 541.151 (* 1 = 541.151 loss)
I0726 16:20:36.121637 27891 solver.cpp:238]     Train net output #23: loss30 = 526.38 (* 1 = 526.38 loss)
I0726 16:20:36.121642 27891 solver.cpp:238]     Train net output #24: loss31 = 519.979 (* 1 = 519.979 loss)
I0726 16:20:36.121649 27891 solver.cpp:238]     Train net output #25: loss32 = 541.54 (* 1 = 541.54 loss)
I0726 16:20:36.121655 27891 solver.cpp:238]     Train net output #26: loss33 = 550.921 (* 1 = 550.921 loss)
I0726 16:20:36.121660 27891 solver.cpp:238]     Train net output #27: loss34 = 538.202 (* 1 = 538.202 loss)
I0726 16:20:36.121666 27891 solver.cpp:238]     Train net output #28: loss35 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121672 27891 solver.cpp:238]     Train net output #29: loss36 = 530.081 (* 1 = 530.081 loss)
I0726 16:20:36.121712 27891 solver.cpp:238]     Train net output #30: loss37 = 526.987 (* 1 = 526.987 loss)
I0726 16:20:36.121722 27891 solver.cpp:238]     Train net output #31: loss38 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121729 27891 solver.cpp:238]     Train net output #32: loss39 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121737 27891 solver.cpp:238]     Train net output #33: loss4 = 530.297 (* 1 = 530.297 loss)
I0726 16:20:36.121742 27891 solver.cpp:238]     Train net output #34: loss40 = 514.629 (* 1 = 514.629 loss)
I0726 16:20:36.121748 27891 solver.cpp:238]     Train net output #35: loss41 = 542.336 (* 1 = 542.336 loss)
I0726 16:20:36.121754 27891 solver.cpp:238]     Train net output #36: loss42 = 534.636 (* 1 = 534.636 loss)
I0726 16:20:36.121760 27891 solver.cpp:238]     Train net output #37: loss43 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121767 27891 solver.cpp:238]     Train net output #38: loss44 = 536.309 (* 1 = 536.309 loss)
I0726 16:20:36.121773 27891 solver.cpp:238]     Train net output #39: loss45 = 532.566 (* 1 = 532.566 loss)
I0726 16:20:36.121778 27891 solver.cpp:238]     Train net output #40: loss46 = 531.86 (* 1 = 531.86 loss)
I0726 16:20:36.121784 27891 solver.cpp:238]     Train net output #41: loss47 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121789 27891 solver.cpp:238]     Train net output #42: loss48 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121795 27891 solver.cpp:238]     Train net output #43: loss49 = 544.112 (* 1 = 544.112 loss)
I0726 16:20:36.121801 27891 solver.cpp:238]     Train net output #44: loss5 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121807 27891 solver.cpp:238]     Train net output #45: loss50 = 538.585 (* 1 = 538.585 loss)
I0726 16:20:36.121814 27891 solver.cpp:238]     Train net output #46: loss51 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121819 27891 solver.cpp:238]     Train net output #47: loss52 = 532.343 (* 1 = 532.343 loss)
I0726 16:20:36.121825 27891 solver.cpp:238]     Train net output #48: loss53 = 527.173 (* 1 = 527.173 loss)
I0726 16:20:36.121831 27891 solver.cpp:238]     Train net output #49: loss54 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121837 27891 solver.cpp:238]     Train net output #50: loss55 = 528.055 (* 1 = 528.055 loss)
I0726 16:20:36.121843 27891 solver.cpp:238]     Train net output #51: loss56 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121848 27891 solver.cpp:238]     Train net output #52: loss57 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121855 27891 solver.cpp:238]     Train net output #53: loss58 = 543.803 (* 1 = 543.803 loss)
I0726 16:20:36.121861 27891 solver.cpp:238]     Train net output #54: loss59 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121867 27891 solver.cpp:238]     Train net output #55: loss6 = 532.821 (* 1 = 532.821 loss)
I0726 16:20:36.121872 27891 solver.cpp:238]     Train net output #56: loss60 = 548.039 (* 1 = 548.039 loss)
I0726 16:20:36.121878 27891 solver.cpp:238]     Train net output #57: loss61 = 525.93 (* 1 = 525.93 loss)
I0726 16:20:36.121884 27891 solver.cpp:238]     Train net output #58: loss62 = 526.609 (* 1 = 526.609 loss)
I0726 16:20:36.121891 27891 solver.cpp:238]     Train net output #59: loss63 = 540.124 (* 1 = 540.124 loss)
I0726 16:20:36.121896 27891 solver.cpp:238]     Train net output #60: loss64 = 535.486 (* 1 = 535.486 loss)
I0726 16:20:36.121902 27891 solver.cpp:238]     Train net output #61: loss7 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121908 27891 solver.cpp:238]     Train net output #62: loss8 = 531.361 (* 1 = 531.361 loss)
I0726 16:20:36.121914 27891 solver.cpp:238]     Train net output #63: loss9 = 520.091 (* 1 = 520.091 loss)
I0726 16:20:36.121920 27891 sgd_solver.cpp:105] Iteration 226800, lr = 1e-09
I0726 16:29:39.481701 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:29:39.484935 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:29:39.874210 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_232200.caffemodel
I0726 16:29:40.118507 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_232200.solverstate
I0726 16:29:40.201813 27891 solver.cpp:331] Iteration 232200, Testing net (#0)
I0726 16:29:55.414786 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:29:55.536875 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:29:55.880059 27891 solver.cpp:398]     Test net output #0: mae = 75.3286 (* 1 = 75.3286 loss)
I0726 16:29:55.880082 27891 solver.cpp:398]     Test net output #1: mse = 12867.4 (* 1 = 12867.4 loss)
I0726 16:29:56.004541 27891 solver.cpp:219] Iteration 232200 (9.64503 iter/s, 559.874s/5400 iters), loss = 34035.4
I0726 16:29:56.004575 27891 solver.cpp:238]     Train net output #0: loss1 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004583 27891 solver.cpp:238]     Train net output #1: loss10 = 530.697 (* 1 = 530.697 loss)
I0726 16:29:56.004590 27891 solver.cpp:238]     Train net output #2: loss11 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004596 27891 solver.cpp:238]     Train net output #3: loss12 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004602 27891 solver.cpp:238]     Train net output #4: loss13 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004608 27891 solver.cpp:238]     Train net output #5: loss14 = 526.353 (* 1 = 526.353 loss)
I0726 16:29:56.004614 27891 solver.cpp:238]     Train net output #6: loss15 = 535.607 (* 1 = 535.607 loss)
I0726 16:29:56.004619 27891 solver.cpp:238]     Train net output #7: loss16 = 529.495 (* 1 = 529.495 loss)
I0726 16:29:56.004626 27891 solver.cpp:238]     Train net output #8: loss17 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004631 27891 solver.cpp:238]     Train net output #9: loss18 = 539.941 (* 1 = 539.941 loss)
I0726 16:29:56.004637 27891 solver.cpp:238]     Train net output #10: loss19 = 527.432 (* 1 = 527.432 loss)
I0726 16:29:56.004643 27891 solver.cpp:238]     Train net output #11: loss2 = 536.496 (* 1 = 536.496 loss)
I0726 16:29:56.004649 27891 solver.cpp:238]     Train net output #12: loss20 = 556.046 (* 1 = 556.046 loss)
I0726 16:29:56.004655 27891 solver.cpp:238]     Train net output #13: loss21 = 536.833 (* 1 = 536.833 loss)
I0726 16:29:56.004662 27891 solver.cpp:238]     Train net output #14: loss22 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004667 27891 solver.cpp:238]     Train net output #15: loss23 = 536.437 (* 1 = 536.437 loss)
I0726 16:29:56.004673 27891 solver.cpp:238]     Train net output #16: loss24 = 528.342 (* 1 = 528.342 loss)
I0726 16:29:56.004679 27891 solver.cpp:238]     Train net output #17: loss25 = 553.721 (* 1 = 553.721 loss)
I0726 16:29:56.004686 27891 solver.cpp:238]     Train net output #18: loss26 = 530.05 (* 1 = 530.05 loss)
I0726 16:29:56.004691 27891 solver.cpp:238]     Train net output #19: loss27 = 526.671 (* 1 = 526.671 loss)
I0726 16:29:56.004698 27891 solver.cpp:238]     Train net output #20: loss28 = 532.942 (* 1 = 532.942 loss)
I0726 16:29:56.004704 27891 solver.cpp:238]     Train net output #21: loss29 = 547.647 (* 1 = 547.647 loss)
I0726 16:29:56.004710 27891 solver.cpp:238]     Train net output #22: loss3 = 542.746 (* 1 = 542.746 loss)
I0726 16:29:56.004716 27891 solver.cpp:238]     Train net output #23: loss30 = 527.674 (* 1 = 527.674 loss)
I0726 16:29:56.004722 27891 solver.cpp:238]     Train net output #24: loss31 = 521.291 (* 1 = 521.291 loss)
I0726 16:29:56.004729 27891 solver.cpp:238]     Train net output #25: loss32 = 543.206 (* 1 = 543.206 loss)
I0726 16:29:56.004734 27891 solver.cpp:238]     Train net output #26: loss33 = 552.672 (* 1 = 552.672 loss)
I0726 16:29:56.004740 27891 solver.cpp:238]     Train net output #27: loss34 = 539.65 (* 1 = 539.65 loss)
I0726 16:29:56.004746 27891 solver.cpp:238]     Train net output #28: loss35 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004753 27891 solver.cpp:238]     Train net output #29: loss36 = 531.431 (* 1 = 531.431 loss)
I0726 16:29:56.004793 27891 solver.cpp:238]     Train net output #30: loss37 = 528.318 (* 1 = 528.318 loss)
I0726 16:29:56.004801 27891 solver.cpp:238]     Train net output #31: loss38 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004807 27891 solver.cpp:238]     Train net output #32: loss39 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004814 27891 solver.cpp:238]     Train net output #33: loss4 = 531.723 (* 1 = 531.723 loss)
I0726 16:29:56.004820 27891 solver.cpp:238]     Train net output #34: loss40 = 516.044 (* 1 = 516.044 loss)
I0726 16:29:56.004827 27891 solver.cpp:238]     Train net output #35: loss41 = 543.844 (* 1 = 543.844 loss)
I0726 16:29:56.004832 27891 solver.cpp:238]     Train net output #36: loss42 = 536.284 (* 1 = 536.284 loss)
I0726 16:29:56.004839 27891 solver.cpp:238]     Train net output #37: loss43 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004850 27891 solver.cpp:238]     Train net output #38: loss44 = 537.652 (* 1 = 537.652 loss)
I0726 16:29:56.004858 27891 solver.cpp:238]     Train net output #39: loss45 = 534.014 (* 1 = 534.014 loss)
I0726 16:29:56.004863 27891 solver.cpp:238]     Train net output #40: loss46 = 533.326 (* 1 = 533.326 loss)
I0726 16:29:56.004869 27891 solver.cpp:238]     Train net output #41: loss47 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004875 27891 solver.cpp:238]     Train net output #42: loss48 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004881 27891 solver.cpp:238]     Train net output #43: loss49 = 545.482 (* 1 = 545.482 loss)
I0726 16:29:56.004889 27891 solver.cpp:238]     Train net output #44: loss5 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004894 27891 solver.cpp:238]     Train net output #45: loss50 = 540.063 (* 1 = 540.063 loss)
I0726 16:29:56.004900 27891 solver.cpp:238]     Train net output #46: loss51 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004906 27891 solver.cpp:238]     Train net output #47: loss52 = 533.739 (* 1 = 533.739 loss)
I0726 16:29:56.004912 27891 solver.cpp:238]     Train net output #48: loss53 = 528.61 (* 1 = 528.61 loss)
I0726 16:29:56.004918 27891 solver.cpp:238]     Train net output #49: loss54 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004925 27891 solver.cpp:238]     Train net output #50: loss55 = 529.675 (* 1 = 529.675 loss)
I0726 16:29:56.004930 27891 solver.cpp:238]     Train net output #51: loss56 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004936 27891 solver.cpp:238]     Train net output #52: loss57 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004947 27891 solver.cpp:238]     Train net output #53: loss58 = 545.16 (* 1 = 545.16 loss)
I0726 16:29:56.004953 27891 solver.cpp:238]     Train net output #54: loss59 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.004959 27891 solver.cpp:238]     Train net output #55: loss6 = 534.351 (* 1 = 534.351 loss)
I0726 16:29:56.004966 27891 solver.cpp:238]     Train net output #56: loss60 = 549.673 (* 1 = 549.673 loss)
I0726 16:29:56.004971 27891 solver.cpp:238]     Train net output #57: loss61 = 527.372 (* 1 = 527.372 loss)
I0726 16:29:56.004977 27891 solver.cpp:238]     Train net output #58: loss62 = 528.003 (* 1 = 528.003 loss)
I0726 16:29:56.004983 27891 solver.cpp:238]     Train net output #59: loss63 = 541.472 (* 1 = 541.472 loss)
I0726 16:29:56.004989 27891 solver.cpp:238]     Train net output #60: loss64 = 537.145 (* 1 = 537.145 loss)
I0726 16:29:56.004995 27891 solver.cpp:238]     Train net output #61: loss7 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.005002 27891 solver.cpp:238]     Train net output #62: loss8 = 532.698 (* 1 = 532.698 loss)
I0726 16:29:56.005007 27891 solver.cpp:238]     Train net output #63: loss9 = 521.403 (* 1 = 521.403 loss)
I0726 16:29:56.005014 27891 sgd_solver.cpp:105] Iteration 232200, lr = 1e-09
I0726 16:39:03.367456 27898 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:39:03.367455 27897 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:39:03.751456 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_237600.caffemodel
I0726 16:39:04.721801 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_237600.solverstate
I0726 16:39:05.144212 27891 solver.cpp:331] Iteration 237600, Testing net (#0)
I0726 16:39:20.570201 27921 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:39:20.660497 27920 data_layer.cpp:73] Restarting data prefetching from start.
I0726 16:39:21.036321 27891 solver.cpp:398]     Test net output #0: mae = 75.6168 (* 1 = 75.6168 loss)
I0726 16:39:21.036650 27891 solver.cpp:398]     Test net output #1: mse = 12795.8 (* 1 = 12795.8 loss)
I0726 16:39:21.161064 27891 solver.cpp:219] Iteration 237600 (9.55514 iter/s, 565.141s/5400 iters), loss = 34201.2
I0726 16:39:21.161125 27891 solver.cpp:238]     Train net output #0: loss1 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161139 27891 solver.cpp:238]     Train net output #1: loss10 = 533.24 (* 1 = 533.24 loss)
I0726 16:39:21.161150 27891 solver.cpp:238]     Train net output #2: loss11 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161160 27891 solver.cpp:238]     Train net output #3: loss12 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161172 27891 solver.cpp:238]     Train net output #4: loss13 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161185 27891 solver.cpp:238]     Train net output #5: loss14 = 529.156 (* 1 = 529.156 loss)
I0726 16:39:21.161195 27891 solver.cpp:238]     Train net output #6: loss15 = 538.221 (* 1 = 538.221 loss)
I0726 16:39:21.161204 27891 solver.cpp:238]     Train net output #7: loss16 = 531.546 (* 1 = 531.546 loss)
I0726 16:39:21.161213 27891 solver.cpp:238]     Train net output #8: loss17 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161223 27891 solver.cpp:238]     Train net output #9: loss18 = 542.68 (* 1 = 542.68 loss)
I0726 16:39:21.161233 27891 solver.cpp:238]     Train net output #10: loss19 = 529.89 (* 1 = 529.89 loss)
I0726 16:39:21.161242 27891 solver.cpp:238]     Train net output #11: loss2 = 539.081 (* 1 = 539.081 loss)
I0726 16:39:21.161252 27891 solver.cpp:238]     Train net output #12: loss20 = 558.812 (* 1 = 558.812 loss)
I0726 16:39:21.161260 27891 solver.cpp:238]     Train net output #13: loss21 = 539.717 (* 1 = 539.717 loss)
I0726 16:39:21.161270 27891 solver.cpp:238]     Train net output #14: loss22 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161279 27891 solver.cpp:238]     Train net output #15: loss23 = 539.316 (* 1 = 539.316 loss)
I0726 16:39:21.161288 27891 solver.cpp:238]     Train net output #16: loss24 = 530.958 (* 1 = 530.958 loss)
I0726 16:39:21.161298 27891 solver.cpp:238]     Train net output #17: loss25 = 556.619 (* 1 = 556.619 loss)
I0726 16:39:21.161311 27891 solver.cpp:238]     Train net output #18: loss26 = 532.79 (* 1 = 532.79 loss)
I0726 16:39:21.161321 27891 solver.cpp:238]     Train net output #19: loss27 = 529.365 (* 1 = 529.365 loss)
I0726 16:39:21.161331 27891 solver.cpp:238]     Train net output #20: loss28 = 535.747 (* 1 = 535.747 loss)
I0726 16:39:21.161340 27891 solver.cpp:238]     Train net output #21: loss29 = 550.41 (* 1 = 550.41 loss)
I0726 16:39:21.161350 27891 solver.cpp:238]     Train net output #22: loss3 = 545.612 (* 1 = 545.612 loss)
I0726 16:39:21.161358 27891 solver.cpp:238]     Train net output #23: loss30 = 530.144 (* 1 = 530.144 loss)
I0726 16:39:21.161367 27891 solver.cpp:238]     Train net output #24: loss31 = 523.718 (* 1 = 523.718 loss)
I0726 16:39:21.161377 27891 solver.cpp:238]     Train net output #25: loss32 = 546.093 (* 1 = 546.093 loss)
I0726 16:39:21.161386 27891 solver.cpp:238]     Train net output #26: loss33 = 555.79 (* 1 = 555.79 loss)
I0726 16:39:21.161398 27891 solver.cpp:238]     Train net output #27: loss34 = 542.318 (* 1 = 542.318 loss)
I0726 16:39:21.161408 27891 solver.cpp:238]     Train net output #28: loss35 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.161417 27891 solver.cpp:238]     Train net output #29: loss36 = 534.009 (* 1 = 534.009 loss)
I0726 16:39:21.203488 27891 solver.cpp:238]     Train net output #30: loss37 = 530.88 (* 1 = 530.88 loss)
I0726 16:39:21.203505 27891 solver.cpp:238]     Train net output #31: loss38 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203510 27891 solver.cpp:238]     Train net output #32: loss39 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203517 27891 solver.cpp:238]     Train net output #33: loss4 = 534.315 (* 1 = 534.315 loss)
I0726 16:39:21.203523 27891 solver.cpp:238]     Train net output #34: loss40 = 518.584 (* 1 = 518.584 loss)
I0726 16:39:21.203529 27891 solver.cpp:238]     Train net output #35: loss41 = 546.483 (* 1 = 546.483 loss)
I0726 16:39:21.203536 27891 solver.cpp:238]     Train net output #36: loss42 = 539.194 (* 1 = 539.194 loss)
I0726 16:39:21.203541 27891 solver.cpp:238]     Train net output #37: loss43 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203547 27891 solver.cpp:238]     Train net output #38: loss44 = 540.285 (* 1 = 540.285 loss)
I0726 16:39:21.203553 27891 solver.cpp:238]     Train net output #39: loss45 = 536.774 (* 1 = 536.774 loss)
I0726 16:39:21.203559 27891 solver.cpp:238]     Train net output #40: loss46 = 536.081 (* 1 = 536.081 loss)
I0726 16:39:21.203565 27891 solver.cpp:238]     Train net output #41: loss47 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203572 27891 solver.cpp:238]     Train net output #42: loss48 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203577 27891 solver.cpp:238]     Train net output #43: loss49 = 548.282 (* 1 = 548.282 loss)
I0726 16:39:21.203583 27891 solver.cpp:238]     Train net output #44: loss5 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203589 27891 solver.cpp:238]     Train net output #45: loss50 = 542.913 (* 1 = 542.913 loss)
I0726 16:39:21.203595 27891 solver.cpp:238]     Train net output #46: loss51 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203601 27891 solver.cpp:238]     Train net output #47: loss52 = 536.442 (* 1 = 536.442 loss)
I0726 16:39:21.203608 27891 solver.cpp:238]     Train net output #48: loss53 = 531.2 (* 1 = 531.2 loss)
I0726 16:39:21.203615 27891 solver.cpp:238]     Train net output #49: loss54 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203621 27891 solver.cpp:238]     Train net output #50: loss55 = 532.245 (* 1 = 532.245 loss)
I0726 16:39:21.203629 27891 solver.cpp:238]     Train net output #51: loss56 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203635 27891 solver.cpp:238]     Train net output #52: loss57 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203641 27891 solver.cpp:238]     Train net output #53: loss58 = 547.805 (* 1 = 547.805 loss)
I0726 16:39:21.203647 27891 solver.cpp:238]     Train net output #54: loss59 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203654 27891 solver.cpp:238]     Train net output #55: loss6 = 537.005 (* 1 = 537.005 loss)
I0726 16:39:21.203660 27891 solver.cpp:238]     Train net output #56: loss60 = 552.524 (* 1 = 552.524 loss)
I0726 16:39:21.203665 27891 solver.cpp:238]     Train net output #57: loss61 = 530.086 (* 1 = 530.086 loss)
I0726 16:39:21.203671 27891 solver.cpp:238]     Train net output #58: loss62 = 530.63 (* 1 = 530.63 loss)
I0726 16:39:21.203677 27891 solver.cpp:238]     Train net output #59: loss63 = 544.226 (* 1 = 544.226 loss)
I0726 16:39:21.203683 27891 solver.cpp:238]     Train net output #60: loss64 = 540.052 (* 1 = 540.052 loss)
I0726 16:39:21.203689 27891 solver.cpp:238]     Train net output #61: loss7 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203696 27891 solver.cpp:238]     Train net output #62: loss8 = 535.348 (* 1 = 535.348 loss)
I0726 16:39:21.203701 27891 solver.cpp:238]     Train net output #63: loss9 = 523.839 (* 1 = 523.839 loss)
I0726 16:39:21.203709 27891 sgd_solver.cpp:105] Iteration 237600, lr = 1e-09
I0726 16:41:01.244138 27891 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_238618.caffemodel
I0726 16:41:02.478412 27891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1_iter_238618.solverstate
I0726 16:41:02.904729 27891 solver.cpp:295] Optimization stopped early.
I0726 16:41:02.907222 27891 caffe.cpp:259] Optimization Done.
