Log file created at: 2017/07/28 09:57:19
Running on machine: peiyong-All-Series
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0728 09:57:19.482625 20134 caffe.cpp:218] Using GPUs 1
I0728 09:57:19.556025 20134 caffe.cpp:223] GPU 1: GeForce GTX TITAN X
I0728 09:57:20.090694 20134 solver.cpp:44] Initializing solver from parameters: 
test_iter: 182
test_interval: 5400
base_lr: 1e-09
display: 5400
max_iter: 2160000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2160000
snapshot: 5400
snapshot_prefix: "examples/crowd/code/shanghaiA/model/network_vgg_1.01"
solver_mode: GPU
device_id: 1
net: "examples/crowd/code/shanghaiA/network_vgg_v1.prototxt"
train_state {
  level: 0
  stage: ""
}
I0728 09:57:20.090864 20134 solver.cpp:87] Creating training net from net file: examples/crowd/code/shanghaiA/network_vgg_v1.prototxt
I0728 09:57:20.091642 20134 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0728 09:57:20.091656 20134 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0728 09:57:20.091681 20134 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer avgscore
I0728 09:57:20.091687 20134 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mae
I0728 09:57:20.091691 20134 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mse
I0728 09:57:20.092130 20134 net.cpp:51] Initializing net from parameters: 
name: "crowd_counting"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/image_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/dmap_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv_score"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv_score"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    group: 64
    stride: 1
    weight_filler {
      type: "constant"
      value: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_score"
  type: "ReLU"
  bottom: "conv_score"
  top: "conv_score"
}
layer {
  name: "slicer_conv"
  type: "Slice"
  bottom: "conv_score"
  top: "score1"
  top: "score2"
  top: "score3"
  top: "score4"
  top: "score5"
  top: "score6"
  top: "score7"
  top: "score8"
  top: "score9"
  top: "score10"
  top: "score11"
  top: "score12"
  top: "score13"
  top: "score14"
  top: "score15"
  top: "score16"
  top: "score17"
  top: "score18"
  top: "score19"
  top: "score20"
  top: "score21"
  top: "score22"
  top: "score23"
  top: "score24"
  top: "score25"
  top: "score26"
  top: "score27"
  top: "score28"
  top: "score29"
  top: "score30"
  top: "score31"
  top: "score32"
  top: "score33"
  top: "score34"
  top: "score35"
  top: "score36"
  top: "score37"
  top: "score38"
  top: "score39"
  top: "score40"
  top: "score41"
  top: "score42"
  top: "score43"
  top: "score44"
  top: "score45"
  top: "score46"
  top: "score47"
  top: "score48"
  top: "score49"
  top: "score50"
  top: "score51"
  top: "score52"
  top: "score53"
  top: "score54"
  top: "score55"
  top: "score56"
  top: "score57"
  top: "score58"
  top: "score59"
  top: "score60"
  top: "score61"
  top: "score62"
  top: "score63"
  top: "score64"
  slice_param {
    axis: 1
  }
}
layer {
  name: "sumscore"
  type: "Eltwise"
  bottom: "score1"
  bottom: "score2"
  bottom: "score3"
  bottom: "score4"
  bottom: "score5"
  bottom: "score6"
  bottom: "score7"
  bottom: "score8"
  bottom: "score9"
  bottom: "score10"
  bottom: "score11"
  bottom: "score12"
  bottom: "score13"
  bottom: "score14"
  bottom: "score15"
  bottom: "score16"
  bottom: "score17"
  bottom: "score18"
  bottom: "score19"
  bottom: "score20"
  bottom: "score21"
  bottom: "score22"
  bottom: "score23"
  bottom: "score24"
  bottom: "score25"
  bottom: "score26"
  bottom: "score27"
  bottom: "score28"
  bottom: "score29"
  bottom: "score30"
  bottom: "score31"
  bottom: "score32"
  bottom: "score33"
  bottom: "score34"
  bottom: "score35"
  bottom: "score36"
  bottom: "score37"
  bottom: "score38"
  bottom: "score39"
  bottom: "score40"
  bottom: "score41"
  bottom: "score42"
  bottom: "score43"
  bottom: "score44"
  bottom: "score45"
  bottom: "score46"
  bottom: "score47"
  bottom: "score48"
  bottom: "score49"
  bottom: "score50"
  bottom: "score51"
  bottom: "score52"
  bottom: "score53"
  bottom: "score54"
  bottom: "score55"
  bottom: "score56"
  bottom: "score57"
  bottom: "score58"
  bottom: "score59"
  bottom: "score60"
  bottom: "score61"
  bottom: "score62"
  bottom: "score63"
  bottom: "score64"
  top: "sumscore"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "loss1"
  type: "NCLLoss"
  bottom: "score1"
  bottom: "label"
  bottom: "sumscore"
  top: "loss1"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss2"
  type: "NCLLoss"
  bottom: "score2"
  bottom: "label"
  bottom: "sumscore"
  top: "loss2"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss3"
  type: "NCLLoss"
  bottom: "score3"
  bottom: "label"
  bottom: "sumscore"
  top: "loss3"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss4"
  type: "NCLLoss"
  bottom: "score4"
  bottom: "label"
  bottom: "sumscore"
  top: "loss4"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss5"
  type: "NCLLoss"
  bottom: "score5"
  bottom: "label"
  bottom: "sumscore"
  top: "loss5"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss6"
  type: "NCLLoss"
  bottom: "score6"
  bottom: "label"
  bottom: "sumscore"
  top: "loss6"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss7"
  type: "NCLLoss"
  bottom: "score7"
  bottom: "label"
  bottom: "sumscore"
  top: "loss7"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss8"
  type: "NCLLoss"
  bottom: "score8"
  bottom: "label"
  bottom: "sumscore"
  top: "loss8"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss9"
  type: "NCLLoss"
  bottom: "score9"
  bottom: "label"
  bottom: "sumscore"
  top: "loss9"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss10"
  type: "NCLLoss"
  bottom: "score10"
  bottom: "label"
  bottom: "sumscore"
  top: "loss10"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss11"
  type: "NCLLoss"
  bottom: "score11"
  bottom: "label"
  bottom: "sumscore"
  top: "loss11"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss12"
  type: "NCLLoss"
  bottom: "score12"
  bottom: "label"
  bottom: "sumscore"
  top: "loss12"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss13"
  type: "NCLLoss"
  bottom: "score13"
  bottom: "label"
  bottom: "sumscore"
  top: "loss13"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss14"
  type: "NCLLoss"
  bottom: "score14"
  bottom: "label"
  bottom: "sumscore"
  top: "loss14"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss15"
  type: "NCLLoss"
  bottom: "score15"
  bottom: "label"
  bottom: "sumscore"
  top: "loss15"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss16"
  type: "NCLLoss"
  bottom: "score16"
  bottom: "label"
  bottom: "sumscore"
  top: "loss16"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss17"
  type: "NCLLoss"
  bottom: "score17"
  bottom: "label"
  bottom: "sumscore"
  top: "loss17"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss18"
  type: "NCLLoss"
  bottom: "score18"
  bottom: "label"
  bottom: "sumscore"
  top: "loss18"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss19"
  type: "NCLLoss"
  bottom: "score19"
  bottom: "label"
  bottom: "sumscore"
  top: "loss19"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss20"
  type: "NCLLoss"
  bottom: "score20"
  bottom: "label"
  bottom: "sumscore"
  top: "loss20"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss21"
  type: "NCLLoss"
  bottom: "score21"
  bottom: "label"
  bottom: "sumscore"
  top: "loss21"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss22"
  type: "NCLLoss"
  bottom: "score22"
  bottom: "label"
  bottom: "sumscore"
  top: "loss22"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss23"
  type: "NCLLoss"
  bottom: "score23"
  bottom: "label"
  bottom: "sumscore"
  top: "loss23"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss24"
  type: "NCLLoss"
  bottom: "score24"
  bottom: "label"
  bottom: "sumscore"
  top: "loss24"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss25"
  type: "NCLLoss"
  bottom: "score25"
  bottom: "label"
  bottom: "sumscore"
  top: "loss25"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss26"
  type: "NCLLoss"
  bottom: "score26"
  bottom: "label"
  bottom: "sumscore"
  top: "loss26"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss27"
  type: "NCLLoss"
  bottom: "score27"
  bottom: "label"
  bottom: "sumscore"
  top: "loss27"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss28"
  type: "NCLLoss"
  bottom: "score28"
  bottom: "label"
  bottom: "sumscore"
  top: "loss28"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss29"
  type: "NCLLoss"
  bottom: "score29"
  bottom: "label"
  bottom: "sumscore"
  top: "loss29"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss30"
  type: "NCLLoss"
  bottom: "score30"
  bottom: "label"
  bottom: "sumscore"
  top: "loss30"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss31"
  type: "NCLLoss"
  bottom: "score31"
  bottom: "label"
  bottom: "sumscore"
  top: "loss31"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss32"
  type: "NCLLoss"
  bottom: "score32"
  bottom: "label"
  bottom: "sumscore"
  top: "loss32"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss33"
  type: "NCLLoss"
  bottom: "score33"
  bottom: "label"
  bottom: "sumscore"
  top: "loss33"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss34"
  type: "NCLLoss"
  bottom: "score34"
  bottom: "label"
  bottom: "sumscore"
  top: "loss34"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss35"
  type: "NCLLoss"
  bottom: "score35"
  bottom: "label"
  bottom: "sumscore"
  top: "loss35"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss36"
  type: "NCLLoss"
  bottom: "score36"
  bottom: "label"
  bottom: "sumscore"
  top: "loss36"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss37"
  type: "NCLLoss"
  bottom: "score37"
  bottom: "label"
  bottom: "sumscore"
  top: "loss37"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss38"
  type: "NCLLoss"
  bottom: "score38"
  bottom: "label"
  bottom: "sumscore"
  top: "loss38"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss39"
  type: "NCLLoss"
  bottom: "score39"
  bottom: "label"
  bottom: "sumscore"
  top: "loss39"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss40"
  type: "NCLLoss"
  bottom: "score40"
  bottom: "label"
  bottom: "sumscore"
  top: "loss40"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss41"
  type: "NCLLoss"
  bottom: "score41"
  bottom: "label"
  bottom: "sumscore"
  top: "loss41"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss42"
  type: "NCLLoss"
  bottom: "score42"
  bottom: "label"
  bottom: "sumscore"
  top: "loss42"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss43"
  type: "NCLLoss"
  bottom: "score43"
  bottom: "label"
  bottom: "sumscore"
  top: "loss43"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss44"
  type: "NCLLoss"
  bottom: "score44"
  bottom: "label"
  bottom: "sumscore"
  top: "loss44"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss45"
  type: "NCLLoss"
  bottom: "score45"
  bottom: "label"
  bottom: "sumscore"
  top: "loss45"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss46"
  type: "NCLLoss"
  bottom: "score46"
  bottom: "label"
  bottom: "sumscore"
  top: "loss46"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss47"
  type: "NCLLoss"
  bottom: "score47"
  bottom: "label"
  bottom: "sumscore"
  top: "loss47"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss48"
  type: "NCLLoss"
  bottom: "score48"
  bottom: "label"
  bottom: "sumscore"
  top: "loss48"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss49"
  type: "NCLLoss"
  bottom: "score49"
  bottom: "label"
  bottom: "sumscore"
  top: "loss49"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss50"
  type: "NCLLoss"
  bottom: "score50"
  bottom: "label"
  bottom: "sumscore"
  top: "loss50"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss51"
  type: "NCLLoss"
  bottom: "score51"
  bottom: "label"
  bottom: "sumscore"
  top: "loss51"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss52"
  type: "NCLLoss"
  bottom: "score52"
  bottom: "label"
  bottom: "sumscore"
  top: "loss52"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss53"
  type: "NCLLoss"
  bottom: "score53"
  bottom: "label"
  bottom: "sumscore"
  top: "loss53"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss54"
  type: "NCLLoss"
  bottom: "score54"
  bottom: "label"
  bottom: "sumscore"
  top: "loss54"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss55"
  type: "NCLLoss"
  bottom: "score55"
  bottom: "label"
  bottom: "sumscore"
  top: "loss55"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss56"
  type: "NCLLoss"
  bottom: "score56"
  bottom: "label"
  bottom: "sumscore"
  top: "loss56"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss57"
  type: "NCLLoss"
  bottom: "score57"
  bottom: "label"
  bottom: "sumscore"
  top: "loss57"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss58"
  type: "NCLLoss"
  bottom: "score58"
  bottom: "label"
  bottom: "sumscore"
  top: "loss58"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss59"
  type: "NCLLoss"
  bottom: "score59"
  bottom: "label"
  bottom: "sumscore"
  top: "loss59"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss60"
  type: "NCLLoss"
  bottom: "score60"
  bottom: "label"
  bottom: "sumscore"
  top: "loss60"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss61"
  type: "NCLLoss"
  bottom: "score61"
  bottom: "label"
  bottom: "sumscore"
  top: "loss61"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss62"
  type: "NCLLoss"
  bottom: "score62"
  bottom: "label"
  bottom: "sumscore"
  top: "loss62"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss63"
  type: "NCLLoss"
  bottom: "score63"
  bottom: "label"
  bottom: "sumscore"
  top: "loss63"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
layer {
  name: "loss64"
  type: "NCLLoss"
  bottom: "score64"
  bottom: "label"
  bottom: "sumscore"
  top: "loss64"
  include {
    phase: TRAIN
  }
  ncl_loss_param {
    lambda: 1.01
    net_num: 64
  }
}
I0728 09:57:20.093828 20134 layer_factory.hpp:77] Creating layer data
I0728 09:57:20.093955 20134 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/image_lmdb
I0728 09:57:20.093993 20134 net.cpp:84] Creating Layer data
I0728 09:57:20.094004 20134 net.cpp:380] data -> data
I0728 09:57:20.095182 20134 data_layer.cpp:45] output data size: 1,3,384,512
I0728 09:57:20.101852 20134 net.cpp:122] Setting up data
I0728 09:57:20.101872 20134 net.cpp:129] Top shape: 1 3 384 512 (589824)
I0728 09:57:20.101877 20134 net.cpp:137] Memory required for data: 2359296
I0728 09:57:20.101887 20134 layer_factory.hpp:77] Creating layer label
I0728 09:57:20.101963 20134 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/train_8/dmap_lmdb
I0728 09:57:20.101984 20134 net.cpp:84] Creating Layer label
I0728 09:57:20.101994 20134 net.cpp:380] label -> label
I0728 09:57:20.102125 20134 data_layer.cpp:45] output data size: 1,1,48,64
I0728 09:57:20.103238 20134 net.cpp:122] Setting up label
I0728 09:57:20.103256 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.103260 20134 net.cpp:137] Memory required for data: 2371584
I0728 09:57:20.103263 20134 layer_factory.hpp:77] Creating layer label_label_0_split
I0728 09:57:20.103279 20134 net.cpp:84] Creating Layer label_label_0_split
I0728 09:57:20.103299 20134 net.cpp:406] label_label_0_split <- label
I0728 09:57:20.103319 20134 net.cpp:380] label_label_0_split -> label_label_0_split_0
I0728 09:57:20.103334 20134 net.cpp:380] label_label_0_split -> label_label_0_split_1
I0728 09:57:20.103348 20134 net.cpp:380] label_label_0_split -> label_label_0_split_2
I0728 09:57:20.103361 20134 net.cpp:380] label_label_0_split -> label_label_0_split_3
I0728 09:57:20.103374 20134 net.cpp:380] label_label_0_split -> label_label_0_split_4
I0728 09:57:20.103394 20134 net.cpp:380] label_label_0_split -> label_label_0_split_5
I0728 09:57:20.103408 20134 net.cpp:380] label_label_0_split -> label_label_0_split_6
I0728 09:57:20.103421 20134 net.cpp:380] label_label_0_split -> label_label_0_split_7
I0728 09:57:20.103435 20134 net.cpp:380] label_label_0_split -> label_label_0_split_8
I0728 09:57:20.103446 20134 net.cpp:380] label_label_0_split -> label_label_0_split_9
I0728 09:57:20.103459 20134 net.cpp:380] label_label_0_split -> label_label_0_split_10
I0728 09:57:20.103472 20134 net.cpp:380] label_label_0_split -> label_label_0_split_11
I0728 09:57:20.103484 20134 net.cpp:380] label_label_0_split -> label_label_0_split_12
I0728 09:57:20.103497 20134 net.cpp:380] label_label_0_split -> label_label_0_split_13
I0728 09:57:20.103518 20134 net.cpp:380] label_label_0_split -> label_label_0_split_14
I0728 09:57:20.103533 20134 net.cpp:380] label_label_0_split -> label_label_0_split_15
I0728 09:57:20.103545 20134 net.cpp:380] label_label_0_split -> label_label_0_split_16
I0728 09:57:20.103559 20134 net.cpp:380] label_label_0_split -> label_label_0_split_17
I0728 09:57:20.103570 20134 net.cpp:380] label_label_0_split -> label_label_0_split_18
I0728 09:57:20.103584 20134 net.cpp:380] label_label_0_split -> label_label_0_split_19
I0728 09:57:20.103596 20134 net.cpp:380] label_label_0_split -> label_label_0_split_20
I0728 09:57:20.103616 20134 net.cpp:380] label_label_0_split -> label_label_0_split_21
I0728 09:57:20.103629 20134 net.cpp:380] label_label_0_split -> label_label_0_split_22
I0728 09:57:20.103642 20134 net.cpp:380] label_label_0_split -> label_label_0_split_23
I0728 09:57:20.103654 20134 net.cpp:380] label_label_0_split -> label_label_0_split_24
I0728 09:57:20.103667 20134 net.cpp:380] label_label_0_split -> label_label_0_split_25
I0728 09:57:20.103706 20134 net.cpp:380] label_label_0_split -> label_label_0_split_26
I0728 09:57:20.103729 20134 net.cpp:380] label_label_0_split -> label_label_0_split_27
I0728 09:57:20.103741 20134 net.cpp:380] label_label_0_split -> label_label_0_split_28
I0728 09:57:20.103754 20134 net.cpp:380] label_label_0_split -> label_label_0_split_29
I0728 09:57:20.103766 20134 net.cpp:380] label_label_0_split -> label_label_0_split_30
I0728 09:57:20.103782 20134 net.cpp:380] label_label_0_split -> label_label_0_split_31
I0728 09:57:20.103796 20134 net.cpp:380] label_label_0_split -> label_label_0_split_32
I0728 09:57:20.103808 20134 net.cpp:380] label_label_0_split -> label_label_0_split_33
I0728 09:57:20.103821 20134 net.cpp:380] label_label_0_split -> label_label_0_split_34
I0728 09:57:20.103833 20134 net.cpp:380] label_label_0_split -> label_label_0_split_35
I0728 09:57:20.103845 20134 net.cpp:380] label_label_0_split -> label_label_0_split_36
I0728 09:57:20.103866 20134 net.cpp:380] label_label_0_split -> label_label_0_split_37
I0728 09:57:20.103878 20134 net.cpp:380] label_label_0_split -> label_label_0_split_38
I0728 09:57:20.103890 20134 net.cpp:380] label_label_0_split -> label_label_0_split_39
I0728 09:57:20.103902 20134 net.cpp:380] label_label_0_split -> label_label_0_split_40
I0728 09:57:20.103914 20134 net.cpp:380] label_label_0_split -> label_label_0_split_41
I0728 09:57:20.103926 20134 net.cpp:380] label_label_0_split -> label_label_0_split_42
I0728 09:57:20.103938 20134 net.cpp:380] label_label_0_split -> label_label_0_split_43
I0728 09:57:20.103951 20134 net.cpp:380] label_label_0_split -> label_label_0_split_44
I0728 09:57:20.103963 20134 net.cpp:380] label_label_0_split -> label_label_0_split_45
I0728 09:57:20.103976 20134 net.cpp:380] label_label_0_split -> label_label_0_split_46
I0728 09:57:20.103987 20134 net.cpp:380] label_label_0_split -> label_label_0_split_47
I0728 09:57:20.103998 20134 net.cpp:380] label_label_0_split -> label_label_0_split_48
I0728 09:57:20.104010 20134 net.cpp:380] label_label_0_split -> label_label_0_split_49
I0728 09:57:20.104022 20134 net.cpp:380] label_label_0_split -> label_label_0_split_50
I0728 09:57:20.104035 20134 net.cpp:380] label_label_0_split -> label_label_0_split_51
I0728 09:57:20.104048 20134 net.cpp:380] label_label_0_split -> label_label_0_split_52
I0728 09:57:20.104059 20134 net.cpp:380] label_label_0_split -> label_label_0_split_53
I0728 09:57:20.104071 20134 net.cpp:380] label_label_0_split -> label_label_0_split_54
I0728 09:57:20.104084 20134 net.cpp:380] label_label_0_split -> label_label_0_split_55
I0728 09:57:20.104096 20134 net.cpp:380] label_label_0_split -> label_label_0_split_56
I0728 09:57:20.104109 20134 net.cpp:380] label_label_0_split -> label_label_0_split_57
I0728 09:57:20.104120 20134 net.cpp:380] label_label_0_split -> label_label_0_split_58
I0728 09:57:20.104132 20134 net.cpp:380] label_label_0_split -> label_label_0_split_59
I0728 09:57:20.104145 20134 net.cpp:380] label_label_0_split -> label_label_0_split_60
I0728 09:57:20.104157 20134 net.cpp:380] label_label_0_split -> label_label_0_split_61
I0728 09:57:20.104169 20134 net.cpp:380] label_label_0_split -> label_label_0_split_62
I0728 09:57:20.104188 20134 net.cpp:380] label_label_0_split -> label_label_0_split_63
I0728 09:57:20.104861 20134 net.cpp:122] Setting up label_label_0_split
I0728 09:57:20.104873 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104879 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104887 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104890 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104895 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104900 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104905 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104910 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104915 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104920 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104925 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104941 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104948 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104953 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104957 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104962 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104966 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104971 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104976 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104981 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104985 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104990 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.104995 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105000 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105005 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105010 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105015 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105018 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105023 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105028 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105033 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105038 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105043 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105048 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105053 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105057 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105062 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105067 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105072 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105077 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105082 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105087 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105092 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105096 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105101 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105105 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105110 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105115 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105120 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105125 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105130 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105134 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105139 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105144 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105149 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105154 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105159 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105164 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105168 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105172 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105177 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105182 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105187 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105192 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.105196 20134 net.cpp:137] Memory required for data: 3158016
I0728 09:57:20.105201 20134 layer_factory.hpp:77] Creating layer conv1_1
I0728 09:57:20.105218 20134 net.cpp:84] Creating Layer conv1_1
I0728 09:57:20.105223 20134 net.cpp:406] conv1_1 <- data
I0728 09:57:20.105232 20134 net.cpp:380] conv1_1 -> conv1_1
I0728 09:57:20.525281 20134 net.cpp:122] Setting up conv1_1
I0728 09:57:20.525362 20134 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0728 09:57:20.525372 20134 net.cpp:137] Memory required for data: 53489664
I0728 09:57:20.525399 20134 layer_factory.hpp:77] Creating layer relu1_1
I0728 09:57:20.525414 20134 net.cpp:84] Creating Layer relu1_1
I0728 09:57:20.525421 20134 net.cpp:406] relu1_1 <- conv1_1
I0728 09:57:20.525429 20134 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0728 09:57:20.525595 20134 net.cpp:122] Setting up relu1_1
I0728 09:57:20.525609 20134 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0728 09:57:20.525612 20134 net.cpp:137] Memory required for data: 103821312
I0728 09:57:20.525617 20134 layer_factory.hpp:77] Creating layer conv1_2
I0728 09:57:20.525631 20134 net.cpp:84] Creating Layer conv1_2
I0728 09:57:20.525637 20134 net.cpp:406] conv1_2 <- conv1_1
I0728 09:57:20.525645 20134 net.cpp:380] conv1_2 -> conv1_2
I0728 09:57:20.528774 20134 net.cpp:122] Setting up conv1_2
I0728 09:57:20.528790 20134 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0728 09:57:20.528794 20134 net.cpp:137] Memory required for data: 154152960
I0728 09:57:20.528802 20134 layer_factory.hpp:77] Creating layer relu1_2
I0728 09:57:20.528808 20134 net.cpp:84] Creating Layer relu1_2
I0728 09:57:20.528811 20134 net.cpp:406] relu1_2 <- conv1_2
I0728 09:57:20.528818 20134 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0728 09:57:20.528970 20134 net.cpp:122] Setting up relu1_2
I0728 09:57:20.528982 20134 net.cpp:129] Top shape: 1 64 384 512 (12582912)
I0728 09:57:20.528987 20134 net.cpp:137] Memory required for data: 204484608
I0728 09:57:20.528990 20134 layer_factory.hpp:77] Creating layer pool1
I0728 09:57:20.528998 20134 net.cpp:84] Creating Layer pool1
I0728 09:57:20.529002 20134 net.cpp:406] pool1 <- conv1_2
I0728 09:57:20.529008 20134 net.cpp:380] pool1 -> pool1
I0728 09:57:20.529062 20134 net.cpp:122] Setting up pool1
I0728 09:57:20.529072 20134 net.cpp:129] Top shape: 1 64 192 256 (3145728)
I0728 09:57:20.529075 20134 net.cpp:137] Memory required for data: 217067520
I0728 09:57:20.529080 20134 layer_factory.hpp:77] Creating layer conv2_1
I0728 09:57:20.529091 20134 net.cpp:84] Creating Layer conv2_1
I0728 09:57:20.529098 20134 net.cpp:406] conv2_1 <- pool1
I0728 09:57:20.529104 20134 net.cpp:380] conv2_1 -> conv2_1
I0728 09:57:20.532009 20134 net.cpp:122] Setting up conv2_1
I0728 09:57:20.532027 20134 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0728 09:57:20.532032 20134 net.cpp:137] Memory required for data: 242233344
I0728 09:57:20.532042 20134 layer_factory.hpp:77] Creating layer relu2_1
I0728 09:57:20.532050 20134 net.cpp:84] Creating Layer relu2_1
I0728 09:57:20.532055 20134 net.cpp:406] relu2_1 <- conv2_1
I0728 09:57:20.532061 20134 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0728 09:57:20.532629 20134 net.cpp:122] Setting up relu2_1
I0728 09:57:20.532644 20134 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0728 09:57:20.532649 20134 net.cpp:137] Memory required for data: 267399168
I0728 09:57:20.532655 20134 layer_factory.hpp:77] Creating layer conv2_2
I0728 09:57:20.532666 20134 net.cpp:84] Creating Layer conv2_2
I0728 09:57:20.532672 20134 net.cpp:406] conv2_2 <- conv2_1
I0728 09:57:20.532680 20134 net.cpp:380] conv2_2 -> conv2_2
I0728 09:57:20.535802 20134 net.cpp:122] Setting up conv2_2
I0728 09:57:20.535820 20134 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0728 09:57:20.535825 20134 net.cpp:137] Memory required for data: 292564992
I0728 09:57:20.535833 20134 layer_factory.hpp:77] Creating layer relu2_2
I0728 09:57:20.535840 20134 net.cpp:84] Creating Layer relu2_2
I0728 09:57:20.535845 20134 net.cpp:406] relu2_2 <- conv2_2
I0728 09:57:20.535851 20134 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0728 09:57:20.536015 20134 net.cpp:122] Setting up relu2_2
I0728 09:57:20.536027 20134 net.cpp:129] Top shape: 1 128 192 256 (6291456)
I0728 09:57:20.536031 20134 net.cpp:137] Memory required for data: 317730816
I0728 09:57:20.536036 20134 layer_factory.hpp:77] Creating layer pool2
I0728 09:57:20.536044 20134 net.cpp:84] Creating Layer pool2
I0728 09:57:20.536049 20134 net.cpp:406] pool2 <- conv2_2
I0728 09:57:20.536088 20134 net.cpp:380] pool2 -> pool2
I0728 09:57:20.536139 20134 net.cpp:122] Setting up pool2
I0728 09:57:20.536147 20134 net.cpp:129] Top shape: 1 128 96 128 (1572864)
I0728 09:57:20.536152 20134 net.cpp:137] Memory required for data: 324022272
I0728 09:57:20.536157 20134 layer_factory.hpp:77] Creating layer conv3_1
I0728 09:57:20.536167 20134 net.cpp:84] Creating Layer conv3_1
I0728 09:57:20.536172 20134 net.cpp:406] conv3_1 <- pool2
I0728 09:57:20.536180 20134 net.cpp:380] conv3_1 -> conv3_1
I0728 09:57:20.541395 20134 net.cpp:122] Setting up conv3_1
I0728 09:57:20.541411 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.541416 20134 net.cpp:137] Memory required for data: 336605184
I0728 09:57:20.541427 20134 layer_factory.hpp:77] Creating layer relu3_1
I0728 09:57:20.541437 20134 net.cpp:84] Creating Layer relu3_1
I0728 09:57:20.541442 20134 net.cpp:406] relu3_1 <- conv3_1
I0728 09:57:20.541448 20134 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0728 09:57:20.541620 20134 net.cpp:122] Setting up relu3_1
I0728 09:57:20.541631 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.541636 20134 net.cpp:137] Memory required for data: 349188096
I0728 09:57:20.541641 20134 layer_factory.hpp:77] Creating layer conv3_2
I0728 09:57:20.541652 20134 net.cpp:84] Creating Layer conv3_2
I0728 09:57:20.541658 20134 net.cpp:406] conv3_2 <- conv3_1
I0728 09:57:20.541666 20134 net.cpp:380] conv3_2 -> conv3_2
I0728 09:57:20.549095 20134 net.cpp:122] Setting up conv3_2
I0728 09:57:20.549110 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.549116 20134 net.cpp:137] Memory required for data: 361771008
I0728 09:57:20.549124 20134 layer_factory.hpp:77] Creating layer relu3_2
I0728 09:57:20.549135 20134 net.cpp:84] Creating Layer relu3_2
I0728 09:57:20.549140 20134 net.cpp:406] relu3_2 <- conv3_2
I0728 09:57:20.549147 20134 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0728 09:57:20.549718 20134 net.cpp:122] Setting up relu3_2
I0728 09:57:20.549732 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.549736 20134 net.cpp:137] Memory required for data: 374353920
I0728 09:57:20.549739 20134 layer_factory.hpp:77] Creating layer conv3_3
I0728 09:57:20.549754 20134 net.cpp:84] Creating Layer conv3_3
I0728 09:57:20.549760 20134 net.cpp:406] conv3_3 <- conv3_2
I0728 09:57:20.549767 20134 net.cpp:380] conv3_3 -> conv3_3
I0728 09:57:20.557165 20134 net.cpp:122] Setting up conv3_3
I0728 09:57:20.557186 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.557191 20134 net.cpp:137] Memory required for data: 386936832
I0728 09:57:20.557200 20134 layer_factory.hpp:77] Creating layer relu3_3
I0728 09:57:20.557207 20134 net.cpp:84] Creating Layer relu3_3
I0728 09:57:20.557212 20134 net.cpp:406] relu3_3 <- conv3_3
I0728 09:57:20.557219 20134 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0728 09:57:20.557397 20134 net.cpp:122] Setting up relu3_3
I0728 09:57:20.557410 20134 net.cpp:129] Top shape: 1 256 96 128 (3145728)
I0728 09:57:20.557413 20134 net.cpp:137] Memory required for data: 399519744
I0728 09:57:20.557418 20134 layer_factory.hpp:77] Creating layer pool3
I0728 09:57:20.557425 20134 net.cpp:84] Creating Layer pool3
I0728 09:57:20.557430 20134 net.cpp:406] pool3 <- conv3_3
I0728 09:57:20.557438 20134 net.cpp:380] pool3 -> pool3
I0728 09:57:20.557485 20134 net.cpp:122] Setting up pool3
I0728 09:57:20.557493 20134 net.cpp:129] Top shape: 1 256 48 64 (786432)
I0728 09:57:20.557497 20134 net.cpp:137] Memory required for data: 402665472
I0728 09:57:20.557502 20134 layer_factory.hpp:77] Creating layer conv4_1
I0728 09:57:20.557513 20134 net.cpp:84] Creating Layer conv4_1
I0728 09:57:20.557518 20134 net.cpp:406] conv4_1 <- pool3
I0728 09:57:20.557524 20134 net.cpp:380] conv4_1 -> conv4_1
I0728 09:57:20.571166 20134 net.cpp:122] Setting up conv4_1
I0728 09:57:20.571197 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.571202 20134 net.cpp:137] Memory required for data: 408956928
I0728 09:57:20.571213 20134 layer_factory.hpp:77] Creating layer relu4_1
I0728 09:57:20.571252 20134 net.cpp:84] Creating Layer relu4_1
I0728 09:57:20.571259 20134 net.cpp:406] relu4_1 <- conv4_1
I0728 09:57:20.571266 20134 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0728 09:57:20.571434 20134 net.cpp:122] Setting up relu4_1
I0728 09:57:20.571445 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.571449 20134 net.cpp:137] Memory required for data: 415248384
I0728 09:57:20.571454 20134 layer_factory.hpp:77] Creating layer conv4_2
I0728 09:57:20.571466 20134 net.cpp:84] Creating Layer conv4_2
I0728 09:57:20.571471 20134 net.cpp:406] conv4_2 <- conv4_1
I0728 09:57:20.571480 20134 net.cpp:380] conv4_2 -> conv4_2
I0728 09:57:20.594384 20134 net.cpp:122] Setting up conv4_2
I0728 09:57:20.594403 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.594408 20134 net.cpp:137] Memory required for data: 421539840
I0728 09:57:20.594421 20134 layer_factory.hpp:77] Creating layer relu4_2
I0728 09:57:20.594429 20134 net.cpp:84] Creating Layer relu4_2
I0728 09:57:20.594434 20134 net.cpp:406] relu4_2 <- conv4_2
I0728 09:57:20.594439 20134 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0728 09:57:20.594993 20134 net.cpp:122] Setting up relu4_2
I0728 09:57:20.595006 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.595010 20134 net.cpp:137] Memory required for data: 427831296
I0728 09:57:20.595015 20134 layer_factory.hpp:77] Creating layer conv4_3
I0728 09:57:20.595026 20134 net.cpp:84] Creating Layer conv4_3
I0728 09:57:20.595031 20134 net.cpp:406] conv4_3 <- conv4_2
I0728 09:57:20.595038 20134 net.cpp:380] conv4_3 -> conv4_3
I0728 09:57:20.617848 20134 net.cpp:122] Setting up conv4_3
I0728 09:57:20.617882 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.617887 20134 net.cpp:137] Memory required for data: 434122752
I0728 09:57:20.617897 20134 layer_factory.hpp:77] Creating layer relu4_3
I0728 09:57:20.617907 20134 net.cpp:84] Creating Layer relu4_3
I0728 09:57:20.617913 20134 net.cpp:406] relu4_3 <- conv4_3
I0728 09:57:20.617919 20134 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0728 09:57:20.618079 20134 net.cpp:122] Setting up relu4_3
I0728 09:57:20.618089 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.618093 20134 net.cpp:137] Memory required for data: 440414208
I0728 09:57:20.618098 20134 layer_factory.hpp:77] Creating layer pool4
I0728 09:57:20.618105 20134 net.cpp:84] Creating Layer pool4
I0728 09:57:20.618109 20134 net.cpp:406] pool4 <- conv4_3
I0728 09:57:20.618116 20134 net.cpp:380] pool4 -> pool4
I0728 09:57:20.618163 20134 net.cpp:122] Setting up pool4
I0728 09:57:20.618171 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.618175 20134 net.cpp:137] Memory required for data: 446705664
I0728 09:57:20.618178 20134 layer_factory.hpp:77] Creating layer conv5_1
I0728 09:57:20.618191 20134 net.cpp:84] Creating Layer conv5_1
I0728 09:57:20.618196 20134 net.cpp:406] conv5_1 <- pool4
I0728 09:57:20.618202 20134 net.cpp:380] conv5_1 -> conv5_1
I0728 09:57:20.639776 20134 net.cpp:122] Setting up conv5_1
I0728 09:57:20.639803 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.639807 20134 net.cpp:137] Memory required for data: 452997120
I0728 09:57:20.639816 20134 layer_factory.hpp:77] Creating layer relu5_1
I0728 09:57:20.639825 20134 net.cpp:84] Creating Layer relu5_1
I0728 09:57:20.639830 20134 net.cpp:406] relu5_1 <- conv5_1
I0728 09:57:20.639837 20134 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0728 09:57:20.640471 20134 net.cpp:122] Setting up relu5_1
I0728 09:57:20.640485 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.640487 20134 net.cpp:137] Memory required for data: 459288576
I0728 09:57:20.640491 20134 layer_factory.hpp:77] Creating layer conv5_2
I0728 09:57:20.640501 20134 net.cpp:84] Creating Layer conv5_2
I0728 09:57:20.640503 20134 net.cpp:406] conv5_2 <- conv5_1
I0728 09:57:20.640511 20134 net.cpp:380] conv5_2 -> conv5_2
I0728 09:57:20.662009 20134 net.cpp:122] Setting up conv5_2
I0728 09:57:20.662039 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.662081 20134 net.cpp:137] Memory required for data: 465580032
I0728 09:57:20.662089 20134 layer_factory.hpp:77] Creating layer relu5_2
I0728 09:57:20.662098 20134 net.cpp:84] Creating Layer relu5_2
I0728 09:57:20.662103 20134 net.cpp:406] relu5_2 <- conv5_2
I0728 09:57:20.662111 20134 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0728 09:57:20.662327 20134 net.cpp:122] Setting up relu5_2
I0728 09:57:20.662336 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.662339 20134 net.cpp:137] Memory required for data: 471871488
I0728 09:57:20.662343 20134 layer_factory.hpp:77] Creating layer conv5_3
I0728 09:57:20.662353 20134 net.cpp:84] Creating Layer conv5_3
I0728 09:57:20.662358 20134 net.cpp:406] conv5_3 <- conv5_2
I0728 09:57:20.662365 20134 net.cpp:380] conv5_3 -> conv5_3
I0728 09:57:20.683930 20134 net.cpp:122] Setting up conv5_3
I0728 09:57:20.683960 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.683964 20134 net.cpp:137] Memory required for data: 478162944
I0728 09:57:20.683971 20134 layer_factory.hpp:77] Creating layer relu5_3
I0728 09:57:20.683985 20134 net.cpp:84] Creating Layer relu5_3
I0728 09:57:20.683991 20134 net.cpp:406] relu5_3 <- conv5_3
I0728 09:57:20.684000 20134 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0728 09:57:20.684691 20134 net.cpp:122] Setting up relu5_3
I0728 09:57:20.684703 20134 net.cpp:129] Top shape: 1 512 48 64 (1572864)
I0728 09:57:20.684706 20134 net.cpp:137] Memory required for data: 484454400
I0728 09:57:20.684710 20134 layer_factory.hpp:77] Creating layer conv_score
I0728 09:57:20.684720 20134 net.cpp:84] Creating Layer conv_score
I0728 09:57:20.684725 20134 net.cpp:406] conv_score <- conv5_3
I0728 09:57:20.684733 20134 net.cpp:380] conv_score -> conv_score
I0728 09:57:20.761788 20134 net.cpp:122] Setting up conv_score
I0728 09:57:20.761819 20134 net.cpp:129] Top shape: 1 64 48 64 (196608)
I0728 09:57:20.761824 20134 net.cpp:137] Memory required for data: 485240832
I0728 09:57:20.761835 20134 layer_factory.hpp:77] Creating layer relu_score
I0728 09:57:20.761847 20134 net.cpp:84] Creating Layer relu_score
I0728 09:57:20.761853 20134 net.cpp:406] relu_score <- conv_score
I0728 09:57:20.761859 20134 net.cpp:367] relu_score -> conv_score (in-place)
I0728 09:57:20.762045 20134 net.cpp:122] Setting up relu_score
I0728 09:57:20.762056 20134 net.cpp:129] Top shape: 1 64 48 64 (196608)
I0728 09:57:20.762060 20134 net.cpp:137] Memory required for data: 486027264
I0728 09:57:20.762064 20134 layer_factory.hpp:77] Creating layer slicer_conv
I0728 09:57:20.762076 20134 net.cpp:84] Creating Layer slicer_conv
I0728 09:57:20.762080 20134 net.cpp:406] slicer_conv <- conv_score
I0728 09:57:20.762092 20134 net.cpp:380] slicer_conv -> score1
I0728 09:57:20.762105 20134 net.cpp:380] slicer_conv -> score2
I0728 09:57:20.762115 20134 net.cpp:380] slicer_conv -> score3
I0728 09:57:20.762125 20134 net.cpp:380] slicer_conv -> score4
I0728 09:57:20.762133 20134 net.cpp:380] slicer_conv -> score5
I0728 09:57:20.762141 20134 net.cpp:380] slicer_conv -> score6
I0728 09:57:20.762151 20134 net.cpp:380] slicer_conv -> score7
I0728 09:57:20.762159 20134 net.cpp:380] slicer_conv -> score8
I0728 09:57:20.762168 20134 net.cpp:380] slicer_conv -> score9
I0728 09:57:20.762176 20134 net.cpp:380] slicer_conv -> score10
I0728 09:57:20.762186 20134 net.cpp:380] slicer_conv -> score11
I0728 09:57:20.762194 20134 net.cpp:380] slicer_conv -> score12
I0728 09:57:20.762202 20134 net.cpp:380] slicer_conv -> score13
I0728 09:57:20.762212 20134 net.cpp:380] slicer_conv -> score14
I0728 09:57:20.762221 20134 net.cpp:380] slicer_conv -> score15
I0728 09:57:20.762229 20134 net.cpp:380] slicer_conv -> score16
I0728 09:57:20.762238 20134 net.cpp:380] slicer_conv -> score17
I0728 09:57:20.762246 20134 net.cpp:380] slicer_conv -> score18
I0728 09:57:20.762255 20134 net.cpp:380] slicer_conv -> score19
I0728 09:57:20.762264 20134 net.cpp:380] slicer_conv -> score20
I0728 09:57:20.762274 20134 net.cpp:380] slicer_conv -> score21
I0728 09:57:20.762284 20134 net.cpp:380] slicer_conv -> score22
I0728 09:57:20.762323 20134 net.cpp:380] slicer_conv -> score23
I0728 09:57:20.762334 20134 net.cpp:380] slicer_conv -> score24
I0728 09:57:20.762343 20134 net.cpp:380] slicer_conv -> score25
I0728 09:57:20.762352 20134 net.cpp:380] slicer_conv -> score26
I0728 09:57:20.762362 20134 net.cpp:380] slicer_conv -> score27
I0728 09:57:20.762372 20134 net.cpp:380] slicer_conv -> score28
I0728 09:57:20.762380 20134 net.cpp:380] slicer_conv -> score29
I0728 09:57:20.762389 20134 net.cpp:380] slicer_conv -> score30
I0728 09:57:20.762398 20134 net.cpp:380] slicer_conv -> score31
I0728 09:57:20.762406 20134 net.cpp:380] slicer_conv -> score32
I0728 09:57:20.762415 20134 net.cpp:380] slicer_conv -> score33
I0728 09:57:20.762426 20134 net.cpp:380] slicer_conv -> score34
I0728 09:57:20.762435 20134 net.cpp:380] slicer_conv -> score35
I0728 09:57:20.762444 20134 net.cpp:380] slicer_conv -> score36
I0728 09:57:20.762452 20134 net.cpp:380] slicer_conv -> score37
I0728 09:57:20.762461 20134 net.cpp:380] slicer_conv -> score38
I0728 09:57:20.762470 20134 net.cpp:380] slicer_conv -> score39
I0728 09:57:20.762480 20134 net.cpp:380] slicer_conv -> score40
I0728 09:57:20.762490 20134 net.cpp:380] slicer_conv -> score41
I0728 09:57:20.762497 20134 net.cpp:380] slicer_conv -> score42
I0728 09:57:20.762506 20134 net.cpp:380] slicer_conv -> score43
I0728 09:57:20.762516 20134 net.cpp:380] slicer_conv -> score44
I0728 09:57:20.762523 20134 net.cpp:380] slicer_conv -> score45
I0728 09:57:20.762545 20134 net.cpp:380] slicer_conv -> score46
I0728 09:57:20.762555 20134 net.cpp:380] slicer_conv -> score47
I0728 09:57:20.762564 20134 net.cpp:380] slicer_conv -> score48
I0728 09:57:20.762573 20134 net.cpp:380] slicer_conv -> score49
I0728 09:57:20.762581 20134 net.cpp:380] slicer_conv -> score50
I0728 09:57:20.762590 20134 net.cpp:380] slicer_conv -> score51
I0728 09:57:20.762599 20134 net.cpp:380] slicer_conv -> score52
I0728 09:57:20.762609 20134 net.cpp:380] slicer_conv -> score53
I0728 09:57:20.762617 20134 net.cpp:380] slicer_conv -> score54
I0728 09:57:20.762625 20134 net.cpp:380] slicer_conv -> score55
I0728 09:57:20.762634 20134 net.cpp:380] slicer_conv -> score56
I0728 09:57:20.762643 20134 net.cpp:380] slicer_conv -> score57
I0728 09:57:20.762652 20134 net.cpp:380] slicer_conv -> score58
I0728 09:57:20.762660 20134 net.cpp:380] slicer_conv -> score59
I0728 09:57:20.762670 20134 net.cpp:380] slicer_conv -> score60
I0728 09:57:20.762678 20134 net.cpp:380] slicer_conv -> score61
I0728 09:57:20.762687 20134 net.cpp:380] slicer_conv -> score62
I0728 09:57:20.762696 20134 net.cpp:380] slicer_conv -> score63
I0728 09:57:20.762706 20134 net.cpp:380] slicer_conv -> score64
I0728 09:57:20.763510 20134 net.cpp:122] Setting up slicer_conv
I0728 09:57:20.763520 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763525 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763530 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763535 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763538 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763543 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763547 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763552 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763556 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763561 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763566 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763569 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763573 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763578 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763582 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763586 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763592 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763595 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763599 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763603 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763618 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763622 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763626 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763630 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763634 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763638 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763643 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763648 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763651 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763656 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763660 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763665 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763669 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763674 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763676 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763680 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763685 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763689 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763695 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763698 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763702 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763706 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763710 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763715 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763720 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763725 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763730 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763733 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763737 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763741 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763746 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763749 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763753 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763757 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763762 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763768 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763774 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763782 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763787 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763809 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763818 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763824 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763828 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763833 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763837 20134 net.cpp:137] Memory required for data: 486813696
I0728 09:57:20.763844 20134 layer_factory.hpp:77] Creating layer score1_slicer_conv_0_split
I0728 09:57:20.763849 20134 net.cpp:84] Creating Layer score1_slicer_conv_0_split
I0728 09:57:20.763859 20134 net.cpp:406] score1_slicer_conv_0_split <- score1
I0728 09:57:20.763871 20134 net.cpp:380] score1_slicer_conv_0_split -> score1_slicer_conv_0_split_0
I0728 09:57:20.763880 20134 net.cpp:380] score1_slicer_conv_0_split -> score1_slicer_conv_0_split_1
I0728 09:57:20.763939 20134 net.cpp:122] Setting up score1_slicer_conv_0_split
I0728 09:57:20.763947 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763952 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.763955 20134 net.cpp:137] Memory required for data: 486838272
I0728 09:57:20.763960 20134 layer_factory.hpp:77] Creating layer score2_slicer_conv_1_split
I0728 09:57:20.763967 20134 net.cpp:84] Creating Layer score2_slicer_conv_1_split
I0728 09:57:20.763972 20134 net.cpp:406] score2_slicer_conv_1_split <- score2
I0728 09:57:20.763988 20134 net.cpp:380] score2_slicer_conv_1_split -> score2_slicer_conv_1_split_0
I0728 09:57:20.763996 20134 net.cpp:380] score2_slicer_conv_1_split -> score2_slicer_conv_1_split_1
I0728 09:57:20.764041 20134 net.cpp:122] Setting up score2_slicer_conv_1_split
I0728 09:57:20.764050 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764056 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764062 20134 net.cpp:137] Memory required for data: 486862848
I0728 09:57:20.764068 20134 layer_factory.hpp:77] Creating layer score3_slicer_conv_2_split
I0728 09:57:20.764073 20134 net.cpp:84] Creating Layer score3_slicer_conv_2_split
I0728 09:57:20.764078 20134 net.cpp:406] score3_slicer_conv_2_split <- score3
I0728 09:57:20.764086 20134 net.cpp:380] score3_slicer_conv_2_split -> score3_slicer_conv_2_split_0
I0728 09:57:20.764092 20134 net.cpp:380] score3_slicer_conv_2_split -> score3_slicer_conv_2_split_1
I0728 09:57:20.764138 20134 net.cpp:122] Setting up score3_slicer_conv_2_split
I0728 09:57:20.764145 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764149 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764153 20134 net.cpp:137] Memory required for data: 486887424
I0728 09:57:20.764158 20134 layer_factory.hpp:77] Creating layer score4_slicer_conv_3_split
I0728 09:57:20.764165 20134 net.cpp:84] Creating Layer score4_slicer_conv_3_split
I0728 09:57:20.764169 20134 net.cpp:406] score4_slicer_conv_3_split <- score4
I0728 09:57:20.764178 20134 net.cpp:380] score4_slicer_conv_3_split -> score4_slicer_conv_3_split_0
I0728 09:57:20.764185 20134 net.cpp:380] score4_slicer_conv_3_split -> score4_slicer_conv_3_split_1
I0728 09:57:20.764225 20134 net.cpp:122] Setting up score4_slicer_conv_3_split
I0728 09:57:20.764232 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764237 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764240 20134 net.cpp:137] Memory required for data: 486912000
I0728 09:57:20.764245 20134 layer_factory.hpp:77] Creating layer score5_slicer_conv_4_split
I0728 09:57:20.764252 20134 net.cpp:84] Creating Layer score5_slicer_conv_4_split
I0728 09:57:20.764256 20134 net.cpp:406] score5_slicer_conv_4_split <- score5
I0728 09:57:20.764262 20134 net.cpp:380] score5_slicer_conv_4_split -> score5_slicer_conv_4_split_0
I0728 09:57:20.764268 20134 net.cpp:380] score5_slicer_conv_4_split -> score5_slicer_conv_4_split_1
I0728 09:57:20.764308 20134 net.cpp:122] Setting up score5_slicer_conv_4_split
I0728 09:57:20.764315 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764320 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764325 20134 net.cpp:137] Memory required for data: 486936576
I0728 09:57:20.764329 20134 layer_factory.hpp:77] Creating layer score6_slicer_conv_5_split
I0728 09:57:20.764335 20134 net.cpp:84] Creating Layer score6_slicer_conv_5_split
I0728 09:57:20.764340 20134 net.cpp:406] score6_slicer_conv_5_split <- score6
I0728 09:57:20.764346 20134 net.cpp:380] score6_slicer_conv_5_split -> score6_slicer_conv_5_split_0
I0728 09:57:20.764353 20134 net.cpp:380] score6_slicer_conv_5_split -> score6_slicer_conv_5_split_1
I0728 09:57:20.764392 20134 net.cpp:122] Setting up score6_slicer_conv_5_split
I0728 09:57:20.764398 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764403 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764407 20134 net.cpp:137] Memory required for data: 486961152
I0728 09:57:20.764411 20134 layer_factory.hpp:77] Creating layer score7_slicer_conv_6_split
I0728 09:57:20.764417 20134 net.cpp:84] Creating Layer score7_slicer_conv_6_split
I0728 09:57:20.764421 20134 net.cpp:406] score7_slicer_conv_6_split <- score7
I0728 09:57:20.764426 20134 net.cpp:380] score7_slicer_conv_6_split -> score7_slicer_conv_6_split_0
I0728 09:57:20.764433 20134 net.cpp:380] score7_slicer_conv_6_split -> score7_slicer_conv_6_split_1
I0728 09:57:20.764477 20134 net.cpp:122] Setting up score7_slicer_conv_6_split
I0728 09:57:20.764482 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764497 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764500 20134 net.cpp:137] Memory required for data: 486985728
I0728 09:57:20.764504 20134 layer_factory.hpp:77] Creating layer score8_slicer_conv_7_split
I0728 09:57:20.764510 20134 net.cpp:84] Creating Layer score8_slicer_conv_7_split
I0728 09:57:20.764514 20134 net.cpp:406] score8_slicer_conv_7_split <- score8
I0728 09:57:20.764521 20134 net.cpp:380] score8_slicer_conv_7_split -> score8_slicer_conv_7_split_0
I0728 09:57:20.764528 20134 net.cpp:380] score8_slicer_conv_7_split -> score8_slicer_conv_7_split_1
I0728 09:57:20.764572 20134 net.cpp:122] Setting up score8_slicer_conv_7_split
I0728 09:57:20.764580 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764585 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764587 20134 net.cpp:137] Memory required for data: 487010304
I0728 09:57:20.764591 20134 layer_factory.hpp:77] Creating layer score9_slicer_conv_8_split
I0728 09:57:20.764597 20134 net.cpp:84] Creating Layer score9_slicer_conv_8_split
I0728 09:57:20.764601 20134 net.cpp:406] score9_slicer_conv_8_split <- score9
I0728 09:57:20.764607 20134 net.cpp:380] score9_slicer_conv_8_split -> score9_slicer_conv_8_split_0
I0728 09:57:20.764613 20134 net.cpp:380] score9_slicer_conv_8_split -> score9_slicer_conv_8_split_1
I0728 09:57:20.764653 20134 net.cpp:122] Setting up score9_slicer_conv_8_split
I0728 09:57:20.764659 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764664 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764668 20134 net.cpp:137] Memory required for data: 487034880
I0728 09:57:20.764672 20134 layer_factory.hpp:77] Creating layer score10_slicer_conv_9_split
I0728 09:57:20.764678 20134 net.cpp:84] Creating Layer score10_slicer_conv_9_split
I0728 09:57:20.764683 20134 net.cpp:406] score10_slicer_conv_9_split <- score10
I0728 09:57:20.764689 20134 net.cpp:380] score10_slicer_conv_9_split -> score10_slicer_conv_9_split_0
I0728 09:57:20.764696 20134 net.cpp:380] score10_slicer_conv_9_split -> score10_slicer_conv_9_split_1
I0728 09:57:20.764734 20134 net.cpp:122] Setting up score10_slicer_conv_9_split
I0728 09:57:20.764741 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764745 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764750 20134 net.cpp:137] Memory required for data: 487059456
I0728 09:57:20.764755 20134 layer_factory.hpp:77] Creating layer score11_slicer_conv_10_split
I0728 09:57:20.764761 20134 net.cpp:84] Creating Layer score11_slicer_conv_10_split
I0728 09:57:20.764765 20134 net.cpp:406] score11_slicer_conv_10_split <- score11
I0728 09:57:20.764770 20134 net.cpp:380] score11_slicer_conv_10_split -> score11_slicer_conv_10_split_0
I0728 09:57:20.764777 20134 net.cpp:380] score11_slicer_conv_10_split -> score11_slicer_conv_10_split_1
I0728 09:57:20.764816 20134 net.cpp:122] Setting up score11_slicer_conv_10_split
I0728 09:57:20.764823 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764827 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764832 20134 net.cpp:137] Memory required for data: 487084032
I0728 09:57:20.764837 20134 layer_factory.hpp:77] Creating layer score12_slicer_conv_11_split
I0728 09:57:20.764842 20134 net.cpp:84] Creating Layer score12_slicer_conv_11_split
I0728 09:57:20.764847 20134 net.cpp:406] score12_slicer_conv_11_split <- score12
I0728 09:57:20.764853 20134 net.cpp:380] score12_slicer_conv_11_split -> score12_slicer_conv_11_split_0
I0728 09:57:20.764860 20134 net.cpp:380] score12_slicer_conv_11_split -> score12_slicer_conv_11_split_1
I0728 09:57:20.764899 20134 net.cpp:122] Setting up score12_slicer_conv_11_split
I0728 09:57:20.764906 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764910 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.764914 20134 net.cpp:137] Memory required for data: 487108608
I0728 09:57:20.764919 20134 layer_factory.hpp:77] Creating layer score13_slicer_conv_12_split
I0728 09:57:20.764926 20134 net.cpp:84] Creating Layer score13_slicer_conv_12_split
I0728 09:57:20.764940 20134 net.cpp:406] score13_slicer_conv_12_split <- score13
I0728 09:57:20.764946 20134 net.cpp:380] score13_slicer_conv_12_split -> score13_slicer_conv_12_split_0
I0728 09:57:20.764953 20134 net.cpp:380] score13_slicer_conv_12_split -> score13_slicer_conv_12_split_1
I0728 09:57:20.764997 20134 net.cpp:122] Setting up score13_slicer_conv_12_split
I0728 09:57:20.765003 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765008 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765012 20134 net.cpp:137] Memory required for data: 487133184
I0728 09:57:20.765017 20134 layer_factory.hpp:77] Creating layer score14_slicer_conv_13_split
I0728 09:57:20.765022 20134 net.cpp:84] Creating Layer score14_slicer_conv_13_split
I0728 09:57:20.765027 20134 net.cpp:406] score14_slicer_conv_13_split <- score14
I0728 09:57:20.765033 20134 net.cpp:380] score14_slicer_conv_13_split -> score14_slicer_conv_13_split_0
I0728 09:57:20.765038 20134 net.cpp:380] score14_slicer_conv_13_split -> score14_slicer_conv_13_split_1
I0728 09:57:20.765079 20134 net.cpp:122] Setting up score14_slicer_conv_13_split
I0728 09:57:20.765085 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765090 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765094 20134 net.cpp:137] Memory required for data: 487157760
I0728 09:57:20.765099 20134 layer_factory.hpp:77] Creating layer score15_slicer_conv_14_split
I0728 09:57:20.765105 20134 net.cpp:84] Creating Layer score15_slicer_conv_14_split
I0728 09:57:20.765108 20134 net.cpp:406] score15_slicer_conv_14_split <- score15
I0728 09:57:20.765115 20134 net.cpp:380] score15_slicer_conv_14_split -> score15_slicer_conv_14_split_0
I0728 09:57:20.765122 20134 net.cpp:380] score15_slicer_conv_14_split -> score15_slicer_conv_14_split_1
I0728 09:57:20.765161 20134 net.cpp:122] Setting up score15_slicer_conv_14_split
I0728 09:57:20.765168 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765173 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765177 20134 net.cpp:137] Memory required for data: 487182336
I0728 09:57:20.765182 20134 layer_factory.hpp:77] Creating layer score16_slicer_conv_15_split
I0728 09:57:20.765187 20134 net.cpp:84] Creating Layer score16_slicer_conv_15_split
I0728 09:57:20.765192 20134 net.cpp:406] score16_slicer_conv_15_split <- score16
I0728 09:57:20.765197 20134 net.cpp:380] score16_slicer_conv_15_split -> score16_slicer_conv_15_split_0
I0728 09:57:20.765202 20134 net.cpp:380] score16_slicer_conv_15_split -> score16_slicer_conv_15_split_1
I0728 09:57:20.765240 20134 net.cpp:122] Setting up score16_slicer_conv_15_split
I0728 09:57:20.765247 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765251 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765255 20134 net.cpp:137] Memory required for data: 487206912
I0728 09:57:20.765259 20134 layer_factory.hpp:77] Creating layer score17_slicer_conv_16_split
I0728 09:57:20.765265 20134 net.cpp:84] Creating Layer score17_slicer_conv_16_split
I0728 09:57:20.765269 20134 net.cpp:406] score17_slicer_conv_16_split <- score17
I0728 09:57:20.765276 20134 net.cpp:380] score17_slicer_conv_16_split -> score17_slicer_conv_16_split_0
I0728 09:57:20.765283 20134 net.cpp:380] score17_slicer_conv_16_split -> score17_slicer_conv_16_split_1
I0728 09:57:20.765331 20134 net.cpp:122] Setting up score17_slicer_conv_16_split
I0728 09:57:20.765338 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765342 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765346 20134 net.cpp:137] Memory required for data: 487231488
I0728 09:57:20.765349 20134 layer_factory.hpp:77] Creating layer score18_slicer_conv_17_split
I0728 09:57:20.765355 20134 net.cpp:84] Creating Layer score18_slicer_conv_17_split
I0728 09:57:20.765359 20134 net.cpp:406] score18_slicer_conv_17_split <- score18
I0728 09:57:20.765365 20134 net.cpp:380] score18_slicer_conv_17_split -> score18_slicer_conv_17_split_0
I0728 09:57:20.765372 20134 net.cpp:380] score18_slicer_conv_17_split -> score18_slicer_conv_17_split_1
I0728 09:57:20.765424 20134 net.cpp:122] Setting up score18_slicer_conv_17_split
I0728 09:57:20.765432 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765436 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765441 20134 net.cpp:137] Memory required for data: 487256064
I0728 09:57:20.765446 20134 layer_factory.hpp:77] Creating layer score19_slicer_conv_18_split
I0728 09:57:20.765451 20134 net.cpp:84] Creating Layer score19_slicer_conv_18_split
I0728 09:57:20.765456 20134 net.cpp:406] score19_slicer_conv_18_split <- score19
I0728 09:57:20.765462 20134 net.cpp:380] score19_slicer_conv_18_split -> score19_slicer_conv_18_split_0
I0728 09:57:20.765470 20134 net.cpp:380] score19_slicer_conv_18_split -> score19_slicer_conv_18_split_1
I0728 09:57:20.765508 20134 net.cpp:122] Setting up score19_slicer_conv_18_split
I0728 09:57:20.765516 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765519 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765523 20134 net.cpp:137] Memory required for data: 487280640
I0728 09:57:20.765527 20134 layer_factory.hpp:77] Creating layer score20_slicer_conv_19_split
I0728 09:57:20.765534 20134 net.cpp:84] Creating Layer score20_slicer_conv_19_split
I0728 09:57:20.765539 20134 net.cpp:406] score20_slicer_conv_19_split <- score20
I0728 09:57:20.765545 20134 net.cpp:380] score20_slicer_conv_19_split -> score20_slicer_conv_19_split_0
I0728 09:57:20.765552 20134 net.cpp:380] score20_slicer_conv_19_split -> score20_slicer_conv_19_split_1
I0728 09:57:20.765591 20134 net.cpp:122] Setting up score20_slicer_conv_19_split
I0728 09:57:20.765599 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765604 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765607 20134 net.cpp:137] Memory required for data: 487305216
I0728 09:57:20.765611 20134 layer_factory.hpp:77] Creating layer score21_slicer_conv_20_split
I0728 09:57:20.765617 20134 net.cpp:84] Creating Layer score21_slicer_conv_20_split
I0728 09:57:20.765621 20134 net.cpp:406] score21_slicer_conv_20_split <- score21
I0728 09:57:20.765627 20134 net.cpp:380] score21_slicer_conv_20_split -> score21_slicer_conv_20_split_0
I0728 09:57:20.765633 20134 net.cpp:380] score21_slicer_conv_20_split -> score21_slicer_conv_20_split_1
I0728 09:57:20.765673 20134 net.cpp:122] Setting up score21_slicer_conv_20_split
I0728 09:57:20.765679 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765684 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765687 20134 net.cpp:137] Memory required for data: 487329792
I0728 09:57:20.765691 20134 layer_factory.hpp:77] Creating layer score22_slicer_conv_21_split
I0728 09:57:20.765698 20134 net.cpp:84] Creating Layer score22_slicer_conv_21_split
I0728 09:57:20.765702 20134 net.cpp:406] score22_slicer_conv_21_split <- score22
I0728 09:57:20.765708 20134 net.cpp:380] score22_slicer_conv_21_split -> score22_slicer_conv_21_split_0
I0728 09:57:20.765714 20134 net.cpp:380] score22_slicer_conv_21_split -> score22_slicer_conv_21_split_1
I0728 09:57:20.765754 20134 net.cpp:122] Setting up score22_slicer_conv_21_split
I0728 09:57:20.765761 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765765 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765770 20134 net.cpp:137] Memory required for data: 487354368
I0728 09:57:20.765774 20134 layer_factory.hpp:77] Creating layer score23_slicer_conv_22_split
I0728 09:57:20.765779 20134 net.cpp:84] Creating Layer score23_slicer_conv_22_split
I0728 09:57:20.765784 20134 net.cpp:406] score23_slicer_conv_22_split <- score23
I0728 09:57:20.765789 20134 net.cpp:380] score23_slicer_conv_22_split -> score23_slicer_conv_22_split_0
I0728 09:57:20.765796 20134 net.cpp:380] score23_slicer_conv_22_split -> score23_slicer_conv_22_split_1
I0728 09:57:20.765837 20134 net.cpp:122] Setting up score23_slicer_conv_22_split
I0728 09:57:20.765844 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765848 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765861 20134 net.cpp:137] Memory required for data: 487378944
I0728 09:57:20.765866 20134 layer_factory.hpp:77] Creating layer score24_slicer_conv_23_split
I0728 09:57:20.765872 20134 net.cpp:84] Creating Layer score24_slicer_conv_23_split
I0728 09:57:20.765875 20134 net.cpp:406] score24_slicer_conv_23_split <- score24
I0728 09:57:20.765882 20134 net.cpp:380] score24_slicer_conv_23_split -> score24_slicer_conv_23_split_0
I0728 09:57:20.765889 20134 net.cpp:380] score24_slicer_conv_23_split -> score24_slicer_conv_23_split_1
I0728 09:57:20.765933 20134 net.cpp:122] Setting up score24_slicer_conv_23_split
I0728 09:57:20.765939 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765944 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.765949 20134 net.cpp:137] Memory required for data: 487403520
I0728 09:57:20.765952 20134 layer_factory.hpp:77] Creating layer score25_slicer_conv_24_split
I0728 09:57:20.765957 20134 net.cpp:84] Creating Layer score25_slicer_conv_24_split
I0728 09:57:20.765962 20134 net.cpp:406] score25_slicer_conv_24_split <- score25
I0728 09:57:20.765967 20134 net.cpp:380] score25_slicer_conv_24_split -> score25_slicer_conv_24_split_0
I0728 09:57:20.765974 20134 net.cpp:380] score25_slicer_conv_24_split -> score25_slicer_conv_24_split_1
I0728 09:57:20.766012 20134 net.cpp:122] Setting up score25_slicer_conv_24_split
I0728 09:57:20.766018 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766023 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766027 20134 net.cpp:137] Memory required for data: 487428096
I0728 09:57:20.766031 20134 layer_factory.hpp:77] Creating layer score26_slicer_conv_25_split
I0728 09:57:20.766037 20134 net.cpp:84] Creating Layer score26_slicer_conv_25_split
I0728 09:57:20.766041 20134 net.cpp:406] score26_slicer_conv_25_split <- score26
I0728 09:57:20.766049 20134 net.cpp:380] score26_slicer_conv_25_split -> score26_slicer_conv_25_split_0
I0728 09:57:20.766057 20134 net.cpp:380] score26_slicer_conv_25_split -> score26_slicer_conv_25_split_1
I0728 09:57:20.766095 20134 net.cpp:122] Setting up score26_slicer_conv_25_split
I0728 09:57:20.766101 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766105 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766109 20134 net.cpp:137] Memory required for data: 487452672
I0728 09:57:20.766113 20134 layer_factory.hpp:77] Creating layer score27_slicer_conv_26_split
I0728 09:57:20.766120 20134 net.cpp:84] Creating Layer score27_slicer_conv_26_split
I0728 09:57:20.766124 20134 net.cpp:406] score27_slicer_conv_26_split <- score27
I0728 09:57:20.766130 20134 net.cpp:380] score27_slicer_conv_26_split -> score27_slicer_conv_26_split_0
I0728 09:57:20.766136 20134 net.cpp:380] score27_slicer_conv_26_split -> score27_slicer_conv_26_split_1
I0728 09:57:20.766175 20134 net.cpp:122] Setting up score27_slicer_conv_26_split
I0728 09:57:20.766182 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766186 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766191 20134 net.cpp:137] Memory required for data: 487477248
I0728 09:57:20.766194 20134 layer_factory.hpp:77] Creating layer score28_slicer_conv_27_split
I0728 09:57:20.766201 20134 net.cpp:84] Creating Layer score28_slicer_conv_27_split
I0728 09:57:20.766204 20134 net.cpp:406] score28_slicer_conv_27_split <- score28
I0728 09:57:20.766211 20134 net.cpp:380] score28_slicer_conv_27_split -> score28_slicer_conv_27_split_0
I0728 09:57:20.766217 20134 net.cpp:380] score28_slicer_conv_27_split -> score28_slicer_conv_27_split_1
I0728 09:57:20.766255 20134 net.cpp:122] Setting up score28_slicer_conv_27_split
I0728 09:57:20.766263 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766266 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766270 20134 net.cpp:137] Memory required for data: 487501824
I0728 09:57:20.766274 20134 layer_factory.hpp:77] Creating layer score29_slicer_conv_28_split
I0728 09:57:20.766288 20134 net.cpp:84] Creating Layer score29_slicer_conv_28_split
I0728 09:57:20.766293 20134 net.cpp:406] score29_slicer_conv_28_split <- score29
I0728 09:57:20.766307 20134 net.cpp:380] score29_slicer_conv_28_split -> score29_slicer_conv_28_split_0
I0728 09:57:20.766314 20134 net.cpp:380] score29_slicer_conv_28_split -> score29_slicer_conv_28_split_1
I0728 09:57:20.766358 20134 net.cpp:122] Setting up score29_slicer_conv_28_split
I0728 09:57:20.766366 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766369 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766373 20134 net.cpp:137] Memory required for data: 487526400
I0728 09:57:20.766378 20134 layer_factory.hpp:77] Creating layer score30_slicer_conv_29_split
I0728 09:57:20.766384 20134 net.cpp:84] Creating Layer score30_slicer_conv_29_split
I0728 09:57:20.766389 20134 net.cpp:406] score30_slicer_conv_29_split <- score30
I0728 09:57:20.766396 20134 net.cpp:380] score30_slicer_conv_29_split -> score30_slicer_conv_29_split_0
I0728 09:57:20.766402 20134 net.cpp:380] score30_slicer_conv_29_split -> score30_slicer_conv_29_split_1
I0728 09:57:20.766440 20134 net.cpp:122] Setting up score30_slicer_conv_29_split
I0728 09:57:20.766448 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766453 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766456 20134 net.cpp:137] Memory required for data: 487550976
I0728 09:57:20.766460 20134 layer_factory.hpp:77] Creating layer score31_slicer_conv_30_split
I0728 09:57:20.766466 20134 net.cpp:84] Creating Layer score31_slicer_conv_30_split
I0728 09:57:20.766471 20134 net.cpp:406] score31_slicer_conv_30_split <- score31
I0728 09:57:20.766479 20134 net.cpp:380] score31_slicer_conv_30_split -> score31_slicer_conv_30_split_0
I0728 09:57:20.766485 20134 net.cpp:380] score31_slicer_conv_30_split -> score31_slicer_conv_30_split_1
I0728 09:57:20.766525 20134 net.cpp:122] Setting up score31_slicer_conv_30_split
I0728 09:57:20.766531 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766536 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766540 20134 net.cpp:137] Memory required for data: 487575552
I0728 09:57:20.766542 20134 layer_factory.hpp:77] Creating layer score32_slicer_conv_31_split
I0728 09:57:20.766548 20134 net.cpp:84] Creating Layer score32_slicer_conv_31_split
I0728 09:57:20.766553 20134 net.cpp:406] score32_slicer_conv_31_split <- score32
I0728 09:57:20.766559 20134 net.cpp:380] score32_slicer_conv_31_split -> score32_slicer_conv_31_split_0
I0728 09:57:20.766566 20134 net.cpp:380] score32_slicer_conv_31_split -> score32_slicer_conv_31_split_1
I0728 09:57:20.766604 20134 net.cpp:122] Setting up score32_slicer_conv_31_split
I0728 09:57:20.766610 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766615 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766619 20134 net.cpp:137] Memory required for data: 487600128
I0728 09:57:20.766623 20134 layer_factory.hpp:77] Creating layer score33_slicer_conv_32_split
I0728 09:57:20.766629 20134 net.cpp:84] Creating Layer score33_slicer_conv_32_split
I0728 09:57:20.766633 20134 net.cpp:406] score33_slicer_conv_32_split <- score33
I0728 09:57:20.766639 20134 net.cpp:380] score33_slicer_conv_32_split -> score33_slicer_conv_32_split_0
I0728 09:57:20.766646 20134 net.cpp:380] score33_slicer_conv_32_split -> score33_slicer_conv_32_split_1
I0728 09:57:20.766686 20134 net.cpp:122] Setting up score33_slicer_conv_32_split
I0728 09:57:20.766693 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766697 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766702 20134 net.cpp:137] Memory required for data: 487624704
I0728 09:57:20.766705 20134 layer_factory.hpp:77] Creating layer score34_slicer_conv_33_split
I0728 09:57:20.766712 20134 net.cpp:84] Creating Layer score34_slicer_conv_33_split
I0728 09:57:20.766716 20134 net.cpp:406] score34_slicer_conv_33_split <- score34
I0728 09:57:20.766722 20134 net.cpp:380] score34_slicer_conv_33_split -> score34_slicer_conv_33_split_0
I0728 09:57:20.766728 20134 net.cpp:380] score34_slicer_conv_33_split -> score34_slicer_conv_33_split_1
I0728 09:57:20.766767 20134 net.cpp:122] Setting up score34_slicer_conv_33_split
I0728 09:57:20.766782 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766786 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766790 20134 net.cpp:137] Memory required for data: 487649280
I0728 09:57:20.766794 20134 layer_factory.hpp:77] Creating layer score35_slicer_conv_34_split
I0728 09:57:20.766800 20134 net.cpp:84] Creating Layer score35_slicer_conv_34_split
I0728 09:57:20.766805 20134 net.cpp:406] score35_slicer_conv_34_split <- score35
I0728 09:57:20.766809 20134 net.cpp:380] score35_slicer_conv_34_split -> score35_slicer_conv_34_split_0
I0728 09:57:20.766815 20134 net.cpp:380] score35_slicer_conv_34_split -> score35_slicer_conv_34_split_1
I0728 09:57:20.766857 20134 net.cpp:122] Setting up score35_slicer_conv_34_split
I0728 09:57:20.766865 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766868 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766873 20134 net.cpp:137] Memory required for data: 487673856
I0728 09:57:20.766877 20134 layer_factory.hpp:77] Creating layer score36_slicer_conv_35_split
I0728 09:57:20.766882 20134 net.cpp:84] Creating Layer score36_slicer_conv_35_split
I0728 09:57:20.766887 20134 net.cpp:406] score36_slicer_conv_35_split <- score36
I0728 09:57:20.766893 20134 net.cpp:380] score36_slicer_conv_35_split -> score36_slicer_conv_35_split_0
I0728 09:57:20.766899 20134 net.cpp:380] score36_slicer_conv_35_split -> score36_slicer_conv_35_split_1
I0728 09:57:20.766937 20134 net.cpp:122] Setting up score36_slicer_conv_35_split
I0728 09:57:20.766944 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766948 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.766952 20134 net.cpp:137] Memory required for data: 487698432
I0728 09:57:20.766957 20134 layer_factory.hpp:77] Creating layer score37_slicer_conv_36_split
I0728 09:57:20.766963 20134 net.cpp:84] Creating Layer score37_slicer_conv_36_split
I0728 09:57:20.766966 20134 net.cpp:406] score37_slicer_conv_36_split <- score37
I0728 09:57:20.766973 20134 net.cpp:380] score37_slicer_conv_36_split -> score37_slicer_conv_36_split_0
I0728 09:57:20.766978 20134 net.cpp:380] score37_slicer_conv_36_split -> score37_slicer_conv_36_split_1
I0728 09:57:20.767019 20134 net.cpp:122] Setting up score37_slicer_conv_36_split
I0728 09:57:20.767025 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767030 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767035 20134 net.cpp:137] Memory required for data: 487723008
I0728 09:57:20.767038 20134 layer_factory.hpp:77] Creating layer score38_slicer_conv_37_split
I0728 09:57:20.767043 20134 net.cpp:84] Creating Layer score38_slicer_conv_37_split
I0728 09:57:20.767047 20134 net.cpp:406] score38_slicer_conv_37_split <- score38
I0728 09:57:20.767055 20134 net.cpp:380] score38_slicer_conv_37_split -> score38_slicer_conv_37_split_0
I0728 09:57:20.767061 20134 net.cpp:380] score38_slicer_conv_37_split -> score38_slicer_conv_37_split_1
I0728 09:57:20.767099 20134 net.cpp:122] Setting up score38_slicer_conv_37_split
I0728 09:57:20.767107 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767110 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767114 20134 net.cpp:137] Memory required for data: 487747584
I0728 09:57:20.767118 20134 layer_factory.hpp:77] Creating layer score39_slicer_conv_38_split
I0728 09:57:20.767125 20134 net.cpp:84] Creating Layer score39_slicer_conv_38_split
I0728 09:57:20.767130 20134 net.cpp:406] score39_slicer_conv_38_split <- score39
I0728 09:57:20.767135 20134 net.cpp:380] score39_slicer_conv_38_split -> score39_slicer_conv_38_split_0
I0728 09:57:20.767143 20134 net.cpp:380] score39_slicer_conv_38_split -> score39_slicer_conv_38_split_1
I0728 09:57:20.767181 20134 net.cpp:122] Setting up score39_slicer_conv_38_split
I0728 09:57:20.767189 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767192 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767196 20134 net.cpp:137] Memory required for data: 487772160
I0728 09:57:20.767207 20134 layer_factory.hpp:77] Creating layer score40_slicer_conv_39_split
I0728 09:57:20.767215 20134 net.cpp:84] Creating Layer score40_slicer_conv_39_split
I0728 09:57:20.767218 20134 net.cpp:406] score40_slicer_conv_39_split <- score40
I0728 09:57:20.767225 20134 net.cpp:380] score40_slicer_conv_39_split -> score40_slicer_conv_39_split_0
I0728 09:57:20.767232 20134 net.cpp:380] score40_slicer_conv_39_split -> score40_slicer_conv_39_split_1
I0728 09:57:20.767276 20134 net.cpp:122] Setting up score40_slicer_conv_39_split
I0728 09:57:20.767282 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767287 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767290 20134 net.cpp:137] Memory required for data: 487796736
I0728 09:57:20.767294 20134 layer_factory.hpp:77] Creating layer score41_slicer_conv_40_split
I0728 09:57:20.767302 20134 net.cpp:84] Creating Layer score41_slicer_conv_40_split
I0728 09:57:20.767307 20134 net.cpp:406] score41_slicer_conv_40_split <- score41
I0728 09:57:20.767312 20134 net.cpp:380] score41_slicer_conv_40_split -> score41_slicer_conv_40_split_0
I0728 09:57:20.767318 20134 net.cpp:380] score41_slicer_conv_40_split -> score41_slicer_conv_40_split_1
I0728 09:57:20.767359 20134 net.cpp:122] Setting up score41_slicer_conv_40_split
I0728 09:57:20.767365 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767369 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767374 20134 net.cpp:137] Memory required for data: 487821312
I0728 09:57:20.767377 20134 layer_factory.hpp:77] Creating layer score42_slicer_conv_41_split
I0728 09:57:20.767383 20134 net.cpp:84] Creating Layer score42_slicer_conv_41_split
I0728 09:57:20.767387 20134 net.cpp:406] score42_slicer_conv_41_split <- score42
I0728 09:57:20.767392 20134 net.cpp:380] score42_slicer_conv_41_split -> score42_slicer_conv_41_split_0
I0728 09:57:20.767400 20134 net.cpp:380] score42_slicer_conv_41_split -> score42_slicer_conv_41_split_1
I0728 09:57:20.767438 20134 net.cpp:122] Setting up score42_slicer_conv_41_split
I0728 09:57:20.767444 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767449 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767453 20134 net.cpp:137] Memory required for data: 487845888
I0728 09:57:20.767457 20134 layer_factory.hpp:77] Creating layer score43_slicer_conv_42_split
I0728 09:57:20.767462 20134 net.cpp:84] Creating Layer score43_slicer_conv_42_split
I0728 09:57:20.767467 20134 net.cpp:406] score43_slicer_conv_42_split <- score43
I0728 09:57:20.767474 20134 net.cpp:380] score43_slicer_conv_42_split -> score43_slicer_conv_42_split_0
I0728 09:57:20.767480 20134 net.cpp:380] score43_slicer_conv_42_split -> score43_slicer_conv_42_split_1
I0728 09:57:20.767519 20134 net.cpp:122] Setting up score43_slicer_conv_42_split
I0728 09:57:20.767526 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767530 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767535 20134 net.cpp:137] Memory required for data: 487870464
I0728 09:57:20.767539 20134 layer_factory.hpp:77] Creating layer score44_slicer_conv_43_split
I0728 09:57:20.767544 20134 net.cpp:84] Creating Layer score44_slicer_conv_43_split
I0728 09:57:20.767549 20134 net.cpp:406] score44_slicer_conv_43_split <- score44
I0728 09:57:20.767554 20134 net.cpp:380] score44_slicer_conv_43_split -> score44_slicer_conv_43_split_0
I0728 09:57:20.767560 20134 net.cpp:380] score44_slicer_conv_43_split -> score44_slicer_conv_43_split_1
I0728 09:57:20.767601 20134 net.cpp:122] Setting up score44_slicer_conv_43_split
I0728 09:57:20.767607 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767611 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767616 20134 net.cpp:137] Memory required for data: 487895040
I0728 09:57:20.767619 20134 layer_factory.hpp:77] Creating layer score45_slicer_conv_44_split
I0728 09:57:20.767626 20134 net.cpp:84] Creating Layer score45_slicer_conv_44_split
I0728 09:57:20.767629 20134 net.cpp:406] score45_slicer_conv_44_split <- score45
I0728 09:57:20.767639 20134 net.cpp:380] score45_slicer_conv_44_split -> score45_slicer_conv_44_split_0
I0728 09:57:20.767654 20134 net.cpp:380] score45_slicer_conv_44_split -> score45_slicer_conv_44_split_1
I0728 09:57:20.767701 20134 net.cpp:122] Setting up score45_slicer_conv_44_split
I0728 09:57:20.767709 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767714 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767717 20134 net.cpp:137] Memory required for data: 487919616
I0728 09:57:20.767721 20134 layer_factory.hpp:77] Creating layer score46_slicer_conv_45_split
I0728 09:57:20.767727 20134 net.cpp:84] Creating Layer score46_slicer_conv_45_split
I0728 09:57:20.767731 20134 net.cpp:406] score46_slicer_conv_45_split <- score46
I0728 09:57:20.767737 20134 net.cpp:380] score46_slicer_conv_45_split -> score46_slicer_conv_45_split_0
I0728 09:57:20.767743 20134 net.cpp:380] score46_slicer_conv_45_split -> score46_slicer_conv_45_split_1
I0728 09:57:20.767786 20134 net.cpp:122] Setting up score46_slicer_conv_45_split
I0728 09:57:20.767792 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767796 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767802 20134 net.cpp:137] Memory required for data: 487944192
I0728 09:57:20.767805 20134 layer_factory.hpp:77] Creating layer score47_slicer_conv_46_split
I0728 09:57:20.767810 20134 net.cpp:84] Creating Layer score47_slicer_conv_46_split
I0728 09:57:20.767815 20134 net.cpp:406] score47_slicer_conv_46_split <- score47
I0728 09:57:20.767822 20134 net.cpp:380] score47_slicer_conv_46_split -> score47_slicer_conv_46_split_0
I0728 09:57:20.767828 20134 net.cpp:380] score47_slicer_conv_46_split -> score47_slicer_conv_46_split_1
I0728 09:57:20.767868 20134 net.cpp:122] Setting up score47_slicer_conv_46_split
I0728 09:57:20.767874 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767879 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767884 20134 net.cpp:137] Memory required for data: 487968768
I0728 09:57:20.767887 20134 layer_factory.hpp:77] Creating layer score48_slicer_conv_47_split
I0728 09:57:20.767894 20134 net.cpp:84] Creating Layer score48_slicer_conv_47_split
I0728 09:57:20.767899 20134 net.cpp:406] score48_slicer_conv_47_split <- score48
I0728 09:57:20.767904 20134 net.cpp:380] score48_slicer_conv_47_split -> score48_slicer_conv_47_split_0
I0728 09:57:20.767910 20134 net.cpp:380] score48_slicer_conv_47_split -> score48_slicer_conv_47_split_1
I0728 09:57:20.767949 20134 net.cpp:122] Setting up score48_slicer_conv_47_split
I0728 09:57:20.767956 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767961 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.767966 20134 net.cpp:137] Memory required for data: 487993344
I0728 09:57:20.767969 20134 layer_factory.hpp:77] Creating layer score49_slicer_conv_48_split
I0728 09:57:20.767976 20134 net.cpp:84] Creating Layer score49_slicer_conv_48_split
I0728 09:57:20.767979 20134 net.cpp:406] score49_slicer_conv_48_split <- score49
I0728 09:57:20.767984 20134 net.cpp:380] score49_slicer_conv_48_split -> score49_slicer_conv_48_split_0
I0728 09:57:20.767992 20134 net.cpp:380] score49_slicer_conv_48_split -> score49_slicer_conv_48_split_1
I0728 09:57:20.768031 20134 net.cpp:122] Setting up score49_slicer_conv_48_split
I0728 09:57:20.768038 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768043 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768048 20134 net.cpp:137] Memory required for data: 488017920
I0728 09:57:20.768051 20134 layer_factory.hpp:77] Creating layer score50_slicer_conv_49_split
I0728 09:57:20.768059 20134 net.cpp:84] Creating Layer score50_slicer_conv_49_split
I0728 09:57:20.768062 20134 net.cpp:406] score50_slicer_conv_49_split <- score50
I0728 09:57:20.768069 20134 net.cpp:380] score50_slicer_conv_49_split -> score50_slicer_conv_49_split_0
I0728 09:57:20.768074 20134 net.cpp:380] score50_slicer_conv_49_split -> score50_slicer_conv_49_split_1
I0728 09:57:20.768115 20134 net.cpp:122] Setting up score50_slicer_conv_49_split
I0728 09:57:20.768121 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768133 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768138 20134 net.cpp:137] Memory required for data: 488042496
I0728 09:57:20.768142 20134 layer_factory.hpp:77] Creating layer score51_slicer_conv_50_split
I0728 09:57:20.768148 20134 net.cpp:84] Creating Layer score51_slicer_conv_50_split
I0728 09:57:20.768152 20134 net.cpp:406] score51_slicer_conv_50_split <- score51
I0728 09:57:20.768159 20134 net.cpp:380] score51_slicer_conv_50_split -> score51_slicer_conv_50_split_0
I0728 09:57:20.768165 20134 net.cpp:380] score51_slicer_conv_50_split -> score51_slicer_conv_50_split_1
I0728 09:57:20.768208 20134 net.cpp:122] Setting up score51_slicer_conv_50_split
I0728 09:57:20.768214 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768218 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768224 20134 net.cpp:137] Memory required for data: 488067072
I0728 09:57:20.768227 20134 layer_factory.hpp:77] Creating layer score52_slicer_conv_51_split
I0728 09:57:20.768232 20134 net.cpp:84] Creating Layer score52_slicer_conv_51_split
I0728 09:57:20.768237 20134 net.cpp:406] score52_slicer_conv_51_split <- score52
I0728 09:57:20.768244 20134 net.cpp:380] score52_slicer_conv_51_split -> score52_slicer_conv_51_split_0
I0728 09:57:20.768250 20134 net.cpp:380] score52_slicer_conv_51_split -> score52_slicer_conv_51_split_1
I0728 09:57:20.768290 20134 net.cpp:122] Setting up score52_slicer_conv_51_split
I0728 09:57:20.768296 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768301 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768304 20134 net.cpp:137] Memory required for data: 488091648
I0728 09:57:20.768308 20134 layer_factory.hpp:77] Creating layer score53_slicer_conv_52_split
I0728 09:57:20.768314 20134 net.cpp:84] Creating Layer score53_slicer_conv_52_split
I0728 09:57:20.768319 20134 net.cpp:406] score53_slicer_conv_52_split <- score53
I0728 09:57:20.768324 20134 net.cpp:380] score53_slicer_conv_52_split -> score53_slicer_conv_52_split_0
I0728 09:57:20.768332 20134 net.cpp:380] score53_slicer_conv_52_split -> score53_slicer_conv_52_split_1
I0728 09:57:20.768369 20134 net.cpp:122] Setting up score53_slicer_conv_52_split
I0728 09:57:20.768376 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768381 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768385 20134 net.cpp:137] Memory required for data: 488116224
I0728 09:57:20.768389 20134 layer_factory.hpp:77] Creating layer score54_slicer_conv_53_split
I0728 09:57:20.768395 20134 net.cpp:84] Creating Layer score54_slicer_conv_53_split
I0728 09:57:20.768399 20134 net.cpp:406] score54_slicer_conv_53_split <- score54
I0728 09:57:20.768406 20134 net.cpp:380] score54_slicer_conv_53_split -> score54_slicer_conv_53_split_0
I0728 09:57:20.768412 20134 net.cpp:380] score54_slicer_conv_53_split -> score54_slicer_conv_53_split_1
I0728 09:57:20.768450 20134 net.cpp:122] Setting up score54_slicer_conv_53_split
I0728 09:57:20.768457 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768461 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768466 20134 net.cpp:137] Memory required for data: 488140800
I0728 09:57:20.768470 20134 layer_factory.hpp:77] Creating layer score55_slicer_conv_54_split
I0728 09:57:20.768477 20134 net.cpp:84] Creating Layer score55_slicer_conv_54_split
I0728 09:57:20.768482 20134 net.cpp:406] score55_slicer_conv_54_split <- score55
I0728 09:57:20.768487 20134 net.cpp:380] score55_slicer_conv_54_split -> score55_slicer_conv_54_split_0
I0728 09:57:20.768514 20134 net.cpp:380] score55_slicer_conv_54_split -> score55_slicer_conv_54_split_1
I0728 09:57:20.768556 20134 net.cpp:122] Setting up score55_slicer_conv_54_split
I0728 09:57:20.768564 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768569 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768573 20134 net.cpp:137] Memory required for data: 488165376
I0728 09:57:20.768577 20134 layer_factory.hpp:77] Creating layer score56_slicer_conv_55_split
I0728 09:57:20.768590 20134 net.cpp:84] Creating Layer score56_slicer_conv_55_split
I0728 09:57:20.768595 20134 net.cpp:406] score56_slicer_conv_55_split <- score56
I0728 09:57:20.768601 20134 net.cpp:380] score56_slicer_conv_55_split -> score56_slicer_conv_55_split_0
I0728 09:57:20.768609 20134 net.cpp:380] score56_slicer_conv_55_split -> score56_slicer_conv_55_split_1
I0728 09:57:20.768649 20134 net.cpp:122] Setting up score56_slicer_conv_55_split
I0728 09:57:20.768657 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768661 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768666 20134 net.cpp:137] Memory required for data: 488189952
I0728 09:57:20.768671 20134 layer_factory.hpp:77] Creating layer score57_slicer_conv_56_split
I0728 09:57:20.768676 20134 net.cpp:84] Creating Layer score57_slicer_conv_56_split
I0728 09:57:20.768679 20134 net.cpp:406] score57_slicer_conv_56_split <- score57
I0728 09:57:20.768685 20134 net.cpp:380] score57_slicer_conv_56_split -> score57_slicer_conv_56_split_0
I0728 09:57:20.768692 20134 net.cpp:380] score57_slicer_conv_56_split -> score57_slicer_conv_56_split_1
I0728 09:57:20.768731 20134 net.cpp:122] Setting up score57_slicer_conv_56_split
I0728 09:57:20.768739 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768743 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768748 20134 net.cpp:137] Memory required for data: 488214528
I0728 09:57:20.768751 20134 layer_factory.hpp:77] Creating layer score58_slicer_conv_57_split
I0728 09:57:20.768757 20134 net.cpp:84] Creating Layer score58_slicer_conv_57_split
I0728 09:57:20.768761 20134 net.cpp:406] score58_slicer_conv_57_split <- score58
I0728 09:57:20.768769 20134 net.cpp:380] score58_slicer_conv_57_split -> score58_slicer_conv_57_split_0
I0728 09:57:20.768775 20134 net.cpp:380] score58_slicer_conv_57_split -> score58_slicer_conv_57_split_1
I0728 09:57:20.768815 20134 net.cpp:122] Setting up score58_slicer_conv_57_split
I0728 09:57:20.768821 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768826 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768831 20134 net.cpp:137] Memory required for data: 488239104
I0728 09:57:20.768834 20134 layer_factory.hpp:77] Creating layer score59_slicer_conv_58_split
I0728 09:57:20.768839 20134 net.cpp:84] Creating Layer score59_slicer_conv_58_split
I0728 09:57:20.768844 20134 net.cpp:406] score59_slicer_conv_58_split <- score59
I0728 09:57:20.768851 20134 net.cpp:380] score59_slicer_conv_58_split -> score59_slicer_conv_58_split_0
I0728 09:57:20.768857 20134 net.cpp:380] score59_slicer_conv_58_split -> score59_slicer_conv_58_split_1
I0728 09:57:20.768900 20134 net.cpp:122] Setting up score59_slicer_conv_58_split
I0728 09:57:20.768906 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768911 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768914 20134 net.cpp:137] Memory required for data: 488263680
I0728 09:57:20.768918 20134 layer_factory.hpp:77] Creating layer score60_slicer_conv_59_split
I0728 09:57:20.768924 20134 net.cpp:84] Creating Layer score60_slicer_conv_59_split
I0728 09:57:20.768929 20134 net.cpp:406] score60_slicer_conv_59_split <- score60
I0728 09:57:20.768935 20134 net.cpp:380] score60_slicer_conv_59_split -> score60_slicer_conv_59_split_0
I0728 09:57:20.768942 20134 net.cpp:380] score60_slicer_conv_59_split -> score60_slicer_conv_59_split_1
I0728 09:57:20.768982 20134 net.cpp:122] Setting up score60_slicer_conv_59_split
I0728 09:57:20.768990 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768995 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.768998 20134 net.cpp:137] Memory required for data: 488288256
I0728 09:57:20.769002 20134 layer_factory.hpp:77] Creating layer score61_slicer_conv_60_split
I0728 09:57:20.769009 20134 net.cpp:84] Creating Layer score61_slicer_conv_60_split
I0728 09:57:20.769013 20134 net.cpp:406] score61_slicer_conv_60_split <- score61
I0728 09:57:20.769021 20134 net.cpp:380] score61_slicer_conv_60_split -> score61_slicer_conv_60_split_0
I0728 09:57:20.769035 20134 net.cpp:380] score61_slicer_conv_60_split -> score61_slicer_conv_60_split_1
I0728 09:57:20.769079 20134 net.cpp:122] Setting up score61_slicer_conv_60_split
I0728 09:57:20.769090 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769095 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769099 20134 net.cpp:137] Memory required for data: 488312832
I0728 09:57:20.769104 20134 layer_factory.hpp:77] Creating layer score62_slicer_conv_61_split
I0728 09:57:20.769110 20134 net.cpp:84] Creating Layer score62_slicer_conv_61_split
I0728 09:57:20.769114 20134 net.cpp:406] score62_slicer_conv_61_split <- score62
I0728 09:57:20.769120 20134 net.cpp:380] score62_slicer_conv_61_split -> score62_slicer_conv_61_split_0
I0728 09:57:20.769127 20134 net.cpp:380] score62_slicer_conv_61_split -> score62_slicer_conv_61_split_1
I0728 09:57:20.769167 20134 net.cpp:122] Setting up score62_slicer_conv_61_split
I0728 09:57:20.769174 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769178 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769183 20134 net.cpp:137] Memory required for data: 488337408
I0728 09:57:20.769187 20134 layer_factory.hpp:77] Creating layer score63_slicer_conv_62_split
I0728 09:57:20.769194 20134 net.cpp:84] Creating Layer score63_slicer_conv_62_split
I0728 09:57:20.769198 20134 net.cpp:406] score63_slicer_conv_62_split <- score63
I0728 09:57:20.769204 20134 net.cpp:380] score63_slicer_conv_62_split -> score63_slicer_conv_62_split_0
I0728 09:57:20.769210 20134 net.cpp:380] score63_slicer_conv_62_split -> score63_slicer_conv_62_split_1
I0728 09:57:20.769250 20134 net.cpp:122] Setting up score63_slicer_conv_62_split
I0728 09:57:20.769258 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769261 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769266 20134 net.cpp:137] Memory required for data: 488361984
I0728 09:57:20.769270 20134 layer_factory.hpp:77] Creating layer score64_slicer_conv_63_split
I0728 09:57:20.769275 20134 net.cpp:84] Creating Layer score64_slicer_conv_63_split
I0728 09:57:20.769279 20134 net.cpp:406] score64_slicer_conv_63_split <- score64
I0728 09:57:20.769285 20134 net.cpp:380] score64_slicer_conv_63_split -> score64_slicer_conv_63_split_0
I0728 09:57:20.769291 20134 net.cpp:380] score64_slicer_conv_63_split -> score64_slicer_conv_63_split_1
I0728 09:57:20.769340 20134 net.cpp:122] Setting up score64_slicer_conv_63_split
I0728 09:57:20.769347 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769351 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769356 20134 net.cpp:137] Memory required for data: 488386560
I0728 09:57:20.769359 20134 layer_factory.hpp:77] Creating layer sumscore
I0728 09:57:20.769374 20134 net.cpp:84] Creating Layer sumscore
I0728 09:57:20.769379 20134 net.cpp:406] sumscore <- score1_slicer_conv_0_split_0
I0728 09:57:20.769385 20134 net.cpp:406] sumscore <- score2_slicer_conv_1_split_0
I0728 09:57:20.769390 20134 net.cpp:406] sumscore <- score3_slicer_conv_2_split_0
I0728 09:57:20.769395 20134 net.cpp:406] sumscore <- score4_slicer_conv_3_split_0
I0728 09:57:20.769400 20134 net.cpp:406] sumscore <- score5_slicer_conv_4_split_0
I0728 09:57:20.769405 20134 net.cpp:406] sumscore <- score6_slicer_conv_5_split_0
I0728 09:57:20.769410 20134 net.cpp:406] sumscore <- score7_slicer_conv_6_split_0
I0728 09:57:20.769415 20134 net.cpp:406] sumscore <- score8_slicer_conv_7_split_0
I0728 09:57:20.769419 20134 net.cpp:406] sumscore <- score9_slicer_conv_8_split_0
I0728 09:57:20.769424 20134 net.cpp:406] sumscore <- score10_slicer_conv_9_split_0
I0728 09:57:20.769429 20134 net.cpp:406] sumscore <- score11_slicer_conv_10_split_0
I0728 09:57:20.769434 20134 net.cpp:406] sumscore <- score12_slicer_conv_11_split_0
I0728 09:57:20.769439 20134 net.cpp:406] sumscore <- score13_slicer_conv_12_split_0
I0728 09:57:20.769443 20134 net.cpp:406] sumscore <- score14_slicer_conv_13_split_0
I0728 09:57:20.769448 20134 net.cpp:406] sumscore <- score15_slicer_conv_14_split_0
I0728 09:57:20.769453 20134 net.cpp:406] sumscore <- score16_slicer_conv_15_split_0
I0728 09:57:20.769465 20134 net.cpp:406] sumscore <- score17_slicer_conv_16_split_0
I0728 09:57:20.769471 20134 net.cpp:406] sumscore <- score18_slicer_conv_17_split_0
I0728 09:57:20.769476 20134 net.cpp:406] sumscore <- score19_slicer_conv_18_split_0
I0728 09:57:20.769480 20134 net.cpp:406] sumscore <- score20_slicer_conv_19_split_0
I0728 09:57:20.769485 20134 net.cpp:406] sumscore <- score21_slicer_conv_20_split_0
I0728 09:57:20.769490 20134 net.cpp:406] sumscore <- score22_slicer_conv_21_split_0
I0728 09:57:20.769495 20134 net.cpp:406] sumscore <- score23_slicer_conv_22_split_0
I0728 09:57:20.769500 20134 net.cpp:406] sumscore <- score24_slicer_conv_23_split_0
I0728 09:57:20.769505 20134 net.cpp:406] sumscore <- score25_slicer_conv_24_split_0
I0728 09:57:20.769508 20134 net.cpp:406] sumscore <- score26_slicer_conv_25_split_0
I0728 09:57:20.769515 20134 net.cpp:406] sumscore <- score27_slicer_conv_26_split_0
I0728 09:57:20.769518 20134 net.cpp:406] sumscore <- score28_slicer_conv_27_split_0
I0728 09:57:20.769523 20134 net.cpp:406] sumscore <- score29_slicer_conv_28_split_0
I0728 09:57:20.769528 20134 net.cpp:406] sumscore <- score30_slicer_conv_29_split_0
I0728 09:57:20.769532 20134 net.cpp:406] sumscore <- score31_slicer_conv_30_split_0
I0728 09:57:20.769537 20134 net.cpp:406] sumscore <- score32_slicer_conv_31_split_0
I0728 09:57:20.769542 20134 net.cpp:406] sumscore <- score33_slicer_conv_32_split_0
I0728 09:57:20.769547 20134 net.cpp:406] sumscore <- score34_slicer_conv_33_split_0
I0728 09:57:20.769551 20134 net.cpp:406] sumscore <- score35_slicer_conv_34_split_0
I0728 09:57:20.769556 20134 net.cpp:406] sumscore <- score36_slicer_conv_35_split_0
I0728 09:57:20.769560 20134 net.cpp:406] sumscore <- score37_slicer_conv_36_split_0
I0728 09:57:20.769565 20134 net.cpp:406] sumscore <- score38_slicer_conv_37_split_0
I0728 09:57:20.769570 20134 net.cpp:406] sumscore <- score39_slicer_conv_38_split_0
I0728 09:57:20.769574 20134 net.cpp:406] sumscore <- score40_slicer_conv_39_split_0
I0728 09:57:20.769579 20134 net.cpp:406] sumscore <- score41_slicer_conv_40_split_0
I0728 09:57:20.769583 20134 net.cpp:406] sumscore <- score42_slicer_conv_41_split_0
I0728 09:57:20.769588 20134 net.cpp:406] sumscore <- score43_slicer_conv_42_split_0
I0728 09:57:20.769593 20134 net.cpp:406] sumscore <- score44_slicer_conv_43_split_0
I0728 09:57:20.769596 20134 net.cpp:406] sumscore <- score45_slicer_conv_44_split_0
I0728 09:57:20.769601 20134 net.cpp:406] sumscore <- score46_slicer_conv_45_split_0
I0728 09:57:20.769606 20134 net.cpp:406] sumscore <- score47_slicer_conv_46_split_0
I0728 09:57:20.769611 20134 net.cpp:406] sumscore <- score48_slicer_conv_47_split_0
I0728 09:57:20.769616 20134 net.cpp:406] sumscore <- score49_slicer_conv_48_split_0
I0728 09:57:20.769621 20134 net.cpp:406] sumscore <- score50_slicer_conv_49_split_0
I0728 09:57:20.769626 20134 net.cpp:406] sumscore <- score51_slicer_conv_50_split_0
I0728 09:57:20.769630 20134 net.cpp:406] sumscore <- score52_slicer_conv_51_split_0
I0728 09:57:20.769635 20134 net.cpp:406] sumscore <- score53_slicer_conv_52_split_0
I0728 09:57:20.769640 20134 net.cpp:406] sumscore <- score54_slicer_conv_53_split_0
I0728 09:57:20.769645 20134 net.cpp:406] sumscore <- score55_slicer_conv_54_split_0
I0728 09:57:20.769649 20134 net.cpp:406] sumscore <- score56_slicer_conv_55_split_0
I0728 09:57:20.769654 20134 net.cpp:406] sumscore <- score57_slicer_conv_56_split_0
I0728 09:57:20.769659 20134 net.cpp:406] sumscore <- score58_slicer_conv_57_split_0
I0728 09:57:20.769662 20134 net.cpp:406] sumscore <- score59_slicer_conv_58_split_0
I0728 09:57:20.769666 20134 net.cpp:406] sumscore <- score60_slicer_conv_59_split_0
I0728 09:57:20.769671 20134 net.cpp:406] sumscore <- score61_slicer_conv_60_split_0
I0728 09:57:20.769675 20134 net.cpp:406] sumscore <- score62_slicer_conv_61_split_0
I0728 09:57:20.769680 20134 net.cpp:406] sumscore <- score63_slicer_conv_62_split_0
I0728 09:57:20.769685 20134 net.cpp:406] sumscore <- score64_slicer_conv_63_split_0
I0728 09:57:20.769698 20134 net.cpp:380] sumscore -> sumscore
I0728 09:57:20.769752 20134 net.cpp:122] Setting up sumscore
I0728 09:57:20.769760 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.769764 20134 net.cpp:137] Memory required for data: 488398848
I0728 09:57:20.769768 20134 layer_factory.hpp:77] Creating layer sumscore_sumscore_0_split
I0728 09:57:20.769781 20134 net.cpp:84] Creating Layer sumscore_sumscore_0_split
I0728 09:57:20.769785 20134 net.cpp:406] sumscore_sumscore_0_split <- sumscore
I0728 09:57:20.769798 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_0
I0728 09:57:20.769811 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_1
I0728 09:57:20.769824 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_2
I0728 09:57:20.769836 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_3
I0728 09:57:20.769847 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_4
I0728 09:57:20.769861 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_5
I0728 09:57:20.769873 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_6
I0728 09:57:20.769886 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_7
I0728 09:57:20.769897 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_8
I0728 09:57:20.769909 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_9
I0728 09:57:20.769922 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_10
I0728 09:57:20.769933 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_11
I0728 09:57:20.769946 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_12
I0728 09:57:20.769958 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_13
I0728 09:57:20.769969 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_14
I0728 09:57:20.769982 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_15
I0728 09:57:20.769995 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_16
I0728 09:57:20.770007 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_17
I0728 09:57:20.770020 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_18
I0728 09:57:20.770031 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_19
I0728 09:57:20.770042 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_20
I0728 09:57:20.770056 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_21
I0728 09:57:20.770067 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_22
I0728 09:57:20.770079 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_23
I0728 09:57:20.770092 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_24
I0728 09:57:20.770104 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_25
I0728 09:57:20.770117 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_26
I0728 09:57:20.770128 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_27
I0728 09:57:20.770140 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_28
I0728 09:57:20.770154 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_29
I0728 09:57:20.770166 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_30
I0728 09:57:20.770179 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_31
I0728 09:57:20.770190 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_32
I0728 09:57:20.770203 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_33
I0728 09:57:20.770216 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_34
I0728 09:57:20.770227 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_35
I0728 09:57:20.770239 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_36
I0728 09:57:20.770262 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_37
I0728 09:57:20.770274 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_38
I0728 09:57:20.770287 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_39
I0728 09:57:20.770298 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_40
I0728 09:57:20.770310 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_41
I0728 09:57:20.770321 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_42
I0728 09:57:20.770334 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_43
I0728 09:57:20.770347 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_44
I0728 09:57:20.770359 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_45
I0728 09:57:20.770371 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_46
I0728 09:57:20.770383 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_47
I0728 09:57:20.770395 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_48
I0728 09:57:20.770407 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_49
I0728 09:57:20.770418 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_50
I0728 09:57:20.770431 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_51
I0728 09:57:20.770442 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_52
I0728 09:57:20.770454 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_53
I0728 09:57:20.770467 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_54
I0728 09:57:20.770479 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_55
I0728 09:57:20.770491 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_56
I0728 09:57:20.770503 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_57
I0728 09:57:20.770515 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_58
I0728 09:57:20.770529 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_59
I0728 09:57:20.770540 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_60
I0728 09:57:20.770552 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_61
I0728 09:57:20.770565 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_62
I0728 09:57:20.770576 20134 net.cpp:380] sumscore_sumscore_0_split -> sumscore_sumscore_0_split_63
I0728 09:57:20.771376 20134 net.cpp:122] Setting up sumscore_sumscore_0_split
I0728 09:57:20.771386 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771391 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771396 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771400 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771406 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771410 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771415 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771420 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771425 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771430 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771435 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771438 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771443 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771448 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771452 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771457 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771462 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771467 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771471 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771486 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771491 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771494 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771499 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771503 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771508 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771512 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771517 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771522 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771525 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771531 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771535 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771539 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771544 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771549 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771553 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771558 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771562 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771567 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771571 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771576 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771580 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771585 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771590 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771595 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771600 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771603 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771610 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771613 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771617 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771622 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771626 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771632 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771636 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771641 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771646 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771651 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771654 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771659 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771663 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771668 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771672 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771677 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771682 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771687 20134 net.cpp:129] Top shape: 1 1 48 64 (3072)
I0728 09:57:20.771690 20134 net.cpp:137] Memory required for data: 489185280
I0728 09:57:20.771694 20134 layer_factory.hpp:77] Creating layer loss1
I0728 09:57:20.771703 20134 net.cpp:84] Creating Layer loss1
I0728 09:57:20.771708 20134 net.cpp:406] loss1 <- score1_slicer_conv_0_split_1
I0728 09:57:20.771714 20134 net.cpp:406] loss1 <- label_label_0_split_0
I0728 09:57:20.771719 20134 net.cpp:406] loss1 <- sumscore_sumscore_0_split_0
I0728 09:57:20.771728 20134 net.cpp:380] loss1 -> loss1
I0728 09:57:20.771809 20134 net.cpp:122] Setting up loss1
I0728 09:57:20.771816 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.771821 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.771844 20134 net.cpp:137] Memory required for data: 489185284
I0728 09:57:20.771849 20134 layer_factory.hpp:77] Creating layer loss2
I0728 09:57:20.771858 20134 net.cpp:84] Creating Layer loss2
I0728 09:57:20.771863 20134 net.cpp:406] loss2 <- score2_slicer_conv_1_split_1
I0728 09:57:20.771878 20134 net.cpp:406] loss2 <- label_label_0_split_1
I0728 09:57:20.771884 20134 net.cpp:406] loss2 <- sumscore_sumscore_0_split_1
I0728 09:57:20.771891 20134 net.cpp:380] loss2 -> loss2
I0728 09:57:20.771970 20134 net.cpp:122] Setting up loss2
I0728 09:57:20.771977 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.771981 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.771987 20134 net.cpp:137] Memory required for data: 489185288
I0728 09:57:20.771992 20134 layer_factory.hpp:77] Creating layer loss3
I0728 09:57:20.771998 20134 net.cpp:84] Creating Layer loss3
I0728 09:57:20.772002 20134 net.cpp:406] loss3 <- score3_slicer_conv_2_split_1
I0728 09:57:20.772008 20134 net.cpp:406] loss3 <- label_label_0_split_2
I0728 09:57:20.772014 20134 net.cpp:406] loss3 <- sumscore_sumscore_0_split_2
I0728 09:57:20.772022 20134 net.cpp:380] loss3 -> loss3
I0728 09:57:20.772094 20134 net.cpp:122] Setting up loss3
I0728 09:57:20.772100 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772104 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772110 20134 net.cpp:137] Memory required for data: 489185292
I0728 09:57:20.772114 20134 layer_factory.hpp:77] Creating layer loss4
I0728 09:57:20.772122 20134 net.cpp:84] Creating Layer loss4
I0728 09:57:20.772127 20134 net.cpp:406] loss4 <- score4_slicer_conv_3_split_1
I0728 09:57:20.772133 20134 net.cpp:406] loss4 <- label_label_0_split_3
I0728 09:57:20.772138 20134 net.cpp:406] loss4 <- sumscore_sumscore_0_split_3
I0728 09:57:20.772145 20134 net.cpp:380] loss4 -> loss4
I0728 09:57:20.772217 20134 net.cpp:122] Setting up loss4
I0728 09:57:20.772224 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772228 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772233 20134 net.cpp:137] Memory required for data: 489185296
I0728 09:57:20.772236 20134 layer_factory.hpp:77] Creating layer loss5
I0728 09:57:20.772243 20134 net.cpp:84] Creating Layer loss5
I0728 09:57:20.772248 20134 net.cpp:406] loss5 <- score5_slicer_conv_4_split_1
I0728 09:57:20.772254 20134 net.cpp:406] loss5 <- label_label_0_split_4
I0728 09:57:20.772259 20134 net.cpp:406] loss5 <- sumscore_sumscore_0_split_4
I0728 09:57:20.772265 20134 net.cpp:380] loss5 -> loss5
I0728 09:57:20.772337 20134 net.cpp:122] Setting up loss5
I0728 09:57:20.772343 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772348 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772353 20134 net.cpp:137] Memory required for data: 489185300
I0728 09:57:20.772358 20134 layer_factory.hpp:77] Creating layer loss6
I0728 09:57:20.772364 20134 net.cpp:84] Creating Layer loss6
I0728 09:57:20.772369 20134 net.cpp:406] loss6 <- score6_slicer_conv_5_split_1
I0728 09:57:20.772375 20134 net.cpp:406] loss6 <- label_label_0_split_5
I0728 09:57:20.772380 20134 net.cpp:406] loss6 <- sumscore_sumscore_0_split_5
I0728 09:57:20.772387 20134 net.cpp:380] loss6 -> loss6
I0728 09:57:20.772454 20134 net.cpp:122] Setting up loss6
I0728 09:57:20.772461 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772465 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772470 20134 net.cpp:137] Memory required for data: 489185304
I0728 09:57:20.772475 20134 layer_factory.hpp:77] Creating layer loss7
I0728 09:57:20.772480 20134 net.cpp:84] Creating Layer loss7
I0728 09:57:20.772485 20134 net.cpp:406] loss7 <- score7_slicer_conv_6_split_1
I0728 09:57:20.772490 20134 net.cpp:406] loss7 <- label_label_0_split_6
I0728 09:57:20.772495 20134 net.cpp:406] loss7 <- sumscore_sumscore_0_split_6
I0728 09:57:20.772502 20134 net.cpp:380] loss7 -> loss7
I0728 09:57:20.772572 20134 net.cpp:122] Setting up loss7
I0728 09:57:20.772578 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772583 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772588 20134 net.cpp:137] Memory required for data: 489185308
I0728 09:57:20.772591 20134 layer_factory.hpp:77] Creating layer loss8
I0728 09:57:20.772603 20134 net.cpp:84] Creating Layer loss8
I0728 09:57:20.772606 20134 net.cpp:406] loss8 <- score8_slicer_conv_7_split_1
I0728 09:57:20.772613 20134 net.cpp:406] loss8 <- label_label_0_split_7
I0728 09:57:20.772626 20134 net.cpp:406] loss8 <- sumscore_sumscore_0_split_7
I0728 09:57:20.772632 20134 net.cpp:380] loss8 -> loss8
I0728 09:57:20.772708 20134 net.cpp:122] Setting up loss8
I0728 09:57:20.772716 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772718 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772724 20134 net.cpp:137] Memory required for data: 489185312
I0728 09:57:20.772728 20134 layer_factory.hpp:77] Creating layer loss9
I0728 09:57:20.772735 20134 net.cpp:84] Creating Layer loss9
I0728 09:57:20.772739 20134 net.cpp:406] loss9 <- score9_slicer_conv_8_split_1
I0728 09:57:20.772745 20134 net.cpp:406] loss9 <- label_label_0_split_8
I0728 09:57:20.772750 20134 net.cpp:406] loss9 <- sumscore_sumscore_0_split_8
I0728 09:57:20.772756 20134 net.cpp:380] loss9 -> loss9
I0728 09:57:20.772826 20134 net.cpp:122] Setting up loss9
I0728 09:57:20.772832 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772836 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772841 20134 net.cpp:137] Memory required for data: 489185316
I0728 09:57:20.772846 20134 layer_factory.hpp:77] Creating layer loss10
I0728 09:57:20.772851 20134 net.cpp:84] Creating Layer loss10
I0728 09:57:20.772856 20134 net.cpp:406] loss10 <- score10_slicer_conv_9_split_1
I0728 09:57:20.772861 20134 net.cpp:406] loss10 <- label_label_0_split_9
I0728 09:57:20.772866 20134 net.cpp:406] loss10 <- sumscore_sumscore_0_split_9
I0728 09:57:20.772872 20134 net.cpp:380] loss10 -> loss10
I0728 09:57:20.772940 20134 net.cpp:122] Setting up loss10
I0728 09:57:20.772948 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.772951 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.772956 20134 net.cpp:137] Memory required for data: 489185320
I0728 09:57:20.772960 20134 layer_factory.hpp:77] Creating layer loss11
I0728 09:57:20.772966 20134 net.cpp:84] Creating Layer loss11
I0728 09:57:20.772970 20134 net.cpp:406] loss11 <- score11_slicer_conv_10_split_1
I0728 09:57:20.772976 20134 net.cpp:406] loss11 <- label_label_0_split_10
I0728 09:57:20.772981 20134 net.cpp:406] loss11 <- sumscore_sumscore_0_split_10
I0728 09:57:20.772989 20134 net.cpp:380] loss11 -> loss11
I0728 09:57:20.773057 20134 net.cpp:122] Setting up loss11
I0728 09:57:20.773064 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773068 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773073 20134 net.cpp:137] Memory required for data: 489185324
I0728 09:57:20.773077 20134 layer_factory.hpp:77] Creating layer loss12
I0728 09:57:20.773084 20134 net.cpp:84] Creating Layer loss12
I0728 09:57:20.773089 20134 net.cpp:406] loss12 <- score12_slicer_conv_11_split_1
I0728 09:57:20.773094 20134 net.cpp:406] loss12 <- label_label_0_split_11
I0728 09:57:20.773099 20134 net.cpp:406] loss12 <- sumscore_sumscore_0_split_11
I0728 09:57:20.773105 20134 net.cpp:380] loss12 -> loss12
I0728 09:57:20.773175 20134 net.cpp:122] Setting up loss12
I0728 09:57:20.773182 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773186 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773191 20134 net.cpp:137] Memory required for data: 489185328
I0728 09:57:20.773195 20134 layer_factory.hpp:77] Creating layer loss13
I0728 09:57:20.773202 20134 net.cpp:84] Creating Layer loss13
I0728 09:57:20.773206 20134 net.cpp:406] loss13 <- score13_slicer_conv_12_split_1
I0728 09:57:20.773212 20134 net.cpp:406] loss13 <- label_label_0_split_12
I0728 09:57:20.773217 20134 net.cpp:406] loss13 <- sumscore_sumscore_0_split_12
I0728 09:57:20.773222 20134 net.cpp:380] loss13 -> loss13
I0728 09:57:20.773293 20134 net.cpp:122] Setting up loss13
I0728 09:57:20.773298 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773315 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773322 20134 net.cpp:137] Memory required for data: 489185332
I0728 09:57:20.773326 20134 layer_factory.hpp:77] Creating layer loss14
I0728 09:57:20.773332 20134 net.cpp:84] Creating Layer loss14
I0728 09:57:20.773337 20134 net.cpp:406] loss14 <- score14_slicer_conv_13_split_1
I0728 09:57:20.773344 20134 net.cpp:406] loss14 <- label_label_0_split_13
I0728 09:57:20.773357 20134 net.cpp:406] loss14 <- sumscore_sumscore_0_split_13
I0728 09:57:20.773365 20134 net.cpp:380] loss14 -> loss14
I0728 09:57:20.773438 20134 net.cpp:122] Setting up loss14
I0728 09:57:20.773445 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773449 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773455 20134 net.cpp:137] Memory required for data: 489185336
I0728 09:57:20.773459 20134 layer_factory.hpp:77] Creating layer loss15
I0728 09:57:20.773465 20134 net.cpp:84] Creating Layer loss15
I0728 09:57:20.773469 20134 net.cpp:406] loss15 <- score15_slicer_conv_14_split_1
I0728 09:57:20.773475 20134 net.cpp:406] loss15 <- label_label_0_split_14
I0728 09:57:20.773479 20134 net.cpp:406] loss15 <- sumscore_sumscore_0_split_14
I0728 09:57:20.773489 20134 net.cpp:380] loss15 -> loss15
I0728 09:57:20.773560 20134 net.cpp:122] Setting up loss15
I0728 09:57:20.773566 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773569 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773576 20134 net.cpp:137] Memory required for data: 489185340
I0728 09:57:20.773579 20134 layer_factory.hpp:77] Creating layer loss16
I0728 09:57:20.773586 20134 net.cpp:84] Creating Layer loss16
I0728 09:57:20.773591 20134 net.cpp:406] loss16 <- score16_slicer_conv_15_split_1
I0728 09:57:20.773597 20134 net.cpp:406] loss16 <- label_label_0_split_15
I0728 09:57:20.773602 20134 net.cpp:406] loss16 <- sumscore_sumscore_0_split_15
I0728 09:57:20.773607 20134 net.cpp:380] loss16 -> loss16
I0728 09:57:20.773680 20134 net.cpp:122] Setting up loss16
I0728 09:57:20.773686 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773690 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773695 20134 net.cpp:137] Memory required for data: 489185344
I0728 09:57:20.773700 20134 layer_factory.hpp:77] Creating layer loss17
I0728 09:57:20.773707 20134 net.cpp:84] Creating Layer loss17
I0728 09:57:20.773712 20134 net.cpp:406] loss17 <- score17_slicer_conv_16_split_1
I0728 09:57:20.773717 20134 net.cpp:406] loss17 <- label_label_0_split_16
I0728 09:57:20.773722 20134 net.cpp:406] loss17 <- sumscore_sumscore_0_split_16
I0728 09:57:20.773727 20134 net.cpp:380] loss17 -> loss17
I0728 09:57:20.773802 20134 net.cpp:122] Setting up loss17
I0728 09:57:20.773808 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773811 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773816 20134 net.cpp:137] Memory required for data: 489185348
I0728 09:57:20.773821 20134 layer_factory.hpp:77] Creating layer loss18
I0728 09:57:20.773826 20134 net.cpp:84] Creating Layer loss18
I0728 09:57:20.773831 20134 net.cpp:406] loss18 <- score18_slicer_conv_17_split_1
I0728 09:57:20.773836 20134 net.cpp:406] loss18 <- label_label_0_split_17
I0728 09:57:20.773841 20134 net.cpp:406] loss18 <- sumscore_sumscore_0_split_17
I0728 09:57:20.773846 20134 net.cpp:380] loss18 -> loss18
I0728 09:57:20.773916 20134 net.cpp:122] Setting up loss18
I0728 09:57:20.773923 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.773927 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.773932 20134 net.cpp:137] Memory required for data: 489185352
I0728 09:57:20.773937 20134 layer_factory.hpp:77] Creating layer loss19
I0728 09:57:20.773943 20134 net.cpp:84] Creating Layer loss19
I0728 09:57:20.773947 20134 net.cpp:406] loss19 <- score19_slicer_conv_18_split_1
I0728 09:57:20.773953 20134 net.cpp:406] loss19 <- label_label_0_split_18
I0728 09:57:20.773957 20134 net.cpp:406] loss19 <- sumscore_sumscore_0_split_18
I0728 09:57:20.773980 20134 net.cpp:380] loss19 -> loss19
I0728 09:57:20.774055 20134 net.cpp:122] Setting up loss19
I0728 09:57:20.774062 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774065 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774071 20134 net.cpp:137] Memory required for data: 489185356
I0728 09:57:20.774083 20134 layer_factory.hpp:77] Creating layer loss20
I0728 09:57:20.774089 20134 net.cpp:84] Creating Layer loss20
I0728 09:57:20.774094 20134 net.cpp:406] loss20 <- score20_slicer_conv_19_split_1
I0728 09:57:20.774101 20134 net.cpp:406] loss20 <- label_label_0_split_19
I0728 09:57:20.774117 20134 net.cpp:406] loss20 <- sumscore_sumscore_0_split_19
I0728 09:57:20.774123 20134 net.cpp:380] loss20 -> loss20
I0728 09:57:20.774215 20134 net.cpp:122] Setting up loss20
I0728 09:57:20.774224 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774227 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774233 20134 net.cpp:137] Memory required for data: 489185360
I0728 09:57:20.774237 20134 layer_factory.hpp:77] Creating layer loss21
I0728 09:57:20.774245 20134 net.cpp:84] Creating Layer loss21
I0728 09:57:20.774250 20134 net.cpp:406] loss21 <- score21_slicer_conv_20_split_1
I0728 09:57:20.774255 20134 net.cpp:406] loss21 <- label_label_0_split_20
I0728 09:57:20.774260 20134 net.cpp:406] loss21 <- sumscore_sumscore_0_split_20
I0728 09:57:20.774266 20134 net.cpp:380] loss21 -> loss21
I0728 09:57:20.774340 20134 net.cpp:122] Setting up loss21
I0728 09:57:20.774348 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774350 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774356 20134 net.cpp:137] Memory required for data: 489185364
I0728 09:57:20.774359 20134 layer_factory.hpp:77] Creating layer loss22
I0728 09:57:20.774364 20134 net.cpp:84] Creating Layer loss22
I0728 09:57:20.774369 20134 net.cpp:406] loss22 <- score22_slicer_conv_21_split_1
I0728 09:57:20.774374 20134 net.cpp:406] loss22 <- label_label_0_split_21
I0728 09:57:20.774379 20134 net.cpp:406] loss22 <- sumscore_sumscore_0_split_21
I0728 09:57:20.774385 20134 net.cpp:380] loss22 -> loss22
I0728 09:57:20.774466 20134 net.cpp:122] Setting up loss22
I0728 09:57:20.774473 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774477 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774482 20134 net.cpp:137] Memory required for data: 489185368
I0728 09:57:20.774484 20134 layer_factory.hpp:77] Creating layer loss23
I0728 09:57:20.774490 20134 net.cpp:84] Creating Layer loss23
I0728 09:57:20.774494 20134 net.cpp:406] loss23 <- score23_slicer_conv_22_split_1
I0728 09:57:20.774500 20134 net.cpp:406] loss23 <- label_label_0_split_22
I0728 09:57:20.774504 20134 net.cpp:406] loss23 <- sumscore_sumscore_0_split_22
I0728 09:57:20.774521 20134 net.cpp:380] loss23 -> loss23
I0728 09:57:20.774593 20134 net.cpp:122] Setting up loss23
I0728 09:57:20.774600 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774605 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774618 20134 net.cpp:137] Memory required for data: 489185372
I0728 09:57:20.774622 20134 layer_factory.hpp:77] Creating layer loss24
I0728 09:57:20.774628 20134 net.cpp:84] Creating Layer loss24
I0728 09:57:20.774633 20134 net.cpp:406] loss24 <- score24_slicer_conv_23_split_1
I0728 09:57:20.774638 20134 net.cpp:406] loss24 <- label_label_0_split_23
I0728 09:57:20.774643 20134 net.cpp:406] loss24 <- sumscore_sumscore_0_split_23
I0728 09:57:20.774651 20134 net.cpp:380] loss24 -> loss24
I0728 09:57:20.774732 20134 net.cpp:122] Setting up loss24
I0728 09:57:20.774740 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774744 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774749 20134 net.cpp:137] Memory required for data: 489185376
I0728 09:57:20.774754 20134 layer_factory.hpp:77] Creating layer loss25
I0728 09:57:20.774761 20134 net.cpp:84] Creating Layer loss25
I0728 09:57:20.774765 20134 net.cpp:406] loss25 <- score25_slicer_conv_24_split_1
I0728 09:57:20.774771 20134 net.cpp:406] loss25 <- label_label_0_split_24
I0728 09:57:20.774775 20134 net.cpp:406] loss25 <- sumscore_sumscore_0_split_24
I0728 09:57:20.774781 20134 net.cpp:380] loss25 -> loss25
I0728 09:57:20.774865 20134 net.cpp:122] Setting up loss25
I0728 09:57:20.774873 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.774876 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.774881 20134 net.cpp:137] Memory required for data: 489185380
I0728 09:57:20.774884 20134 layer_factory.hpp:77] Creating layer loss26
I0728 09:57:20.774890 20134 net.cpp:84] Creating Layer loss26
I0728 09:57:20.774895 20134 net.cpp:406] loss26 <- score26_slicer_conv_25_split_1
I0728 09:57:20.774900 20134 net.cpp:406] loss26 <- label_label_0_split_25
I0728 09:57:20.774914 20134 net.cpp:406] loss26 <- sumscore_sumscore_0_split_25
I0728 09:57:20.774920 20134 net.cpp:380] loss26 -> loss26
I0728 09:57:20.774992 20134 net.cpp:122] Setting up loss26
I0728 09:57:20.774999 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.775003 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.775017 20134 net.cpp:137] Memory required for data: 489185384
I0728 09:57:20.775022 20134 layer_factory.hpp:77] Creating layer loss27
I0728 09:57:20.775038 20134 net.cpp:84] Creating Layer loss27
I0728 09:57:20.775043 20134 net.cpp:406] loss27 <- score27_slicer_conv_26_split_1
I0728 09:57:20.775049 20134 net.cpp:406] loss27 <- label_label_0_split_26
I0728 09:57:20.775054 20134 net.cpp:406] loss27 <- sumscore_sumscore_0_split_26
I0728 09:57:20.775059 20134 net.cpp:380] loss27 -> loss27
I0728 09:57:20.775146 20134 net.cpp:122] Setting up loss27
I0728 09:57:20.775153 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.775157 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.775162 20134 net.cpp:137] Memory required for data: 489185388
I0728 09:57:20.775167 20134 layer_factory.hpp:77] Creating layer loss28
I0728 09:57:20.775173 20134 net.cpp:84] Creating Layer loss28
I0728 09:57:20.775178 20134 net.cpp:406] loss28 <- score28_slicer_conv_27_split_1
I0728 09:57:20.775183 20134 net.cpp:406] loss28 <- label_label_0_split_27
I0728 09:57:20.775187 20134 net.cpp:406] loss28 <- sumscore_sumscore_0_split_27
I0728 09:57:20.775193 20134 net.cpp:380] loss28 -> loss28
I0728 09:57:20.775274 20134 net.cpp:122] Setting up loss28
I0728 09:57:20.775282 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.775285 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.775291 20134 net.cpp:137] Memory required for data: 489185392
I0728 09:57:20.775295 20134 layer_factory.hpp:77] Creating layer loss29
I0728 09:57:20.775302 20134 net.cpp:84] Creating Layer loss29
I0728 09:57:20.775306 20134 net.cpp:406] loss29 <- score29_slicer_conv_28_split_1
I0728 09:57:20.775312 20134 net.cpp:406] loss29 <- label_label_0_split_28
I0728 09:57:20.775317 20134 net.cpp:406] loss29 <- sumscore_sumscore_0_split_28
I0728 09:57:20.789458 20134 net.cpp:380] loss29 -> loss29
I0728 09:57:20.789589 20134 net.cpp:122] Setting up loss29
I0728 09:57:20.789599 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.789604 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.789613 20134 net.cpp:137] Memory required for data: 489185396
I0728 09:57:20.789618 20134 layer_factory.hpp:77] Creating layer loss30
I0728 09:57:20.789625 20134 net.cpp:84] Creating Layer loss30
I0728 09:57:20.789631 20134 net.cpp:406] loss30 <- score30_slicer_conv_29_split_1
I0728 09:57:20.789638 20134 net.cpp:406] loss30 <- label_label_0_split_29
I0728 09:57:20.789644 20134 net.cpp:406] loss30 <- sumscore_sumscore_0_split_29
I0728 09:57:20.789656 20134 net.cpp:380] loss30 -> loss30
I0728 09:57:20.789737 20134 net.cpp:122] Setting up loss30
I0728 09:57:20.789744 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.789750 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.789757 20134 net.cpp:137] Memory required for data: 489185400
I0728 09:57:20.789762 20134 layer_factory.hpp:77] Creating layer loss31
I0728 09:57:20.789769 20134 net.cpp:84] Creating Layer loss31
I0728 09:57:20.789774 20134 net.cpp:406] loss31 <- score31_slicer_conv_30_split_1
I0728 09:57:20.789780 20134 net.cpp:406] loss31 <- label_label_0_split_30
I0728 09:57:20.789786 20134 net.cpp:406] loss31 <- sumscore_sumscore_0_split_30
I0728 09:57:20.789793 20134 net.cpp:380] loss31 -> loss31
I0728 09:57:20.789873 20134 net.cpp:122] Setting up loss31
I0728 09:57:20.789880 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.789885 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.789891 20134 net.cpp:137] Memory required for data: 489185404
I0728 09:57:20.789896 20134 layer_factory.hpp:77] Creating layer loss32
I0728 09:57:20.789901 20134 net.cpp:84] Creating Layer loss32
I0728 09:57:20.789906 20134 net.cpp:406] loss32 <- score32_slicer_conv_31_split_1
I0728 09:57:20.789911 20134 net.cpp:406] loss32 <- label_label_0_split_31
I0728 09:57:20.789940 20134 net.cpp:406] loss32 <- sumscore_sumscore_0_split_31
I0728 09:57:20.789949 20134 net.cpp:380] loss32 -> loss32
I0728 09:57:20.790032 20134 net.cpp:122] Setting up loss32
I0728 09:57:20.790040 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790045 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790051 20134 net.cpp:137] Memory required for data: 489185408
I0728 09:57:20.790056 20134 layer_factory.hpp:77] Creating layer loss33
I0728 09:57:20.790063 20134 net.cpp:84] Creating Layer loss33
I0728 09:57:20.790068 20134 net.cpp:406] loss33 <- score33_slicer_conv_32_split_1
I0728 09:57:20.790074 20134 net.cpp:406] loss33 <- label_label_0_split_32
I0728 09:57:20.790081 20134 net.cpp:406] loss33 <- sumscore_sumscore_0_split_32
I0728 09:57:20.790088 20134 net.cpp:380] loss33 -> loss33
I0728 09:57:20.790164 20134 net.cpp:122] Setting up loss33
I0728 09:57:20.790171 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790174 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790180 20134 net.cpp:137] Memory required for data: 489185412
I0728 09:57:20.790184 20134 layer_factory.hpp:77] Creating layer loss34
I0728 09:57:20.790191 20134 net.cpp:84] Creating Layer loss34
I0728 09:57:20.790196 20134 net.cpp:406] loss34 <- score34_slicer_conv_33_split_1
I0728 09:57:20.790202 20134 net.cpp:406] loss34 <- label_label_0_split_33
I0728 09:57:20.790210 20134 net.cpp:406] loss34 <- sumscore_sumscore_0_split_33
I0728 09:57:20.790216 20134 net.cpp:380] loss34 -> loss34
I0728 09:57:20.790290 20134 net.cpp:122] Setting up loss34
I0728 09:57:20.790298 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790302 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790307 20134 net.cpp:137] Memory required for data: 489185416
I0728 09:57:20.790313 20134 layer_factory.hpp:77] Creating layer loss35
I0728 09:57:20.790319 20134 net.cpp:84] Creating Layer loss35
I0728 09:57:20.790324 20134 net.cpp:406] loss35 <- score35_slicer_conv_34_split_1
I0728 09:57:20.790329 20134 net.cpp:406] loss35 <- label_label_0_split_34
I0728 09:57:20.790335 20134 net.cpp:406] loss35 <- sumscore_sumscore_0_split_34
I0728 09:57:20.790343 20134 net.cpp:380] loss35 -> loss35
I0728 09:57:20.790419 20134 net.cpp:122] Setting up loss35
I0728 09:57:20.790426 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790431 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790436 20134 net.cpp:137] Memory required for data: 489185420
I0728 09:57:20.790441 20134 layer_factory.hpp:77] Creating layer loss36
I0728 09:57:20.790446 20134 net.cpp:84] Creating Layer loss36
I0728 09:57:20.790452 20134 net.cpp:406] loss36 <- score36_slicer_conv_35_split_1
I0728 09:57:20.790457 20134 net.cpp:406] loss36 <- label_label_0_split_35
I0728 09:57:20.790462 20134 net.cpp:406] loss36 <- sumscore_sumscore_0_split_35
I0728 09:57:20.790468 20134 net.cpp:380] loss36 -> loss36
I0728 09:57:20.790542 20134 net.cpp:122] Setting up loss36
I0728 09:57:20.790549 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790554 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790558 20134 net.cpp:137] Memory required for data: 489185424
I0728 09:57:20.790563 20134 layer_factory.hpp:77] Creating layer loss37
I0728 09:57:20.790570 20134 net.cpp:84] Creating Layer loss37
I0728 09:57:20.790575 20134 net.cpp:406] loss37 <- score37_slicer_conv_36_split_1
I0728 09:57:20.790581 20134 net.cpp:406] loss37 <- label_label_0_split_36
I0728 09:57:20.790586 20134 net.cpp:406] loss37 <- sumscore_sumscore_0_split_36
I0728 09:57:20.790593 20134 net.cpp:380] loss37 -> loss37
I0728 09:57:20.790664 20134 net.cpp:122] Setting up loss37
I0728 09:57:20.790673 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790676 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790681 20134 net.cpp:137] Memory required for data: 489185428
I0728 09:57:20.790685 20134 layer_factory.hpp:77] Creating layer loss38
I0728 09:57:20.790693 20134 net.cpp:84] Creating Layer loss38
I0728 09:57:20.790697 20134 net.cpp:406] loss38 <- score38_slicer_conv_37_split_1
I0728 09:57:20.790702 20134 net.cpp:406] loss38 <- label_label_0_split_37
I0728 09:57:20.790717 20134 net.cpp:406] loss38 <- sumscore_sumscore_0_split_37
I0728 09:57:20.790726 20134 net.cpp:380] loss38 -> loss38
I0728 09:57:20.790803 20134 net.cpp:122] Setting up loss38
I0728 09:57:20.790810 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790814 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790820 20134 net.cpp:137] Memory required for data: 489185432
I0728 09:57:20.790825 20134 layer_factory.hpp:77] Creating layer loss39
I0728 09:57:20.790833 20134 net.cpp:84] Creating Layer loss39
I0728 09:57:20.790838 20134 net.cpp:406] loss39 <- score39_slicer_conv_38_split_1
I0728 09:57:20.790843 20134 net.cpp:406] loss39 <- label_label_0_split_38
I0728 09:57:20.790849 20134 net.cpp:406] loss39 <- sumscore_sumscore_0_split_38
I0728 09:57:20.790855 20134 net.cpp:380] loss39 -> loss39
I0728 09:57:20.790930 20134 net.cpp:122] Setting up loss39
I0728 09:57:20.790937 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.790941 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.790946 20134 net.cpp:137] Memory required for data: 489185436
I0728 09:57:20.790951 20134 layer_factory.hpp:77] Creating layer loss40
I0728 09:57:20.790959 20134 net.cpp:84] Creating Layer loss40
I0728 09:57:20.790964 20134 net.cpp:406] loss40 <- score40_slicer_conv_39_split_1
I0728 09:57:20.790969 20134 net.cpp:406] loss40 <- label_label_0_split_39
I0728 09:57:20.790974 20134 net.cpp:406] loss40 <- sumscore_sumscore_0_split_39
I0728 09:57:20.790980 20134 net.cpp:380] loss40 -> loss40
I0728 09:57:20.791057 20134 net.cpp:122] Setting up loss40
I0728 09:57:20.791064 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791069 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791074 20134 net.cpp:137] Memory required for data: 489185440
I0728 09:57:20.791079 20134 layer_factory.hpp:77] Creating layer loss41
I0728 09:57:20.791085 20134 net.cpp:84] Creating Layer loss41
I0728 09:57:20.791090 20134 net.cpp:406] loss41 <- score41_slicer_conv_40_split_1
I0728 09:57:20.791095 20134 net.cpp:406] loss41 <- label_label_0_split_40
I0728 09:57:20.791100 20134 net.cpp:406] loss41 <- sumscore_sumscore_0_split_40
I0728 09:57:20.791107 20134 net.cpp:380] loss41 -> loss41
I0728 09:57:20.791180 20134 net.cpp:122] Setting up loss41
I0728 09:57:20.791188 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791191 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791198 20134 net.cpp:137] Memory required for data: 489185444
I0728 09:57:20.791201 20134 layer_factory.hpp:77] Creating layer loss42
I0728 09:57:20.791208 20134 net.cpp:84] Creating Layer loss42
I0728 09:57:20.791211 20134 net.cpp:406] loss42 <- score42_slicer_conv_41_split_1
I0728 09:57:20.791216 20134 net.cpp:406] loss42 <- label_label_0_split_41
I0728 09:57:20.791221 20134 net.cpp:406] loss42 <- sumscore_sumscore_0_split_41
I0728 09:57:20.791229 20134 net.cpp:380] loss42 -> loss42
I0728 09:57:20.791301 20134 net.cpp:122] Setting up loss42
I0728 09:57:20.791307 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791311 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791317 20134 net.cpp:137] Memory required for data: 489185448
I0728 09:57:20.791321 20134 layer_factory.hpp:77] Creating layer loss43
I0728 09:57:20.791333 20134 net.cpp:84] Creating Layer loss43
I0728 09:57:20.791338 20134 net.cpp:406] loss43 <- score43_slicer_conv_42_split_1
I0728 09:57:20.791343 20134 net.cpp:406] loss43 <- label_label_0_split_42
I0728 09:57:20.791349 20134 net.cpp:406] loss43 <- sumscore_sumscore_0_split_42
I0728 09:57:20.791355 20134 net.cpp:380] loss43 -> loss43
I0728 09:57:20.791431 20134 net.cpp:122] Setting up loss43
I0728 09:57:20.791438 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791442 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791447 20134 net.cpp:137] Memory required for data: 489185452
I0728 09:57:20.791452 20134 layer_factory.hpp:77] Creating layer loss44
I0728 09:57:20.791461 20134 net.cpp:84] Creating Layer loss44
I0728 09:57:20.791467 20134 net.cpp:406] loss44 <- score44_slicer_conv_43_split_1
I0728 09:57:20.791472 20134 net.cpp:406] loss44 <- label_label_0_split_43
I0728 09:57:20.791487 20134 net.cpp:406] loss44 <- sumscore_sumscore_0_split_43
I0728 09:57:20.791496 20134 net.cpp:380] loss44 -> loss44
I0728 09:57:20.791574 20134 net.cpp:122] Setting up loss44
I0728 09:57:20.791581 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791584 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791590 20134 net.cpp:137] Memory required for data: 489185456
I0728 09:57:20.791595 20134 layer_factory.hpp:77] Creating layer loss45
I0728 09:57:20.791601 20134 net.cpp:84] Creating Layer loss45
I0728 09:57:20.791605 20134 net.cpp:406] loss45 <- score45_slicer_conv_44_split_1
I0728 09:57:20.791611 20134 net.cpp:406] loss45 <- label_label_0_split_44
I0728 09:57:20.791616 20134 net.cpp:406] loss45 <- sumscore_sumscore_0_split_44
I0728 09:57:20.791622 20134 net.cpp:380] loss45 -> loss45
I0728 09:57:20.791694 20134 net.cpp:122] Setting up loss45
I0728 09:57:20.791702 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791707 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791712 20134 net.cpp:137] Memory required for data: 489185460
I0728 09:57:20.791716 20134 layer_factory.hpp:77] Creating layer loss46
I0728 09:57:20.791723 20134 net.cpp:84] Creating Layer loss46
I0728 09:57:20.791726 20134 net.cpp:406] loss46 <- score46_slicer_conv_45_split_1
I0728 09:57:20.791733 20134 net.cpp:406] loss46 <- label_label_0_split_45
I0728 09:57:20.791738 20134 net.cpp:406] loss46 <- sumscore_sumscore_0_split_45
I0728 09:57:20.791745 20134 net.cpp:380] loss46 -> loss46
I0728 09:57:20.791818 20134 net.cpp:122] Setting up loss46
I0728 09:57:20.791826 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791829 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791836 20134 net.cpp:137] Memory required for data: 489185464
I0728 09:57:20.791839 20134 layer_factory.hpp:77] Creating layer loss47
I0728 09:57:20.791847 20134 net.cpp:84] Creating Layer loss47
I0728 09:57:20.791851 20134 net.cpp:406] loss47 <- score47_slicer_conv_46_split_1
I0728 09:57:20.791857 20134 net.cpp:406] loss47 <- label_label_0_split_46
I0728 09:57:20.791862 20134 net.cpp:406] loss47 <- sumscore_sumscore_0_split_46
I0728 09:57:20.791868 20134 net.cpp:380] loss47 -> loss47
I0728 09:57:20.791942 20134 net.cpp:122] Setting up loss47
I0728 09:57:20.791949 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.791954 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.791959 20134 net.cpp:137] Memory required for data: 489185468
I0728 09:57:20.791962 20134 layer_factory.hpp:77] Creating layer loss48
I0728 09:57:20.791970 20134 net.cpp:84] Creating Layer loss48
I0728 09:57:20.791975 20134 net.cpp:406] loss48 <- score48_slicer_conv_47_split_1
I0728 09:57:20.791981 20134 net.cpp:406] loss48 <- label_label_0_split_47
I0728 09:57:20.791986 20134 net.cpp:406] loss48 <- sumscore_sumscore_0_split_47
I0728 09:57:20.791992 20134 net.cpp:380] loss48 -> loss48
I0728 09:57:20.792065 20134 net.cpp:122] Setting up loss48
I0728 09:57:20.792073 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792076 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792083 20134 net.cpp:137] Memory required for data: 489185472
I0728 09:57:20.792086 20134 layer_factory.hpp:77] Creating layer loss49
I0728 09:57:20.792093 20134 net.cpp:84] Creating Layer loss49
I0728 09:57:20.792098 20134 net.cpp:406] loss49 <- score49_slicer_conv_48_split_1
I0728 09:57:20.792104 20134 net.cpp:406] loss49 <- label_label_0_split_48
I0728 09:57:20.792107 20134 net.cpp:406] loss49 <- sumscore_sumscore_0_split_48
I0728 09:57:20.792114 20134 net.cpp:380] loss49 -> loss49
I0728 09:57:20.792184 20134 net.cpp:122] Setting up loss49
I0728 09:57:20.792191 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792196 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792201 20134 net.cpp:137] Memory required for data: 489185476
I0728 09:57:20.792206 20134 layer_factory.hpp:77] Creating layer loss50
I0728 09:57:20.792212 20134 net.cpp:84] Creating Layer loss50
I0728 09:57:20.792217 20134 net.cpp:406] loss50 <- score50_slicer_conv_49_split_1
I0728 09:57:20.792223 20134 net.cpp:406] loss50 <- label_label_0_split_49
I0728 09:57:20.792237 20134 net.cpp:406] loss50 <- sumscore_sumscore_0_split_49
I0728 09:57:20.792245 20134 net.cpp:380] loss50 -> loss50
I0728 09:57:20.792320 20134 net.cpp:122] Setting up loss50
I0728 09:57:20.792327 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792332 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792338 20134 net.cpp:137] Memory required for data: 489185480
I0728 09:57:20.792342 20134 layer_factory.hpp:77] Creating layer loss51
I0728 09:57:20.792351 20134 net.cpp:84] Creating Layer loss51
I0728 09:57:20.792356 20134 net.cpp:406] loss51 <- score51_slicer_conv_50_split_1
I0728 09:57:20.792361 20134 net.cpp:406] loss51 <- label_label_0_split_50
I0728 09:57:20.792366 20134 net.cpp:406] loss51 <- sumscore_sumscore_0_split_50
I0728 09:57:20.792372 20134 net.cpp:380] loss51 -> loss51
I0728 09:57:20.792448 20134 net.cpp:122] Setting up loss51
I0728 09:57:20.792454 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792459 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792464 20134 net.cpp:137] Memory required for data: 489185484
I0728 09:57:20.792469 20134 layer_factory.hpp:77] Creating layer loss52
I0728 09:57:20.792476 20134 net.cpp:84] Creating Layer loss52
I0728 09:57:20.792481 20134 net.cpp:406] loss52 <- score52_slicer_conv_51_split_1
I0728 09:57:20.792487 20134 net.cpp:406] loss52 <- label_label_0_split_51
I0728 09:57:20.792492 20134 net.cpp:406] loss52 <- sumscore_sumscore_0_split_51
I0728 09:57:20.792497 20134 net.cpp:380] loss52 -> loss52
I0728 09:57:20.792572 20134 net.cpp:122] Setting up loss52
I0728 09:57:20.792579 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792583 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792589 20134 net.cpp:137] Memory required for data: 489185488
I0728 09:57:20.792594 20134 layer_factory.hpp:77] Creating layer loss53
I0728 09:57:20.792600 20134 net.cpp:84] Creating Layer loss53
I0728 09:57:20.792605 20134 net.cpp:406] loss53 <- score53_slicer_conv_52_split_1
I0728 09:57:20.792610 20134 net.cpp:406] loss53 <- label_label_0_split_52
I0728 09:57:20.792615 20134 net.cpp:406] loss53 <- sumscore_sumscore_0_split_52
I0728 09:57:20.792621 20134 net.cpp:380] loss53 -> loss53
I0728 09:57:20.792693 20134 net.cpp:122] Setting up loss53
I0728 09:57:20.792701 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792704 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792709 20134 net.cpp:137] Memory required for data: 489185492
I0728 09:57:20.792714 20134 layer_factory.hpp:77] Creating layer loss54
I0728 09:57:20.792721 20134 net.cpp:84] Creating Layer loss54
I0728 09:57:20.792724 20134 net.cpp:406] loss54 <- score54_slicer_conv_53_split_1
I0728 09:57:20.792731 20134 net.cpp:406] loss54 <- label_label_0_split_53
I0728 09:57:20.792735 20134 net.cpp:406] loss54 <- sumscore_sumscore_0_split_53
I0728 09:57:20.792742 20134 net.cpp:380] loss54 -> loss54
I0728 09:57:20.792814 20134 net.cpp:122] Setting up loss54
I0728 09:57:20.792820 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792824 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792829 20134 net.cpp:137] Memory required for data: 489185496
I0728 09:57:20.792834 20134 layer_factory.hpp:77] Creating layer loss55
I0728 09:57:20.792841 20134 net.cpp:84] Creating Layer loss55
I0728 09:57:20.792846 20134 net.cpp:406] loss55 <- score55_slicer_conv_54_split_1
I0728 09:57:20.792851 20134 net.cpp:406] loss55 <- label_label_0_split_54
I0728 09:57:20.792856 20134 net.cpp:406] loss55 <- sumscore_sumscore_0_split_54
I0728 09:57:20.792865 20134 net.cpp:380] loss55 -> loss55
I0728 09:57:20.792942 20134 net.cpp:122] Setting up loss55
I0728 09:57:20.792948 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.792953 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.792958 20134 net.cpp:137] Memory required for data: 489185500
I0728 09:57:20.792963 20134 layer_factory.hpp:77] Creating layer loss56
I0728 09:57:20.792970 20134 net.cpp:84] Creating Layer loss56
I0728 09:57:20.792975 20134 net.cpp:406] loss56 <- score56_slicer_conv_55_split_1
I0728 09:57:20.792981 20134 net.cpp:406] loss56 <- label_label_0_split_55
I0728 09:57:20.792995 20134 net.cpp:406] loss56 <- sumscore_sumscore_0_split_55
I0728 09:57:20.793002 20134 net.cpp:380] loss56 -> loss56
I0728 09:57:20.793081 20134 net.cpp:122] Setting up loss56
I0728 09:57:20.793088 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793092 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793098 20134 net.cpp:137] Memory required for data: 489185504
I0728 09:57:20.793103 20134 layer_factory.hpp:77] Creating layer loss57
I0728 09:57:20.793109 20134 net.cpp:84] Creating Layer loss57
I0728 09:57:20.793113 20134 net.cpp:406] loss57 <- score57_slicer_conv_56_split_1
I0728 09:57:20.793118 20134 net.cpp:406] loss57 <- label_label_0_split_56
I0728 09:57:20.793124 20134 net.cpp:406] loss57 <- sumscore_sumscore_0_split_56
I0728 09:57:20.793129 20134 net.cpp:380] loss57 -> loss57
I0728 09:57:20.793205 20134 net.cpp:122] Setting up loss57
I0728 09:57:20.793211 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793215 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793220 20134 net.cpp:137] Memory required for data: 489185508
I0728 09:57:20.793226 20134 layer_factory.hpp:77] Creating layer loss58
I0728 09:57:20.793231 20134 net.cpp:84] Creating Layer loss58
I0728 09:57:20.793236 20134 net.cpp:406] loss58 <- score58_slicer_conv_57_split_1
I0728 09:57:20.793241 20134 net.cpp:406] loss58 <- label_label_0_split_57
I0728 09:57:20.793247 20134 net.cpp:406] loss58 <- sumscore_sumscore_0_split_57
I0728 09:57:20.793253 20134 net.cpp:380] loss58 -> loss58
I0728 09:57:20.793344 20134 net.cpp:122] Setting up loss58
I0728 09:57:20.793352 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793356 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793364 20134 net.cpp:137] Memory required for data: 489185512
I0728 09:57:20.793368 20134 layer_factory.hpp:77] Creating layer loss59
I0728 09:57:20.793375 20134 net.cpp:84] Creating Layer loss59
I0728 09:57:20.793380 20134 net.cpp:406] loss59 <- score59_slicer_conv_58_split_1
I0728 09:57:20.793387 20134 net.cpp:406] loss59 <- label_label_0_split_58
I0728 09:57:20.793392 20134 net.cpp:406] loss59 <- sumscore_sumscore_0_split_58
I0728 09:57:20.793400 20134 net.cpp:380] loss59 -> loss59
I0728 09:57:20.793473 20134 net.cpp:122] Setting up loss59
I0728 09:57:20.793480 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793484 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793490 20134 net.cpp:137] Memory required for data: 489185516
I0728 09:57:20.793494 20134 layer_factory.hpp:77] Creating layer loss60
I0728 09:57:20.793501 20134 net.cpp:84] Creating Layer loss60
I0728 09:57:20.793507 20134 net.cpp:406] loss60 <- score60_slicer_conv_59_split_1
I0728 09:57:20.793512 20134 net.cpp:406] loss60 <- label_label_0_split_59
I0728 09:57:20.793517 20134 net.cpp:406] loss60 <- sumscore_sumscore_0_split_59
I0728 09:57:20.793524 20134 net.cpp:380] loss60 -> loss60
I0728 09:57:20.793599 20134 net.cpp:122] Setting up loss60
I0728 09:57:20.793606 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793611 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793617 20134 net.cpp:137] Memory required for data: 489185520
I0728 09:57:20.793620 20134 layer_factory.hpp:77] Creating layer loss61
I0728 09:57:20.793627 20134 net.cpp:84] Creating Layer loss61
I0728 09:57:20.793632 20134 net.cpp:406] loss61 <- score61_slicer_conv_60_split_1
I0728 09:57:20.793638 20134 net.cpp:406] loss61 <- label_label_0_split_60
I0728 09:57:20.793643 20134 net.cpp:406] loss61 <- sumscore_sumscore_0_split_60
I0728 09:57:20.793650 20134 net.cpp:380] loss61 -> loss61
I0728 09:57:20.793721 20134 net.cpp:122] Setting up loss61
I0728 09:57:20.793728 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793732 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793738 20134 net.cpp:137] Memory required for data: 489185524
I0728 09:57:20.793742 20134 layer_factory.hpp:77] Creating layer loss62
I0728 09:57:20.793750 20134 net.cpp:84] Creating Layer loss62
I0728 09:57:20.793754 20134 net.cpp:406] loss62 <- score62_slicer_conv_61_split_1
I0728 09:57:20.793759 20134 net.cpp:406] loss62 <- label_label_0_split_61
I0728 09:57:20.793776 20134 net.cpp:406] loss62 <- sumscore_sumscore_0_split_61
I0728 09:57:20.793783 20134 net.cpp:380] loss62 -> loss62
I0728 09:57:20.793859 20134 net.cpp:122] Setting up loss62
I0728 09:57:20.793866 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793870 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.793876 20134 net.cpp:137] Memory required for data: 489185528
I0728 09:57:20.793881 20134 layer_factory.hpp:77] Creating layer loss63
I0728 09:57:20.793887 20134 net.cpp:84] Creating Layer loss63
I0728 09:57:20.793892 20134 net.cpp:406] loss63 <- score63_slicer_conv_62_split_1
I0728 09:57:20.793898 20134 net.cpp:406] loss63 <- label_label_0_split_62
I0728 09:57:20.793903 20134 net.cpp:406] loss63 <- sumscore_sumscore_0_split_62
I0728 09:57:20.793910 20134 net.cpp:380] loss63 -> loss63
I0728 09:57:20.793983 20134 net.cpp:122] Setting up loss63
I0728 09:57:20.793990 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.793994 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.794000 20134 net.cpp:137] Memory required for data: 489185532
I0728 09:57:20.794004 20134 layer_factory.hpp:77] Creating layer loss64
I0728 09:57:20.794013 20134 net.cpp:84] Creating Layer loss64
I0728 09:57:20.794018 20134 net.cpp:406] loss64 <- score64_slicer_conv_63_split_1
I0728 09:57:20.794023 20134 net.cpp:406] loss64 <- label_label_0_split_63
I0728 09:57:20.794028 20134 net.cpp:406] loss64 <- sumscore_sumscore_0_split_63
I0728 09:57:20.794035 20134 net.cpp:380] loss64 -> loss64
I0728 09:57:20.794111 20134 net.cpp:122] Setting up loss64
I0728 09:57:20.794119 20134 net.cpp:129] Top shape: (1)
I0728 09:57:20.794122 20134 net.cpp:132]     with loss weight 1
I0728 09:57:20.794128 20134 net.cpp:137] Memory required for data: 489185536
I0728 09:57:20.794133 20134 net.cpp:198] loss64 needs backward computation.
I0728 09:57:20.794142 20134 net.cpp:198] loss63 needs backward computation.
I0728 09:57:20.794148 20134 net.cpp:198] loss62 needs backward computation.
I0728 09:57:20.794153 20134 net.cpp:198] loss61 needs backward computation.
I0728 09:57:20.794158 20134 net.cpp:198] loss60 needs backward computation.
I0728 09:57:20.794163 20134 net.cpp:198] loss59 needs backward computation.
I0728 09:57:20.794167 20134 net.cpp:198] loss58 needs backward computation.
I0728 09:57:20.794173 20134 net.cpp:198] loss57 needs backward computation.
I0728 09:57:20.794178 20134 net.cpp:198] loss56 needs backward computation.
I0728 09:57:20.794183 20134 net.cpp:198] loss55 needs backward computation.
I0728 09:57:20.794188 20134 net.cpp:198] loss54 needs backward computation.
I0728 09:57:20.794193 20134 net.cpp:198] loss53 needs backward computation.
I0728 09:57:20.794198 20134 net.cpp:198] loss52 needs backward computation.
I0728 09:57:20.794203 20134 net.cpp:198] loss51 needs backward computation.
I0728 09:57:20.794209 20134 net.cpp:198] loss50 needs backward computation.
I0728 09:57:20.794214 20134 net.cpp:198] loss49 needs backward computation.
I0728 09:57:20.794217 20134 net.cpp:198] loss48 needs backward computation.
I0728 09:57:20.794224 20134 net.cpp:198] loss47 needs backward computation.
I0728 09:57:20.794229 20134 net.cpp:198] loss46 needs backward computation.
I0728 09:57:20.794234 20134 net.cpp:198] loss45 needs backward computation.
I0728 09:57:20.794239 20134 net.cpp:198] loss44 needs backward computation.
I0728 09:57:20.794244 20134 net.cpp:198] loss43 needs backward computation.
I0728 09:57:20.794248 20134 net.cpp:198] loss42 needs backward computation.
I0728 09:57:20.794253 20134 net.cpp:198] loss41 needs backward computation.
I0728 09:57:20.794258 20134 net.cpp:198] loss40 needs backward computation.
I0728 09:57:20.794263 20134 net.cpp:198] loss39 needs backward computation.
I0728 09:57:20.794270 20134 net.cpp:198] loss38 needs backward computation.
I0728 09:57:20.794275 20134 net.cpp:198] loss37 needs backward computation.
I0728 09:57:20.794279 20134 net.cpp:198] loss36 needs backward computation.
I0728 09:57:20.794284 20134 net.cpp:198] loss35 needs backward computation.
I0728 09:57:20.794298 20134 net.cpp:198] loss34 needs backward computation.
I0728 09:57:20.794304 20134 net.cpp:198] loss33 needs backward computation.
I0728 09:57:20.794309 20134 net.cpp:198] loss32 needs backward computation.
I0728 09:57:20.794314 20134 net.cpp:198] loss31 needs backward computation.
I0728 09:57:20.794320 20134 net.cpp:198] loss30 needs backward computation.
I0728 09:57:20.794325 20134 net.cpp:198] loss29 needs backward computation.
I0728 09:57:20.794330 20134 net.cpp:198] loss28 needs backward computation.
I0728 09:57:20.794335 20134 net.cpp:198] loss27 needs backward computation.
I0728 09:57:20.794340 20134 net.cpp:198] loss26 needs backward computation.
I0728 09:57:20.794345 20134 net.cpp:198] loss25 needs backward computation.
I0728 09:57:20.794350 20134 net.cpp:198] loss24 needs backward computation.
I0728 09:57:20.794355 20134 net.cpp:198] loss23 needs backward computation.
I0728 09:57:20.794360 20134 net.cpp:198] loss22 needs backward computation.
I0728 09:57:20.794366 20134 net.cpp:198] loss21 needs backward computation.
I0728 09:57:20.794371 20134 net.cpp:198] loss20 needs backward computation.
I0728 09:57:20.794376 20134 net.cpp:198] loss19 needs backward computation.
I0728 09:57:20.794381 20134 net.cpp:198] loss18 needs backward computation.
I0728 09:57:20.794386 20134 net.cpp:198] loss17 needs backward computation.
I0728 09:57:20.794391 20134 net.cpp:198] loss16 needs backward computation.
I0728 09:57:20.794396 20134 net.cpp:198] loss15 needs backward computation.
I0728 09:57:20.794401 20134 net.cpp:198] loss14 needs backward computation.
I0728 09:57:20.794406 20134 net.cpp:198] loss13 needs backward computation.
I0728 09:57:20.794416 20134 net.cpp:198] loss12 needs backward computation.
I0728 09:57:20.794421 20134 net.cpp:198] loss11 needs backward computation.
I0728 09:57:20.794426 20134 net.cpp:198] loss10 needs backward computation.
I0728 09:57:20.794432 20134 net.cpp:198] loss9 needs backward computation.
I0728 09:57:20.794437 20134 net.cpp:198] loss8 needs backward computation.
I0728 09:57:20.794442 20134 net.cpp:198] loss7 needs backward computation.
I0728 09:57:20.794447 20134 net.cpp:198] loss6 needs backward computation.
I0728 09:57:20.794453 20134 net.cpp:198] loss5 needs backward computation.
I0728 09:57:20.794459 20134 net.cpp:198] loss4 needs backward computation.
I0728 09:57:20.794464 20134 net.cpp:198] loss3 needs backward computation.
I0728 09:57:20.794469 20134 net.cpp:198] loss2 needs backward computation.
I0728 09:57:20.794474 20134 net.cpp:198] loss1 needs backward computation.
I0728 09:57:20.794481 20134 net.cpp:198] sumscore_sumscore_0_split needs backward computation.
I0728 09:57:20.794484 20134 net.cpp:198] sumscore needs backward computation.
I0728 09:57:20.794507 20134 net.cpp:198] score64_slicer_conv_63_split needs backward computation.
I0728 09:57:20.794512 20134 net.cpp:198] score63_slicer_conv_62_split needs backward computation.
I0728 09:57:20.794517 20134 net.cpp:198] score62_slicer_conv_61_split needs backward computation.
I0728 09:57:20.794520 20134 net.cpp:198] score61_slicer_conv_60_split needs backward computation.
I0728 09:57:20.794525 20134 net.cpp:198] score60_slicer_conv_59_split needs backward computation.
I0728 09:57:20.794529 20134 net.cpp:198] score59_slicer_conv_58_split needs backward computation.
I0728 09:57:20.794534 20134 net.cpp:198] score58_slicer_conv_57_split needs backward computation.
I0728 09:57:20.794538 20134 net.cpp:198] score57_slicer_conv_56_split needs backward computation.
I0728 09:57:20.794543 20134 net.cpp:198] score56_slicer_conv_55_split needs backward computation.
I0728 09:57:20.794548 20134 net.cpp:198] score55_slicer_conv_54_split needs backward computation.
I0728 09:57:20.794551 20134 net.cpp:198] score54_slicer_conv_53_split needs backward computation.
I0728 09:57:20.794555 20134 net.cpp:198] score53_slicer_conv_52_split needs backward computation.
I0728 09:57:20.794560 20134 net.cpp:198] score52_slicer_conv_51_split needs backward computation.
I0728 09:57:20.794564 20134 net.cpp:198] score51_slicer_conv_50_split needs backward computation.
I0728 09:57:20.794576 20134 net.cpp:198] score50_slicer_conv_49_split needs backward computation.
I0728 09:57:20.794581 20134 net.cpp:198] score49_slicer_conv_48_split needs backward computation.
I0728 09:57:20.794586 20134 net.cpp:198] score48_slicer_conv_47_split needs backward computation.
I0728 09:57:20.794590 20134 net.cpp:198] score47_slicer_conv_46_split needs backward computation.
I0728 09:57:20.794595 20134 net.cpp:198] score46_slicer_conv_45_split needs backward computation.
I0728 09:57:20.794600 20134 net.cpp:198] score45_slicer_conv_44_split needs backward computation.
I0728 09:57:20.794603 20134 net.cpp:198] score44_slicer_conv_43_split needs backward computation.
I0728 09:57:20.794607 20134 net.cpp:198] score43_slicer_conv_42_split needs backward computation.
I0728 09:57:20.794611 20134 net.cpp:198] score42_slicer_conv_41_split needs backward computation.
I0728 09:57:20.794616 20134 net.cpp:198] score41_slicer_conv_40_split needs backward computation.
I0728 09:57:20.794621 20134 net.cpp:198] score40_slicer_conv_39_split needs backward computation.
I0728 09:57:20.794626 20134 net.cpp:198] score39_slicer_conv_38_split needs backward computation.
I0728 09:57:20.794631 20134 net.cpp:198] score38_slicer_conv_37_split needs backward computation.
I0728 09:57:20.794636 20134 net.cpp:198] score37_slicer_conv_36_split needs backward computation.
I0728 09:57:20.794639 20134 net.cpp:198] score36_slicer_conv_35_split needs backward computation.
I0728 09:57:20.794643 20134 net.cpp:198] score35_slicer_conv_34_split needs backward computation.
I0728 09:57:20.794648 20134 net.cpp:198] score34_slicer_conv_33_split needs backward computation.
I0728 09:57:20.794652 20134 net.cpp:198] score33_slicer_conv_32_split needs backward computation.
I0728 09:57:20.794656 20134 net.cpp:198] score32_slicer_conv_31_split needs backward computation.
I0728 09:57:20.794661 20134 net.cpp:198] score31_slicer_conv_30_split needs backward computation.
I0728 09:57:20.794665 20134 net.cpp:198] score30_slicer_conv_29_split needs backward computation.
I0728 09:57:20.794669 20134 net.cpp:198] score29_slicer_conv_28_split needs backward computation.
I0728 09:57:20.794673 20134 net.cpp:198] score28_slicer_conv_27_split needs backward computation.
I0728 09:57:20.794678 20134 net.cpp:198] score27_slicer_conv_26_split needs backward computation.
I0728 09:57:20.794682 20134 net.cpp:198] score26_slicer_conv_25_split needs backward computation.
I0728 09:57:20.794687 20134 net.cpp:198] score25_slicer_conv_24_split needs backward computation.
I0728 09:57:20.794692 20134 net.cpp:198] score24_slicer_conv_23_split needs backward computation.
I0728 09:57:20.794695 20134 net.cpp:198] score23_slicer_conv_22_split needs backward computation.
I0728 09:57:20.794699 20134 net.cpp:198] score22_slicer_conv_21_split needs backward computation.
I0728 09:57:20.794704 20134 net.cpp:198] score21_slicer_conv_20_split needs backward computation.
I0728 09:57:20.794708 20134 net.cpp:198] score20_slicer_conv_19_split needs backward computation.
I0728 09:57:20.794713 20134 net.cpp:198] score19_slicer_conv_18_split needs backward computation.
I0728 09:57:20.794718 20134 net.cpp:198] score18_slicer_conv_17_split needs backward computation.
I0728 09:57:20.794721 20134 net.cpp:198] score17_slicer_conv_16_split needs backward computation.
I0728 09:57:20.794726 20134 net.cpp:198] score16_slicer_conv_15_split needs backward computation.
I0728 09:57:20.794730 20134 net.cpp:198] score15_slicer_conv_14_split needs backward computation.
I0728 09:57:20.794734 20134 net.cpp:198] score14_slicer_conv_13_split needs backward computation.
I0728 09:57:20.794739 20134 net.cpp:198] score13_slicer_conv_12_split needs backward computation.
I0728 09:57:20.794744 20134 net.cpp:198] score12_slicer_conv_11_split needs backward computation.
I0728 09:57:20.794747 20134 net.cpp:198] score11_slicer_conv_10_split needs backward computation.
I0728 09:57:20.794752 20134 net.cpp:198] score10_slicer_conv_9_split needs backward computation.
I0728 09:57:20.794757 20134 net.cpp:198] score9_slicer_conv_8_split needs backward computation.
I0728 09:57:20.794767 20134 net.cpp:198] score8_slicer_conv_7_split needs backward computation.
I0728 09:57:20.794772 20134 net.cpp:198] score7_slicer_conv_6_split needs backward computation.
I0728 09:57:20.794776 20134 net.cpp:198] score6_slicer_conv_5_split needs backward computation.
I0728 09:57:20.794781 20134 net.cpp:198] score5_slicer_conv_4_split needs backward computation.
I0728 09:57:20.794785 20134 net.cpp:198] score4_slicer_conv_3_split needs backward computation.
I0728 09:57:20.794790 20134 net.cpp:198] score3_slicer_conv_2_split needs backward computation.
I0728 09:57:20.794795 20134 net.cpp:198] score2_slicer_conv_1_split needs backward computation.
I0728 09:57:20.794800 20134 net.cpp:198] score1_slicer_conv_0_split needs backward computation.
I0728 09:57:20.794803 20134 net.cpp:198] slicer_conv needs backward computation.
I0728 09:57:20.794807 20134 net.cpp:198] relu_score needs backward computation.
I0728 09:57:20.794812 20134 net.cpp:198] conv_score needs backward computation.
I0728 09:57:20.794816 20134 net.cpp:198] relu5_3 needs backward computation.
I0728 09:57:20.794821 20134 net.cpp:198] conv5_3 needs backward computation.
I0728 09:57:20.794826 20134 net.cpp:198] relu5_2 needs backward computation.
I0728 09:57:20.794829 20134 net.cpp:198] conv5_2 needs backward computation.
I0728 09:57:20.794833 20134 net.cpp:198] relu5_1 needs backward computation.
I0728 09:57:20.794837 20134 net.cpp:198] conv5_1 needs backward computation.
I0728 09:57:20.794842 20134 net.cpp:198] pool4 needs backward computation.
I0728 09:57:20.794847 20134 net.cpp:198] relu4_3 needs backward computation.
I0728 09:57:20.794850 20134 net.cpp:198] conv4_3 needs backward computation.
I0728 09:57:20.794855 20134 net.cpp:198] relu4_2 needs backward computation.
I0728 09:57:20.794862 20134 net.cpp:198] conv4_2 needs backward computation.
I0728 09:57:20.794878 20134 net.cpp:198] relu4_1 needs backward computation.
I0728 09:57:20.794883 20134 net.cpp:198] conv4_1 needs backward computation.
I0728 09:57:20.794888 20134 net.cpp:198] pool3 needs backward computation.
I0728 09:57:20.794891 20134 net.cpp:198] relu3_3 needs backward computation.
I0728 09:57:20.794895 20134 net.cpp:198] conv3_3 needs backward computation.
I0728 09:57:20.794901 20134 net.cpp:198] relu3_2 needs backward computation.
I0728 09:57:20.794905 20134 net.cpp:198] conv3_2 needs backward computation.
I0728 09:57:20.794909 20134 net.cpp:198] relu3_1 needs backward computation.
I0728 09:57:20.794914 20134 net.cpp:198] conv3_1 needs backward computation.
I0728 09:57:20.794919 20134 net.cpp:198] pool2 needs backward computation.
I0728 09:57:20.794922 20134 net.cpp:198] relu2_2 needs backward computation.
I0728 09:57:20.794926 20134 net.cpp:198] conv2_2 needs backward computation.
I0728 09:57:20.794930 20134 net.cpp:198] relu2_1 needs backward computation.
I0728 09:57:20.794934 20134 net.cpp:198] conv2_1 needs backward computation.
I0728 09:57:20.794939 20134 net.cpp:198] pool1 needs backward computation.
I0728 09:57:20.794944 20134 net.cpp:198] relu1_2 needs backward computation.
I0728 09:57:20.794947 20134 net.cpp:198] conv1_2 needs backward computation.
I0728 09:57:20.794951 20134 net.cpp:198] relu1_1 needs backward computation.
I0728 09:57:20.794955 20134 net.cpp:198] conv1_1 needs backward computation.
I0728 09:57:20.794972 20134 net.cpp:200] label_label_0_split does not need backward computation.
I0728 09:57:20.794977 20134 net.cpp:200] label does not need backward computation.
I0728 09:57:20.794981 20134 net.cpp:200] data does not need backward computation.
I0728 09:57:20.794986 20134 net.cpp:242] This network produces output loss1
I0728 09:57:20.794989 20134 net.cpp:242] This network produces output loss10
I0728 09:57:20.794994 20134 net.cpp:242] This network produces output loss11
I0728 09:57:20.794998 20134 net.cpp:242] This network produces output loss12
I0728 09:57:20.795002 20134 net.cpp:242] This network produces output loss13
I0728 09:57:20.795006 20134 net.cpp:242] This network produces output loss14
I0728 09:57:20.795011 20134 net.cpp:242] This network produces output loss15
I0728 09:57:20.795029 20134 net.cpp:242] This network produces output loss16
I0728 09:57:20.795034 20134 net.cpp:242] This network produces output loss17
I0728 09:57:20.795039 20134 net.cpp:242] This network produces output loss18
I0728 09:57:20.795043 20134 net.cpp:242] This network produces output loss19
I0728 09:57:20.795047 20134 net.cpp:242] This network produces output loss2
I0728 09:57:20.795050 20134 net.cpp:242] This network produces output loss20
I0728 09:57:20.795054 20134 net.cpp:242] This network produces output loss21
I0728 09:57:20.795058 20134 net.cpp:242] This network produces output loss22
I0728 09:57:20.795063 20134 net.cpp:242] This network produces output loss23
I0728 09:57:20.795065 20134 net.cpp:242] This network produces output loss24
I0728 09:57:20.795070 20134 net.cpp:242] This network produces output loss25
I0728 09:57:20.795074 20134 net.cpp:242] This network produces output loss26
I0728 09:57:20.795078 20134 net.cpp:242] This network produces output loss27
I0728 09:57:20.795081 20134 net.cpp:242] This network produces output loss28
I0728 09:57:20.795085 20134 net.cpp:242] This network produces output loss29
I0728 09:57:20.795089 20134 net.cpp:242] This network produces output loss3
I0728 09:57:20.795094 20134 net.cpp:242] This network produces output loss30
I0728 09:57:20.795097 20134 net.cpp:242] This network produces output loss31
I0728 09:57:20.795100 20134 net.cpp:242] This network produces output loss32
I0728 09:57:20.795104 20134 net.cpp:242] This network produces output loss33
I0728 09:57:20.795109 20134 net.cpp:242] This network produces output loss34
I0728 09:57:20.795111 20134 net.cpp:242] This network produces output loss35
I0728 09:57:20.795115 20134 net.cpp:242] This network produces output loss36
I0728 09:57:20.795120 20134 net.cpp:242] This network produces output loss37
I0728 09:57:20.795123 20134 net.cpp:242] This network produces output loss38
I0728 09:57:20.795127 20134 net.cpp:242] This network produces output loss39
I0728 09:57:20.795131 20134 net.cpp:242] This network produces output loss4
I0728 09:57:20.795135 20134 net.cpp:242] This network produces output loss40
I0728 09:57:20.795140 20134 net.cpp:242] This network produces output loss41
I0728 09:57:20.795142 20134 net.cpp:242] This network produces output loss42
I0728 09:57:20.795146 20134 net.cpp:242] This network produces output loss43
I0728 09:57:20.795150 20134 net.cpp:242] This network produces output loss44
I0728 09:57:20.795153 20134 net.cpp:242] This network produces output loss45
I0728 09:57:20.795157 20134 net.cpp:242] This network produces output loss46
I0728 09:57:20.795161 20134 net.cpp:242] This network produces output loss47
I0728 09:57:20.795164 20134 net.cpp:242] This network produces output loss48
I0728 09:57:20.795168 20134 net.cpp:242] This network produces output loss49
I0728 09:57:20.795172 20134 net.cpp:242] This network produces output loss5
I0728 09:57:20.795176 20134 net.cpp:242] This network produces output loss50
I0728 09:57:20.795179 20134 net.cpp:242] This network produces output loss51
I0728 09:57:20.795183 20134 net.cpp:242] This network produces output loss52
I0728 09:57:20.795186 20134 net.cpp:242] This network produces output loss53
I0728 09:57:20.795191 20134 net.cpp:242] This network produces output loss54
I0728 09:57:20.795194 20134 net.cpp:242] This network produces output loss55
I0728 09:57:20.795197 20134 net.cpp:242] This network produces output loss56
I0728 09:57:20.795202 20134 net.cpp:242] This network produces output loss57
I0728 09:57:20.795205 20134 net.cpp:242] This network produces output loss58
I0728 09:57:20.813951 20134 net.cpp:242] This network produces output loss59
I0728 09:57:20.813984 20134 net.cpp:242] This network produces output loss6
I0728 09:57:20.813995 20134 net.cpp:242] This network produces output loss60
I0728 09:57:20.814004 20134 net.cpp:242] This network produces output loss61
I0728 09:57:20.814013 20134 net.cpp:242] This network produces output loss62
I0728 09:57:20.814021 20134 net.cpp:242] This network produces output loss63
I0728 09:57:20.814069 20134 net.cpp:242] This network produces output loss64
I0728 09:57:20.814079 20134 net.cpp:242] This network produces output loss7
I0728 09:57:20.814087 20134 net.cpp:242] This network produces output loss8
I0728 09:57:20.814096 20134 net.cpp:242] This network produces output loss9
I0728 09:57:20.814489 20134 net.cpp:255] Network initialization done.
I0728 09:57:20.816615 20134 solver.cpp:173] Creating test net (#0) specified by net file: examples/crowd/code/shanghaiA/network_vgg_v1.prototxt
I0728 09:57:20.816807 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0728 09:57:20.816823 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0728 09:57:20.816869 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss1
I0728 09:57:20.816880 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss2
I0728 09:57:20.816890 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss3
I0728 09:57:20.816897 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss4
I0728 09:57:20.816906 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss5
I0728 09:57:20.816915 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss6
I0728 09:57:20.816925 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss7
I0728 09:57:20.816932 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss8
I0728 09:57:20.816941 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss9
I0728 09:57:20.816951 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss10
I0728 09:57:20.816958 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss11
I0728 09:57:20.816967 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss12
I0728 09:57:20.816977 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss13
I0728 09:57:20.816985 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss14
I0728 09:57:20.816993 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss15
I0728 09:57:20.817003 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss16
I0728 09:57:20.817011 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss17
I0728 09:57:20.817020 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss18
I0728 09:57:20.817029 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss19
I0728 09:57:20.817037 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss20
I0728 09:57:20.817046 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss21
I0728 09:57:20.817055 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss22
I0728 09:57:20.817064 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss23
I0728 09:57:20.817072 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss24
I0728 09:57:20.817081 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss25
I0728 09:57:20.817090 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss26
I0728 09:57:20.817122 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss27
I0728 09:57:20.817132 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss28
I0728 09:57:20.817140 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss29
I0728 09:57:20.817149 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss30
I0728 09:57:20.817158 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss31
I0728 09:57:20.817167 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss32
I0728 09:57:20.817175 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss33
I0728 09:57:20.817184 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss34
I0728 09:57:20.817193 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss35
I0728 09:57:20.817201 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss36
I0728 09:57:20.817210 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss37
I0728 09:57:20.817219 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss38
I0728 09:57:20.817227 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss39
I0728 09:57:20.817236 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss40
I0728 09:57:20.817245 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss41
I0728 09:57:20.817255 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss42
I0728 09:57:20.817262 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss43
I0728 09:57:20.817271 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss44
I0728 09:57:20.817279 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss45
I0728 09:57:20.817288 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss46
I0728 09:57:20.817297 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss47
I0728 09:57:20.817324 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss48
I0728 09:57:20.817335 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss49
I0728 09:57:20.817343 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss50
I0728 09:57:20.817353 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss51
I0728 09:57:20.817361 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss52
I0728 09:57:20.817370 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss53
I0728 09:57:20.817378 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss54
I0728 09:57:20.817387 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss55
I0728 09:57:20.817396 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss56
I0728 09:57:20.817404 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss57
I0728 09:57:20.817414 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss58
I0728 09:57:20.817436 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss59
I0728 09:57:20.817445 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss60
I0728 09:57:20.817454 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss61
I0728 09:57:20.817463 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss62
I0728 09:57:20.817471 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss63
I0728 09:57:20.817481 20134 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss64
I0728 09:57:20.818011 20134 net.cpp:51] Initializing net from parameters: 
name: "crowd_counting"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/image_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/dmap_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  param {
    lr_mult: 0.2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv_score"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv_score"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    group: 64
    stride: 1
    weight_filler {
      type: "constant"
      value: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_score"
  type: "ReLU"
  bottom: "conv_score"
  top: "conv_score"
}
layer {
  name: "slicer_conv"
  type: "Slice"
  bottom: "conv_score"
  top: "score1"
  top: "score2"
  top: "score3"
  top: "score4"
  top: "score5"
  top: "score6"
  top: "score7"
  top: "score8"
  top: "score9"
  top: "score10"
  top: "score11"
  top: "score12"
  top: "score13"
  top: "score14"
  top: "score15"
  top: "score16"
  top: "score17"
  top: "score18"
  top: "score19"
  top: "score20"
  top: "score21"
  top: "score22"
  top: "score23"
  top: "score24"
  top: "score25"
  top: "score26"
  top: "score27"
  top: "score28"
  top: "score29"
  top: "score30"
  top: "score31"
  top: "score32"
  top: "score33"
  top: "score34"
  top: "score35"
  top: "score36"
  top: "score37"
  top: "score38"
  top: "score39"
  top: "score40"
  top: "score41"
  top: "score42"
  top: "score43"
  top: "score44"
  top: "score45"
  top: "score46"
  top: "score47"
  top: "score48"
  top: "score49"
  top: "score50"
  top: "score51"
  top: "score52"
  top: "score53"
  top: "score54"
  top: "score55"
  top: "score56"
  top: "score57"
  top: "score58"
  top: "score59"
  top: "score60"
  top: "score61"
  top: "score62"
  top: "score63"
  top: "score64"
  slice_param {
    axis: 1
  }
}
layer {
  name: "sumscore"
  type: "Eltwise"
  bottom: "score1"
  bottom: "score2"
  bottom: "score3"
  bottom: "score4"
  bottom: "score5"
  bottom: "score6"
  bottom: "score7"
  bottom: "score8"
  bottom: "score9"
  bottom: "score10"
  bottom: "score11"
  bottom: "score12"
  bottom: "score13"
  bottom: "score14"
  bottom: "score15"
  bottom: "score16"
  bottom: "score17"
  bottom: "score18"
  bottom: "score19"
  bottom: "score20"
  bottom: "score21"
  bottom: "score22"
  bottom: "score23"
  bottom: "score24"
  bottom: "score25"
  bottom: "score26"
  bottom: "score27"
  bottom: "score28"
  bottom: "score29"
  bottom: "score30"
  bottom: "score31"
  bottom: "score32"
  bottom: "score33"
  bottom: "score34"
  bottom: "score35"
  bottom: "score36"
  bottom: "score37"
  bottom: "score38"
  bottom: "score39"
  bottom: "score40"
  bottom: "score41"
  bottom: "score42"
  bottom: "score43"
  bottom: "score44"
  bottom: "score45"
  bottom: "score46"
  bottom: "score47"
  bottom: "score48"
  bottom: "score49"
  bottom: "score50"
  bottom: "score51"
  bottom: "score52"
  bottom: "score53"
  bottom: "score54"
  bottom: "score55"
  bottom: "score56"
  bottom: "score57"
  bottom: "score58"
  bottom: "score59"
  bottom: "score60"
  bottom: "score61"
  bottom: "score62"
  bottom: "score63"
  bottom: "score64"
  top: "sumscore"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "avgscore"
  type: "Power"
  bottom: "sumscore"
  top: "avgscore"
  include {
    phase: TEST
  }
  power_param {
    power: 1
    scale: 0.015625
    shift: 0
  }
}
layer {
  name: "mae"
  type: "MAELoss"
  bottom: "avgscore"
  bottom: "label"
  top: "mae"
  include {
    phase: TEST
  }
}
layer {
  name: "mse"
  type: "MSELoss"
  bottom: "avgscore"
  bottom: "label"
  top: "mse"
  include {
    phase: TEST
  }
}
I0728 09:57:20.818925 20134 layer_factory.hpp:77] Creating layer data
I0728 09:57:20.819046 20134 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/image_lmdb
I0728 09:57:20.819087 20134 net.cpp:84] Creating Layer data
I0728 09:57:20.819100 20134 net.cpp:380] data -> data
I0728 09:57:20.822918 20134 data_layer.cpp:45] output data size: 1,3,704,1024
I0728 09:57:20.848795 20134 net.cpp:122] Setting up data
I0728 09:57:20.848839 20134 net.cpp:129] Top shape: 1 3 704 1024 (2162688)
I0728 09:57:20.848847 20134 net.cpp:137] Memory required for data: 8650752
I0728 09:57:20.848858 20134 layer_factory.hpp:77] Creating layer label
I0728 09:57:20.850539 20134 db_lmdb.cpp:35] Opened lmdb /home/peiyong/Work/Zenglin/szl/ShanghaiTech/partA/test_8/dmap_lmdb
I0728 09:57:20.850620 20134 net.cpp:84] Creating Layer label
I0728 09:57:20.850638 20134 net.cpp:380] label -> label
I0728 09:57:20.850965 20134 data_layer.cpp:45] output data size: 1,1,88,128
I0728 09:57:20.851251 20134 net.cpp:122] Setting up label
I0728 09:57:20.851272 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:20.851279 20134 net.cpp:137] Memory required for data: 8695808
I0728 09:57:20.851285 20134 layer_factory.hpp:77] Creating layer label_label_0_split
I0728 09:57:20.851300 20134 net.cpp:84] Creating Layer label_label_0_split
I0728 09:57:20.851308 20134 net.cpp:406] label_label_0_split <- label
I0728 09:57:20.851320 20134 net.cpp:380] label_label_0_split -> label_label_0_split_0
I0728 09:57:20.851336 20134 net.cpp:380] label_label_0_split -> label_label_0_split_1
I0728 09:57:20.851536 20134 net.cpp:122] Setting up label_label_0_split
I0728 09:57:20.851552 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:20.851562 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:20.851568 20134 net.cpp:137] Memory required for data: 8785920
I0728 09:57:20.851575 20134 layer_factory.hpp:77] Creating layer conv1_1
I0728 09:57:20.851596 20134 net.cpp:84] Creating Layer conv1_1
I0728 09:57:20.851604 20134 net.cpp:406] conv1_1 <- data
I0728 09:57:20.851615 20134 net.cpp:380] conv1_1 -> conv1_1
I0728 09:57:20.859024 20134 net.cpp:122] Setting up conv1_1
I0728 09:57:20.859061 20134 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0728 09:57:20.859068 20134 net.cpp:137] Memory required for data: 193335296
I0728 09:57:20.859089 20134 layer_factory.hpp:77] Creating layer relu1_1
I0728 09:57:20.859108 20134 net.cpp:84] Creating Layer relu1_1
I0728 09:57:20.859117 20134 net.cpp:406] relu1_1 <- conv1_1
I0728 09:57:20.859127 20134 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0728 09:57:20.860236 20134 net.cpp:122] Setting up relu1_1
I0728 09:57:20.860258 20134 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0728 09:57:20.860265 20134 net.cpp:137] Memory required for data: 377884672
I0728 09:57:20.860273 20134 layer_factory.hpp:77] Creating layer conv1_2
I0728 09:57:20.860293 20134 net.cpp:84] Creating Layer conv1_2
I0728 09:57:20.860301 20134 net.cpp:406] conv1_2 <- conv1_1
I0728 09:57:20.860313 20134 net.cpp:380] conv1_2 -> conv1_2
I0728 09:57:20.867449 20134 net.cpp:122] Setting up conv1_2
I0728 09:57:20.867475 20134 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0728 09:57:20.867482 20134 net.cpp:137] Memory required for data: 562434048
I0728 09:57:20.867513 20134 layer_factory.hpp:77] Creating layer relu1_2
I0728 09:57:20.867527 20134 net.cpp:84] Creating Layer relu1_2
I0728 09:57:20.867534 20134 net.cpp:406] relu1_2 <- conv1_2
I0728 09:57:20.867544 20134 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0728 09:57:20.867862 20134 net.cpp:122] Setting up relu1_2
I0728 09:57:20.867880 20134 net.cpp:129] Top shape: 1 64 704 1024 (46137344)
I0728 09:57:20.867887 20134 net.cpp:137] Memory required for data: 746983424
I0728 09:57:20.867894 20134 layer_factory.hpp:77] Creating layer pool1
I0728 09:57:20.867907 20134 net.cpp:84] Creating Layer pool1
I0728 09:57:20.867913 20134 net.cpp:406] pool1 <- conv1_2
I0728 09:57:20.867924 20134 net.cpp:380] pool1 -> pool1
I0728 09:57:20.868024 20134 net.cpp:122] Setting up pool1
I0728 09:57:20.868037 20134 net.cpp:129] Top shape: 1 64 352 512 (11534336)
I0728 09:57:20.868044 20134 net.cpp:137] Memory required for data: 793120768
I0728 09:57:20.868052 20134 layer_factory.hpp:77] Creating layer conv2_1
I0728 09:57:20.868069 20134 net.cpp:84] Creating Layer conv2_1
I0728 09:57:20.868077 20134 net.cpp:406] conv2_1 <- pool1
I0728 09:57:20.868088 20134 net.cpp:380] conv2_1 -> conv2_1
I0728 09:57:20.873652 20134 net.cpp:122] Setting up conv2_1
I0728 09:57:20.873678 20134 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0728 09:57:20.873685 20134 net.cpp:137] Memory required for data: 885395456
I0728 09:57:20.873703 20134 layer_factory.hpp:77] Creating layer relu2_1
I0728 09:57:20.873713 20134 net.cpp:84] Creating Layer relu2_1
I0728 09:57:20.873754 20134 net.cpp:406] relu2_1 <- conv2_1
I0728 09:57:20.873766 20134 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0728 09:57:20.874788 20134 net.cpp:122] Setting up relu2_1
I0728 09:57:20.874809 20134 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0728 09:57:20.874815 20134 net.cpp:137] Memory required for data: 977670144
I0728 09:57:20.874824 20134 layer_factory.hpp:77] Creating layer conv2_2
I0728 09:57:20.874840 20134 net.cpp:84] Creating Layer conv2_2
I0728 09:57:20.874846 20134 net.cpp:406] conv2_2 <- conv2_1
I0728 09:57:20.874858 20134 net.cpp:380] conv2_2 -> conv2_2
I0728 09:57:20.881458 20134 net.cpp:122] Setting up conv2_2
I0728 09:57:20.881482 20134 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0728 09:57:20.881489 20134 net.cpp:137] Memory required for data: 1069944832
I0728 09:57:20.881502 20134 layer_factory.hpp:77] Creating layer relu2_2
I0728 09:57:20.881513 20134 net.cpp:84] Creating Layer relu2_2
I0728 09:57:20.881520 20134 net.cpp:406] relu2_2 <- conv2_2
I0728 09:57:20.881531 20134 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0728 09:57:20.883203 20134 net.cpp:122] Setting up relu2_2
I0728 09:57:20.883224 20134 net.cpp:129] Top shape: 1 128 352 512 (23068672)
I0728 09:57:20.883230 20134 net.cpp:137] Memory required for data: 1162219520
I0728 09:57:20.883237 20134 layer_factory.hpp:77] Creating layer pool2
I0728 09:57:20.883249 20134 net.cpp:84] Creating Layer pool2
I0728 09:57:20.883255 20134 net.cpp:406] pool2 <- conv2_2
I0728 09:57:20.883265 20134 net.cpp:380] pool2 -> pool2
I0728 09:57:20.883358 20134 net.cpp:122] Setting up pool2
I0728 09:57:20.883370 20134 net.cpp:129] Top shape: 1 128 176 256 (5767168)
I0728 09:57:20.883376 20134 net.cpp:137] Memory required for data: 1185288192
I0728 09:57:20.883383 20134 layer_factory.hpp:77] Creating layer conv3_1
I0728 09:57:20.883396 20134 net.cpp:84] Creating Layer conv3_1
I0728 09:57:20.883402 20134 net.cpp:406] conv3_1 <- pool2
I0728 09:57:20.883412 20134 net.cpp:380] conv3_1 -> conv3_1
I0728 09:57:20.891955 20134 net.cpp:122] Setting up conv3_1
I0728 09:57:20.891986 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.891993 20134 net.cpp:137] Memory required for data: 1231425536
I0728 09:57:20.892011 20134 layer_factory.hpp:77] Creating layer relu3_1
I0728 09:57:20.892024 20134 net.cpp:84] Creating Layer relu3_1
I0728 09:57:20.892031 20134 net.cpp:406] relu3_1 <- conv3_1
I0728 09:57:20.892041 20134 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0728 09:57:20.892329 20134 net.cpp:122] Setting up relu3_1
I0728 09:57:20.892345 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.892351 20134 net.cpp:137] Memory required for data: 1277562880
I0728 09:57:20.892359 20134 layer_factory.hpp:77] Creating layer conv3_2
I0728 09:57:20.892374 20134 net.cpp:84] Creating Layer conv3_2
I0728 09:57:20.892380 20134 net.cpp:406] conv3_2 <- conv3_1
I0728 09:57:20.892390 20134 net.cpp:380] conv3_2 -> conv3_2
I0728 09:57:20.905122 20134 net.cpp:122] Setting up conv3_2
I0728 09:57:20.905158 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.905165 20134 net.cpp:137] Memory required for data: 1323700224
I0728 09:57:20.905179 20134 layer_factory.hpp:77] Creating layer relu3_2
I0728 09:57:20.905202 20134 net.cpp:84] Creating Layer relu3_2
I0728 09:57:20.905210 20134 net.cpp:406] relu3_2 <- conv3_2
I0728 09:57:20.905220 20134 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0728 09:57:20.906163 20134 net.cpp:122] Setting up relu3_2
I0728 09:57:20.906183 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.906189 20134 net.cpp:137] Memory required for data: 1369837568
I0728 09:57:20.906195 20134 layer_factory.hpp:77] Creating layer conv3_3
I0728 09:57:20.906211 20134 net.cpp:84] Creating Layer conv3_3
I0728 09:57:20.906219 20134 net.cpp:406] conv3_3 <- conv3_2
I0728 09:57:20.906229 20134 net.cpp:380] conv3_3 -> conv3_3
I0728 09:57:20.918089 20134 net.cpp:122] Setting up conv3_3
I0728 09:57:20.918110 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.918148 20134 net.cpp:137] Memory required for data: 1415974912
I0728 09:57:20.918159 20134 layer_factory.hpp:77] Creating layer relu3_3
I0728 09:57:20.918169 20134 net.cpp:84] Creating Layer relu3_3
I0728 09:57:20.918175 20134 net.cpp:406] relu3_3 <- conv3_3
I0728 09:57:20.918184 20134 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0728 09:57:20.919052 20134 net.cpp:122] Setting up relu3_3
I0728 09:57:20.919071 20134 net.cpp:129] Top shape: 1 256 176 256 (11534336)
I0728 09:57:20.919078 20134 net.cpp:137] Memory required for data: 1462112256
I0728 09:57:20.919085 20134 layer_factory.hpp:77] Creating layer pool3
I0728 09:57:20.919095 20134 net.cpp:84] Creating Layer pool3
I0728 09:57:20.919101 20134 net.cpp:406] pool3 <- conv3_3
I0728 09:57:20.919111 20134 net.cpp:380] pool3 -> pool3
I0728 09:57:20.919198 20134 net.cpp:122] Setting up pool3
I0728 09:57:20.919209 20134 net.cpp:129] Top shape: 1 256 88 128 (2883584)
I0728 09:57:20.919215 20134 net.cpp:137] Memory required for data: 1473646592
I0728 09:57:20.919220 20134 layer_factory.hpp:77] Creating layer conv4_1
I0728 09:57:20.919232 20134 net.cpp:84] Creating Layer conv4_1
I0728 09:57:20.919239 20134 net.cpp:406] conv4_1 <- pool3
I0728 09:57:20.919248 20134 net.cpp:380] conv4_1 -> conv4_1
I0728 09:57:20.938832 20134 net.cpp:122] Setting up conv4_1
I0728 09:57:20.938863 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:20.938869 20134 net.cpp:137] Memory required for data: 1496715264
I0728 09:57:20.938881 20134 layer_factory.hpp:77] Creating layer relu4_1
I0728 09:57:20.938891 20134 net.cpp:84] Creating Layer relu4_1
I0728 09:57:20.938899 20134 net.cpp:406] relu4_1 <- conv4_1
I0728 09:57:20.938907 20134 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0728 09:57:20.939164 20134 net.cpp:122] Setting up relu4_1
I0728 09:57:20.939180 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:20.939187 20134 net.cpp:137] Memory required for data: 1519783936
I0728 09:57:20.939193 20134 layer_factory.hpp:77] Creating layer conv4_2
I0728 09:57:20.939206 20134 net.cpp:84] Creating Layer conv4_2
I0728 09:57:20.939213 20134 net.cpp:406] conv4_2 <- conv4_1
I0728 09:57:20.939223 20134 net.cpp:380] conv4_2 -> conv4_2
I0728 09:57:20.972391 20134 net.cpp:122] Setting up conv4_2
I0728 09:57:20.972427 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:20.972434 20134 net.cpp:137] Memory required for data: 1542852608
I0728 09:57:20.972451 20134 layer_factory.hpp:77] Creating layer relu4_2
I0728 09:57:20.972465 20134 net.cpp:84] Creating Layer relu4_2
I0728 09:57:20.972471 20134 net.cpp:406] relu4_2 <- conv4_2
I0728 09:57:20.972481 20134 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0728 09:57:20.973256 20134 net.cpp:122] Setting up relu4_2
I0728 09:57:20.973274 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:20.973279 20134 net.cpp:137] Memory required for data: 1565921280
I0728 09:57:20.973285 20134 layer_factory.hpp:77] Creating layer conv4_3
I0728 09:57:20.973299 20134 net.cpp:84] Creating Layer conv4_3
I0728 09:57:20.973315 20134 net.cpp:406] conv4_3 <- conv4_2
I0728 09:57:20.973325 20134 net.cpp:380] conv4_3 -> conv4_3
I0728 09:57:21.002846 20134 net.cpp:122] Setting up conv4_3
I0728 09:57:21.002879 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.002884 20134 net.cpp:137] Memory required for data: 1588989952
I0728 09:57:21.002897 20134 layer_factory.hpp:77] Creating layer relu4_3
I0728 09:57:21.002907 20134 net.cpp:84] Creating Layer relu4_3
I0728 09:57:21.002913 20134 net.cpp:406] relu4_3 <- conv4_3
I0728 09:57:21.002923 20134 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0728 09:57:21.003643 20134 net.cpp:122] Setting up relu4_3
I0728 09:57:21.003659 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.003662 20134 net.cpp:137] Memory required for data: 1612058624
I0728 09:57:21.003665 20134 layer_factory.hpp:77] Creating layer pool4
I0728 09:57:21.003672 20134 net.cpp:84] Creating Layer pool4
I0728 09:57:21.003677 20134 net.cpp:406] pool4 <- conv4_3
I0728 09:57:21.003685 20134 net.cpp:380] pool4 -> pool4
I0728 09:57:21.003801 20134 net.cpp:122] Setting up pool4
I0728 09:57:21.003813 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.003818 20134 net.cpp:137] Memory required for data: 1635127296
I0728 09:57:21.003823 20134 layer_factory.hpp:77] Creating layer conv5_1
I0728 09:57:21.003835 20134 net.cpp:84] Creating Layer conv5_1
I0728 09:57:21.003840 20134 net.cpp:406] conv5_1 <- pool4
I0728 09:57:21.003849 20134 net.cpp:380] conv5_1 -> conv5_1
I0728 09:57:21.029106 20134 net.cpp:122] Setting up conv5_1
I0728 09:57:21.029127 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.029131 20134 net.cpp:137] Memory required for data: 1658195968
I0728 09:57:21.029140 20134 layer_factory.hpp:77] Creating layer relu5_1
I0728 09:57:21.029147 20134 net.cpp:84] Creating Layer relu5_1
I0728 09:57:21.029153 20134 net.cpp:406] relu5_1 <- conv5_1
I0728 09:57:21.029160 20134 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0728 09:57:21.029395 20134 net.cpp:122] Setting up relu5_1
I0728 09:57:21.029407 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.029412 20134 net.cpp:137] Memory required for data: 1681264640
I0728 09:57:21.029417 20134 layer_factory.hpp:77] Creating layer conv5_2
I0728 09:57:21.029428 20134 net.cpp:84] Creating Layer conv5_2
I0728 09:57:21.029433 20134 net.cpp:406] conv5_2 <- conv5_1
I0728 09:57:21.029440 20134 net.cpp:380] conv5_2 -> conv5_2
I0728 09:57:21.053678 20134 net.cpp:122] Setting up conv5_2
I0728 09:57:21.053709 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.053712 20134 net.cpp:137] Memory required for data: 1704333312
I0728 09:57:21.053722 20134 layer_factory.hpp:77] Creating layer relu5_2
I0728 09:57:21.053732 20134 net.cpp:84] Creating Layer relu5_2
I0728 09:57:21.053738 20134 net.cpp:406] relu5_2 <- conv5_2
I0728 09:57:21.053745 20134 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0728 09:57:21.054538 20134 net.cpp:122] Setting up relu5_2
I0728 09:57:21.054551 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.054556 20134 net.cpp:137] Memory required for data: 1727401984
I0728 09:57:21.054561 20134 layer_factory.hpp:77] Creating layer conv5_3
I0728 09:57:21.054574 20134 net.cpp:84] Creating Layer conv5_3
I0728 09:57:21.054577 20134 net.cpp:406] conv5_3 <- conv5_2
I0728 09:57:21.054585 20134 net.cpp:380] conv5_3 -> conv5_3
I0728 09:57:21.076956 20134 net.cpp:122] Setting up conv5_3
I0728 09:57:21.076974 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.076978 20134 net.cpp:137] Memory required for data: 1750470656
I0728 09:57:21.076987 20134 layer_factory.hpp:77] Creating layer relu5_3
I0728 09:57:21.076997 20134 net.cpp:84] Creating Layer relu5_3
I0728 09:57:21.077003 20134 net.cpp:406] relu5_3 <- conv5_3
I0728 09:57:21.077008 20134 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0728 09:57:21.077213 20134 net.cpp:122] Setting up relu5_3
I0728 09:57:21.077224 20134 net.cpp:129] Top shape: 1 512 88 128 (5767168)
I0728 09:57:21.077229 20134 net.cpp:137] Memory required for data: 1773539328
I0728 09:57:21.077231 20134 layer_factory.hpp:77] Creating layer conv_score
I0728 09:57:21.077241 20134 net.cpp:84] Creating Layer conv_score
I0728 09:57:21.077245 20134 net.cpp:406] conv_score <- conv5_3
I0728 09:57:21.077252 20134 net.cpp:380] conv_score -> conv_score
I0728 09:57:21.161170 20134 net.cpp:122] Setting up conv_score
I0728 09:57:21.161200 20134 net.cpp:129] Top shape: 1 64 88 128 (720896)
I0728 09:57:21.161203 20134 net.cpp:137] Memory required for data: 1776422912
I0728 09:57:21.161213 20134 layer_factory.hpp:77] Creating layer relu_score
I0728 09:57:21.161222 20134 net.cpp:84] Creating Layer relu_score
I0728 09:57:21.161227 20134 net.cpp:406] relu_score <- conv_score
I0728 09:57:21.161237 20134 net.cpp:367] relu_score -> conv_score (in-place)
I0728 09:57:21.161449 20134 net.cpp:122] Setting up relu_score
I0728 09:57:21.161460 20134 net.cpp:129] Top shape: 1 64 88 128 (720896)
I0728 09:57:21.161464 20134 net.cpp:137] Memory required for data: 1779306496
I0728 09:57:21.161468 20134 layer_factory.hpp:77] Creating layer slicer_conv
I0728 09:57:21.161514 20134 net.cpp:84] Creating Layer slicer_conv
I0728 09:57:21.161520 20134 net.cpp:406] slicer_conv <- conv_score
I0728 09:57:21.161531 20134 net.cpp:380] slicer_conv -> score1
I0728 09:57:21.161543 20134 net.cpp:380] slicer_conv -> score2
I0728 09:57:21.161552 20134 net.cpp:380] slicer_conv -> score3
I0728 09:57:21.161561 20134 net.cpp:380] slicer_conv -> score4
I0728 09:57:21.161571 20134 net.cpp:380] slicer_conv -> score5
I0728 09:57:21.161578 20134 net.cpp:380] slicer_conv -> score6
I0728 09:57:21.161586 20134 net.cpp:380] slicer_conv -> score7
I0728 09:57:21.161597 20134 net.cpp:380] slicer_conv -> score8
I0728 09:57:21.161605 20134 net.cpp:380] slicer_conv -> score9
I0728 09:57:21.161613 20134 net.cpp:380] slicer_conv -> score10
I0728 09:57:21.161623 20134 net.cpp:380] slicer_conv -> score11
I0728 09:57:21.161638 20134 net.cpp:380] slicer_conv -> score12
I0728 09:57:21.161646 20134 net.cpp:380] slicer_conv -> score13
I0728 09:57:21.161654 20134 net.cpp:380] slicer_conv -> score14
I0728 09:57:21.161664 20134 net.cpp:380] slicer_conv -> score15
I0728 09:57:21.161671 20134 net.cpp:380] slicer_conv -> score16
I0728 09:57:21.161680 20134 net.cpp:380] slicer_conv -> score17
I0728 09:57:21.161689 20134 net.cpp:380] slicer_conv -> score18
I0728 09:57:21.161697 20134 net.cpp:380] slicer_conv -> score19
I0728 09:57:21.161706 20134 net.cpp:380] slicer_conv -> score20
I0728 09:57:21.161715 20134 net.cpp:380] slicer_conv -> score21
I0728 09:57:21.161723 20134 net.cpp:380] slicer_conv -> score22
I0728 09:57:21.161731 20134 net.cpp:380] slicer_conv -> score23
I0728 09:57:21.161741 20134 net.cpp:380] slicer_conv -> score24
I0728 09:57:21.161751 20134 net.cpp:380] slicer_conv -> score25
I0728 09:57:21.161758 20134 net.cpp:380] slicer_conv -> score26
I0728 09:57:21.161767 20134 net.cpp:380] slicer_conv -> score27
I0728 09:57:21.161775 20134 net.cpp:380] slicer_conv -> score28
I0728 09:57:21.161784 20134 net.cpp:380] slicer_conv -> score29
I0728 09:57:21.161794 20134 net.cpp:380] slicer_conv -> score30
I0728 09:57:21.161803 20134 net.cpp:380] slicer_conv -> score31
I0728 09:57:21.161813 20134 net.cpp:380] slicer_conv -> score32
I0728 09:57:21.161821 20134 net.cpp:380] slicer_conv -> score33
I0728 09:57:21.161830 20134 net.cpp:380] slicer_conv -> score34
I0728 09:57:21.161839 20134 net.cpp:380] slicer_conv -> score35
I0728 09:57:21.161847 20134 net.cpp:380] slicer_conv -> score36
I0728 09:57:21.161857 20134 net.cpp:380] slicer_conv -> score37
I0728 09:57:21.161866 20134 net.cpp:380] slicer_conv -> score38
I0728 09:57:21.161875 20134 net.cpp:380] slicer_conv -> score39
I0728 09:57:21.161883 20134 net.cpp:380] slicer_conv -> score40
I0728 09:57:21.161891 20134 net.cpp:380] slicer_conv -> score41
I0728 09:57:21.161900 20134 net.cpp:380] slicer_conv -> score42
I0728 09:57:21.161909 20134 net.cpp:380] slicer_conv -> score43
I0728 09:57:21.161923 20134 net.cpp:380] slicer_conv -> score44
I0728 09:57:21.161932 20134 net.cpp:380] slicer_conv -> score45
I0728 09:57:21.161942 20134 net.cpp:380] slicer_conv -> score46
I0728 09:57:21.161949 20134 net.cpp:380] slicer_conv -> score47
I0728 09:57:21.161958 20134 net.cpp:380] slicer_conv -> score48
I0728 09:57:21.161967 20134 net.cpp:380] slicer_conv -> score49
I0728 09:57:21.161975 20134 net.cpp:380] slicer_conv -> score50
I0728 09:57:21.161984 20134 net.cpp:380] slicer_conv -> score51
I0728 09:57:21.161993 20134 net.cpp:380] slicer_conv -> score52
I0728 09:57:21.162003 20134 net.cpp:380] slicer_conv -> score53
I0728 09:57:21.162011 20134 net.cpp:380] slicer_conv -> score54
I0728 09:57:21.162020 20134 net.cpp:380] slicer_conv -> score55
I0728 09:57:21.162029 20134 net.cpp:380] slicer_conv -> score56
I0728 09:57:21.162037 20134 net.cpp:380] slicer_conv -> score57
I0728 09:57:21.162045 20134 net.cpp:380] slicer_conv -> score58
I0728 09:57:21.162055 20134 net.cpp:380] slicer_conv -> score59
I0728 09:57:21.162062 20134 net.cpp:380] slicer_conv -> score60
I0728 09:57:21.162071 20134 net.cpp:380] slicer_conv -> score61
I0728 09:57:21.162080 20134 net.cpp:380] slicer_conv -> score62
I0728 09:57:21.162099 20134 net.cpp:380] slicer_conv -> score63
I0728 09:57:21.162108 20134 net.cpp:380] slicer_conv -> score64
I0728 09:57:21.163458 20134 net.cpp:122] Setting up slicer_conv
I0728 09:57:21.163468 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163473 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163478 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163482 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163486 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163488 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163491 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163494 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163497 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163499 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163503 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163506 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163527 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163529 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163538 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163542 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163547 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163552 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163555 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163559 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163564 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163568 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163573 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163578 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163581 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163586 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163590 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163594 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163599 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163604 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163607 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163612 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163616 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163620 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163625 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163630 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163633 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163637 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163642 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163646 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163650 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163655 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163661 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163664 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163669 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163673 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163677 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163683 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163687 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163692 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163697 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163702 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163705 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163709 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163714 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163729 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163734 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163738 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163743 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163748 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163753 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163756 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163760 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163764 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.163769 20134 net.cpp:137] Memory required for data: 1782190080
I0728 09:57:21.163772 20134 layer_factory.hpp:77] Creating layer sumscore
I0728 09:57:21.163785 20134 net.cpp:84] Creating Layer sumscore
I0728 09:57:21.163790 20134 net.cpp:406] sumscore <- score1
I0728 09:57:21.163795 20134 net.cpp:406] sumscore <- score2
I0728 09:57:21.163800 20134 net.cpp:406] sumscore <- score3
I0728 09:57:21.163805 20134 net.cpp:406] sumscore <- score4
I0728 09:57:21.163810 20134 net.cpp:406] sumscore <- score5
I0728 09:57:21.163813 20134 net.cpp:406] sumscore <- score6
I0728 09:57:21.163817 20134 net.cpp:406] sumscore <- score7
I0728 09:57:21.163821 20134 net.cpp:406] sumscore <- score8
I0728 09:57:21.163825 20134 net.cpp:406] sumscore <- score9
I0728 09:57:21.163830 20134 net.cpp:406] sumscore <- score10
I0728 09:57:21.163835 20134 net.cpp:406] sumscore <- score11
I0728 09:57:21.163838 20134 net.cpp:406] sumscore <- score12
I0728 09:57:21.163842 20134 net.cpp:406] sumscore <- score13
I0728 09:57:21.163846 20134 net.cpp:406] sumscore <- score14
I0728 09:57:21.163851 20134 net.cpp:406] sumscore <- score15
I0728 09:57:21.163854 20134 net.cpp:406] sumscore <- score16
I0728 09:57:21.163858 20134 net.cpp:406] sumscore <- score17
I0728 09:57:21.163863 20134 net.cpp:406] sumscore <- score18
I0728 09:57:21.163867 20134 net.cpp:406] sumscore <- score19
I0728 09:57:21.163872 20134 net.cpp:406] sumscore <- score20
I0728 09:57:21.163875 20134 net.cpp:406] sumscore <- score21
I0728 09:57:21.163879 20134 net.cpp:406] sumscore <- score22
I0728 09:57:21.163884 20134 net.cpp:406] sumscore <- score23
I0728 09:57:21.163887 20134 net.cpp:406] sumscore <- score24
I0728 09:57:21.163892 20134 net.cpp:406] sumscore <- score25
I0728 09:57:21.163895 20134 net.cpp:406] sumscore <- score26
I0728 09:57:21.163899 20134 net.cpp:406] sumscore <- score27
I0728 09:57:21.163903 20134 net.cpp:406] sumscore <- score28
I0728 09:57:21.163908 20134 net.cpp:406] sumscore <- score29
I0728 09:57:21.163911 20134 net.cpp:406] sumscore <- score30
I0728 09:57:21.163915 20134 net.cpp:406] sumscore <- score31
I0728 09:57:21.163920 20134 net.cpp:406] sumscore <- score32
I0728 09:57:21.163924 20134 net.cpp:406] sumscore <- score33
I0728 09:57:21.163928 20134 net.cpp:406] sumscore <- score34
I0728 09:57:21.163933 20134 net.cpp:406] sumscore <- score35
I0728 09:57:21.163936 20134 net.cpp:406] sumscore <- score36
I0728 09:57:21.163940 20134 net.cpp:406] sumscore <- score37
I0728 09:57:21.163944 20134 net.cpp:406] sumscore <- score38
I0728 09:57:21.163947 20134 net.cpp:406] sumscore <- score39
I0728 09:57:21.163951 20134 net.cpp:406] sumscore <- score40
I0728 09:57:21.163955 20134 net.cpp:406] sumscore <- score41
I0728 09:57:21.163959 20134 net.cpp:406] sumscore <- score42
I0728 09:57:21.163964 20134 net.cpp:406] sumscore <- score43
I0728 09:57:21.163967 20134 net.cpp:406] sumscore <- score44
I0728 09:57:21.163971 20134 net.cpp:406] sumscore <- score45
I0728 09:57:21.163975 20134 net.cpp:406] sumscore <- score46
I0728 09:57:21.163980 20134 net.cpp:406] sumscore <- score47
I0728 09:57:21.163983 20134 net.cpp:406] sumscore <- score48
I0728 09:57:21.163987 20134 net.cpp:406] sumscore <- score49
I0728 09:57:21.163992 20134 net.cpp:406] sumscore <- score50
I0728 09:57:21.163996 20134 net.cpp:406] sumscore <- score51
I0728 09:57:21.164000 20134 net.cpp:406] sumscore <- score52
I0728 09:57:21.164005 20134 net.cpp:406] sumscore <- score53
I0728 09:57:21.164016 20134 net.cpp:406] sumscore <- score54
I0728 09:57:21.164019 20134 net.cpp:406] sumscore <- score55
I0728 09:57:21.164023 20134 net.cpp:406] sumscore <- score56
I0728 09:57:21.164027 20134 net.cpp:406] sumscore <- score57
I0728 09:57:21.164031 20134 net.cpp:406] sumscore <- score58
I0728 09:57:21.164036 20134 net.cpp:406] sumscore <- score59
I0728 09:57:21.164039 20134 net.cpp:406] sumscore <- score60
I0728 09:57:21.164043 20134 net.cpp:406] sumscore <- score61
I0728 09:57:21.164047 20134 net.cpp:406] sumscore <- score62
I0728 09:57:21.164050 20134 net.cpp:406] sumscore <- score63
I0728 09:57:21.164054 20134 net.cpp:406] sumscore <- score64
I0728 09:57:21.164064 20134 net.cpp:380] sumscore -> sumscore
I0728 09:57:21.164116 20134 net.cpp:122] Setting up sumscore
I0728 09:57:21.164126 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.164130 20134 net.cpp:137] Memory required for data: 1782235136
I0728 09:57:21.164134 20134 layer_factory.hpp:77] Creating layer avgscore
I0728 09:57:21.164141 20134 net.cpp:84] Creating Layer avgscore
I0728 09:57:21.164145 20134 net.cpp:406] avgscore <- sumscore
I0728 09:57:21.164151 20134 net.cpp:380] avgscore -> avgscore
I0728 09:57:21.164197 20134 net.cpp:122] Setting up avgscore
I0728 09:57:21.164206 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.164209 20134 net.cpp:137] Memory required for data: 1782280192
I0728 09:57:21.164213 20134 layer_factory.hpp:77] Creating layer avgscore_avgscore_0_split
I0728 09:57:21.164221 20134 net.cpp:84] Creating Layer avgscore_avgscore_0_split
I0728 09:57:21.164224 20134 net.cpp:406] avgscore_avgscore_0_split <- avgscore
I0728 09:57:21.164230 20134 net.cpp:380] avgscore_avgscore_0_split -> avgscore_avgscore_0_split_0
I0728 09:57:21.164237 20134 net.cpp:380] avgscore_avgscore_0_split -> avgscore_avgscore_0_split_1
I0728 09:57:21.164306 20134 net.cpp:122] Setting up avgscore_avgscore_0_split
I0728 09:57:21.164314 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.164319 20134 net.cpp:129] Top shape: 1 1 88 128 (11264)
I0728 09:57:21.164321 20134 net.cpp:137] Memory required for data: 1782370304
I0728 09:57:21.164325 20134 layer_factory.hpp:77] Creating layer mae
I0728 09:57:21.164333 20134 net.cpp:84] Creating Layer mae
I0728 09:57:21.164337 20134 net.cpp:406] mae <- avgscore_avgscore_0_split_0
I0728 09:57:21.164342 20134 net.cpp:406] mae <- label_label_0_split_0
I0728 09:57:21.164347 20134 net.cpp:380] mae -> mae
I0728 09:57:21.164417 20134 net.cpp:122] Setting up mae
I0728 09:57:21.164425 20134 net.cpp:129] Top shape: (1)
I0728 09:57:21.164428 20134 net.cpp:132]     with loss weight 1
I0728 09:57:21.164439 20134 net.cpp:137] Memory required for data: 1782370308
I0728 09:57:21.164445 20134 layer_factory.hpp:77] Creating layer mse
I0728 09:57:21.164451 20134 net.cpp:84] Creating Layer mse
I0728 09:57:21.164456 20134 net.cpp:406] mse <- avgscore_avgscore_0_split_1
I0728 09:57:21.164461 20134 net.cpp:406] mse <- label_label_0_split_1
I0728 09:57:21.164469 20134 net.cpp:380] mse -> mse
I0728 09:57:21.164539 20134 net.cpp:122] Setting up mse
I0728 09:57:21.164546 20134 net.cpp:129] Top shape: (1)
I0728 09:57:21.164551 20134 net.cpp:132]     with loss weight 1
I0728 09:57:21.164556 20134 net.cpp:137] Memory required for data: 1782370312
I0728 09:57:21.164561 20134 net.cpp:198] mse needs backward computation.
I0728 09:57:21.164566 20134 net.cpp:198] mae needs backward computation.
I0728 09:57:21.164571 20134 net.cpp:198] avgscore_avgscore_0_split needs backward computation.
I0728 09:57:21.164574 20134 net.cpp:198] avgscore needs backward computation.
I0728 09:57:21.164578 20134 net.cpp:198] sumscore needs backward computation.
I0728 09:57:21.164598 20134 net.cpp:198] slicer_conv needs backward computation.
I0728 09:57:21.164602 20134 net.cpp:198] relu_score needs backward computation.
I0728 09:57:21.164607 20134 net.cpp:198] conv_score needs backward computation.
I0728 09:57:21.164610 20134 net.cpp:198] relu5_3 needs backward computation.
I0728 09:57:21.164614 20134 net.cpp:198] conv5_3 needs backward computation.
I0728 09:57:21.164628 20134 net.cpp:198] relu5_2 needs backward computation.
I0728 09:57:21.164633 20134 net.cpp:198] conv5_2 needs backward computation.
I0728 09:57:21.164638 20134 net.cpp:198] relu5_1 needs backward computation.
I0728 09:57:21.164641 20134 net.cpp:198] conv5_1 needs backward computation.
I0728 09:57:21.164645 20134 net.cpp:198] pool4 needs backward computation.
I0728 09:57:21.164650 20134 net.cpp:198] relu4_3 needs backward computation.
I0728 09:57:21.164654 20134 net.cpp:198] conv4_3 needs backward computation.
I0728 09:57:21.164659 20134 net.cpp:198] relu4_2 needs backward computation.
I0728 09:57:21.164662 20134 net.cpp:198] conv4_2 needs backward computation.
I0728 09:57:21.164667 20134 net.cpp:198] relu4_1 needs backward computation.
I0728 09:57:21.164671 20134 net.cpp:198] conv4_1 needs backward computation.
I0728 09:57:21.164676 20134 net.cpp:198] pool3 needs backward computation.
I0728 09:57:21.164680 20134 net.cpp:198] relu3_3 needs backward computation.
I0728 09:57:21.164685 20134 net.cpp:198] conv3_3 needs backward computation.
I0728 09:57:21.164688 20134 net.cpp:198] relu3_2 needs backward computation.
I0728 09:57:21.164692 20134 net.cpp:198] conv3_2 needs backward computation.
I0728 09:57:21.164696 20134 net.cpp:198] relu3_1 needs backward computation.
I0728 09:57:21.164700 20134 net.cpp:198] conv3_1 needs backward computation.
I0728 09:57:21.164705 20134 net.cpp:198] pool2 needs backward computation.
I0728 09:57:21.164710 20134 net.cpp:198] relu2_2 needs backward computation.
I0728 09:57:21.164713 20134 net.cpp:198] conv2_2 needs backward computation.
I0728 09:57:21.164717 20134 net.cpp:198] relu2_1 needs backward computation.
I0728 09:57:21.164721 20134 net.cpp:198] conv2_1 needs backward computation.
I0728 09:57:21.164726 20134 net.cpp:198] pool1 needs backward computation.
I0728 09:57:21.164731 20134 net.cpp:198] relu1_2 needs backward computation.
I0728 09:57:21.164734 20134 net.cpp:198] conv1_2 needs backward computation.
I0728 09:57:21.164739 20134 net.cpp:198] relu1_1 needs backward computation.
I0728 09:57:21.164743 20134 net.cpp:198] conv1_1 needs backward computation.
I0728 09:57:21.164747 20134 net.cpp:200] label_label_0_split does not need backward computation.
I0728 09:57:21.164752 20134 net.cpp:200] label does not need backward computation.
I0728 09:57:21.164757 20134 net.cpp:200] data does not need backward computation.
I0728 09:57:21.164760 20134 net.cpp:242] This network produces output mae
I0728 09:57:21.164765 20134 net.cpp:242] This network produces output mse
I0728 09:57:21.164794 20134 net.cpp:255] Network initialization done.
I0728 09:57:21.165038 20134 solver.cpp:56] Solver scaffolding done.
I0728 09:57:21.166837 20134 caffe.cpp:155] Finetuning from ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0728 09:57:22.435570 20134 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0728 09:57:22.852522 20134 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0728 09:57:22.854553 20134 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0728 09:57:22.854573 20134 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0728 09:57:22.854579 20134 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0728 09:57:23.116809 20134 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0728 09:57:23.461063 20134 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0728 09:57:23.462258 20134 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./examples/crowd/code/shanghaiA/VGG_ILSVRC_16_layers.caffemodel
I0728 09:57:23.462306 20134 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0728 09:57:23.462313 20134 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0728 09:57:23.477576 20134 caffe.cpp:248] Starting Optimization
I0728 09:57:23.477602 20134 solver.cpp:273] Solving crowd_counting
I0728 09:57:23.477604 20134 solver.cpp:274] Learning Rate Policy: step
I0728 09:57:23.482808 20134 solver.cpp:331] Iteration 0, Testing net (#0)
I0728 09:57:37.004526 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 09:57:37.116039 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 09:57:37.414854 20134 solver.cpp:398]     Test net output #0: mae = 427.436 (* 1 = 427.436 loss)
I0728 09:57:37.414875 20134 solver.cpp:398]     Test net output #1: mse = 308720 (* 1 = 308720 loss)
I0728 09:57:37.543628 20134 solver.cpp:219] Iteration 0 (-1.34304e+30 iter/s, 14.0657s/5400 iters), loss = 128685
I0728 09:57:37.543680 20134 solver.cpp:238]     Train net output #0: loss1 = 2010.82 (* 1 = 2010.82 loss)
I0728 09:57:37.543690 20134 solver.cpp:238]     Train net output #1: loss10 = 2010.9 (* 1 = 2010.9 loss)
I0728 09:57:37.543696 20134 solver.cpp:238]     Train net output #2: loss11 = 2010.81 (* 1 = 2010.81 loss)
I0728 09:57:37.543702 20134 solver.cpp:238]     Train net output #3: loss12 = 2010.84 (* 1 = 2010.84 loss)
I0728 09:57:37.543709 20134 solver.cpp:238]     Train net output #4: loss13 = 2010.92 (* 1 = 2010.92 loss)
I0728 09:57:37.543715 20134 solver.cpp:238]     Train net output #5: loss14 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.543721 20134 solver.cpp:238]     Train net output #6: loss15 = 2010.63 (* 1 = 2010.63 loss)
I0728 09:57:37.543727 20134 solver.cpp:238]     Train net output #7: loss16 = 2010.87 (* 1 = 2010.87 loss)
I0728 09:57:37.543733 20134 solver.cpp:238]     Train net output #8: loss17 = 2010.61 (* 1 = 2010.61 loss)
I0728 09:57:37.543740 20134 solver.cpp:238]     Train net output #9: loss18 = 2010.6 (* 1 = 2010.6 loss)
I0728 09:57:37.543746 20134 solver.cpp:238]     Train net output #10: loss19 = 2010.89 (* 1 = 2010.89 loss)
I0728 09:57:37.543752 20134 solver.cpp:238]     Train net output #11: loss2 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.543758 20134 solver.cpp:238]     Train net output #12: loss20 = 2010.52 (* 1 = 2010.52 loss)
I0728 09:57:37.543764 20134 solver.cpp:238]     Train net output #13: loss21 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.543771 20134 solver.cpp:238]     Train net output #14: loss22 = 2010.09 (* 1 = 2010.09 loss)
I0728 09:57:37.543776 20134 solver.cpp:238]     Train net output #15: loss23 = 2010.76 (* 1 = 2010.76 loss)
I0728 09:57:37.543782 20134 solver.cpp:238]     Train net output #16: loss24 = 2010.63 (* 1 = 2010.63 loss)
I0728 09:57:37.543788 20134 solver.cpp:238]     Train net output #17: loss25 = 2010.92 (* 1 = 2010.92 loss)
I0728 09:57:37.543794 20134 solver.cpp:238]     Train net output #18: loss26 = 2010.92 (* 1 = 2010.92 loss)
I0728 09:57:37.543802 20134 solver.cpp:238]     Train net output #19: loss27 = 2010.62 (* 1 = 2010.62 loss)
I0728 09:57:37.543807 20134 solver.cpp:238]     Train net output #20: loss28 = 2010.72 (* 1 = 2010.72 loss)
I0728 09:57:37.543813 20134 solver.cpp:238]     Train net output #21: loss29 = 2010.8 (* 1 = 2010.8 loss)
I0728 09:57:37.543819 20134 solver.cpp:238]     Train net output #22: loss3 = 2010.81 (* 1 = 2010.81 loss)
I0728 09:57:37.543825 20134 solver.cpp:238]     Train net output #23: loss30 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.543831 20134 solver.cpp:238]     Train net output #24: loss31 = 2010.58 (* 1 = 2010.58 loss)
I0728 09:57:37.543838 20134 solver.cpp:238]     Train net output #25: loss32 = 2010.76 (* 1 = 2010.76 loss)
I0728 09:57:37.543844 20134 solver.cpp:238]     Train net output #26: loss33 = 2010.59 (* 1 = 2010.59 loss)
I0728 09:57:37.543850 20134 solver.cpp:238]     Train net output #27: loss34 = 2010.9 (* 1 = 2010.9 loss)
I0728 09:57:37.543856 20134 solver.cpp:238]     Train net output #28: loss35 = 2010.55 (* 1 = 2010.55 loss)
I0728 09:57:37.543895 20134 solver.cpp:238]     Train net output #29: loss36 = 2010.88 (* 1 = 2010.88 loss)
I0728 09:57:37.543901 20134 solver.cpp:238]     Train net output #30: loss37 = 2010.87 (* 1 = 2010.87 loss)
I0728 09:57:37.543908 20134 solver.cpp:238]     Train net output #31: loss38 = 2010.78 (* 1 = 2010.78 loss)
I0728 09:57:37.543915 20134 solver.cpp:238]     Train net output #32: loss39 = 2010.73 (* 1 = 2010.73 loss)
I0728 09:57:37.543922 20134 solver.cpp:238]     Train net output #33: loss4 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.543927 20134 solver.cpp:238]     Train net output #34: loss40 = 2010.88 (* 1 = 2010.88 loss)
I0728 09:57:37.543946 20134 solver.cpp:238]     Train net output #35: loss41 = 2010.78 (* 1 = 2010.78 loss)
I0728 09:57:37.543956 20134 solver.cpp:238]     Train net output #36: loss42 = 2010.05 (* 1 = 2010.05 loss)
I0728 09:57:37.543964 20134 solver.cpp:238]     Train net output #37: loss43 = 2010.89 (* 1 = 2010.89 loss)
I0728 09:57:37.543973 20134 solver.cpp:238]     Train net output #38: loss44 = 2010.89 (* 1 = 2010.89 loss)
I0728 09:57:37.543983 20134 solver.cpp:238]     Train net output #39: loss45 = 2010.81 (* 1 = 2010.81 loss)
I0728 09:57:37.543993 20134 solver.cpp:238]     Train net output #40: loss46 = 2010.84 (* 1 = 2010.84 loss)
I0728 09:57:37.544003 20134 solver.cpp:238]     Train net output #41: loss47 = 2010.59 (* 1 = 2010.59 loss)
I0728 09:57:37.544013 20134 solver.cpp:238]     Train net output #42: loss48 = 2010.28 (* 1 = 2010.28 loss)
I0728 09:57:37.544023 20134 solver.cpp:238]     Train net output #43: loss49 = 2010.3 (* 1 = 2010.3 loss)
I0728 09:57:37.544034 20134 solver.cpp:238]     Train net output #44: loss5 = 2010.91 (* 1 = 2010.91 loss)
I0728 09:57:37.544044 20134 solver.cpp:238]     Train net output #45: loss50 = 2010.79 (* 1 = 2010.79 loss)
I0728 09:57:37.544054 20134 solver.cpp:238]     Train net output #46: loss51 = 2010.92 (* 1 = 2010.92 loss)
I0728 09:57:37.544064 20134 solver.cpp:238]     Train net output #47: loss52 = 2010.73 (* 1 = 2010.73 loss)
I0728 09:57:37.544072 20134 solver.cpp:238]     Train net output #48: loss53 = 2010.89 (* 1 = 2010.89 loss)
I0728 09:57:37.544082 20134 solver.cpp:238]     Train net output #49: loss54 = 2010.9 (* 1 = 2010.9 loss)
I0728 09:57:37.544093 20134 solver.cpp:238]     Train net output #50: loss55 = 2010.58 (* 1 = 2010.58 loss)
I0728 09:57:37.544103 20134 solver.cpp:238]     Train net output #51: loss56 = 2010.62 (* 1 = 2010.62 loss)
I0728 09:57:37.544113 20134 solver.cpp:238]     Train net output #52: loss57 = 2010.26 (* 1 = 2010.26 loss)
I0728 09:57:37.544123 20134 solver.cpp:238]     Train net output #53: loss58 = 2010.71 (* 1 = 2010.71 loss)
I0728 09:57:37.544129 20134 solver.cpp:238]     Train net output #54: loss59 = 2010.91 (* 1 = 2010.91 loss)
I0728 09:57:37.544136 20134 solver.cpp:238]     Train net output #55: loss6 = 2010.69 (* 1 = 2010.69 loss)
I0728 09:57:37.544142 20134 solver.cpp:238]     Train net output #56: loss60 = 2010.84 (* 1 = 2010.84 loss)
I0728 09:57:37.544148 20134 solver.cpp:238]     Train net output #57: loss61 = 2010.2 (* 1 = 2010.2 loss)
I0728 09:57:37.544154 20134 solver.cpp:238]     Train net output #58: loss62 = 2010.93 (* 1 = 2010.93 loss)
I0728 09:57:37.544160 20134 solver.cpp:238]     Train net output #59: loss63 = 2010.94 (* 1 = 2010.94 loss)
I0728 09:57:37.544167 20134 solver.cpp:238]     Train net output #60: loss64 = 2009.61 (* 1 = 2009.61 loss)
I0728 09:57:37.544173 20134 solver.cpp:238]     Train net output #61: loss7 = 2010.69 (* 1 = 2010.69 loss)
I0728 09:57:37.544178 20134 solver.cpp:238]     Train net output #62: loss8 = 2010.83 (* 1 = 2010.83 loss)
I0728 09:57:37.544184 20134 solver.cpp:238]     Train net output #63: loss9 = 2010.75 (* 1 = 2010.75 loss)
I0728 09:57:37.544203 20134 sgd_solver.cpp:105] Iteration 0, lr = 1e-09
I0728 10:06:34.667255 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:06:34.668289 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:06:35.058091 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_5400.caffemodel
I0728 10:06:35.331571 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_5400.solverstate
I0728 10:06:35.416321 20134 solver.cpp:331] Iteration 5400, Testing net (#0)
I0728 10:06:50.649194 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:06:50.683732 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:06:51.115020 20134 solver.cpp:398]     Test net output #0: mae = 160.33 (* 1 = 160.33 loss)
I0728 10:06:51.115048 20134 solver.cpp:398]     Test net output #1: mse = 40818.5 (* 1 = 40818.5 loss)
I0728 10:06:51.239943 20134 solver.cpp:219] Iteration 5400 (9.75282 iter/s, 553.686s/5400 iters), loss = 286587
I0728 10:06:51.239990 20134 solver.cpp:238]     Train net output #0: loss1 = 4450.1 (* 1 = 4450.1 loss)
I0728 10:06:51.240002 20134 solver.cpp:238]     Train net output #1: loss10 = 4536.11 (* 1 = 4536.11 loss)
I0728 10:06:51.240011 20134 solver.cpp:238]     Train net output #2: loss11 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240018 20134 solver.cpp:238]     Train net output #3: loss12 = 4543.71 (* 1 = 4543.71 loss)
I0728 10:06:51.240026 20134 solver.cpp:238]     Train net output #4: loss13 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240034 20134 solver.cpp:238]     Train net output #5: loss14 = 4506.2 (* 1 = 4506.2 loss)
I0728 10:06:51.240044 20134 solver.cpp:238]     Train net output #6: loss15 = 4435.47 (* 1 = 4435.47 loss)
I0728 10:06:51.240052 20134 solver.cpp:238]     Train net output #7: loss16 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240059 20134 solver.cpp:238]     Train net output #8: loss17 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240067 20134 solver.cpp:238]     Train net output #9: loss18 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240075 20134 solver.cpp:238]     Train net output #10: loss19 = 4509.98 (* 1 = 4509.98 loss)
I0728 10:06:51.240083 20134 solver.cpp:238]     Train net output #11: loss2 = 4445.26 (* 1 = 4445.26 loss)
I0728 10:06:51.240092 20134 solver.cpp:238]     Train net output #12: loss20 = 4463.14 (* 1 = 4463.14 loss)
I0728 10:06:51.240099 20134 solver.cpp:238]     Train net output #13: loss21 = 4582.75 (* 1 = 4582.75 loss)
I0728 10:06:51.240108 20134 solver.cpp:238]     Train net output #14: loss22 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240114 20134 solver.cpp:238]     Train net output #15: loss23 = 4560.97 (* 1 = 4560.97 loss)
I0728 10:06:51.240124 20134 solver.cpp:238]     Train net output #16: loss24 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240133 20134 solver.cpp:238]     Train net output #17: loss25 = 4555.68 (* 1 = 4555.68 loss)
I0728 10:06:51.240140 20134 solver.cpp:238]     Train net output #18: loss26 = 4470.47 (* 1 = 4470.47 loss)
I0728 10:06:51.240149 20134 solver.cpp:238]     Train net output #19: loss27 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240156 20134 solver.cpp:238]     Train net output #20: loss28 = 4439.39 (* 1 = 4439.39 loss)
I0728 10:06:51.240164 20134 solver.cpp:238]     Train net output #21: loss29 = 4568.12 (* 1 = 4568.12 loss)
I0728 10:06:51.240172 20134 solver.cpp:238]     Train net output #22: loss3 = 4600.16 (* 1 = 4600.16 loss)
I0728 10:06:51.240180 20134 solver.cpp:238]     Train net output #23: loss30 = 4547.54 (* 1 = 4547.54 loss)
I0728 10:06:51.240188 20134 solver.cpp:238]     Train net output #24: loss31 = 4505.49 (* 1 = 4505.49 loss)
I0728 10:06:51.240196 20134 solver.cpp:238]     Train net output #25: loss32 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240205 20134 solver.cpp:238]     Train net output #26: loss33 = 4473.89 (* 1 = 4473.89 loss)
I0728 10:06:51.240212 20134 solver.cpp:238]     Train net output #27: loss34 = 4434.38 (* 1 = 4434.38 loss)
I0728 10:06:51.240221 20134 solver.cpp:238]     Train net output #28: loss35 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240228 20134 solver.cpp:238]     Train net output #29: loss36 = 4450.41 (* 1 = 4450.41 loss)
I0728 10:06:51.240272 20134 solver.cpp:238]     Train net output #30: loss37 = 4507.05 (* 1 = 4507.05 loss)
I0728 10:06:51.240280 20134 solver.cpp:238]     Train net output #31: loss38 = 4480.65 (* 1 = 4480.65 loss)
I0728 10:06:51.240288 20134 solver.cpp:238]     Train net output #32: loss39 = 4434.2 (* 1 = 4434.2 loss)
I0728 10:06:51.240296 20134 solver.cpp:238]     Train net output #33: loss4 = 4520.77 (* 1 = 4520.77 loss)
I0728 10:06:51.240304 20134 solver.cpp:238]     Train net output #34: loss40 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240312 20134 solver.cpp:238]     Train net output #35: loss41 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240321 20134 solver.cpp:238]     Train net output #36: loss42 = 4433.38 (* 1 = 4433.38 loss)
I0728 10:06:51.240329 20134 solver.cpp:238]     Train net output #37: loss43 = 4433.42 (* 1 = 4433.42 loss)
I0728 10:06:51.240339 20134 solver.cpp:238]     Train net output #38: loss44 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240350 20134 solver.cpp:238]     Train net output #39: loss45 = 4549.55 (* 1 = 4549.55 loss)
I0728 10:06:51.240360 20134 solver.cpp:238]     Train net output #40: loss46 = 4515.62 (* 1 = 4515.62 loss)
I0728 10:06:51.240370 20134 solver.cpp:238]     Train net output #41: loss47 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240381 20134 solver.cpp:238]     Train net output #42: loss48 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240391 20134 solver.cpp:238]     Train net output #43: loss49 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240409 20134 solver.cpp:238]     Train net output #44: loss5 = 4451.25 (* 1 = 4451.25 loss)
I0728 10:06:51.240420 20134 solver.cpp:238]     Train net output #45: loss50 = 4714.52 (* 1 = 4714.52 loss)
I0728 10:06:51.240432 20134 solver.cpp:238]     Train net output #46: loss51 = 4444.78 (* 1 = 4444.78 loss)
I0728 10:06:51.240442 20134 solver.cpp:238]     Train net output #47: loss52 = 4501.02 (* 1 = 4501.02 loss)
I0728 10:06:51.240452 20134 solver.cpp:238]     Train net output #48: loss53 = 4515.13 (* 1 = 4515.13 loss)
I0728 10:06:51.240461 20134 solver.cpp:238]     Train net output #49: loss54 = 4461.99 (* 1 = 4461.99 loss)
I0728 10:06:51.240473 20134 solver.cpp:238]     Train net output #50: loss55 = 4507.28 (* 1 = 4507.28 loss)
I0728 10:06:51.240483 20134 solver.cpp:238]     Train net output #51: loss56 = 4457.57 (* 1 = 4457.57 loss)
I0728 10:06:51.240494 20134 solver.cpp:238]     Train net output #52: loss57 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240504 20134 solver.cpp:238]     Train net output #53: loss58 = 4459.66 (* 1 = 4459.66 loss)
I0728 10:06:51.240515 20134 solver.cpp:238]     Train net output #54: loss59 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240522 20134 solver.cpp:238]     Train net output #55: loss6 = 4561.2 (* 1 = 4561.2 loss)
I0728 10:06:51.240530 20134 solver.cpp:238]     Train net output #56: loss60 = 4473.41 (* 1 = 4473.41 loss)
I0728 10:06:51.240535 20134 solver.cpp:238]     Train net output #57: loss61 = 4658.24 (* 1 = 4658.24 loss)
I0728 10:06:51.240541 20134 solver.cpp:238]     Train net output #58: loss62 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240548 20134 solver.cpp:238]     Train net output #59: loss63 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240555 20134 solver.cpp:238]     Train net output #60: loss64 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240561 20134 solver.cpp:238]     Train net output #61: loss7 = 4499.81 (* 1 = 4499.81 loss)
I0728 10:06:51.240567 20134 solver.cpp:238]     Train net output #62: loss8 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240573 20134 solver.cpp:238]     Train net output #63: loss9 = 4433.21 (* 1 = 4433.21 loss)
I0728 10:06:51.240581 20134 sgd_solver.cpp:105] Iteration 5400, lr = 1e-09
I0728 10:15:53.038727 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:15:53.041074 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:15:53.436915 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_10800.caffemodel
I0728 10:15:53.697870 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_10800.solverstate
I0728 10:15:53.782485 20134 solver.cpp:331] Iteration 10800, Testing net (#0)
I0728 10:16:09.013427 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:16:09.138384 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:16:09.478139 20134 solver.cpp:398]     Test net output #0: mae = 159.413 (* 1 = 159.413 loss)
I0728 10:16:09.478166 20134 solver.cpp:398]     Test net output #1: mse = 42565.7 (* 1 = 42565.7 loss)
I0728 10:16:09.603153 20134 solver.cpp:219] Iteration 10800 (9.67129 iter/s, 558.354s/5400 iters), loss = 222235
I0728 10:16:09.603199 20134 solver.cpp:238]     Train net output #0: loss1 = 3445.8 (* 1 = 3445.8 loss)
I0728 10:16:09.603210 20134 solver.cpp:238]     Train net output #1: loss10 = 3478.28 (* 1 = 3478.28 loss)
I0728 10:16:09.603217 20134 solver.cpp:238]     Train net output #2: loss11 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603224 20134 solver.cpp:238]     Train net output #3: loss12 = 3540.63 (* 1 = 3540.63 loss)
I0728 10:16:09.603232 20134 solver.cpp:238]     Train net output #4: loss13 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603240 20134 solver.cpp:238]     Train net output #5: loss14 = 3497.23 (* 1 = 3497.23 loss)
I0728 10:16:09.603245 20134 solver.cpp:238]     Train net output #6: loss15 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603252 20134 solver.cpp:238]     Train net output #7: loss16 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603258 20134 solver.cpp:238]     Train net output #8: loss17 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603266 20134 solver.cpp:238]     Train net output #9: loss18 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603271 20134 solver.cpp:238]     Train net output #10: loss19 = 3520.63 (* 1 = 3520.63 loss)
I0728 10:16:09.603278 20134 solver.cpp:238]     Train net output #11: loss2 = 3467.12 (* 1 = 3467.12 loss)
I0728 10:16:09.603284 20134 solver.cpp:238]     Train net output #12: loss20 = 3544.29 (* 1 = 3544.29 loss)
I0728 10:16:09.603291 20134 solver.cpp:238]     Train net output #13: loss21 = 3488.32 (* 1 = 3488.32 loss)
I0728 10:16:09.603297 20134 solver.cpp:238]     Train net output #14: loss22 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603303 20134 solver.cpp:238]     Train net output #15: loss23 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603310 20134 solver.cpp:238]     Train net output #16: loss24 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603317 20134 solver.cpp:238]     Train net output #17: loss25 = 3490.77 (* 1 = 3490.77 loss)
I0728 10:16:09.603323 20134 solver.cpp:238]     Train net output #18: loss26 = 3471.67 (* 1 = 3471.67 loss)
I0728 10:16:09.603330 20134 solver.cpp:238]     Train net output #19: loss27 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603337 20134 solver.cpp:238]     Train net output #20: loss28 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603343 20134 solver.cpp:238]     Train net output #21: loss29 = 3584.75 (* 1 = 3584.75 loss)
I0728 10:16:09.603349 20134 solver.cpp:238]     Train net output #22: loss3 = 3585.07 (* 1 = 3585.07 loss)
I0728 10:16:09.603355 20134 solver.cpp:238]     Train net output #23: loss30 = 3549.18 (* 1 = 3549.18 loss)
I0728 10:16:09.603363 20134 solver.cpp:238]     Train net output #24: loss31 = 3486.05 (* 1 = 3486.05 loss)
I0728 10:16:09.603368 20134 solver.cpp:238]     Train net output #25: loss32 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603374 20134 solver.cpp:238]     Train net output #26: loss33 = 3459.2 (* 1 = 3459.2 loss)
I0728 10:16:09.603380 20134 solver.cpp:238]     Train net output #27: loss34 = 3440.58 (* 1 = 3440.58 loss)
I0728 10:16:09.603387 20134 solver.cpp:238]     Train net output #28: loss35 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603433 20134 solver.cpp:238]     Train net output #29: loss36 = 3437.19 (* 1 = 3437.19 loss)
I0728 10:16:09.603446 20134 solver.cpp:238]     Train net output #30: loss37 = 3499.24 (* 1 = 3499.24 loss)
I0728 10:16:09.603452 20134 solver.cpp:238]     Train net output #31: loss38 = 3499.45 (* 1 = 3499.45 loss)
I0728 10:16:09.603459 20134 solver.cpp:238]     Train net output #32: loss39 = 3437.83 (* 1 = 3437.83 loss)
I0728 10:16:09.603473 20134 solver.cpp:238]     Train net output #33: loss4 = 3525.6 (* 1 = 3525.6 loss)
I0728 10:16:09.603480 20134 solver.cpp:238]     Train net output #34: loss40 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603487 20134 solver.cpp:238]     Train net output #35: loss41 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603493 20134 solver.cpp:238]     Train net output #36: loss42 = 3455.29 (* 1 = 3455.29 loss)
I0728 10:16:09.603499 20134 solver.cpp:238]     Train net output #37: loss43 = 3441.83 (* 1 = 3441.83 loss)
I0728 10:16:09.603507 20134 solver.cpp:238]     Train net output #38: loss44 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603513 20134 solver.cpp:238]     Train net output #39: loss45 = 3528.96 (* 1 = 3528.96 loss)
I0728 10:16:09.603518 20134 solver.cpp:238]     Train net output #40: loss46 = 3553.17 (* 1 = 3553.17 loss)
I0728 10:16:09.603524 20134 solver.cpp:238]     Train net output #41: loss47 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603530 20134 solver.cpp:238]     Train net output #42: loss48 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603536 20134 solver.cpp:238]     Train net output #43: loss49 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603543 20134 solver.cpp:238]     Train net output #44: loss5 = 3448.37 (* 1 = 3448.37 loss)
I0728 10:16:09.603549 20134 solver.cpp:238]     Train net output #45: loss50 = 3516.37 (* 1 = 3516.37 loss)
I0728 10:16:09.603555 20134 solver.cpp:238]     Train net output #46: loss51 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603561 20134 solver.cpp:238]     Train net output #47: loss52 = 3540.47 (* 1 = 3540.47 loss)
I0728 10:16:09.603567 20134 solver.cpp:238]     Train net output #48: loss53 = 3564.53 (* 1 = 3564.53 loss)
I0728 10:16:09.603574 20134 solver.cpp:238]     Train net output #49: loss54 = 3489.66 (* 1 = 3489.66 loss)
I0728 10:16:09.603580 20134 solver.cpp:238]     Train net output #50: loss55 = 3491.28 (* 1 = 3491.28 loss)
I0728 10:16:09.603586 20134 solver.cpp:238]     Train net output #51: loss56 = 3453.33 (* 1 = 3453.33 loss)
I0728 10:16:09.603592 20134 solver.cpp:238]     Train net output #52: loss57 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603600 20134 solver.cpp:238]     Train net output #53: loss58 = 3436.95 (* 1 = 3436.95 loss)
I0728 10:16:09.603605 20134 solver.cpp:238]     Train net output #54: loss59 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603611 20134 solver.cpp:238]     Train net output #55: loss6 = 3583.41 (* 1 = 3583.41 loss)
I0728 10:16:09.603617 20134 solver.cpp:238]     Train net output #56: loss60 = 3446.7 (* 1 = 3446.7 loss)
I0728 10:16:09.603623 20134 solver.cpp:238]     Train net output #57: loss61 = 3582.59 (* 1 = 3582.59 loss)
I0728 10:16:09.603631 20134 solver.cpp:238]     Train net output #58: loss62 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603636 20134 solver.cpp:238]     Train net output #59: loss63 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603642 20134 solver.cpp:238]     Train net output #60: loss64 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603649 20134 solver.cpp:238]     Train net output #61: loss7 = 3477.48 (* 1 = 3477.48 loss)
I0728 10:16:09.603655 20134 solver.cpp:238]     Train net output #62: loss8 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603662 20134 solver.cpp:238]     Train net output #63: loss9 = 3436.93 (* 1 = 3436.93 loss)
I0728 10:16:09.603668 20134 sgd_solver.cpp:105] Iteration 10800, lr = 1e-09
I0728 10:25:11.677160 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:25:11.678279 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:25:12.075492 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_16200.caffemodel
I0728 10:25:12.336943 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_16200.solverstate
I0728 10:25:12.422969 20134 solver.cpp:331] Iteration 16200, Testing net (#0)
I0728 10:25:27.646801 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:25:27.744777 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:25:28.112002 20134 solver.cpp:398]     Test net output #0: mae = 140.175 (* 1 = 140.175 loss)
I0728 10:25:28.112028 20134 solver.cpp:398]     Test net output #1: mse = 33691.5 (* 1 = 33691.5 loss)
I0728 10:25:28.236879 20134 solver.cpp:219] Iteration 16200 (9.66661 iter/s, 558.624s/5400 iters), loss = 192617
I0728 10:25:28.236922 20134 solver.cpp:238]     Train net output #0: loss1 = 2982.89 (* 1 = 2982.89 loss)
I0728 10:25:28.236932 20134 solver.cpp:238]     Train net output #1: loss10 = 3005.95 (* 1 = 3005.95 loss)
I0728 10:25:28.236938 20134 solver.cpp:238]     Train net output #2: loss11 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236944 20134 solver.cpp:238]     Train net output #3: loss12 = 3076.13 (* 1 = 3076.13 loss)
I0728 10:25:28.236950 20134 solver.cpp:238]     Train net output #4: loss13 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236958 20134 solver.cpp:238]     Train net output #5: loss14 = 3021.21 (* 1 = 3021.21 loss)
I0728 10:25:28.236963 20134 solver.cpp:238]     Train net output #6: loss15 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236969 20134 solver.cpp:238]     Train net output #7: loss16 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236975 20134 solver.cpp:238]     Train net output #8: loss17 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236981 20134 solver.cpp:238]     Train net output #9: loss18 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.236989 20134 solver.cpp:238]     Train net output #10: loss19 = 3057.91 (* 1 = 3057.91 loss)
I0728 10:25:28.236994 20134 solver.cpp:238]     Train net output #11: loss2 = 2990.42 (* 1 = 2990.42 loss)
I0728 10:25:28.237000 20134 solver.cpp:238]     Train net output #12: loss20 = 3089.24 (* 1 = 3089.24 loss)
I0728 10:25:28.237007 20134 solver.cpp:238]     Train net output #13: loss21 = 2987.36 (* 1 = 2987.36 loss)
I0728 10:25:28.237013 20134 solver.cpp:238]     Train net output #14: loss22 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237020 20134 solver.cpp:238]     Train net output #15: loss23 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237025 20134 solver.cpp:238]     Train net output #16: loss24 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237031 20134 solver.cpp:238]     Train net output #17: loss25 = 3013.39 (* 1 = 3013.39 loss)
I0728 10:25:28.237037 20134 solver.cpp:238]     Train net output #18: loss26 = 3008.52 (* 1 = 3008.52 loss)
I0728 10:25:28.237045 20134 solver.cpp:238]     Train net output #19: loss27 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237051 20134 solver.cpp:238]     Train net output #20: loss28 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237056 20134 solver.cpp:238]     Train net output #21: loss29 = 3144.9 (* 1 = 3144.9 loss)
I0728 10:25:28.237063 20134 solver.cpp:238]     Train net output #22: loss3 = 3142.22 (* 1 = 3142.22 loss)
I0728 10:25:28.237069 20134 solver.cpp:238]     Train net output #23: loss30 = 3077.84 (* 1 = 3077.84 loss)
I0728 10:25:28.237076 20134 solver.cpp:238]     Train net output #24: loss31 = 3020.5 (* 1 = 3020.5 loss)
I0728 10:25:28.237082 20134 solver.cpp:238]     Train net output #25: loss32 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237088 20134 solver.cpp:238]     Train net output #26: loss33 = 3007.16 (* 1 = 3007.16 loss)
I0728 10:25:28.237094 20134 solver.cpp:238]     Train net output #27: loss34 = 2993.43 (* 1 = 2993.43 loss)
I0728 10:25:28.237102 20134 solver.cpp:238]     Train net output #28: loss35 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237144 20134 solver.cpp:238]     Train net output #29: loss36 = 2978.94 (* 1 = 2978.94 loss)
I0728 10:25:28.237156 20134 solver.cpp:238]     Train net output #30: loss37 = 3050.3 (* 1 = 3050.3 loss)
I0728 10:25:28.237166 20134 solver.cpp:238]     Train net output #31: loss38 = 3052 (* 1 = 3052 loss)
I0728 10:25:28.237176 20134 solver.cpp:238]     Train net output #32: loss39 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237190 20134 solver.cpp:238]     Train net output #33: loss4 = 3001.79 (* 1 = 3001.79 loss)
I0728 10:25:28.237198 20134 solver.cpp:238]     Train net output #34: loss40 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237205 20134 solver.cpp:238]     Train net output #35: loss41 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237211 20134 solver.cpp:238]     Train net output #36: loss42 = 2981.85 (* 1 = 2981.85 loss)
I0728 10:25:28.237218 20134 solver.cpp:238]     Train net output #37: loss43 = 2991.57 (* 1 = 2991.57 loss)
I0728 10:25:28.237224 20134 solver.cpp:238]     Train net output #38: loss44 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237231 20134 solver.cpp:238]     Train net output #39: loss45 = 3044.49 (* 1 = 3044.49 loss)
I0728 10:25:28.237236 20134 solver.cpp:238]     Train net output #40: loss46 = 3104.76 (* 1 = 3104.76 loss)
I0728 10:25:28.237243 20134 solver.cpp:238]     Train net output #41: loss47 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237251 20134 solver.cpp:238]     Train net output #42: loss48 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237257 20134 solver.cpp:238]     Train net output #43: loss49 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237263 20134 solver.cpp:238]     Train net output #44: loss5 = 2992 (* 1 = 2992 loss)
I0728 10:25:28.237269 20134 solver.cpp:238]     Train net output #45: loss50 = 2995.89 (* 1 = 2995.89 loss)
I0728 10:25:28.237277 20134 solver.cpp:238]     Train net output #46: loss51 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237282 20134 solver.cpp:238]     Train net output #47: loss52 = 3061.2 (* 1 = 3061.2 loss)
I0728 10:25:28.237289 20134 solver.cpp:238]     Train net output #48: loss53 = 3111.92 (* 1 = 3111.92 loss)
I0728 10:25:28.237295 20134 solver.cpp:238]     Train net output #49: loss54 = 3036.59 (* 1 = 3036.59 loss)
I0728 10:25:28.237308 20134 solver.cpp:238]     Train net output #50: loss55 = 3004.34 (* 1 = 3004.34 loss)
I0728 10:25:28.237315 20134 solver.cpp:238]     Train net output #51: loss56 = 2996.51 (* 1 = 2996.51 loss)
I0728 10:25:28.237323 20134 solver.cpp:238]     Train net output #52: loss57 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237329 20134 solver.cpp:238]     Train net output #53: loss58 = 2978.86 (* 1 = 2978.86 loss)
I0728 10:25:28.237334 20134 solver.cpp:238]     Train net output #54: loss59 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237341 20134 solver.cpp:238]     Train net output #55: loss6 = 3123.27 (* 1 = 3123.27 loss)
I0728 10:25:28.237347 20134 solver.cpp:238]     Train net output #56: loss60 = 2983.28 (* 1 = 2983.28 loss)
I0728 10:25:28.237354 20134 solver.cpp:238]     Train net output #57: loss61 = 3082.82 (* 1 = 3082.82 loss)
I0728 10:25:28.237360 20134 solver.cpp:238]     Train net output #58: loss62 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237366 20134 solver.cpp:238]     Train net output #59: loss63 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237373 20134 solver.cpp:238]     Train net output #60: loss64 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237380 20134 solver.cpp:238]     Train net output #61: loss7 = 3026.48 (* 1 = 3026.48 loss)
I0728 10:25:28.237385 20134 solver.cpp:238]     Train net output #62: loss8 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237392 20134 solver.cpp:238]     Train net output #63: loss9 = 2978.85 (* 1 = 2978.85 loss)
I0728 10:25:28.237398 20134 sgd_solver.cpp:105] Iteration 16200, lr = 1e-09
I0728 10:34:29.504750 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:34:29.507581 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:34:29.894655 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_21600.caffemodel
I0728 10:34:30.125815 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_21600.solverstate
I0728 10:34:30.209000 20134 solver.cpp:331] Iteration 21600, Testing net (#0)
I0728 10:34:45.431367 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:34:45.468873 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:34:45.896051 20134 solver.cpp:398]     Test net output #0: mae = 118.664 (* 1 = 118.664 loss)
I0728 10:34:45.896076 20134 solver.cpp:398]     Test net output #1: mse = 24616.4 (* 1 = 24616.4 loss)
I0728 10:34:46.020581 20134 solver.cpp:219] Iteration 21600 (9.68134 iter/s, 557.774s/5400 iters), loss = 164949
I0728 10:34:46.020620 20134 solver.cpp:238]     Train net output #0: loss1 = 2554.32 (* 1 = 2554.32 loss)
I0728 10:34:46.020629 20134 solver.cpp:238]     Train net output #1: loss10 = 2564.18 (* 1 = 2564.18 loss)
I0728 10:34:46.020635 20134 solver.cpp:238]     Train net output #2: loss11 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020642 20134 solver.cpp:238]     Train net output #3: loss12 = 2632.49 (* 1 = 2632.49 loss)
I0728 10:34:46.020647 20134 solver.cpp:238]     Train net output #4: loss13 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020653 20134 solver.cpp:238]     Train net output #5: loss14 = 2575.48 (* 1 = 2575.48 loss)
I0728 10:34:46.020658 20134 solver.cpp:238]     Train net output #6: loss15 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020664 20134 solver.cpp:238]     Train net output #7: loss16 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020669 20134 solver.cpp:238]     Train net output #8: loss17 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020675 20134 solver.cpp:238]     Train net output #9: loss18 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020681 20134 solver.cpp:238]     Train net output #10: loss19 = 2621.15 (* 1 = 2621.15 loss)
I0728 10:34:46.020687 20134 solver.cpp:238]     Train net output #11: loss2 = 2555.79 (* 1 = 2555.79 loss)
I0728 10:34:46.020692 20134 solver.cpp:238]     Train net output #12: loss20 = 2625.83 (* 1 = 2625.83 loss)
I0728 10:34:46.020699 20134 solver.cpp:238]     Train net output #13: loss21 = 2549.32 (* 1 = 2549.32 loss)
I0728 10:34:46.020704 20134 solver.cpp:238]     Train net output #14: loss22 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020710 20134 solver.cpp:238]     Train net output #15: loss23 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020716 20134 solver.cpp:238]     Train net output #16: loss24 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020721 20134 solver.cpp:238]     Train net output #17: loss25 = 2568.25 (* 1 = 2568.25 loss)
I0728 10:34:46.020727 20134 solver.cpp:238]     Train net output #18: loss26 = 2579.98 (* 1 = 2579.98 loss)
I0728 10:34:46.020733 20134 solver.cpp:238]     Train net output #19: loss27 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020738 20134 solver.cpp:238]     Train net output #20: loss28 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020745 20134 solver.cpp:238]     Train net output #21: loss29 = 2711.76 (* 1 = 2711.76 loss)
I0728 10:34:46.020750 20134 solver.cpp:238]     Train net output #22: loss3 = 2688.04 (* 1 = 2688.04 loss)
I0728 10:34:46.020756 20134 solver.cpp:238]     Train net output #23: loss30 = 2636.16 (* 1 = 2636.16 loss)
I0728 10:34:46.020762 20134 solver.cpp:238]     Train net output #24: loss31 = 2588.22 (* 1 = 2588.22 loss)
I0728 10:34:46.020768 20134 solver.cpp:238]     Train net output #25: loss32 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020773 20134 solver.cpp:238]     Train net output #26: loss33 = 2579.83 (* 1 = 2579.83 loss)
I0728 10:34:46.020779 20134 solver.cpp:238]     Train net output #27: loss34 = 2564.85 (* 1 = 2564.85 loss)
I0728 10:34:46.020786 20134 solver.cpp:238]     Train net output #28: loss35 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020825 20134 solver.cpp:238]     Train net output #29: loss36 = 2552.43 (* 1 = 2552.43 loss)
I0728 10:34:46.020834 20134 solver.cpp:238]     Train net output #30: loss37 = 2635.16 (* 1 = 2635.16 loss)
I0728 10:34:46.020841 20134 solver.cpp:238]     Train net output #31: loss38 = 2621.76 (* 1 = 2621.76 loss)
I0728 10:34:46.020849 20134 solver.cpp:238]     Train net output #32: loss39 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020859 20134 solver.cpp:238]     Train net output #33: loss4 = 2565.12 (* 1 = 2565.12 loss)
I0728 10:34:46.020864 20134 solver.cpp:238]     Train net output #34: loss40 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020870 20134 solver.cpp:238]     Train net output #35: loss41 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020876 20134 solver.cpp:238]     Train net output #36: loss42 = 2548.64 (* 1 = 2548.64 loss)
I0728 10:34:46.020882 20134 solver.cpp:238]     Train net output #37: loss43 = 2571.62 (* 1 = 2571.62 loss)
I0728 10:34:46.020889 20134 solver.cpp:238]     Train net output #38: loss44 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020894 20134 solver.cpp:238]     Train net output #39: loss45 = 2595.61 (* 1 = 2595.61 loss)
I0728 10:34:46.020900 20134 solver.cpp:238]     Train net output #40: loss46 = 2677.63 (* 1 = 2677.63 loss)
I0728 10:34:46.020905 20134 solver.cpp:238]     Train net output #41: loss47 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020913 20134 solver.cpp:238]     Train net output #42: loss48 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020920 20134 solver.cpp:238]     Train net output #43: loss49 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020925 20134 solver.cpp:238]     Train net output #44: loss5 = 2565.98 (* 1 = 2565.98 loss)
I0728 10:34:46.020931 20134 solver.cpp:238]     Train net output #45: loss50 = 2558.09 (* 1 = 2558.09 loss)
I0728 10:34:46.020936 20134 solver.cpp:238]     Train net output #46: loss51 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020942 20134 solver.cpp:238]     Train net output #47: loss52 = 2601.71 (* 1 = 2601.71 loss)
I0728 10:34:46.020948 20134 solver.cpp:238]     Train net output #48: loss53 = 2668.88 (* 1 = 2668.88 loss)
I0728 10:34:46.020954 20134 solver.cpp:238]     Train net output #49: loss54 = 2602.97 (* 1 = 2602.97 loss)
I0728 10:34:46.020961 20134 solver.cpp:238]     Train net output #50: loss55 = 2562.42 (* 1 = 2562.42 loss)
I0728 10:34:46.020967 20134 solver.cpp:238]     Train net output #51: loss56 = 2574 (* 1 = 2574 loss)
I0728 10:34:46.020972 20134 solver.cpp:238]     Train net output #52: loss57 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020977 20134 solver.cpp:238]     Train net output #53: loss58 = 2552.27 (* 1 = 2552.27 loss)
I0728 10:34:46.020982 20134 solver.cpp:238]     Train net output #54: loss59 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.020987 20134 solver.cpp:238]     Train net output #55: loss6 = 2677.51 (* 1 = 2677.51 loss)
I0728 10:34:46.020990 20134 solver.cpp:238]     Train net output #56: loss60 = 2567.43 (* 1 = 2567.43 loss)
I0728 10:34:46.020995 20134 solver.cpp:238]     Train net output #57: loss61 = 2598.38 (* 1 = 2598.38 loss)
I0728 10:34:46.021001 20134 solver.cpp:238]     Train net output #58: loss62 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.021008 20134 solver.cpp:238]     Train net output #59: loss63 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.021013 20134 solver.cpp:238]     Train net output #60: loss64 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.021019 20134 solver.cpp:238]     Train net output #61: loss7 = 2605.45 (* 1 = 2605.45 loss)
I0728 10:34:46.021024 20134 solver.cpp:238]     Train net output #62: loss8 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.021030 20134 solver.cpp:238]     Train net output #63: loss9 = 2552.28 (* 1 = 2552.28 loss)
I0728 10:34:46.021036 20134 sgd_solver.cpp:105] Iteration 21600, lr = 1e-09
I0728 10:43:47.424093 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:43:47.425132 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:43:47.811270 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_27000.caffemodel
I0728 10:43:48.043714 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_27000.solverstate
I0728 10:43:48.126955 20134 solver.cpp:331] Iteration 27000, Testing net (#0)
I0728 10:44:03.343788 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:44:03.383405 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:44:03.808529 20134 solver.cpp:398]     Test net output #0: mae = 108.486 (* 1 = 108.486 loss)
I0728 10:44:03.808562 20134 solver.cpp:398]     Test net output #1: mse = 21141.2 (* 1 = 21141.2 loss)
I0728 10:44:03.933128 20134 solver.cpp:219] Iteration 27000 (9.67913 iter/s, 557.901s/5400 iters), loss = 147084
I0728 10:44:03.933166 20134 solver.cpp:238]     Train net output #0: loss1 = 2278.03 (* 1 = 2278.03 loss)
I0728 10:44:03.933176 20134 solver.cpp:238]     Train net output #1: loss10 = 2280.04 (* 1 = 2280.04 loss)
I0728 10:44:03.933182 20134 solver.cpp:238]     Train net output #2: loss11 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933187 20134 solver.cpp:238]     Train net output #3: loss12 = 2347.25 (* 1 = 2347.25 loss)
I0728 10:44:03.933193 20134 solver.cpp:238]     Train net output #4: loss13 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933199 20134 solver.cpp:238]     Train net output #5: loss14 = 2287.66 (* 1 = 2287.66 loss)
I0728 10:44:03.933205 20134 solver.cpp:238]     Train net output #6: loss15 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933212 20134 solver.cpp:238]     Train net output #7: loss16 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933217 20134 solver.cpp:238]     Train net output #8: loss17 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933223 20134 solver.cpp:238]     Train net output #9: loss18 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933228 20134 solver.cpp:238]     Train net output #10: loss19 = 2344.95 (* 1 = 2344.95 loss)
I0728 10:44:03.933234 20134 solver.cpp:238]     Train net output #11: loss2 = 2276.67 (* 1 = 2276.67 loss)
I0728 10:44:03.933240 20134 solver.cpp:238]     Train net output #12: loss20 = 2328.12 (* 1 = 2328.12 loss)
I0728 10:44:03.933245 20134 solver.cpp:238]     Train net output #13: loss21 = 2268.86 (* 1 = 2268.86 loss)
I0728 10:44:03.933251 20134 solver.cpp:238]     Train net output #14: loss22 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933257 20134 solver.cpp:238]     Train net output #15: loss23 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933264 20134 solver.cpp:238]     Train net output #16: loss24 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933269 20134 solver.cpp:238]     Train net output #17: loss25 = 2286.76 (* 1 = 2286.76 loss)
I0728 10:44:03.933274 20134 solver.cpp:238]     Train net output #18: loss26 = 2305.75 (* 1 = 2305.75 loss)
I0728 10:44:03.933280 20134 solver.cpp:238]     Train net output #19: loss27 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933286 20134 solver.cpp:238]     Train net output #20: loss28 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933292 20134 solver.cpp:238]     Train net output #21: loss29 = 2426.39 (* 1 = 2426.39 loss)
I0728 10:44:03.933298 20134 solver.cpp:238]     Train net output #22: loss3 = 2367.84 (* 1 = 2367.84 loss)
I0728 10:44:03.933308 20134 solver.cpp:238]     Train net output #23: loss30 = 2350.98 (* 1 = 2350.98 loss)
I0728 10:44:03.933315 20134 solver.cpp:238]     Train net output #24: loss31 = 2308.92 (* 1 = 2308.92 loss)
I0728 10:44:03.933321 20134 solver.cpp:238]     Train net output #25: loss32 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933327 20134 solver.cpp:238]     Train net output #26: loss33 = 2303.76 (* 1 = 2303.76 loss)
I0728 10:44:03.933332 20134 solver.cpp:238]     Train net output #27: loss34 = 2280.49 (* 1 = 2280.49 loss)
I0728 10:44:03.933338 20134 solver.cpp:238]     Train net output #28: loss35 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933387 20134 solver.cpp:238]     Train net output #29: loss36 = 2276.78 (* 1 = 2276.78 loss)
I0728 10:44:03.933398 20134 solver.cpp:238]     Train net output #30: loss37 = 2361.97 (* 1 = 2361.97 loss)
I0728 10:44:03.933408 20134 solver.cpp:238]     Train net output #31: loss38 = 2347.65 (* 1 = 2347.65 loss)
I0728 10:44:03.933418 20134 solver.cpp:238]     Train net output #32: loss39 = 2284.44 (* 1 = 2284.44 loss)
I0728 10:44:03.933430 20134 solver.cpp:238]     Train net output #33: loss4 = 2285.03 (* 1 = 2285.03 loss)
I0728 10:44:03.933439 20134 solver.cpp:238]     Train net output #34: loss40 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933449 20134 solver.cpp:238]     Train net output #35: loss41 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933459 20134 solver.cpp:238]     Train net output #36: loss42 = 2272.86 (* 1 = 2272.86 loss)
I0728 10:44:03.933468 20134 solver.cpp:238]     Train net output #37: loss43 = 2305.29 (* 1 = 2305.29 loss)
I0728 10:44:03.933477 20134 solver.cpp:238]     Train net output #38: loss44 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933487 20134 solver.cpp:238]     Train net output #39: loss45 = 2308.14 (* 1 = 2308.14 loss)
I0728 10:44:03.933497 20134 solver.cpp:238]     Train net output #40: loss46 = 2396.42 (* 1 = 2396.42 loss)
I0728 10:44:03.933506 20134 solver.cpp:238]     Train net output #41: loss47 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933516 20134 solver.cpp:238]     Train net output #42: loss48 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933526 20134 solver.cpp:238]     Train net output #43: loss49 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933537 20134 solver.cpp:238]     Train net output #44: loss5 = 2289.72 (* 1 = 2289.72 loss)
I0728 10:44:03.933547 20134 solver.cpp:238]     Train net output #45: loss50 = 2282.51 (* 1 = 2282.51 loss)
I0728 10:44:03.933555 20134 solver.cpp:238]     Train net output #46: loss51 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933565 20134 solver.cpp:238]     Train net output #47: loss52 = 2303.25 (* 1 = 2303.25 loss)
I0728 10:44:03.933576 20134 solver.cpp:238]     Train net output #48: loss53 = 2383.75 (* 1 = 2383.75 loss)
I0728 10:44:03.933584 20134 solver.cpp:238]     Train net output #49: loss54 = 2321.56 (* 1 = 2321.56 loss)
I0728 10:44:03.933590 20134 solver.cpp:238]     Train net output #50: loss55 = 2280.82 (* 1 = 2280.82 loss)
I0728 10:44:03.933601 20134 solver.cpp:238]     Train net output #51: loss56 = 2305.18 (* 1 = 2305.18 loss)
I0728 10:44:03.933607 20134 solver.cpp:238]     Train net output #52: loss57 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933614 20134 solver.cpp:238]     Train net output #53: loss58 = 2276.67 (* 1 = 2276.67 loss)
I0728 10:44:03.933619 20134 solver.cpp:238]     Train net output #54: loss59 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933624 20134 solver.cpp:238]     Train net output #55: loss6 = 2387.87 (* 1 = 2387.87 loss)
I0728 10:44:03.933630 20134 solver.cpp:238]     Train net output #56: loss60 = 2296.43 (* 1 = 2296.43 loss)
I0728 10:44:03.933635 20134 solver.cpp:238]     Train net output #57: loss61 = 2297.05 (* 1 = 2297.05 loss)
I0728 10:44:03.933641 20134 solver.cpp:238]     Train net output #58: loss62 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933647 20134 solver.cpp:238]     Train net output #59: loss63 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933655 20134 solver.cpp:238]     Train net output #60: loss64 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933665 20134 solver.cpp:238]     Train net output #61: loss7 = 2327.55 (* 1 = 2327.55 loss)
I0728 10:44:03.933676 20134 solver.cpp:238]     Train net output #62: loss8 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933686 20134 solver.cpp:238]     Train net output #63: loss9 = 2276.68 (* 1 = 2276.68 loss)
I0728 10:44:03.933696 20134 sgd_solver.cpp:105] Iteration 27000, lr = 1e-09
I0728 10:53:04.654057 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:53:04.655913 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:53:05.041743 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_32400.caffemodel
I0728 10:53:05.272615 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_32400.solverstate
I0728 10:53:05.356277 20134 solver.cpp:331] Iteration 32400, Testing net (#0)
I0728 10:53:20.566505 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:53:20.688295 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 10:53:21.031379 20134 solver.cpp:398]     Test net output #0: mae = 102.092 (* 1 = 102.092 loss)
I0728 10:53:21.031401 20134 solver.cpp:398]     Test net output #1: mse = 19250.8 (* 1 = 19250.8 loss)
I0728 10:53:21.155639 20134 solver.cpp:219] Iteration 32400 (9.69114 iter/s, 557.21s/5400 iters), loss = 134348
I0728 10:53:21.155675 20134 solver.cpp:238]     Train net output #0: loss1 = 2081.31 (* 1 = 2081.31 loss)
I0728 10:53:21.155683 20134 solver.cpp:238]     Train net output #1: loss10 = 2079.36 (* 1 = 2079.36 loss)
I0728 10:53:21.155688 20134 solver.cpp:238]     Train net output #2: loss11 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155694 20134 solver.cpp:238]     Train net output #3: loss12 = 2143.11 (* 1 = 2143.11 loss)
I0728 10:53:21.155702 20134 solver.cpp:238]     Train net output #4: loss13 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155709 20134 solver.cpp:238]     Train net output #5: loss14 = 2088.54 (* 1 = 2088.54 loss)
I0728 10:53:21.155715 20134 solver.cpp:238]     Train net output #6: loss15 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155721 20134 solver.cpp:238]     Train net output #7: loss16 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155727 20134 solver.cpp:238]     Train net output #8: loss17 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155733 20134 solver.cpp:238]     Train net output #9: loss18 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155740 20134 solver.cpp:238]     Train net output #10: loss19 = 2150.84 (* 1 = 2150.84 loss)
I0728 10:53:21.155746 20134 solver.cpp:238]     Train net output #11: loss2 = 2079.21 (* 1 = 2079.21 loss)
I0728 10:53:21.155752 20134 solver.cpp:238]     Train net output #12: loss20 = 2117.71 (* 1 = 2117.71 loss)
I0728 10:53:21.155757 20134 solver.cpp:238]     Train net output #13: loss21 = 2070.61 (* 1 = 2070.61 loss)
I0728 10:53:21.155763 20134 solver.cpp:238]     Train net output #14: loss22 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155768 20134 solver.cpp:238]     Train net output #15: loss23 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155773 20134 solver.cpp:238]     Train net output #16: loss24 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155779 20134 solver.cpp:238]     Train net output #17: loss25 = 2088.36 (* 1 = 2088.36 loss)
I0728 10:53:21.155786 20134 solver.cpp:238]     Train net output #18: loss26 = 2106.68 (* 1 = 2106.68 loss)
I0728 10:53:21.155791 20134 solver.cpp:238]     Train net output #19: loss27 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155797 20134 solver.cpp:238]     Train net output #20: loss28 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155802 20134 solver.cpp:238]     Train net output #21: loss29 = 2214.33 (* 1 = 2214.33 loss)
I0728 10:53:21.155808 20134 solver.cpp:238]     Train net output #22: loss3 = 2150.04 (* 1 = 2150.04 loss)
I0728 10:53:21.155814 20134 solver.cpp:238]     Train net output #23: loss30 = 2143.76 (* 1 = 2143.76 loss)
I0728 10:53:21.155819 20134 solver.cpp:238]     Train net output #24: loss31 = 2107.37 (* 1 = 2107.37 loss)
I0728 10:53:21.155825 20134 solver.cpp:238]     Train net output #25: loss32 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155830 20134 solver.cpp:238]     Train net output #26: loss33 = 2101.99 (* 1 = 2101.99 loss)
I0728 10:53:21.155836 20134 solver.cpp:238]     Train net output #27: loss34 = 2080.51 (* 1 = 2080.51 loss)
I0728 10:53:21.155841 20134 solver.cpp:238]     Train net output #28: loss35 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155848 20134 solver.cpp:238]     Train net output #29: loss36 = 2079.93 (* 1 = 2079.93 loss)
I0728 10:53:21.155884 20134 solver.cpp:238]     Train net output #30: loss37 = 2161.63 (* 1 = 2161.63 loss)
I0728 10:53:21.155890 20134 solver.cpp:238]     Train net output #31: loss38 = 2148.8 (* 1 = 2148.8 loss)
I0728 10:53:21.155896 20134 solver.cpp:238]     Train net output #32: loss39 = 2095.9 (* 1 = 2095.9 loss)
I0728 10:53:21.155901 20134 solver.cpp:238]     Train net output #33: loss4 = 2085.35 (* 1 = 2085.35 loss)
I0728 10:53:21.155907 20134 solver.cpp:238]     Train net output #34: loss40 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155913 20134 solver.cpp:238]     Train net output #35: loss41 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155920 20134 solver.cpp:238]     Train net output #36: loss42 = 2074.35 (* 1 = 2074.35 loss)
I0728 10:53:21.155925 20134 solver.cpp:238]     Train net output #37: loss43 = 2110.79 (* 1 = 2110.79 loss)
I0728 10:53:21.155930 20134 solver.cpp:238]     Train net output #38: loss44 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155936 20134 solver.cpp:238]     Train net output #39: loss45 = 2106.35 (* 1 = 2106.35 loss)
I0728 10:53:21.155941 20134 solver.cpp:238]     Train net output #40: loss46 = 2192.11 (* 1 = 2192.11 loss)
I0728 10:53:21.155947 20134 solver.cpp:238]     Train net output #41: loss47 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155953 20134 solver.cpp:238]     Train net output #42: loss48 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155966 20134 solver.cpp:238]     Train net output #43: loss49 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155972 20134 solver.cpp:238]     Train net output #44: loss5 = 2093.98 (* 1 = 2093.98 loss)
I0728 10:53:21.155977 20134 solver.cpp:238]     Train net output #45: loss50 = 2085.84 (* 1 = 2085.84 loss)
I0728 10:53:21.155982 20134 solver.cpp:238]     Train net output #46: loss51 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.155988 20134 solver.cpp:238]     Train net output #47: loss52 = 2099.95 (* 1 = 2099.95 loss)
I0728 10:53:21.155993 20134 solver.cpp:238]     Train net output #48: loss53 = 2177.05 (* 1 = 2177.05 loss)
I0728 10:53:21.155999 20134 solver.cpp:238]     Train net output #49: loss54 = 2122.65 (* 1 = 2122.65 loss)
I0728 10:53:21.156005 20134 solver.cpp:238]     Train net output #50: loss55 = 2081.8 (* 1 = 2081.8 loss)
I0728 10:53:21.156011 20134 solver.cpp:238]     Train net output #51: loss56 = 2111.74 (* 1 = 2111.74 loss)
I0728 10:53:21.156016 20134 solver.cpp:238]     Train net output #52: loss57 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156023 20134 solver.cpp:238]     Train net output #53: loss58 = 2079.87 (* 1 = 2079.87 loss)
I0728 10:53:21.156028 20134 solver.cpp:238]     Train net output #54: loss59 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156034 20134 solver.cpp:238]     Train net output #55: loss6 = 2178.91 (* 1 = 2178.91 loss)
I0728 10:53:21.156039 20134 solver.cpp:238]     Train net output #56: loss60 = 2100.53 (* 1 = 2100.53 loss)
I0728 10:53:21.156045 20134 solver.cpp:238]     Train net output #57: loss61 = 2091.47 (* 1 = 2091.47 loss)
I0728 10:53:21.156050 20134 solver.cpp:238]     Train net output #58: loss62 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156056 20134 solver.cpp:238]     Train net output #59: loss63 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156062 20134 solver.cpp:238]     Train net output #60: loss64 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156067 20134 solver.cpp:238]     Train net output #61: loss7 = 2124.95 (* 1 = 2124.95 loss)
I0728 10:53:21.156074 20134 solver.cpp:238]     Train net output #62: loss8 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156080 20134 solver.cpp:238]     Train net output #63: loss9 = 2079.9 (* 1 = 2079.9 loss)
I0728 10:53:21.156085 20134 sgd_solver.cpp:105] Iteration 32400, lr = 1e-09
I0728 11:02:21.114259 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:02:21.117522 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:02:21.506299 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_37800.caffemodel
I0728 11:02:21.744248 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_37800.solverstate
I0728 11:02:21.826649 20134 solver.cpp:331] Iteration 37800, Testing net (#0)
I0728 11:02:37.053835 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:02:37.108626 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:02:37.518285 20134 solver.cpp:398]     Test net output #0: mae = 97.2974 (* 1 = 97.2974 loss)
I0728 11:02:37.518312 20134 solver.cpp:398]     Test net output #1: mse = 18058.4 (* 1 = 18058.4 loss)
I0728 11:02:37.643299 20134 solver.cpp:219] Iteration 37800 (9.70391 iter/s, 556.477s/5400 iters), loss = 123470
I0728 11:02:37.643348 20134 solver.cpp:238]     Train net output #0: loss1 = 1912.25 (* 1 = 1912.25 loss)
I0728 11:02:37.643363 20134 solver.cpp:238]     Train net output #1: loss10 = 1909.08 (* 1 = 1909.08 loss)
I0728 11:02:37.643376 20134 solver.cpp:238]     Train net output #2: loss11 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643388 20134 solver.cpp:238]     Train net output #3: loss12 = 1967.2 (* 1 = 1967.2 loss)
I0728 11:02:37.643400 20134 solver.cpp:238]     Train net output #4: loss13 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643412 20134 solver.cpp:238]     Train net output #5: loss14 = 1919.51 (* 1 = 1919.51 loss)
I0728 11:02:37.643424 20134 solver.cpp:238]     Train net output #6: loss15 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643436 20134 solver.cpp:238]     Train net output #7: loss16 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643448 20134 solver.cpp:238]     Train net output #8: loss17 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643460 20134 solver.cpp:238]     Train net output #9: loss18 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643472 20134 solver.cpp:238]     Train net output #10: loss19 = 1979.98 (* 1 = 1979.98 loss)
I0728 11:02:37.643483 20134 solver.cpp:238]     Train net output #11: loss2 = 1910.57 (* 1 = 1910.57 loss)
I0728 11:02:37.643496 20134 solver.cpp:238]     Train net output #12: loss20 = 1943.11 (* 1 = 1943.11 loss)
I0728 11:02:37.643507 20134 solver.cpp:238]     Train net output #13: loss21 = 1901.89 (* 1 = 1901.89 loss)
I0728 11:02:37.643519 20134 solver.cpp:238]     Train net output #14: loss22 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643530 20134 solver.cpp:238]     Train net output #15: loss23 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643543 20134 solver.cpp:238]     Train net output #16: loss24 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643553 20134 solver.cpp:238]     Train net output #17: loss25 = 1919.97 (* 1 = 1919.97 loss)
I0728 11:02:37.643563 20134 solver.cpp:238]     Train net output #18: loss26 = 1935.47 (* 1 = 1935.47 loss)
I0728 11:02:37.643573 20134 solver.cpp:238]     Train net output #19: loss27 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643585 20134 solver.cpp:238]     Train net output #20: loss28 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643596 20134 solver.cpp:238]     Train net output #21: loss29 = 2030.04 (* 1 = 2030.04 loss)
I0728 11:02:37.643607 20134 solver.cpp:238]     Train net output #22: loss3 = 1963.75 (* 1 = 1963.75 loss)
I0728 11:02:37.643618 20134 solver.cpp:238]     Train net output #23: loss30 = 1966.99 (* 1 = 1966.99 loss)
I0728 11:02:37.643630 20134 solver.cpp:238]     Train net output #24: loss31 = 1935.45 (* 1 = 1935.45 loss)
I0728 11:02:37.643642 20134 solver.cpp:238]     Train net output #25: loss32 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643654 20134 solver.cpp:238]     Train net output #26: loss33 = 1930.05 (* 1 = 1930.05 loss)
I0728 11:02:37.643666 20134 solver.cpp:238]     Train net output #27: loss34 = 1911.62 (* 1 = 1911.62 loss)
I0728 11:02:37.643677 20134 solver.cpp:238]     Train net output #28: loss35 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643733 20134 solver.cpp:238]     Train net output #29: loss36 = 1911.48 (* 1 = 1911.48 loss)
I0728 11:02:37.643745 20134 solver.cpp:238]     Train net output #30: loss37 = 1984.7 (* 1 = 1984.7 loss)
I0728 11:02:37.643754 20134 solver.cpp:238]     Train net output #31: loss38 = 1976.58 (* 1 = 1976.58 loss)
I0728 11:02:37.643761 20134 solver.cpp:238]     Train net output #32: loss39 = 1930.11 (* 1 = 1930.11 loss)
I0728 11:02:37.643769 20134 solver.cpp:238]     Train net output #33: loss4 = 1916.54 (* 1 = 1916.54 loss)
I0728 11:02:37.643775 20134 solver.cpp:238]     Train net output #34: loss40 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643782 20134 solver.cpp:238]     Train net output #35: loss41 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643790 20134 solver.cpp:238]     Train net output #36: loss42 = 1905.85 (* 1 = 1905.85 loss)
I0728 11:02:37.643795 20134 solver.cpp:238]     Train net output #37: loss43 = 1938.25 (* 1 = 1938.25 loss)
I0728 11:02:37.643802 20134 solver.cpp:238]     Train net output #38: loss44 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643808 20134 solver.cpp:238]     Train net output #39: loss45 = 1934.8 (* 1 = 1934.8 loss)
I0728 11:02:37.643815 20134 solver.cpp:238]     Train net output #40: loss46 = 2014.99 (* 1 = 2014.99 loss)
I0728 11:02:37.643821 20134 solver.cpp:238]     Train net output #41: loss47 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643828 20134 solver.cpp:238]     Train net output #42: loss48 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643834 20134 solver.cpp:238]     Train net output #43: loss49 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643841 20134 solver.cpp:238]     Train net output #44: loss5 = 1925.67 (* 1 = 1925.67 loss)
I0728 11:02:37.643847 20134 solver.cpp:238]     Train net output #45: loss50 = 1916.46 (* 1 = 1916.46 loss)
I0728 11:02:37.643854 20134 solver.cpp:238]     Train net output #46: loss51 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643860 20134 solver.cpp:238]     Train net output #47: loss52 = 1930.16 (* 1 = 1930.16 loss)
I0728 11:02:37.643867 20134 solver.cpp:238]     Train net output #48: loss53 = 1994.71 (* 1 = 1994.71 loss)
I0728 11:02:37.643874 20134 solver.cpp:238]     Train net output #49: loss54 = 1951.86 (* 1 = 1951.86 loss)
I0728 11:02:37.643880 20134 solver.cpp:238]     Train net output #50: loss55 = 1913.4 (* 1 = 1913.4 loss)
I0728 11:02:37.643887 20134 solver.cpp:238]     Train net output #51: loss56 = 1944.32 (* 1 = 1944.32 loss)
I0728 11:02:37.643893 20134 solver.cpp:238]     Train net output #52: loss57 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643900 20134 solver.cpp:238]     Train net output #53: loss58 = 1911.43 (* 1 = 1911.43 loss)
I0728 11:02:37.643906 20134 solver.cpp:238]     Train net output #54: loss59 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643913 20134 solver.cpp:238]     Train net output #55: loss6 = 1999.86 (* 1 = 1999.86 loss)
I0728 11:02:37.643920 20134 solver.cpp:238]     Train net output #56: loss60 = 1932.35 (* 1 = 1932.35 loss)
I0728 11:02:37.643926 20134 solver.cpp:238]     Train net output #57: loss61 = 1920.93 (* 1 = 1920.93 loss)
I0728 11:02:37.643932 20134 solver.cpp:238]     Train net output #58: loss62 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643939 20134 solver.cpp:238]     Train net output #59: loss63 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643946 20134 solver.cpp:238]     Train net output #60: loss64 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643954 20134 solver.cpp:238]     Train net output #61: loss7 = 1953.34 (* 1 = 1953.34 loss)
I0728 11:02:37.643959 20134 solver.cpp:238]     Train net output #62: loss8 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643966 20134 solver.cpp:238]     Train net output #63: loss9 = 1911.47 (* 1 = 1911.47 loss)
I0728 11:02:37.643973 20134 sgd_solver.cpp:105] Iteration 37800, lr = 1e-09
I0728 11:11:40.007179 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:11:40.008797 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:11:40.398999 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_43200.caffemodel
I0728 11:11:40.659070 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_43200.solverstate
I0728 11:11:40.744822 20134 solver.cpp:331] Iteration 43200, Testing net (#0)
I0728 11:11:55.964319 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:11:55.991019 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:11:56.430006 20134 solver.cpp:398]     Test net output #0: mae = 94.8413 (* 1 = 94.8413 loss)
I0728 11:11:56.430034 20134 solver.cpp:398]     Test net output #1: mse = 17270.3 (* 1 = 17270.3 loss)
I0728 11:11:56.554517 20134 solver.cpp:219] Iteration 43200 (9.66183 iter/s, 558.901s/5400 iters), loss = 115245
I0728 11:11:56.554561 20134 solver.cpp:238]     Train net output #0: loss1 = 1784.96 (* 1 = 1784.96 loss)
I0728 11:11:56.554572 20134 solver.cpp:238]     Train net output #1: loss10 = 1779.86 (* 1 = 1779.86 loss)
I0728 11:11:56.554579 20134 solver.cpp:238]     Train net output #2: loss11 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554586 20134 solver.cpp:238]     Train net output #3: loss12 = 1833.54 (* 1 = 1833.54 loss)
I0728 11:11:56.554592 20134 solver.cpp:238]     Train net output #4: loss13 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554599 20134 solver.cpp:238]     Train net output #5: loss14 = 1791.49 (* 1 = 1791.49 loss)
I0728 11:11:56.554605 20134 solver.cpp:238]     Train net output #6: loss15 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554610 20134 solver.cpp:238]     Train net output #7: loss16 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554616 20134 solver.cpp:238]     Train net output #8: loss17 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554622 20134 solver.cpp:238]     Train net output #9: loss18 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554628 20134 solver.cpp:238]     Train net output #10: loss19 = 1853.43 (* 1 = 1853.43 loss)
I0728 11:11:56.554636 20134 solver.cpp:238]     Train net output #11: loss2 = 1783.4 (* 1 = 1783.4 loss)
I0728 11:11:56.554641 20134 solver.cpp:238]     Train net output #12: loss20 = 1809.78 (* 1 = 1809.78 loss)
I0728 11:11:56.554648 20134 solver.cpp:238]     Train net output #13: loss21 = 1774.07 (* 1 = 1774.07 loss)
I0728 11:11:56.554654 20134 solver.cpp:238]     Train net output #14: loss22 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554661 20134 solver.cpp:238]     Train net output #15: loss23 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554666 20134 solver.cpp:238]     Train net output #16: loss24 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554673 20134 solver.cpp:238]     Train net output #17: loss25 = 1793.51 (* 1 = 1793.51 loss)
I0728 11:11:56.554679 20134 solver.cpp:238]     Train net output #18: loss26 = 1806.36 (* 1 = 1806.36 loss)
I0728 11:11:56.554685 20134 solver.cpp:238]     Train net output #19: loss27 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554692 20134 solver.cpp:238]     Train net output #20: loss28 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554698 20134 solver.cpp:238]     Train net output #21: loss29 = 1889.33 (* 1 = 1889.33 loss)
I0728 11:11:56.554704 20134 solver.cpp:238]     Train net output #22: loss3 = 1823.96 (* 1 = 1823.96 loss)
I0728 11:11:56.554710 20134 solver.cpp:238]     Train net output #23: loss30 = 1835.05 (* 1 = 1835.05 loss)
I0728 11:11:56.554716 20134 solver.cpp:238]     Train net output #24: loss31 = 1805.69 (* 1 = 1805.69 loss)
I0728 11:11:56.554723 20134 solver.cpp:238]     Train net output #25: loss32 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554729 20134 solver.cpp:238]     Train net output #26: loss33 = 1801.15 (* 1 = 1801.15 loss)
I0728 11:11:56.554735 20134 solver.cpp:238]     Train net output #27: loss34 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554741 20134 solver.cpp:238]     Train net output #28: loss35 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554783 20134 solver.cpp:238]     Train net output #29: loss36 = 1792.23 (* 1 = 1792.23 loss)
I0728 11:11:56.554790 20134 solver.cpp:238]     Train net output #30: loss37 = 1848.63 (* 1 = 1848.63 loss)
I0728 11:11:56.554795 20134 solver.cpp:238]     Train net output #31: loss38 = 1846.12 (* 1 = 1846.12 loss)
I0728 11:11:56.554800 20134 solver.cpp:238]     Train net output #32: loss39 = 1804.36 (* 1 = 1804.36 loss)
I0728 11:11:56.554805 20134 solver.cpp:238]     Train net output #33: loss4 = 1788.48 (* 1 = 1788.48 loss)
I0728 11:11:56.554811 20134 solver.cpp:238]     Train net output #34: loss40 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554817 20134 solver.cpp:238]     Train net output #35: loss41 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554823 20134 solver.cpp:238]     Train net output #36: loss42 = 1779.83 (* 1 = 1779.83 loss)
I0728 11:11:56.554831 20134 solver.cpp:238]     Train net output #37: loss43 = 1806.15 (* 1 = 1806.15 loss)
I0728 11:11:56.554836 20134 solver.cpp:238]     Train net output #38: loss44 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554842 20134 solver.cpp:238]     Train net output #39: loss45 = 1805.38 (* 1 = 1805.38 loss)
I0728 11:11:56.554848 20134 solver.cpp:238]     Train net output #40: loss46 = 1880.69 (* 1 = 1880.69 loss)
I0728 11:11:56.554854 20134 solver.cpp:238]     Train net output #41: loss47 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554862 20134 solver.cpp:238]     Train net output #42: loss48 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554867 20134 solver.cpp:238]     Train net output #43: loss49 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554873 20134 solver.cpp:238]     Train net output #44: loss5 = 1798.95 (* 1 = 1798.95 loss)
I0728 11:11:56.554880 20134 solver.cpp:238]     Train net output #45: loss50 = 1788.53 (* 1 = 1788.53 loss)
I0728 11:11:56.554886 20134 solver.cpp:238]     Train net output #46: loss51 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554893 20134 solver.cpp:238]     Train net output #47: loss52 = 1800.26 (* 1 = 1800.26 loss)
I0728 11:11:56.554898 20134 solver.cpp:238]     Train net output #48: loss53 = 1856.57 (* 1 = 1856.57 loss)
I0728 11:11:56.554905 20134 solver.cpp:238]     Train net output #49: loss54 = 1822.94 (* 1 = 1822.94 loss)
I0728 11:11:56.554911 20134 solver.cpp:238]     Train net output #50: loss55 = 1786.44 (* 1 = 1786.44 loss)
I0728 11:11:56.554924 20134 solver.cpp:238]     Train net output #51: loss56 = 1817.35 (* 1 = 1817.35 loss)
I0728 11:11:56.554930 20134 solver.cpp:238]     Train net output #52: loss57 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554936 20134 solver.cpp:238]     Train net output #53: loss58 = 1784.36 (* 1 = 1784.36 loss)
I0728 11:11:56.554942 20134 solver.cpp:238]     Train net output #54: loss59 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554949 20134 solver.cpp:238]     Train net output #55: loss6 = 1864.01 (* 1 = 1864.01 loss)
I0728 11:11:56.554955 20134 solver.cpp:238]     Train net output #56: loss60 = 1805.51 (* 1 = 1805.51 loss)
I0728 11:11:56.554961 20134 solver.cpp:238]     Train net output #57: loss61 = 1791.67 (* 1 = 1791.67 loss)
I0728 11:11:56.554967 20134 solver.cpp:238]     Train net output #58: loss62 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554973 20134 solver.cpp:238]     Train net output #59: loss63 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554980 20134 solver.cpp:238]     Train net output #60: loss64 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554986 20134 solver.cpp:238]     Train net output #61: loss7 = 1824.59 (* 1 = 1824.59 loss)
I0728 11:11:56.554992 20134 solver.cpp:238]     Train net output #62: loss8 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.554999 20134 solver.cpp:238]     Train net output #63: loss9 = 1784.41 (* 1 = 1784.41 loss)
I0728 11:11:56.555006 20134 sgd_solver.cpp:105] Iteration 43200, lr = 1e-09
I0728 11:20:58.617033 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:20:58.618901 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:20:59.007457 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_48600.caffemodel
I0728 11:20:59.240717 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_48600.solverstate
I0728 11:20:59.324324 20134 solver.cpp:331] Iteration 48600, Testing net (#0)
I0728 11:21:14.551316 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:21:14.669705 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:21:15.016324 20134 solver.cpp:398]     Test net output #0: mae = 89.9735 (* 1 = 89.9735 loss)
I0728 11:21:15.016352 20134 solver.cpp:398]     Test net output #1: mse = 16127.6 (* 1 = 16127.6 loss)
I0728 11:21:15.141091 20134 solver.cpp:219] Iteration 48600 (9.66748 iter/s, 558.574s/5400 iters), loss = 108992
I0728 11:21:15.141135 20134 solver.cpp:238]     Train net output #0: loss1 = 1688.09 (* 1 = 1688.09 loss)
I0728 11:21:15.141146 20134 solver.cpp:238]     Train net output #1: loss10 = 1682.21 (* 1 = 1682.21 loss)
I0728 11:21:15.141155 20134 solver.cpp:238]     Train net output #2: loss11 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141163 20134 solver.cpp:238]     Train net output #3: loss12 = 1731.61 (* 1 = 1731.61 loss)
I0728 11:21:15.141172 20134 solver.cpp:238]     Train net output #4: loss13 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141180 20134 solver.cpp:238]     Train net output #5: loss14 = 1694.45 (* 1 = 1694.45 loss)
I0728 11:21:15.141188 20134 solver.cpp:238]     Train net output #6: loss15 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141196 20134 solver.cpp:238]     Train net output #7: loss16 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141206 20134 solver.cpp:238]     Train net output #8: loss17 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141214 20134 solver.cpp:238]     Train net output #9: loss18 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141222 20134 solver.cpp:238]     Train net output #10: loss19 = 1754.89 (* 1 = 1754.89 loss)
I0728 11:21:15.141229 20134 solver.cpp:238]     Train net output #11: loss2 = 1686.61 (* 1 = 1686.61 loss)
I0728 11:21:15.141237 20134 solver.cpp:238]     Train net output #12: loss20 = 1710.35 (* 1 = 1710.35 loss)
I0728 11:21:15.141247 20134 solver.cpp:238]     Train net output #13: loss21 = 1676.97 (* 1 = 1676.97 loss)
I0728 11:21:15.141252 20134 solver.cpp:238]     Train net output #14: loss22 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141257 20134 solver.cpp:238]     Train net output #15: loss23 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141261 20134 solver.cpp:238]     Train net output #16: loss24 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141266 20134 solver.cpp:238]     Train net output #17: loss25 = 1697.75 (* 1 = 1697.75 loss)
I0728 11:21:15.141270 20134 solver.cpp:238]     Train net output #18: loss26 = 1707.26 (* 1 = 1707.26 loss)
I0728 11:21:15.141276 20134 solver.cpp:238]     Train net output #19: loss27 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141299 20134 solver.cpp:238]     Train net output #20: loss28 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141321 20134 solver.cpp:238]     Train net output #21: loss29 = 1780.94 (* 1 = 1780.94 loss)
I0728 11:21:15.141330 20134 solver.cpp:238]     Train net output #22: loss3 = 1721.14 (* 1 = 1721.14 loss)
I0728 11:21:15.141335 20134 solver.cpp:238]     Train net output #23: loss30 = 1736.47 (* 1 = 1736.47 loss)
I0728 11:21:15.141342 20134 solver.cpp:238]     Train net output #24: loss31 = 1707.22 (* 1 = 1707.22 loss)
I0728 11:21:15.141350 20134 solver.cpp:238]     Train net output #25: loss32 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141356 20134 solver.cpp:238]     Train net output #26: loss33 = 1702.95 (* 1 = 1702.95 loss)
I0728 11:21:15.141363 20134 solver.cpp:238]     Train net output #27: loss34 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141369 20134 solver.cpp:238]     Train net output #28: loss35 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141412 20134 solver.cpp:238]     Train net output #29: loss36 = 1687.64 (* 1 = 1687.64 loss)
I0728 11:21:15.141419 20134 solver.cpp:238]     Train net output #30: loss37 = 1742.6 (* 1 = 1742.6 loss)
I0728 11:21:15.141427 20134 solver.cpp:238]     Train net output #31: loss38 = 1745.89 (* 1 = 1745.89 loss)
I0728 11:21:15.141434 20134 solver.cpp:238]     Train net output #32: loss39 = 1708.07 (* 1 = 1708.07 loss)
I0728 11:21:15.141440 20134 solver.cpp:238]     Train net output #33: loss4 = 1690.61 (* 1 = 1690.61 loss)
I0728 11:21:15.141448 20134 solver.cpp:238]     Train net output #34: loss40 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141454 20134 solver.cpp:238]     Train net output #35: loss41 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141463 20134 solver.cpp:238]     Train net output #36: loss42 = 1684.23 (* 1 = 1684.23 loss)
I0728 11:21:15.141470 20134 solver.cpp:238]     Train net output #37: loss43 = 1706.13 (* 1 = 1706.13 loss)
I0728 11:21:15.141475 20134 solver.cpp:238]     Train net output #38: loss44 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141484 20134 solver.cpp:238]     Train net output #39: loss45 = 1707.76 (* 1 = 1707.76 loss)
I0728 11:21:15.141491 20134 solver.cpp:238]     Train net output #40: loss46 = 1777.84 (* 1 = 1777.84 loss)
I0728 11:21:15.141500 20134 solver.cpp:238]     Train net output #41: loss47 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141508 20134 solver.cpp:238]     Train net output #42: loss48 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141516 20134 solver.cpp:238]     Train net output #43: loss49 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141525 20134 solver.cpp:238]     Train net output #44: loss5 = 1702.85 (* 1 = 1702.85 loss)
I0728 11:21:15.141533 20134 solver.cpp:238]     Train net output #45: loss50 = 1691.06 (* 1 = 1691.06 loss)
I0728 11:21:15.141541 20134 solver.cpp:238]     Train net output #46: loss51 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141549 20134 solver.cpp:238]     Train net output #47: loss52 = 1703.87 (* 1 = 1703.87 loss)
I0728 11:21:15.141558 20134 solver.cpp:238]     Train net output #48: loss53 = 1750.47 (* 1 = 1750.47 loss)
I0728 11:21:15.141566 20134 solver.cpp:238]     Train net output #49: loss54 = 1724.61 (* 1 = 1724.61 loss)
I0728 11:21:15.141574 20134 solver.cpp:238]     Train net output #50: loss55 = 1689.96 (* 1 = 1689.96 loss)
I0728 11:21:15.141582 20134 solver.cpp:238]     Train net output #51: loss56 = 1720.71 (* 1 = 1720.71 loss)
I0728 11:21:15.141590 20134 solver.cpp:238]     Train net output #52: loss57 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141599 20134 solver.cpp:238]     Train net output #53: loss58 = 1705.37 (* 1 = 1705.37 loss)
I0728 11:21:15.141607 20134 solver.cpp:238]     Train net output #54: loss59 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141615 20134 solver.cpp:238]     Train net output #55: loss6 = 1760.83 (* 1 = 1760.83 loss)
I0728 11:21:15.141623 20134 solver.cpp:238]     Train net output #56: loss60 = 1707.59 (* 1 = 1707.59 loss)
I0728 11:21:15.141631 20134 solver.cpp:238]     Train net output #57: loss61 = 1691.91 (* 1 = 1691.91 loss)
I0728 11:21:15.141639 20134 solver.cpp:238]     Train net output #58: loss62 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141649 20134 solver.cpp:238]     Train net output #59: loss63 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141656 20134 solver.cpp:238]     Train net output #60: loss64 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141664 20134 solver.cpp:238]     Train net output #61: loss7 = 1726.07 (* 1 = 1726.07 loss)
I0728 11:21:15.141672 20134 solver.cpp:238]     Train net output #62: loss8 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141680 20134 solver.cpp:238]     Train net output #63: loss9 = 1687.62 (* 1 = 1687.62 loss)
I0728 11:21:15.141690 20134 sgd_solver.cpp:105] Iteration 48600, lr = 1e-09
I0728 11:30:14.874925 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:30:14.876312 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:30:15.273707 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_54000.caffemodel
I0728 11:30:15.506543 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_54000.solverstate
I0728 11:30:15.590073 20134 solver.cpp:331] Iteration 54000, Testing net (#0)
I0728 11:30:30.798213 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:30:30.827430 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:30:31.262740 20134 solver.cpp:398]     Test net output #0: mae = 86.8642 (* 1 = 86.8642 loss)
I0728 11:30:31.262779 20134 solver.cpp:398]     Test net output #1: mse = 15284.1 (* 1 = 15284.1 loss)
I0728 11:30:31.387334 20134 solver.cpp:219] Iteration 54000 (9.70815 iter/s, 556.234s/5400 iters), loss = 102424
I0728 11:30:31.387380 20134 solver.cpp:238]     Train net output #0: loss1 = 1586.78 (* 1 = 1586.78 loss)
I0728 11:30:31.387400 20134 solver.cpp:238]     Train net output #1: loss10 = 1579.73 (* 1 = 1579.73 loss)
I0728 11:30:31.387408 20134 solver.cpp:238]     Train net output #2: loss11 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387413 20134 solver.cpp:238]     Train net output #3: loss12 = 1624.89 (* 1 = 1624.89 loss)
I0728 11:30:31.387419 20134 solver.cpp:238]     Train net output #4: loss13 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387425 20134 solver.cpp:238]     Train net output #5: loss14 = 1592.71 (* 1 = 1592.71 loss)
I0728 11:30:31.387431 20134 solver.cpp:238]     Train net output #6: loss15 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387437 20134 solver.cpp:238]     Train net output #7: loss16 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387444 20134 solver.cpp:238]     Train net output #8: loss17 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387450 20134 solver.cpp:238]     Train net output #9: loss18 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387456 20134 solver.cpp:238]     Train net output #10: loss19 = 1651.43 (* 1 = 1651.43 loss)
I0728 11:30:31.387462 20134 solver.cpp:238]     Train net output #11: loss2 = 1585.35 (* 1 = 1585.35 loss)
I0728 11:30:31.387470 20134 solver.cpp:238]     Train net output #12: loss20 = 1604.66 (* 1 = 1604.66 loss)
I0728 11:30:31.387476 20134 solver.cpp:238]     Train net output #13: loss21 = 1575.06 (* 1 = 1575.06 loss)
I0728 11:30:31.387482 20134 solver.cpp:238]     Train net output #14: loss22 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387488 20134 solver.cpp:238]     Train net output #15: loss23 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387495 20134 solver.cpp:238]     Train net output #16: loss24 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387501 20134 solver.cpp:238]     Train net output #17: loss25 = 1596.66 (* 1 = 1596.66 loss)
I0728 11:30:31.387506 20134 solver.cpp:238]     Train net output #18: loss26 = 1603.88 (* 1 = 1603.88 loss)
I0728 11:30:31.387512 20134 solver.cpp:238]     Train net output #19: loss27 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387518 20134 solver.cpp:238]     Train net output #20: loss28 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387526 20134 solver.cpp:238]     Train net output #21: loss29 = 1667.18 (* 1 = 1667.18 loss)
I0728 11:30:31.387531 20134 solver.cpp:238]     Train net output #22: loss3 = 1616.7 (* 1 = 1616.7 loss)
I0728 11:30:31.387537 20134 solver.cpp:238]     Train net output #23: loss30 = 1631.23 (* 1 = 1631.23 loss)
I0728 11:30:31.387543 20134 solver.cpp:238]     Train net output #24: loss31 = 1604.32 (* 1 = 1604.32 loss)
I0728 11:30:31.387550 20134 solver.cpp:238]     Train net output #25: loss32 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387557 20134 solver.cpp:238]     Train net output #26: loss33 = 1600.39 (* 1 = 1600.39 loss)
I0728 11:30:31.387562 20134 solver.cpp:238]     Train net output #27: loss34 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387568 20134 solver.cpp:238]     Train net output #28: loss35 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387606 20134 solver.cpp:238]     Train net output #29: loss36 = 1586.41 (* 1 = 1586.41 loss)
I0728 11:30:31.387614 20134 solver.cpp:238]     Train net output #30: loss37 = 1632.21 (* 1 = 1632.21 loss)
I0728 11:30:31.387619 20134 solver.cpp:238]     Train net output #31: loss38 = 1640.69 (* 1 = 1640.69 loss)
I0728 11:30:31.387625 20134 solver.cpp:238]     Train net output #32: loss39 = 1606.29 (* 1 = 1606.29 loss)
I0728 11:30:31.387631 20134 solver.cpp:238]     Train net output #33: loss4 = 1588.76 (* 1 = 1588.76 loss)
I0728 11:30:31.387637 20134 solver.cpp:238]     Train net output #34: loss40 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387643 20134 solver.cpp:238]     Train net output #35: loss41 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387650 20134 solver.cpp:238]     Train net output #36: loss42 = 1584.08 (* 1 = 1584.08 loss)
I0728 11:30:31.387665 20134 solver.cpp:238]     Train net output #37: loss43 = 1603.37 (* 1 = 1603.37 loss)
I0728 11:30:31.387670 20134 solver.cpp:238]     Train net output #38: loss44 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387676 20134 solver.cpp:238]     Train net output #39: loss45 = 1604.79 (* 1 = 1604.79 loss)
I0728 11:30:31.387682 20134 solver.cpp:238]     Train net output #40: loss46 = 1667.46 (* 1 = 1667.46 loss)
I0728 11:30:31.387688 20134 solver.cpp:238]     Train net output #41: loss47 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387694 20134 solver.cpp:238]     Train net output #42: loss48 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387701 20134 solver.cpp:238]     Train net output #43: loss49 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387706 20134 solver.cpp:238]     Train net output #44: loss5 = 1601.9 (* 1 = 1601.9 loss)
I0728 11:30:31.387712 20134 solver.cpp:238]     Train net output #45: loss50 = 1589.2 (* 1 = 1589.2 loss)
I0728 11:30:31.387717 20134 solver.cpp:238]     Train net output #46: loss51 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387723 20134 solver.cpp:238]     Train net output #47: loss52 = 1603.21 (* 1 = 1603.21 loss)
I0728 11:30:31.387729 20134 solver.cpp:238]     Train net output #48: loss53 = 1640.35 (* 1 = 1640.35 loss)
I0728 11:30:31.387735 20134 solver.cpp:238]     Train net output #49: loss54 = 1619.91 (* 1 = 1619.91 loss)
I0728 11:30:31.387742 20134 solver.cpp:238]     Train net output #50: loss55 = 1588.98 (* 1 = 1588.98 loss)
I0728 11:30:31.387748 20134 solver.cpp:238]     Train net output #51: loss56 = 1618.2 (* 1 = 1618.2 loss)
I0728 11:30:31.387753 20134 solver.cpp:238]     Train net output #52: loss57 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387758 20134 solver.cpp:238]     Train net output #53: loss58 = 1602.91 (* 1 = 1602.91 loss)
I0728 11:30:31.387764 20134 solver.cpp:238]     Train net output #54: loss59 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387770 20134 solver.cpp:238]     Train net output #55: loss6 = 1651.35 (* 1 = 1651.35 loss)
I0728 11:30:31.387776 20134 solver.cpp:238]     Train net output #56: loss60 = 1605.24 (* 1 = 1605.24 loss)
I0728 11:30:31.387783 20134 solver.cpp:238]     Train net output #57: loss61 = 1587.59 (* 1 = 1587.59 loss)
I0728 11:30:31.387789 20134 solver.cpp:238]     Train net output #58: loss62 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387794 20134 solver.cpp:238]     Train net output #59: loss63 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387799 20134 solver.cpp:238]     Train net output #60: loss64 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387805 20134 solver.cpp:238]     Train net output #61: loss7 = 1621.66 (* 1 = 1621.66 loss)
I0728 11:30:31.387811 20134 solver.cpp:238]     Train net output #62: loss8 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387817 20134 solver.cpp:238]     Train net output #63: loss9 = 1586.39 (* 1 = 1586.39 loss)
I0728 11:30:31.387825 20134 sgd_solver.cpp:105] Iteration 54000, lr = 1e-09
I0728 11:39:31.508908 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:39:31.510596 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:39:31.909298 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_59400.caffemodel
I0728 11:39:32.172749 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_59400.solverstate
I0728 11:39:32.256188 20134 solver.cpp:331] Iteration 59400, Testing net (#0)
I0728 11:39:47.465996 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:39:47.497182 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:39:47.929925 20134 solver.cpp:398]     Test net output #0: mae = 84.4662 (* 1 = 84.4662 loss)
I0728 11:39:47.929960 20134 solver.cpp:398]     Test net output #1: mse = 14682.3 (* 1 = 14682.3 loss)
I0728 11:39:48.054733 20134 solver.cpp:219] Iteration 59400 (9.70079 iter/s, 556.656s/5400 iters), loss = 97241.8
I0728 11:39:48.054775 20134 solver.cpp:238]     Train net output #0: loss1 = 1506.71 (* 1 = 1506.71 loss)
I0728 11:39:48.054786 20134 solver.cpp:238]     Train net output #1: loss10 = 1498.86 (* 1 = 1498.86 loss)
I0728 11:39:48.054793 20134 solver.cpp:238]     Train net output #2: loss11 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054800 20134 solver.cpp:238]     Train net output #3: loss12 = 1541.17 (* 1 = 1541.17 loss)
I0728 11:39:48.054807 20134 solver.cpp:238]     Train net output #4: loss13 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054813 20134 solver.cpp:238]     Train net output #5: loss14 = 1512.38 (* 1 = 1512.38 loss)
I0728 11:39:48.054819 20134 solver.cpp:238]     Train net output #6: loss15 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054826 20134 solver.cpp:238]     Train net output #7: loss16 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054832 20134 solver.cpp:238]     Train net output #8: loss17 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054838 20134 solver.cpp:238]     Train net output #9: loss18 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054847 20134 solver.cpp:238]     Train net output #10: loss19 = 1568.55 (* 1 = 1568.55 loss)
I0728 11:39:48.054853 20134 solver.cpp:238]     Train net output #11: loss2 = 1505.33 (* 1 = 1505.33 loss)
I0728 11:39:48.054859 20134 solver.cpp:238]     Train net output #12: loss20 = 1521.28 (* 1 = 1521.28 loss)
I0728 11:39:48.054867 20134 solver.cpp:238]     Train net output #13: loss21 = 1494.85 (* 1 = 1494.85 loss)
I0728 11:39:48.054873 20134 solver.cpp:238]     Train net output #14: loss22 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054879 20134 solver.cpp:238]     Train net output #15: loss23 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054885 20134 solver.cpp:238]     Train net output #16: loss24 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054893 20134 solver.cpp:238]     Train net output #17: loss25 = 1516.74 (* 1 = 1516.74 loss)
I0728 11:39:48.054898 20134 solver.cpp:238]     Train net output #18: loss26 = 1522.24 (* 1 = 1522.24 loss)
I0728 11:39:48.054906 20134 solver.cpp:238]     Train net output #19: loss27 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054913 20134 solver.cpp:238]     Train net output #20: loss28 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054919 20134 solver.cpp:238]     Train net output #21: loss29 = 1577.58 (* 1 = 1577.58 loss)
I0728 11:39:48.054926 20134 solver.cpp:238]     Train net output #22: loss3 = 1535.02 (* 1 = 1535.02 loss)
I0728 11:39:48.054932 20134 solver.cpp:238]     Train net output #23: loss30 = 1547.75 (* 1 = 1547.75 loss)
I0728 11:39:48.054939 20134 solver.cpp:238]     Train net output #24: loss31 = 1522.7 (* 1 = 1522.7 loss)
I0728 11:39:48.054944 20134 solver.cpp:238]     Train net output #25: loss32 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054949 20134 solver.cpp:238]     Train net output #26: loss33 = 1519.34 (* 1 = 1519.34 loss)
I0728 11:39:48.054955 20134 solver.cpp:238]     Train net output #27: loss34 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.054961 20134 solver.cpp:238]     Train net output #28: loss35 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055001 20134 solver.cpp:238]     Train net output #29: loss36 = 1506.38 (* 1 = 1506.38 loss)
I0728 11:39:48.055008 20134 solver.cpp:238]     Train net output #30: loss37 = 1544.51 (* 1 = 1544.51 loss)
I0728 11:39:48.055016 20134 solver.cpp:238]     Train net output #31: loss38 = 1557 (* 1 = 1557 loss)
I0728 11:39:48.055022 20134 solver.cpp:238]     Train net output #32: loss39 = 1525.56 (* 1 = 1525.56 loss)
I0728 11:39:48.055028 20134 solver.cpp:238]     Train net output #33: loss4 = 1508.4 (* 1 = 1508.4 loss)
I0728 11:39:48.055034 20134 solver.cpp:238]     Train net output #34: loss40 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055040 20134 solver.cpp:238]     Train net output #35: loss41 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055047 20134 solver.cpp:238]     Train net output #36: loss42 = 1504.7 (* 1 = 1504.7 loss)
I0728 11:39:48.055053 20134 solver.cpp:238]     Train net output #37: loss43 = 1522.15 (* 1 = 1522.15 loss)
I0728 11:39:48.055060 20134 solver.cpp:238]     Train net output #38: loss44 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055068 20134 solver.cpp:238]     Train net output #39: loss45 = 1523.5 (* 1 = 1523.5 loss)
I0728 11:39:48.055075 20134 solver.cpp:238]     Train net output #40: loss46 = 1579.68 (* 1 = 1579.68 loss)
I0728 11:39:48.055083 20134 solver.cpp:238]     Train net output #41: loss47 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055089 20134 solver.cpp:238]     Train net output #42: loss48 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055096 20134 solver.cpp:238]     Train net output #43: loss49 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055104 20134 solver.cpp:238]     Train net output #44: loss5 = 1522.51 (* 1 = 1522.51 loss)
I0728 11:39:48.055109 20134 solver.cpp:238]     Train net output #45: loss50 = 1508.63 (* 1 = 1508.63 loss)
I0728 11:39:48.055116 20134 solver.cpp:238]     Train net output #46: loss51 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055124 20134 solver.cpp:238]     Train net output #47: loss52 = 1524.44 (* 1 = 1524.44 loss)
I0728 11:39:48.055130 20134 solver.cpp:238]     Train net output #48: loss53 = 1554.23 (* 1 = 1554.23 loss)
I0728 11:39:48.055136 20134 solver.cpp:238]     Train net output #49: loss54 = 1537.13 (* 1 = 1537.13 loss)
I0728 11:39:48.055142 20134 solver.cpp:238]     Train net output #50: loss55 = 1509.13 (* 1 = 1509.13 loss)
I0728 11:39:48.055148 20134 solver.cpp:238]     Train net output #51: loss56 = 1536.72 (* 1 = 1536.72 loss)
I0728 11:39:48.055155 20134 solver.cpp:238]     Train net output #52: loss57 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055160 20134 solver.cpp:238]     Train net output #53: loss58 = 1521.78 (* 1 = 1521.78 loss)
I0728 11:39:48.055166 20134 solver.cpp:238]     Train net output #54: loss59 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055172 20134 solver.cpp:238]     Train net output #55: loss6 = 1564.74 (* 1 = 1564.74 loss)
I0728 11:39:48.055178 20134 solver.cpp:238]     Train net output #56: loss60 = 1524.13 (* 1 = 1524.13 loss)
I0728 11:39:48.055184 20134 solver.cpp:238]     Train net output #57: loss61 = 1504.24 (* 1 = 1504.24 loss)
I0728 11:39:48.055191 20134 solver.cpp:238]     Train net output #58: loss62 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055197 20134 solver.cpp:238]     Train net output #59: loss63 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055202 20134 solver.cpp:238]     Train net output #60: loss64 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055208 20134 solver.cpp:238]     Train net output #61: loss7 = 1538.82 (* 1 = 1538.82 loss)
I0728 11:39:48.055214 20134 solver.cpp:238]     Train net output #62: loss8 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055219 20134 solver.cpp:238]     Train net output #63: loss9 = 1506.37 (* 1 = 1506.37 loss)
I0728 11:39:48.055227 20134 sgd_solver.cpp:105] Iteration 59400, lr = 1e-09
I0728 11:48:38.934222 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:48:38.935322 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:48:39.321185 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_64800.caffemodel
I0728 11:48:39.555517 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_64800.solverstate
I0728 11:48:39.635852 20134 solver.cpp:331] Iteration 64800, Testing net (#0)
I0728 11:48:54.827967 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:48:54.848546 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:48:55.292955 20134 solver.cpp:398]     Test net output #0: mae = 82.582 (* 1 = 82.582 loss)
I0728 11:48:55.292979 20134 solver.cpp:398]     Test net output #1: mse = 14213.3 (* 1 = 14213.3 loss)
I0728 11:48:55.417474 20134 solver.cpp:219] Iteration 64800 (9.86569 iter/s, 547.352s/5400 iters), loss = 92295.2
I0728 11:48:55.417516 20134 solver.cpp:238]     Train net output #0: loss1 = 1430.66 (* 1 = 1430.66 loss)
I0728 11:48:55.417526 20134 solver.cpp:238]     Train net output #1: loss10 = 1421.79 (* 1 = 1421.79 loss)
I0728 11:48:55.417532 20134 solver.cpp:238]     Train net output #2: loss11 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417538 20134 solver.cpp:238]     Train net output #3: loss12 = 1461.69 (* 1 = 1461.69 loss)
I0728 11:48:55.417544 20134 solver.cpp:238]     Train net output #4: loss13 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417551 20134 solver.cpp:238]     Train net output #5: loss14 = 1436.05 (* 1 = 1436.05 loss)
I0728 11:48:55.417557 20134 solver.cpp:238]     Train net output #6: loss15 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417562 20134 solver.cpp:238]     Train net output #7: loss16 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417568 20134 solver.cpp:238]     Train net output #8: loss17 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417575 20134 solver.cpp:238]     Train net output #9: loss18 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417580 20134 solver.cpp:238]     Train net output #10: loss19 = 1489.95 (* 1 = 1489.95 loss)
I0728 11:48:55.417587 20134 solver.cpp:238]     Train net output #11: loss2 = 1429.32 (* 1 = 1429.32 loss)
I0728 11:48:55.417593 20134 solver.cpp:238]     Train net output #12: loss20 = 1441.76 (* 1 = 1441.76 loss)
I0728 11:48:55.417599 20134 solver.cpp:238]     Train net output #13: loss21 = 1418.93 (* 1 = 1418.93 loss)
I0728 11:48:55.417605 20134 solver.cpp:238]     Train net output #14: loss22 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417611 20134 solver.cpp:238]     Train net output #15: loss23 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417616 20134 solver.cpp:238]     Train net output #16: loss24 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417623 20134 solver.cpp:238]     Train net output #17: loss25 = 1441.13 (* 1 = 1441.13 loss)
I0728 11:48:55.417629 20134 solver.cpp:238]     Train net output #18: loss26 = 1445.3 (* 1 = 1445.3 loss)
I0728 11:48:55.417634 20134 solver.cpp:238]     Train net output #19: loss27 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417640 20134 solver.cpp:238]     Train net output #20: loss28 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417646 20134 solver.cpp:238]     Train net output #21: loss29 = 1493.13 (* 1 = 1493.13 loss)
I0728 11:48:55.417654 20134 solver.cpp:238]     Train net output #22: loss3 = 1457.62 (* 1 = 1457.62 loss)
I0728 11:48:55.417659 20134 solver.cpp:238]     Train net output #23: loss30 = 1467.58 (* 1 = 1467.58 loss)
I0728 11:48:55.417665 20134 solver.cpp:238]     Train net output #24: loss31 = 1445.28 (* 1 = 1445.28 loss)
I0728 11:48:55.417671 20134 solver.cpp:238]     Train net output #25: loss32 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417677 20134 solver.cpp:238]     Train net output #26: loss33 = 1443.14 (* 1 = 1443.14 loss)
I0728 11:48:55.417683 20134 solver.cpp:238]     Train net output #27: loss34 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417690 20134 solver.cpp:238]     Train net output #28: loss35 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417695 20134 solver.cpp:238]     Train net output #29: loss36 = 1430.41 (* 1 = 1430.41 loss)
I0728 11:48:55.417728 20134 solver.cpp:238]     Train net output #30: loss37 = 1461.64 (* 1 = 1461.64 loss)
I0728 11:48:55.417737 20134 solver.cpp:238]     Train net output #31: loss38 = 1476.82 (* 1 = 1476.82 loss)
I0728 11:48:55.417742 20134 solver.cpp:238]     Train net output #32: loss39 = 1449.07 (* 1 = 1449.07 loss)
I0728 11:48:55.417749 20134 solver.cpp:238]     Train net output #33: loss4 = 1431.8 (* 1 = 1431.8 loss)
I0728 11:48:55.417757 20134 solver.cpp:238]     Train net output #34: loss40 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417762 20134 solver.cpp:238]     Train net output #35: loss41 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417768 20134 solver.cpp:238]     Train net output #36: loss42 = 1429 (* 1 = 1429 loss)
I0728 11:48:55.417775 20134 solver.cpp:238]     Train net output #37: loss43 = 1445.46 (* 1 = 1445.46 loss)
I0728 11:48:55.417781 20134 solver.cpp:238]     Train net output #38: loss44 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417788 20134 solver.cpp:238]     Train net output #39: loss45 = 1445.75 (* 1 = 1445.75 loss)
I0728 11:48:55.417793 20134 solver.cpp:238]     Train net output #40: loss46 = 1494.78 (* 1 = 1494.78 loss)
I0728 11:48:55.417799 20134 solver.cpp:238]     Train net output #41: loss47 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417805 20134 solver.cpp:238]     Train net output #42: loss48 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417816 20134 solver.cpp:238]     Train net output #43: loss49 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417822 20134 solver.cpp:238]     Train net output #44: loss5 = 1446.57 (* 1 = 1446.57 loss)
I0728 11:48:55.417829 20134 solver.cpp:238]     Train net output #45: loss50 = 1433.26 (* 1 = 1433.26 loss)
I0728 11:48:55.417834 20134 solver.cpp:238]     Train net output #46: loss51 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417840 20134 solver.cpp:238]     Train net output #47: loss52 = 1449.56 (* 1 = 1449.56 loss)
I0728 11:48:55.417845 20134 solver.cpp:238]     Train net output #48: loss53 = 1472.44 (* 1 = 1472.44 loss)
I0728 11:48:55.417851 20134 solver.cpp:238]     Train net output #49: loss54 = 1458.12 (* 1 = 1458.12 loss)
I0728 11:48:55.417858 20134 solver.cpp:238]     Train net output #50: loss55 = 1433.09 (* 1 = 1433.09 loss)
I0728 11:48:55.417865 20134 solver.cpp:238]     Train net output #51: loss56 = 1458.59 (* 1 = 1458.59 loss)
I0728 11:48:55.417870 20134 solver.cpp:238]     Train net output #52: loss57 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417876 20134 solver.cpp:238]     Train net output #53: loss58 = 1444.75 (* 1 = 1444.75 loss)
I0728 11:48:55.417882 20134 solver.cpp:238]     Train net output #54: loss59 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417887 20134 solver.cpp:238]     Train net output #55: loss6 = 1481.65 (* 1 = 1481.65 loss)
I0728 11:48:55.417893 20134 solver.cpp:238]     Train net output #56: loss60 = 1446.34 (* 1 = 1446.34 loss)
I0728 11:48:55.417899 20134 solver.cpp:238]     Train net output #57: loss61 = 1425.62 (* 1 = 1425.62 loss)
I0728 11:48:55.417906 20134 solver.cpp:238]     Train net output #58: loss62 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417912 20134 solver.cpp:238]     Train net output #59: loss63 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417917 20134 solver.cpp:238]     Train net output #60: loss64 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417923 20134 solver.cpp:238]     Train net output #61: loss7 = 1459.52 (* 1 = 1459.52 loss)
I0728 11:48:55.417929 20134 solver.cpp:238]     Train net output #62: loss8 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417934 20134 solver.cpp:238]     Train net output #63: loss9 = 1430.4 (* 1 = 1430.4 loss)
I0728 11:48:55.417940 20134 sgd_solver.cpp:105] Iteration 64800, lr = 1e-09
I0728 11:57:46.156275 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:57:46.158983 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:57:46.543053 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_70200.caffemodel
I0728 11:57:46.767500 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_70200.solverstate
I0728 11:57:46.849979 20134 solver.cpp:331] Iteration 70200, Testing net (#0)
I0728 11:58:02.049387 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:58:02.059115 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 11:58:02.513772 20134 solver.cpp:398]     Test net output #0: mae = 81.2971 (* 1 = 81.2971 loss)
I0728 11:58:02.513794 20134 solver.cpp:398]     Test net output #1: mse = 13931.9 (* 1 = 13931.9 loss)
I0728 11:58:02.638233 20134 solver.cpp:219] Iteration 70200 (9.86807 iter/s, 547.219s/5400 iters), loss = 88338.2
I0728 11:58:02.638278 20134 solver.cpp:238]     Train net output #0: loss1 = 1369.74 (* 1 = 1369.74 loss)
I0728 11:58:02.638286 20134 solver.cpp:238]     Train net output #1: loss10 = 1360.07 (* 1 = 1360.07 loss)
I0728 11:58:02.638293 20134 solver.cpp:238]     Train net output #2: loss11 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638299 20134 solver.cpp:238]     Train net output #3: loss12 = 1398.17 (* 1 = 1398.17 loss)
I0728 11:58:02.638305 20134 solver.cpp:238]     Train net output #4: loss13 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638311 20134 solver.cpp:238]     Train net output #5: loss14 = 1375.13 (* 1 = 1375.13 loss)
I0728 11:58:02.638319 20134 solver.cpp:238]     Train net output #6: loss15 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638324 20134 solver.cpp:238]     Train net output #7: loss16 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638330 20134 solver.cpp:238]     Train net output #8: loss17 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638336 20134 solver.cpp:238]     Train net output #9: loss18 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638342 20134 solver.cpp:238]     Train net output #10: loss19 = 1426.39 (* 1 = 1426.39 loss)
I0728 11:58:02.638348 20134 solver.cpp:238]     Train net output #11: loss2 = 1368.36 (* 1 = 1368.36 loss)
I0728 11:58:02.638355 20134 solver.cpp:238]     Train net output #12: loss20 = 1377.48 (* 1 = 1377.48 loss)
I0728 11:58:02.638361 20134 solver.cpp:238]     Train net output #13: loss21 = 1358.5 (* 1 = 1358.5 loss)
I0728 11:58:02.638367 20134 solver.cpp:238]     Train net output #14: loss22 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638373 20134 solver.cpp:238]     Train net output #15: loss23 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638380 20134 solver.cpp:238]     Train net output #16: loss24 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638386 20134 solver.cpp:238]     Train net output #17: loss25 = 1385.13 (* 1 = 1385.13 loss)
I0728 11:58:02.638393 20134 solver.cpp:238]     Train net output #18: loss26 = 1383.21 (* 1 = 1383.21 loss)
I0728 11:58:02.638401 20134 solver.cpp:238]     Train net output #19: loss27 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638407 20134 solver.cpp:238]     Train net output #20: loss28 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638413 20134 solver.cpp:238]     Train net output #21: loss29 = 1424.34 (* 1 = 1424.34 loss)
I0728 11:58:02.638419 20134 solver.cpp:238]     Train net output #22: loss3 = 1393.38 (* 1 = 1393.38 loss)
I0728 11:58:02.638427 20134 solver.cpp:238]     Train net output #23: loss30 = 1404.08 (* 1 = 1404.08 loss)
I0728 11:58:02.638432 20134 solver.cpp:238]     Train net output #24: loss31 = 1383.38 (* 1 = 1383.38 loss)
I0728 11:58:02.638438 20134 solver.cpp:238]     Train net output #25: loss32 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638444 20134 solver.cpp:238]     Train net output #26: loss33 = 1381.79 (* 1 = 1381.79 loss)
I0728 11:58:02.638450 20134 solver.cpp:238]     Train net output #27: loss34 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638458 20134 solver.cpp:238]     Train net output #28: loss35 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638492 20134 solver.cpp:238]     Train net output #29: loss36 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638504 20134 solver.cpp:238]     Train net output #30: loss37 = 1395.26 (* 1 = 1395.26 loss)
I0728 11:58:02.638514 20134 solver.cpp:238]     Train net output #31: loss38 = 1412.94 (* 1 = 1412.94 loss)
I0728 11:58:02.638525 20134 solver.cpp:238]     Train net output #32: loss39 = 1387.8 (* 1 = 1387.8 loss)
I0728 11:58:02.638533 20134 solver.cpp:238]     Train net output #33: loss4 = 1370.3 (* 1 = 1370.3 loss)
I0728 11:58:02.638540 20134 solver.cpp:238]     Train net output #34: loss40 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638545 20134 solver.cpp:238]     Train net output #35: loss41 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638551 20134 solver.cpp:238]     Train net output #36: loss42 = 1368.4 (* 1 = 1368.4 loss)
I0728 11:58:02.638558 20134 solver.cpp:238]     Train net output #37: loss43 = 1383.45 (* 1 = 1383.45 loss)
I0728 11:58:02.638564 20134 solver.cpp:238]     Train net output #38: loss44 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638571 20134 solver.cpp:238]     Train net output #39: loss45 = 1384.09 (* 1 = 1384.09 loss)
I0728 11:58:02.638577 20134 solver.cpp:238]     Train net output #40: loss46 = 1427.17 (* 1 = 1427.17 loss)
I0728 11:58:02.638583 20134 solver.cpp:238]     Train net output #41: loss47 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638589 20134 solver.cpp:238]     Train net output #42: loss48 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638595 20134 solver.cpp:238]     Train net output #43: loss49 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638602 20134 solver.cpp:238]     Train net output #44: loss5 = 1385.52 (* 1 = 1385.52 loss)
I0728 11:58:02.638608 20134 solver.cpp:238]     Train net output #45: loss50 = 1373.58 (* 1 = 1373.58 loss)
I0728 11:58:02.638614 20134 solver.cpp:238]     Train net output #46: loss51 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638620 20134 solver.cpp:238]     Train net output #47: loss52 = 1390 (* 1 = 1390 loss)
I0728 11:58:02.638628 20134 solver.cpp:238]     Train net output #48: loss53 = 1407.17 (* 1 = 1407.17 loss)
I0728 11:58:02.638633 20134 solver.cpp:238]     Train net output #49: loss54 = 1394.78 (* 1 = 1394.78 loss)
I0728 11:58:02.638639 20134 solver.cpp:238]     Train net output #50: loss55 = 1372.25 (* 1 = 1372.25 loss)
I0728 11:58:02.638646 20134 solver.cpp:238]     Train net output #51: loss56 = 1395.93 (* 1 = 1395.93 loss)
I0728 11:58:02.638653 20134 solver.cpp:238]     Train net output #52: loss57 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638659 20134 solver.cpp:238]     Train net output #53: loss58 = 1382.56 (* 1 = 1382.56 loss)
I0728 11:58:02.638664 20134 solver.cpp:238]     Train net output #54: loss59 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638671 20134 solver.cpp:238]     Train net output #55: loss6 = 1415.23 (* 1 = 1415.23 loss)
I0728 11:58:02.638677 20134 solver.cpp:238]     Train net output #56: loss60 = 1383.5 (* 1 = 1383.5 loss)
I0728 11:58:02.638684 20134 solver.cpp:238]     Train net output #57: loss61 = 1362.63 (* 1 = 1362.63 loss)
I0728 11:58:02.638690 20134 solver.cpp:238]     Train net output #58: loss62 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638696 20134 solver.cpp:238]     Train net output #59: loss63 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638702 20134 solver.cpp:238]     Train net output #60: loss64 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638708 20134 solver.cpp:238]     Train net output #61: loss7 = 1396.63 (* 1 = 1396.63 loss)
I0728 11:58:02.638716 20134 solver.cpp:238]     Train net output #62: loss8 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638723 20134 solver.cpp:238]     Train net output #63: loss9 = 1369.51 (* 1 = 1369.51 loss)
I0728 11:58:02.638731 20134 sgd_solver.cpp:105] Iteration 70200, lr = 1e-09
I0728 12:06:52.872817 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:06:52.874464 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:06:53.259739 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_75600.caffemodel
I0728 12:06:53.477072 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_75600.solverstate
I0728 12:06:53.560282 20134 solver.cpp:331] Iteration 75600, Testing net (#0)
I0728 12:07:08.782910 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:07:08.792341 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:07:09.247366 20134 solver.cpp:398]     Test net output #0: mae = 80.2371 (* 1 = 80.2371 loss)
I0728 12:07:09.247390 20134 solver.cpp:398]     Test net output #1: mse = 13738.1 (* 1 = 13738.1 loss)
I0728 12:07:09.371923 20134 solver.cpp:219] Iteration 75600 (9.87695 iter/s, 546.727s/5400 iters), loss = 84968.5
I0728 12:07:09.371973 20134 solver.cpp:238]     Train net output #0: loss1 = 1317.97 (* 1 = 1317.97 loss)
I0728 12:07:09.371982 20134 solver.cpp:238]     Train net output #1: loss10 = 1307.83 (* 1 = 1307.83 loss)
I0728 12:07:09.371989 20134 solver.cpp:238]     Train net output #2: loss11 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.371995 20134 solver.cpp:238]     Train net output #3: loss12 = 1343.97 (* 1 = 1343.97 loss)
I0728 12:07:09.372001 20134 solver.cpp:238]     Train net output #4: loss13 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372009 20134 solver.cpp:238]     Train net output #5: loss14 = 1323.29 (* 1 = 1323.29 loss)
I0728 12:07:09.372015 20134 solver.cpp:238]     Train net output #6: loss15 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372021 20134 solver.cpp:238]     Train net output #7: loss16 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372027 20134 solver.cpp:238]     Train net output #8: loss17 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372033 20134 solver.cpp:238]     Train net output #9: loss18 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372040 20134 solver.cpp:238]     Train net output #10: loss19 = 1371.59 (* 1 = 1371.59 loss)
I0728 12:07:09.372046 20134 solver.cpp:238]     Train net output #11: loss2 = 1316.51 (* 1 = 1316.51 loss)
I0728 12:07:09.372052 20134 solver.cpp:238]     Train net output #12: loss20 = 1323.02 (* 1 = 1323.02 loss)
I0728 12:07:09.372058 20134 solver.cpp:238]     Train net output #13: loss21 = 1307.38 (* 1 = 1307.38 loss)
I0728 12:07:09.372064 20134 solver.cpp:238]     Train net output #14: loss22 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372071 20134 solver.cpp:238]     Train net output #15: loss23 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372076 20134 solver.cpp:238]     Train net output #16: loss24 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372082 20134 solver.cpp:238]     Train net output #17: loss25 = 1332.99 (* 1 = 1332.99 loss)
I0728 12:07:09.372088 20134 solver.cpp:238]     Train net output #18: loss26 = 1330.56 (* 1 = 1330.56 loss)
I0728 12:07:09.372095 20134 solver.cpp:238]     Train net output #19: loss27 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372102 20134 solver.cpp:238]     Train net output #20: loss28 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372107 20134 solver.cpp:238]     Train net output #21: loss29 = 1366.36 (* 1 = 1366.36 loss)
I0728 12:07:09.372114 20134 solver.cpp:238]     Train net output #22: loss3 = 1338.7 (* 1 = 1338.7 loss)
I0728 12:07:09.372120 20134 solver.cpp:238]     Train net output #23: loss30 = 1349.68 (* 1 = 1349.68 loss)
I0728 12:07:09.372126 20134 solver.cpp:238]     Train net output #24: loss31 = 1330.79 (* 1 = 1330.79 loss)
I0728 12:07:09.372133 20134 solver.cpp:238]     Train net output #25: loss32 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372139 20134 solver.cpp:238]     Train net output #26: loss33 = 1329.85 (* 1 = 1329.85 loss)
I0728 12:07:09.372145 20134 solver.cpp:238]     Train net output #27: loss34 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372151 20134 solver.cpp:238]     Train net output #28: loss35 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372184 20134 solver.cpp:238]     Train net output #29: loss36 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372191 20134 solver.cpp:238]     Train net output #30: loss37 = 1339.67 (* 1 = 1339.67 loss)
I0728 12:07:09.372198 20134 solver.cpp:238]     Train net output #31: loss38 = 1358.37 (* 1 = 1358.37 loss)
I0728 12:07:09.372205 20134 solver.cpp:238]     Train net output #32: loss39 = 1335.7 (* 1 = 1335.7 loss)
I0728 12:07:09.372213 20134 solver.cpp:238]     Train net output #33: loss4 = 1318.19 (* 1 = 1318.19 loss)
I0728 12:07:09.372227 20134 solver.cpp:238]     Train net output #34: loss40 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372237 20134 solver.cpp:238]     Train net output #35: loss41 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372246 20134 solver.cpp:238]     Train net output #36: loss42 = 1316.71 (* 1 = 1316.71 loss)
I0728 12:07:09.372256 20134 solver.cpp:238]     Train net output #37: loss43 = 1330.68 (* 1 = 1330.68 loss)
I0728 12:07:09.372265 20134 solver.cpp:238]     Train net output #38: loss44 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372275 20134 solver.cpp:238]     Train net output #39: loss45 = 1331.35 (* 1 = 1331.35 loss)
I0728 12:07:09.372287 20134 solver.cpp:238]     Train net output #40: loss46 = 1369.61 (* 1 = 1369.61 loss)
I0728 12:07:09.372297 20134 solver.cpp:238]     Train net output #41: loss47 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372305 20134 solver.cpp:238]     Train net output #42: loss48 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372316 20134 solver.cpp:238]     Train net output #43: loss49 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372326 20134 solver.cpp:238]     Train net output #44: loss5 = 1333.74 (* 1 = 1333.74 loss)
I0728 12:07:09.372337 20134 solver.cpp:238]     Train net output #45: loss50 = 1323 (* 1 = 1323 loss)
I0728 12:07:09.372347 20134 solver.cpp:238]     Train net output #46: loss51 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372357 20134 solver.cpp:238]     Train net output #47: loss52 = 1338.44 (* 1 = 1338.44 loss)
I0728 12:07:09.372366 20134 solver.cpp:238]     Train net output #48: loss53 = 1351.57 (* 1 = 1351.57 loss)
I0728 12:07:09.372373 20134 solver.cpp:238]     Train net output #49: loss54 = 1340.58 (* 1 = 1340.58 loss)
I0728 12:07:09.372380 20134 solver.cpp:238]     Train net output #50: loss55 = 1320.42 (* 1 = 1320.42 loss)
I0728 12:07:09.372385 20134 solver.cpp:238]     Train net output #51: loss56 = 1342.12 (* 1 = 1342.12 loss)
I0728 12:07:09.372391 20134 solver.cpp:238]     Train net output #52: loss57 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372397 20134 solver.cpp:238]     Train net output #53: loss58 = 1329.79 (* 1 = 1329.79 loss)
I0728 12:07:09.372403 20134 solver.cpp:238]     Train net output #54: loss59 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372409 20134 solver.cpp:238]     Train net output #55: loss6 = 1358 (* 1 = 1358 loss)
I0728 12:07:09.372416 20134 solver.cpp:238]     Train net output #56: loss60 = 1330.25 (* 1 = 1330.25 loss)
I0728 12:07:09.372421 20134 solver.cpp:238]     Train net output #57: loss61 = 1309.39 (* 1 = 1309.39 loss)
I0728 12:07:09.372427 20134 solver.cpp:238]     Train net output #58: loss62 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372433 20134 solver.cpp:238]     Train net output #59: loss63 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372439 20134 solver.cpp:238]     Train net output #60: loss64 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372445 20134 solver.cpp:238]     Train net output #61: loss7 = 1343.52 (* 1 = 1343.52 loss)
I0728 12:07:09.372452 20134 solver.cpp:238]     Train net output #62: loss8 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372457 20134 solver.cpp:238]     Train net output #63: loss9 = 1317.75 (* 1 = 1317.75 loss)
I0728 12:07:09.372464 20134 sgd_solver.cpp:105] Iteration 75600, lr = 1e-09
I0728 12:15:59.441861 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:15:59.442842 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:15:59.828423 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_81000.caffemodel
I0728 12:16:00.041594 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_81000.solverstate
I0728 12:16:00.120751 20134 solver.cpp:331] Iteration 81000, Testing net (#0)
I0728 12:16:15.298164 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:16:15.319181 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:16:15.762213 20134 solver.cpp:398]     Test net output #0: mae = 79.3616 (* 1 = 79.3616 loss)
I0728 12:16:15.762235 20134 solver.cpp:398]     Test net output #1: mse = 13551.5 (* 1 = 13551.5 loss)
I0728 12:16:15.886988 20134 solver.cpp:219] Iteration 81000 (9.88094 iter/s, 546.507s/5400 iters), loss = 81856.2
I0728 12:16:15.887028 20134 solver.cpp:238]     Train net output #0: loss1 = 1269.96 (* 1 = 1269.96 loss)
I0728 12:16:15.887037 20134 solver.cpp:238]     Train net output #1: loss10 = 1259.55 (* 1 = 1259.55 loss)
I0728 12:16:15.887043 20134 solver.cpp:238]     Train net output #2: loss11 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887049 20134 solver.cpp:238]     Train net output #3: loss12 = 1293.78 (* 1 = 1293.78 loss)
I0728 12:16:15.887055 20134 solver.cpp:238]     Train net output #4: loss13 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887061 20134 solver.cpp:238]     Train net output #5: loss14 = 1275.02 (* 1 = 1275.02 loss)
I0728 12:16:15.887068 20134 solver.cpp:238]     Train net output #6: loss15 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887073 20134 solver.cpp:238]     Train net output #7: loss16 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887079 20134 solver.cpp:238]     Train net output #8: loss17 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887085 20134 solver.cpp:238]     Train net output #9: loss18 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887091 20134 solver.cpp:238]     Train net output #10: loss19 = 1319.18 (* 1 = 1319.18 loss)
I0728 12:16:15.887097 20134 solver.cpp:238]     Train net output #11: loss2 = 1268.37 (* 1 = 1268.37 loss)
I0728 12:16:15.887104 20134 solver.cpp:238]     Train net output #12: loss20 = 1272.9 (* 1 = 1272.9 loss)
I0728 12:16:15.887109 20134 solver.cpp:238]     Train net output #13: loss21 = 1259.92 (* 1 = 1259.92 loss)
I0728 12:16:15.887115 20134 solver.cpp:238]     Train net output #14: loss22 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887121 20134 solver.cpp:238]     Train net output #15: loss23 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887127 20134 solver.cpp:238]     Train net output #16: loss24 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887135 20134 solver.cpp:238]     Train net output #17: loss25 = 1284.62 (* 1 = 1284.62 loss)
I0728 12:16:15.887140 20134 solver.cpp:238]     Train net output #18: loss26 = 1281.72 (* 1 = 1281.72 loss)
I0728 12:16:15.887146 20134 solver.cpp:238]     Train net output #19: loss27 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887152 20134 solver.cpp:238]     Train net output #20: loss28 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887158 20134 solver.cpp:238]     Train net output #21: loss29 = 1313.21 (* 1 = 1313.21 loss)
I0728 12:16:15.887164 20134 solver.cpp:238]     Train net output #22: loss3 = 1289.05 (* 1 = 1289.05 loss)
I0728 12:16:15.887171 20134 solver.cpp:238]     Train net output #23: loss30 = 1298.63 (* 1 = 1298.63 loss)
I0728 12:16:15.887176 20134 solver.cpp:238]     Train net output #24: loss31 = 1282.02 (* 1 = 1282.02 loss)
I0728 12:16:15.887182 20134 solver.cpp:238]     Train net output #25: loss32 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887188 20134 solver.cpp:238]     Train net output #26: loss33 = 1281.6 (* 1 = 1281.6 loss)
I0728 12:16:15.887194 20134 solver.cpp:238]     Train net output #27: loss34 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887200 20134 solver.cpp:238]     Train net output #28: loss35 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887205 20134 solver.cpp:238]     Train net output #29: loss36 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887238 20134 solver.cpp:238]     Train net output #30: loss37 = 1288.71 (* 1 = 1288.71 loss)
I0728 12:16:15.887244 20134 solver.cpp:238]     Train net output #31: loss38 = 1307.57 (* 1 = 1307.57 loss)
I0728 12:16:15.887250 20134 solver.cpp:238]     Train net output #32: loss39 = 1287.1 (* 1 = 1287.1 loss)
I0728 12:16:15.887256 20134 solver.cpp:238]     Train net output #33: loss4 = 1270.48 (* 1 = 1270.48 loss)
I0728 12:16:15.887261 20134 solver.cpp:238]     Train net output #34: loss40 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887267 20134 solver.cpp:238]     Train net output #35: loss41 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887274 20134 solver.cpp:238]     Train net output #36: loss42 = 1268.71 (* 1 = 1268.71 loss)
I0728 12:16:15.887279 20134 solver.cpp:238]     Train net output #37: loss43 = 1281.56 (* 1 = 1281.56 loss)
I0728 12:16:15.887285 20134 solver.cpp:238]     Train net output #38: loss44 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887290 20134 solver.cpp:238]     Train net output #39: loss45 = 1282.27 (* 1 = 1282.27 loss)
I0728 12:16:15.887297 20134 solver.cpp:238]     Train net output #40: loss46 = 1315.8 (* 1 = 1315.8 loss)
I0728 12:16:15.887303 20134 solver.cpp:238]     Train net output #41: loss47 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887310 20134 solver.cpp:238]     Train net output #42: loss48 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887315 20134 solver.cpp:238]     Train net output #43: loss49 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887321 20134 solver.cpp:238]     Train net output #44: loss5 = 1285.62 (* 1 = 1285.62 loss)
I0728 12:16:15.887327 20134 solver.cpp:238]     Train net output #45: loss50 = 1275.83 (* 1 = 1275.83 loss)
I0728 12:16:15.887333 20134 solver.cpp:238]     Train net output #46: loss51 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887339 20134 solver.cpp:238]     Train net output #47: loss52 = 1290.84 (* 1 = 1290.84 loss)
I0728 12:16:15.887346 20134 solver.cpp:238]     Train net output #48: loss53 = 1299.87 (* 1 = 1299.87 loss)
I0728 12:16:15.887351 20134 solver.cpp:238]     Train net output #49: loss54 = 1290.31 (* 1 = 1290.31 loss)
I0728 12:16:15.887357 20134 solver.cpp:238]     Train net output #50: loss55 = 1272.15 (* 1 = 1272.15 loss)
I0728 12:16:15.887363 20134 solver.cpp:238]     Train net output #51: loss56 = 1291.8 (* 1 = 1291.8 loss)
I0728 12:16:15.887370 20134 solver.cpp:238]     Train net output #52: loss57 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887377 20134 solver.cpp:238]     Train net output #53: loss58 = 1280.57 (* 1 = 1280.57 loss)
I0728 12:16:15.887382 20134 solver.cpp:238]     Train net output #54: loss59 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887387 20134 solver.cpp:238]     Train net output #55: loss6 = 1304.86 (* 1 = 1304.86 loss)
I0728 12:16:15.887394 20134 solver.cpp:238]     Train net output #56: loss60 = 1280.6 (* 1 = 1280.6 loss)
I0728 12:16:15.887400 20134 solver.cpp:238]     Train net output #57: loss61 = 1260.36 (* 1 = 1260.36 loss)
I0728 12:16:15.887406 20134 solver.cpp:238]     Train net output #58: loss62 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887413 20134 solver.cpp:238]     Train net output #59: loss63 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887418 20134 solver.cpp:238]     Train net output #60: loss64 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887424 20134 solver.cpp:238]     Train net output #61: loss7 = 1294.34 (* 1 = 1294.34 loss)
I0728 12:16:15.887430 20134 solver.cpp:238]     Train net output #62: loss8 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887436 20134 solver.cpp:238]     Train net output #63: loss9 = 1269.7 (* 1 = 1269.7 loss)
I0728 12:16:15.887442 20134 sgd_solver.cpp:105] Iteration 81000, lr = 1e-09
I0728 12:25:06.509717 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:25:06.511662 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:25:06.897622 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_86400.caffemodel
I0728 12:25:07.110751 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_86400.solverstate
I0728 12:25:07.191185 20134 solver.cpp:331] Iteration 86400, Testing net (#0)
I0728 12:25:22.381279 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:25:22.408939 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:25:22.845927 20134 solver.cpp:398]     Test net output #0: mae = 78.6399 (* 1 = 78.6399 loss)
I0728 12:25:22.845949 20134 solver.cpp:398]     Test net output #1: mse = 13386.3 (* 1 = 13386.3 loss)
I0728 12:25:22.970470 20134 solver.cpp:219] Iteration 86400 (9.8707 iter/s, 547.074s/5400 iters), loss = 79272
I0728 12:25:22.970510 20134 solver.cpp:238]     Train net output #0: loss1 = 1230.03 (* 1 = 1230.03 loss)
I0728 12:25:22.970518 20134 solver.cpp:238]     Train net output #1: loss10 = 1219.45 (* 1 = 1219.45 loss)
I0728 12:25:22.970525 20134 solver.cpp:238]     Train net output #2: loss11 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970530 20134 solver.cpp:238]     Train net output #3: loss12 = 1252.11 (* 1 = 1252.11 loss)
I0728 12:25:22.970536 20134 solver.cpp:238]     Train net output #4: loss13 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970541 20134 solver.cpp:238]     Train net output #5: loss14 = 1234.86 (* 1 = 1234.86 loss)
I0728 12:25:22.970547 20134 solver.cpp:238]     Train net output #6: loss15 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970553 20134 solver.cpp:238]     Train net output #7: loss16 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970559 20134 solver.cpp:238]     Train net output #8: loss17 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970564 20134 solver.cpp:238]     Train net output #9: loss18 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970571 20134 solver.cpp:238]     Train net output #10: loss19 = 1275.3 (* 1 = 1275.3 loss)
I0728 12:25:22.970577 20134 solver.cpp:238]     Train net output #11: loss2 = 1228.29 (* 1 = 1228.29 loss)
I0728 12:25:22.970583 20134 solver.cpp:238]     Train net output #12: loss20 = 1230.96 (* 1 = 1230.96 loss)
I0728 12:25:22.970588 20134 solver.cpp:238]     Train net output #13: loss21 = 1220.45 (* 1 = 1220.45 loss)
I0728 12:25:22.970595 20134 solver.cpp:238]     Train net output #14: loss22 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970602 20134 solver.cpp:238]     Train net output #15: loss23 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970609 20134 solver.cpp:238]     Train net output #16: loss24 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970615 20134 solver.cpp:238]     Train net output #17: loss25 = 1244.25 (* 1 = 1244.25 loss)
I0728 12:25:22.970621 20134 solver.cpp:238]     Train net output #18: loss26 = 1241.11 (* 1 = 1241.11 loss)
I0728 12:25:22.970628 20134 solver.cpp:238]     Train net output #19: loss27 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970633 20134 solver.cpp:238]     Train net output #20: loss28 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970640 20134 solver.cpp:238]     Train net output #21: loss29 = 1269.47 (* 1 = 1269.47 loss)
I0728 12:25:22.970646 20134 solver.cpp:238]     Train net output #22: loss3 = 1247.83 (* 1 = 1247.83 loss)
I0728 12:25:22.970652 20134 solver.cpp:238]     Train net output #23: loss30 = 1256.08 (* 1 = 1256.08 loss)
I0728 12:25:22.970659 20134 solver.cpp:238]     Train net output #24: loss31 = 1241.09 (* 1 = 1241.09 loss)
I0728 12:25:22.970664 20134 solver.cpp:238]     Train net output #25: loss32 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970671 20134 solver.cpp:238]     Train net output #26: loss33 = 1241.32 (* 1 = 1241.32 loss)
I0728 12:25:22.970677 20134 solver.cpp:238]     Train net output #27: loss34 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970683 20134 solver.cpp:238]     Train net output #28: loss35 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970719 20134 solver.cpp:238]     Train net output #29: loss36 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970731 20134 solver.cpp:238]     Train net output #30: loss37 = 1247.03 (* 1 = 1247.03 loss)
I0728 12:25:22.970741 20134 solver.cpp:238]     Train net output #31: loss38 = 1264.95 (* 1 = 1264.95 loss)
I0728 12:25:22.970748 20134 solver.cpp:238]     Train net output #32: loss39 = 1246.4 (* 1 = 1246.4 loss)
I0728 12:25:22.970754 20134 solver.cpp:238]     Train net output #33: loss4 = 1231.54 (* 1 = 1231.54 loss)
I0728 12:25:22.970760 20134 solver.cpp:238]     Train net output #34: loss40 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970772 20134 solver.cpp:238]     Train net output #35: loss41 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970778 20134 solver.cpp:238]     Train net output #36: loss42 = 1228.77 (* 1 = 1228.77 loss)
I0728 12:25:22.970784 20134 solver.cpp:238]     Train net output #37: loss43 = 1240.56 (* 1 = 1240.56 loss)
I0728 12:25:22.970790 20134 solver.cpp:238]     Train net output #38: loss44 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970796 20134 solver.cpp:238]     Train net output #39: loss45 = 1241.24 (* 1 = 1241.24 loss)
I0728 12:25:22.970803 20134 solver.cpp:238]     Train net output #40: loss46 = 1271.06 (* 1 = 1271.06 loss)
I0728 12:25:22.970808 20134 solver.cpp:238]     Train net output #41: loss47 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970814 20134 solver.cpp:238]     Train net output #42: loss48 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970820 20134 solver.cpp:238]     Train net output #43: loss49 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970825 20134 solver.cpp:238]     Train net output #44: loss5 = 1245.53 (* 1 = 1245.53 loss)
I0728 12:25:22.970831 20134 solver.cpp:238]     Train net output #45: loss50 = 1236.5 (* 1 = 1236.5 loss)
I0728 12:25:22.970837 20134 solver.cpp:238]     Train net output #46: loss51 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970844 20134 solver.cpp:238]     Train net output #47: loss52 = 1250.81 (* 1 = 1250.81 loss)
I0728 12:25:22.970849 20134 solver.cpp:238]     Train net output #48: loss53 = 1256.82 (* 1 = 1256.82 loss)
I0728 12:25:22.970855 20134 solver.cpp:238]     Train net output #49: loss54 = 1248.72 (* 1 = 1248.72 loss)
I0728 12:25:22.970861 20134 solver.cpp:238]     Train net output #50: loss55 = 1232.1 (* 1 = 1232.1 loss)
I0728 12:25:22.970867 20134 solver.cpp:238]     Train net output #51: loss56 = 1249.63 (* 1 = 1249.63 loss)
I0728 12:25:22.970873 20134 solver.cpp:238]     Train net output #52: loss57 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970880 20134 solver.cpp:238]     Train net output #53: loss58 = 1239.7 (* 1 = 1239.7 loss)
I0728 12:25:22.970885 20134 solver.cpp:238]     Train net output #54: loss59 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970890 20134 solver.cpp:238]     Train net output #55: loss6 = 1260.52 (* 1 = 1260.52 loss)
I0728 12:25:22.970897 20134 solver.cpp:238]     Train net output #56: loss60 = 1239.6 (* 1 = 1239.6 loss)
I0728 12:25:22.970902 20134 solver.cpp:238]     Train net output #57: loss61 = 1220.08 (* 1 = 1220.08 loss)
I0728 12:25:22.970909 20134 solver.cpp:238]     Train net output #58: loss62 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970916 20134 solver.cpp:238]     Train net output #59: loss63 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970921 20134 solver.cpp:238]     Train net output #60: loss64 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970927 20134 solver.cpp:238]     Train net output #61: loss7 = 1253.64 (* 1 = 1253.64 loss)
I0728 12:25:22.970933 20134 solver.cpp:238]     Train net output #62: loss8 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970939 20134 solver.cpp:238]     Train net output #63: loss9 = 1229.74 (* 1 = 1229.74 loss)
I0728 12:25:22.970945 20134 sgd_solver.cpp:105] Iteration 86400, lr = 1e-09
I0728 12:34:13.986863 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:34:13.989939 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:34:14.374579 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_91800.caffemodel
I0728 12:34:14.605136 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_91800.solverstate
I0728 12:34:14.692291 20134 solver.cpp:331] Iteration 91800, Testing net (#0)
I0728 12:34:29.887248 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:34:29.907759 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:34:30.350874 20134 solver.cpp:398]     Test net output #0: mae = 78.0671 (* 1 = 78.0671 loss)
I0728 12:34:30.350895 20134 solver.cpp:398]     Test net output #1: mse = 13222.3 (* 1 = 13222.3 loss)
I0728 12:34:30.475322 20134 solver.cpp:219] Iteration 91800 (9.86313 iter/s, 547.493s/5400 iters), loss = 77411.8
I0728 12:34:30.475366 20134 solver.cpp:238]     Train net output #0: loss1 = 1201.53 (* 1 = 1201.53 loss)
I0728 12:34:30.475376 20134 solver.cpp:238]     Train net output #1: loss10 = 1190.93 (* 1 = 1190.93 loss)
I0728 12:34:30.475383 20134 solver.cpp:238]     Train net output #2: loss11 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475389 20134 solver.cpp:238]     Train net output #3: loss12 = 1222.47 (* 1 = 1222.47 loss)
I0728 12:34:30.475396 20134 solver.cpp:238]     Train net output #4: loss13 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475402 20134 solver.cpp:238]     Train net output #5: loss14 = 1206.25 (* 1 = 1206.25 loss)
I0728 12:34:30.475409 20134 solver.cpp:238]     Train net output #6: loss15 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475415 20134 solver.cpp:238]     Train net output #7: loss16 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475421 20134 solver.cpp:238]     Train net output #8: loss17 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475427 20134 solver.cpp:238]     Train net output #9: loss18 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475435 20134 solver.cpp:238]     Train net output #10: loss19 = 1242.8 (* 1 = 1242.8 loss)
I0728 12:34:30.475440 20134 solver.cpp:238]     Train net output #11: loss2 = 1199.65 (* 1 = 1199.65 loss)
I0728 12:34:30.475447 20134 solver.cpp:238]     Train net output #12: loss20 = 1201.69 (* 1 = 1201.69 loss)
I0728 12:34:30.475453 20134 solver.cpp:238]     Train net output #13: loss21 = 1192.51 (* 1 = 1192.51 loss)
I0728 12:34:30.475461 20134 solver.cpp:238]     Train net output #14: loss22 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475466 20134 solver.cpp:238]     Train net output #15: loss23 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475473 20134 solver.cpp:238]     Train net output #16: loss24 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475479 20134 solver.cpp:238]     Train net output #17: loss25 = 1215.3 (* 1 = 1215.3 loss)
I0728 12:34:30.475486 20134 solver.cpp:238]     Train net output #18: loss26 = 1211.76 (* 1 = 1211.76 loss)
I0728 12:34:30.475492 20134 solver.cpp:238]     Train net output #19: loss27 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475499 20134 solver.cpp:238]     Train net output #20: loss28 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475507 20134 solver.cpp:238]     Train net output #21: loss29 = 1238.25 (* 1 = 1238.25 loss)
I0728 12:34:30.475512 20134 solver.cpp:238]     Train net output #22: loss3 = 1218.82 (* 1 = 1218.82 loss)
I0728 12:34:30.475520 20134 solver.cpp:238]     Train net output #23: loss30 = 1225.86 (* 1 = 1225.86 loss)
I0728 12:34:30.475528 20134 solver.cpp:238]     Train net output #24: loss31 = 1211.83 (* 1 = 1211.83 loss)
I0728 12:34:30.475536 20134 solver.cpp:238]     Train net output #25: loss32 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475543 20134 solver.cpp:238]     Train net output #26: loss33 = 1212.03 (* 1 = 1212.03 loss)
I0728 12:34:30.475549 20134 solver.cpp:238]     Train net output #27: loss34 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475555 20134 solver.cpp:238]     Train net output #28: loss35 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475589 20134 solver.cpp:238]     Train net output #29: loss36 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475596 20134 solver.cpp:238]     Train net output #30: loss37 = 1217.62 (* 1 = 1217.62 loss)
I0728 12:34:30.475602 20134 solver.cpp:238]     Train net output #31: loss38 = 1234.39 (* 1 = 1234.39 loss)
I0728 12:34:30.475610 20134 solver.cpp:238]     Train net output #32: loss39 = 1217.15 (* 1 = 1217.15 loss)
I0728 12:34:30.475615 20134 solver.cpp:238]     Train net output #33: loss4 = 1203.85 (* 1 = 1203.85 loss)
I0728 12:34:30.475623 20134 solver.cpp:238]     Train net output #34: loss40 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475630 20134 solver.cpp:238]     Train net output #35: loss41 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475636 20134 solver.cpp:238]     Train net output #36: loss42 = 1200.27 (* 1 = 1200.27 loss)
I0728 12:34:30.475642 20134 solver.cpp:238]     Train net output #37: loss43 = 1211.47 (* 1 = 1211.47 loss)
I0728 12:34:30.475648 20134 solver.cpp:238]     Train net output #38: loss44 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475656 20134 solver.cpp:238]     Train net output #39: loss45 = 1212.17 (* 1 = 1212.17 loss)
I0728 12:34:30.475661 20134 solver.cpp:238]     Train net output #40: loss46 = 1238.88 (* 1 = 1238.88 loss)
I0728 12:34:30.475668 20134 solver.cpp:238]     Train net output #41: loss47 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475674 20134 solver.cpp:238]     Train net output #42: loss48 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475680 20134 solver.cpp:238]     Train net output #43: loss49 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475687 20134 solver.cpp:238]     Train net output #44: loss5 = 1217.07 (* 1 = 1217.07 loss)
I0728 12:34:30.475693 20134 solver.cpp:238]     Train net output #45: loss50 = 1208.03 (* 1 = 1208.03 loss)
I0728 12:34:30.475700 20134 solver.cpp:238]     Train net output #46: loss51 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475706 20134 solver.cpp:238]     Train net output #47: loss52 = 1222.89 (* 1 = 1222.89 loss)
I0728 12:34:30.475713 20134 solver.cpp:238]     Train net output #48: loss53 = 1226.08 (* 1 = 1226.08 loss)
I0728 12:34:30.475719 20134 solver.cpp:238]     Train net output #49: loss54 = 1218.94 (* 1 = 1218.94 loss)
I0728 12:34:30.475725 20134 solver.cpp:238]     Train net output #50: loss55 = 1203.56 (* 1 = 1203.56 loss)
I0728 12:34:30.475733 20134 solver.cpp:238]     Train net output #51: loss56 = 1219.19 (* 1 = 1219.19 loss)
I0728 12:34:30.475739 20134 solver.cpp:238]     Train net output #52: loss57 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475745 20134 solver.cpp:238]     Train net output #53: loss58 = 1212.66 (* 1 = 1212.66 loss)
I0728 12:34:30.475751 20134 solver.cpp:238]     Train net output #54: loss59 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475759 20134 solver.cpp:238]     Train net output #55: loss6 = 1228.28 (* 1 = 1228.28 loss)
I0728 12:34:30.475764 20134 solver.cpp:238]     Train net output #56: loss60 = 1210.38 (* 1 = 1210.38 loss)
I0728 12:34:30.475771 20134 solver.cpp:238]     Train net output #57: loss61 = 1191.51 (* 1 = 1191.51 loss)
I0728 12:34:30.475777 20134 solver.cpp:238]     Train net output #58: loss62 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475785 20134 solver.cpp:238]     Train net output #59: loss63 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475790 20134 solver.cpp:238]     Train net output #60: loss64 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475796 20134 solver.cpp:238]     Train net output #61: loss7 = 1224.43 (* 1 = 1224.43 loss)
I0728 12:34:30.475803 20134 solver.cpp:238]     Train net output #62: loss8 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475811 20134 solver.cpp:238]     Train net output #63: loss9 = 1201.21 (* 1 = 1201.21 loss)
I0728 12:34:30.475817 20134 sgd_solver.cpp:105] Iteration 91800, lr = 1e-09
I0728 12:43:21.226029 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:43:21.227319 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:43:21.612673 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_97200.caffemodel
I0728 12:43:21.825587 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_97200.solverstate
I0728 12:43:21.905814 20134 solver.cpp:331] Iteration 97200, Testing net (#0)
I0728 12:43:37.109771 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:43:37.119046 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:43:37.574724 20134 solver.cpp:398]     Test net output #0: mae = 77.492 (* 1 = 77.492 loss)
I0728 12:43:37.574749 20134 solver.cpp:398]     Test net output #1: mse = 13071 (* 1 = 13071 loss)
I0728 12:43:37.699604 20134 solver.cpp:219] Iteration 97200 (9.86817 iter/s, 547.214s/5400 iters), loss = 75816
I0728 12:43:37.699646 20134 solver.cpp:238]     Train net output #0: loss1 = 1177.36 (* 1 = 1177.36 loss)
I0728 12:43:37.699656 20134 solver.cpp:238]     Train net output #1: loss10 = 1166.35 (* 1 = 1166.35 loss)
I0728 12:43:37.699661 20134 solver.cpp:238]     Train net output #2: loss11 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699667 20134 solver.cpp:238]     Train net output #3: loss12 = 1196.87 (* 1 = 1196.87 loss)
I0728 12:43:37.699673 20134 solver.cpp:238]     Train net output #4: loss13 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699679 20134 solver.cpp:238]     Train net output #5: loss14 = 1181.73 (* 1 = 1181.73 loss)
I0728 12:43:37.699684 20134 solver.cpp:238]     Train net output #6: loss15 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699689 20134 solver.cpp:238]     Train net output #7: loss16 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699694 20134 solver.cpp:238]     Train net output #8: loss17 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699699 20134 solver.cpp:238]     Train net output #9: loss18 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699703 20134 solver.cpp:238]     Train net output #10: loss19 = 1214.48 (* 1 = 1214.48 loss)
I0728 12:43:37.699708 20134 solver.cpp:238]     Train net output #11: loss2 = 1175.06 (* 1 = 1175.06 loss)
I0728 12:43:37.699713 20134 solver.cpp:238]     Train net output #12: loss20 = 1176.51 (* 1 = 1176.51 loss)
I0728 12:43:37.699718 20134 solver.cpp:238]     Train net output #13: loss21 = 1168.4 (* 1 = 1168.4 loss)
I0728 12:43:37.699723 20134 solver.cpp:238]     Train net output #14: loss22 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699730 20134 solver.cpp:238]     Train net output #15: loss23 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699736 20134 solver.cpp:238]     Train net output #16: loss24 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699743 20134 solver.cpp:238]     Train net output #17: loss25 = 1190.55 (* 1 = 1190.55 loss)
I0728 12:43:37.699748 20134 solver.cpp:238]     Train net output #18: loss26 = 1186.38 (* 1 = 1186.38 loss)
I0728 12:43:37.699754 20134 solver.cpp:238]     Train net output #19: loss27 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699760 20134 solver.cpp:238]     Train net output #20: loss28 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699767 20134 solver.cpp:238]     Train net output #21: loss29 = 1211.09 (* 1 = 1211.09 loss)
I0728 12:43:37.699774 20134 solver.cpp:238]     Train net output #22: loss3 = 1193.62 (* 1 = 1193.62 loss)
I0728 12:43:37.699779 20134 solver.cpp:238]     Train net output #23: loss30 = 1200.16 (* 1 = 1200.16 loss)
I0728 12:43:37.699785 20134 solver.cpp:238]     Train net output #24: loss31 = 1186.61 (* 1 = 1186.61 loss)
I0728 12:43:37.699791 20134 solver.cpp:238]     Train net output #25: loss32 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699797 20134 solver.cpp:238]     Train net output #26: loss33 = 1186.8 (* 1 = 1186.8 loss)
I0728 12:43:37.699803 20134 solver.cpp:238]     Train net output #27: loss34 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699810 20134 solver.cpp:238]     Train net output #28: loss35 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699815 20134 solver.cpp:238]     Train net output #29: loss36 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699851 20134 solver.cpp:238]     Train net output #30: loss37 = 1192.58 (* 1 = 1192.58 loss)
I0728 12:43:37.699863 20134 solver.cpp:238]     Train net output #31: loss38 = 1207.87 (* 1 = 1207.87 loss)
I0728 12:43:37.699874 20134 solver.cpp:238]     Train net output #32: loss39 = 1191.84 (* 1 = 1191.84 loss)
I0728 12:43:37.699882 20134 solver.cpp:238]     Train net output #33: loss4 = 1179.64 (* 1 = 1179.64 loss)
I0728 12:43:37.699887 20134 solver.cpp:238]     Train net output #34: loss40 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699893 20134 solver.cpp:238]     Train net output #35: loss41 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699899 20134 solver.cpp:238]     Train net output #36: loss42 = 1175.79 (* 1 = 1175.79 loss)
I0728 12:43:37.699905 20134 solver.cpp:238]     Train net output #37: loss43 = 1186.73 (* 1 = 1186.73 loss)
I0728 12:43:37.699911 20134 solver.cpp:238]     Train net output #38: loss44 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699918 20134 solver.cpp:238]     Train net output #39: loss45 = 1187.13 (* 1 = 1187.13 loss)
I0728 12:43:37.699924 20134 solver.cpp:238]     Train net output #40: loss46 = 1211.12 (* 1 = 1211.12 loss)
I0728 12:43:37.699930 20134 solver.cpp:238]     Train net output #41: loss47 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699936 20134 solver.cpp:238]     Train net output #42: loss48 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699942 20134 solver.cpp:238]     Train net output #43: loss49 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699949 20134 solver.cpp:238]     Train net output #44: loss5 = 1192.73 (* 1 = 1192.73 loss)
I0728 12:43:37.699955 20134 solver.cpp:238]     Train net output #45: loss50 = 1183.25 (* 1 = 1183.25 loss)
I0728 12:43:37.699971 20134 solver.cpp:238]     Train net output #46: loss51 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.699978 20134 solver.cpp:238]     Train net output #47: loss52 = 1198.99 (* 1 = 1198.99 loss)
I0728 12:43:37.699985 20134 solver.cpp:238]     Train net output #48: loss53 = 1199.61 (* 1 = 1199.61 loss)
I0728 12:43:37.699991 20134 solver.cpp:238]     Train net output #49: loss54 = 1193.3 (* 1 = 1193.3 loss)
I0728 12:43:37.699997 20134 solver.cpp:238]     Train net output #50: loss55 = 1179.12 (* 1 = 1179.12 loss)
I0728 12:43:37.700003 20134 solver.cpp:238]     Train net output #51: loss56 = 1192.99 (* 1 = 1192.99 loss)
I0728 12:43:37.700011 20134 solver.cpp:238]     Train net output #52: loss57 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700016 20134 solver.cpp:238]     Train net output #53: loss58 = 1189.93 (* 1 = 1189.93 loss)
I0728 12:43:37.700022 20134 solver.cpp:238]     Train net output #54: loss59 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700028 20134 solver.cpp:238]     Train net output #55: loss6 = 1200.77 (* 1 = 1200.77 loss)
I0728 12:43:37.700034 20134 solver.cpp:238]     Train net output #56: loss60 = 1185.21 (* 1 = 1185.21 loss)
I0728 12:43:37.700042 20134 solver.cpp:238]     Train net output #57: loss61 = 1166.74 (* 1 = 1166.74 loss)
I0728 12:43:37.700047 20134 solver.cpp:238]     Train net output #58: loss62 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700052 20134 solver.cpp:238]     Train net output #59: loss63 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700059 20134 solver.cpp:238]     Train net output #60: loss64 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700065 20134 solver.cpp:238]     Train net output #61: loss7 = 1199.43 (* 1 = 1199.43 loss)
I0728 12:43:37.700072 20134 solver.cpp:238]     Train net output #62: loss8 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700076 20134 solver.cpp:238]     Train net output #63: loss9 = 1176.71 (* 1 = 1176.71 loss)
I0728 12:43:37.700083 20134 sgd_solver.cpp:105] Iteration 97200, lr = 1e-09
I0728 12:52:28.598472 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:52:28.610070 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:52:28.984609 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_102600.caffemodel
I0728 12:52:29.195420 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_102600.solverstate
I0728 12:52:29.274405 20134 solver.cpp:331] Iteration 102600, Testing net (#0)
I0728 12:52:44.476794 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:52:44.487383 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 12:52:44.941716 20134 solver.cpp:398]     Test net output #0: mae = 76.8248 (* 1 = 76.8248 loss)
I0728 12:52:44.941743 20134 solver.cpp:398]     Test net output #1: mse = 12883.4 (* 1 = 12883.4 loss)
I0728 12:52:45.065961 20134 solver.cpp:219] Iteration 102600 (9.8656 iter/s, 547.356s/5400 iters), loss = 74246
I0728 12:52:45.066001 20134 solver.cpp:238]     Train net output #0: loss1 = 1156.55 (* 1 = 1156.55 loss)
I0728 12:52:45.066011 20134 solver.cpp:238]     Train net output #1: loss10 = 1142.05 (* 1 = 1142.05 loss)
I0728 12:52:45.066017 20134 solver.cpp:238]     Train net output #2: loss11 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066025 20134 solver.cpp:238]     Train net output #3: loss12 = 1171.58 (* 1 = 1171.58 loss)
I0728 12:52:45.066030 20134 solver.cpp:238]     Train net output #4: loss13 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066035 20134 solver.cpp:238]     Train net output #5: loss14 = 1157.45 (* 1 = 1157.45 loss)
I0728 12:52:45.066041 20134 solver.cpp:238]     Train net output #6: loss15 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066047 20134 solver.cpp:238]     Train net output #7: loss16 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066053 20134 solver.cpp:238]     Train net output #8: loss17 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066058 20134 solver.cpp:238]     Train net output #9: loss18 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066064 20134 solver.cpp:238]     Train net output #10: loss19 = 1187.28 (* 1 = 1187.28 loss)
I0728 12:52:45.066071 20134 solver.cpp:238]     Train net output #11: loss2 = 1150.78 (* 1 = 1150.78 loss)
I0728 12:52:45.066076 20134 solver.cpp:238]     Train net output #12: loss20 = 1151.9 (* 1 = 1151.9 loss)
I0728 12:52:45.066082 20134 solver.cpp:238]     Train net output #13: loss21 = 1144.5 (* 1 = 1144.5 loss)
I0728 12:52:45.066088 20134 solver.cpp:238]     Train net output #14: loss22 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066094 20134 solver.cpp:238]     Train net output #15: loss23 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066100 20134 solver.cpp:238]     Train net output #16: loss24 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066107 20134 solver.cpp:238]     Train net output #17: loss25 = 1165.96 (* 1 = 1165.96 loss)
I0728 12:52:45.066112 20134 solver.cpp:238]     Train net output #18: loss26 = 1161.17 (* 1 = 1161.17 loss)
I0728 12:52:45.066118 20134 solver.cpp:238]     Train net output #19: loss27 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066124 20134 solver.cpp:238]     Train net output #20: loss28 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066131 20134 solver.cpp:238]     Train net output #21: loss29 = 1184.11 (* 1 = 1184.11 loss)
I0728 12:52:45.066138 20134 solver.cpp:238]     Train net output #22: loss3 = 1168.28 (* 1 = 1168.28 loss)
I0728 12:52:45.066143 20134 solver.cpp:238]     Train net output #23: loss30 = 1174.61 (* 1 = 1174.61 loss)
I0728 12:52:45.066149 20134 solver.cpp:238]     Train net output #24: loss31 = 1161.79 (* 1 = 1161.79 loss)
I0728 12:52:45.066155 20134 solver.cpp:238]     Train net output #25: loss32 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066161 20134 solver.cpp:238]     Train net output #26: loss33 = 1161.47 (* 1 = 1161.47 loss)
I0728 12:52:45.066166 20134 solver.cpp:238]     Train net output #27: loss34 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066172 20134 solver.cpp:238]     Train net output #28: loss35 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066179 20134 solver.cpp:238]     Train net output #29: loss36 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066213 20134 solver.cpp:238]     Train net output #30: loss37 = 1167.96 (* 1 = 1167.96 loss)
I0728 12:52:45.066223 20134 solver.cpp:238]     Train net output #31: loss38 = 1181.72 (* 1 = 1181.72 loss)
I0728 12:52:45.066233 20134 solver.cpp:238]     Train net output #32: loss39 = 1166.68 (* 1 = 1166.68 loss)
I0728 12:52:45.066244 20134 solver.cpp:238]     Train net output #33: loss4 = 1155.24 (* 1 = 1155.24 loss)
I0728 12:52:45.066254 20134 solver.cpp:238]     Train net output #34: loss40 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066264 20134 solver.cpp:238]     Train net output #35: loss41 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066274 20134 solver.cpp:238]     Train net output #36: loss42 = 1151.6 (* 1 = 1151.6 loss)
I0728 12:52:45.066283 20134 solver.cpp:238]     Train net output #37: loss43 = 1161.96 (* 1 = 1161.96 loss)
I0728 12:52:45.066293 20134 solver.cpp:238]     Train net output #38: loss44 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066303 20134 solver.cpp:238]     Train net output #39: loss45 = 1162.44 (* 1 = 1162.44 loss)
I0728 12:52:45.066314 20134 solver.cpp:238]     Train net output #40: loss46 = 1184.1 (* 1 = 1184.1 loss)
I0728 12:52:45.066323 20134 solver.cpp:238]     Train net output #41: loss47 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066329 20134 solver.cpp:238]     Train net output #42: loss48 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066334 20134 solver.cpp:238]     Train net output #43: loss49 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066340 20134 solver.cpp:238]     Train net output #44: loss5 = 1168.34 (* 1 = 1168.34 loss)
I0728 12:52:45.066347 20134 solver.cpp:238]     Train net output #45: loss50 = 1158.2 (* 1 = 1158.2 loss)
I0728 12:52:45.066352 20134 solver.cpp:238]     Train net output #46: loss51 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066359 20134 solver.cpp:238]     Train net output #47: loss52 = 1174.83 (* 1 = 1174.83 loss)
I0728 12:52:45.066365 20134 solver.cpp:238]     Train net output #48: loss53 = 1173.58 (* 1 = 1173.58 loss)
I0728 12:52:45.066370 20134 solver.cpp:238]     Train net output #49: loss54 = 1168.05 (* 1 = 1168.05 loss)
I0728 12:52:45.066376 20134 solver.cpp:238]     Train net output #50: loss55 = 1154.91 (* 1 = 1154.91 loss)
I0728 12:52:45.066382 20134 solver.cpp:238]     Train net output #51: loss56 = 1167.2 (* 1 = 1167.2 loss)
I0728 12:52:45.066388 20134 solver.cpp:238]     Train net output #52: loss57 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066395 20134 solver.cpp:238]     Train net output #53: loss58 = 1166.33 (* 1 = 1166.33 loss)
I0728 12:52:45.066400 20134 solver.cpp:238]     Train net output #54: loss59 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066406 20134 solver.cpp:238]     Train net output #55: loss6 = 1174.46 (* 1 = 1174.46 loss)
I0728 12:52:45.066411 20134 solver.cpp:238]     Train net output #56: loss60 = 1160.18 (* 1 = 1160.18 loss)
I0728 12:52:45.066417 20134 solver.cpp:238]     Train net output #57: loss61 = 1142.63 (* 1 = 1142.63 loss)
I0728 12:52:45.066423 20134 solver.cpp:238]     Train net output #58: loss62 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066429 20134 solver.cpp:238]     Train net output #59: loss63 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066435 20134 solver.cpp:238]     Train net output #60: loss64 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066442 20134 solver.cpp:238]     Train net output #61: loss7 = 1174.47 (* 1 = 1174.47 loss)
I0728 12:52:45.066447 20134 solver.cpp:238]     Train net output #62: loss8 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066453 20134 solver.cpp:238]     Train net output #63: loss9 = 1152.5 (* 1 = 1152.5 loss)
I0728 12:52:45.066459 20134 sgd_solver.cpp:105] Iteration 102600, lr = 1e-09
I0728 13:01:36.194049 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:01:36.195215 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:01:36.580229 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_108000.caffemodel
I0728 13:01:36.793128 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_108000.solverstate
I0728 13:01:36.873162 20134 solver.cpp:331] Iteration 108000, Testing net (#0)
I0728 13:01:52.066383 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:01:52.089401 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:01:52.530794 20134 solver.cpp:398]     Test net output #0: mae = 76.0231 (* 1 = 76.0231 loss)
I0728 13:01:52.530818 20134 solver.cpp:398]     Test net output #1: mse = 12713.8 (* 1 = 12713.8 loss)
I0728 13:01:52.655521 20134 solver.cpp:219] Iteration 108000 (9.86159 iter/s, 547.579s/5400 iters), loss = 72765.2
I0728 13:01:52.655560 20134 solver.cpp:238]     Train net output #0: loss1 = 1135.24 (* 1 = 1135.24 loss)
I0728 13:01:52.655575 20134 solver.cpp:238]     Train net output #1: loss10 = 1119.04 (* 1 = 1119.04 loss)
I0728 13:01:52.655585 20134 solver.cpp:238]     Train net output #2: loss11 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655596 20134 solver.cpp:238]     Train net output #3: loss12 = 1147.54 (* 1 = 1147.54 loss)
I0728 13:01:52.655607 20134 solver.cpp:238]     Train net output #4: loss13 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655618 20134 solver.cpp:238]     Train net output #5: loss14 = 1134.36 (* 1 = 1134.36 loss)
I0728 13:01:52.655629 20134 solver.cpp:238]     Train net output #6: loss15 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655640 20134 solver.cpp:238]     Train net output #7: loss16 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655650 20134 solver.cpp:238]     Train net output #8: loss17 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655661 20134 solver.cpp:238]     Train net output #9: loss18 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655673 20134 solver.cpp:238]     Train net output #10: loss19 = 1161.68 (* 1 = 1161.68 loss)
I0728 13:01:52.655683 20134 solver.cpp:238]     Train net output #11: loss2 = 1127.77 (* 1 = 1127.77 loss)
I0728 13:01:52.655694 20134 solver.cpp:238]     Train net output #12: loss20 = 1127.91 (* 1 = 1127.91 loss)
I0728 13:01:52.655705 20134 solver.cpp:238]     Train net output #13: loss21 = 1121.9 (* 1 = 1121.9 loss)
I0728 13:01:52.655716 20134 solver.cpp:238]     Train net output #14: loss22 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655727 20134 solver.cpp:238]     Train net output #15: loss23 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655738 20134 solver.cpp:238]     Train net output #16: loss24 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655748 20134 solver.cpp:238]     Train net output #17: loss25 = 1142.42 (* 1 = 1142.42 loss)
I0728 13:01:52.655761 20134 solver.cpp:238]     Train net output #18: loss26 = 1137.42 (* 1 = 1137.42 loss)
I0728 13:01:52.655771 20134 solver.cpp:238]     Train net output #19: loss27 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655781 20134 solver.cpp:238]     Train net output #20: loss28 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655792 20134 solver.cpp:238]     Train net output #21: loss29 = 1158.17 (* 1 = 1158.17 loss)
I0728 13:01:52.655803 20134 solver.cpp:238]     Train net output #22: loss3 = 1144.1 (* 1 = 1144.1 loss)
I0728 13:01:52.655813 20134 solver.cpp:238]     Train net output #23: loss30 = 1150.76 (* 1 = 1150.76 loss)
I0728 13:01:52.655824 20134 solver.cpp:238]     Train net output #24: loss31 = 1138.4 (* 1 = 1138.4 loss)
I0728 13:01:52.655834 20134 solver.cpp:238]     Train net output #25: loss32 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655845 20134 solver.cpp:238]     Train net output #26: loss33 = 1137.78 (* 1 = 1137.78 loss)
I0728 13:01:52.655855 20134 solver.cpp:238]     Train net output #27: loss34 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655865 20134 solver.cpp:238]     Train net output #28: loss35 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655905 20134 solver.cpp:238]     Train net output #29: loss36 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655921 20134 solver.cpp:238]     Train net output #30: loss37 = 1144.18 (* 1 = 1144.18 loss)
I0728 13:01:52.655933 20134 solver.cpp:238]     Train net output #31: loss38 = 1156.98 (* 1 = 1156.98 loss)
I0728 13:01:52.655944 20134 solver.cpp:238]     Train net output #32: loss39 = 1142.86 (* 1 = 1142.86 loss)
I0728 13:01:52.655956 20134 solver.cpp:238]     Train net output #33: loss4 = 1132.2 (* 1 = 1132.2 loss)
I0728 13:01:52.655966 20134 solver.cpp:238]     Train net output #34: loss40 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655977 20134 solver.cpp:238]     Train net output #35: loss41 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.655988 20134 solver.cpp:238]     Train net output #36: loss42 = 1128.62 (* 1 = 1128.62 loss)
I0728 13:01:52.655999 20134 solver.cpp:238]     Train net output #37: loss43 = 1138.35 (* 1 = 1138.35 loss)
I0728 13:01:52.656009 20134 solver.cpp:238]     Train net output #38: loss44 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656021 20134 solver.cpp:238]     Train net output #39: loss45 = 1139.01 (* 1 = 1139.01 loss)
I0728 13:01:52.656033 20134 solver.cpp:238]     Train net output #40: loss46 = 1158.11 (* 1 = 1158.11 loss)
I0728 13:01:52.656044 20134 solver.cpp:238]     Train net output #41: loss47 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656054 20134 solver.cpp:238]     Train net output #42: loss48 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656064 20134 solver.cpp:238]     Train net output #43: loss49 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656076 20134 solver.cpp:238]     Train net output #44: loss5 = 1145.16 (* 1 = 1145.16 loss)
I0728 13:01:52.656086 20134 solver.cpp:238]     Train net output #45: loss50 = 1134.73 (* 1 = 1134.73 loss)
I0728 13:01:52.656097 20134 solver.cpp:238]     Train net output #46: loss51 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656108 20134 solver.cpp:238]     Train net output #47: loss52 = 1152.09 (* 1 = 1152.09 loss)
I0728 13:01:52.656118 20134 solver.cpp:238]     Train net output #48: loss53 = 1149.21 (* 1 = 1149.21 loss)
I0728 13:01:52.656128 20134 solver.cpp:238]     Train net output #49: loss54 = 1144.01 (* 1 = 1144.01 loss)
I0728 13:01:52.656139 20134 solver.cpp:238]     Train net output #50: loss55 = 1131.94 (* 1 = 1131.94 loss)
I0728 13:01:52.656149 20134 solver.cpp:238]     Train net output #51: loss56 = 1142.79 (* 1 = 1142.79 loss)
I0728 13:01:52.656160 20134 solver.cpp:238]     Train net output #52: loss57 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656172 20134 solver.cpp:238]     Train net output #53: loss58 = 1142.93 (* 1 = 1142.93 loss)
I0728 13:01:52.656183 20134 solver.cpp:238]     Train net output #54: loss59 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656193 20134 solver.cpp:238]     Train net output #55: loss6 = 1149.5 (* 1 = 1149.5 loss)
I0728 13:01:52.656204 20134 solver.cpp:238]     Train net output #56: loss60 = 1136.3 (* 1 = 1136.3 loss)
I0728 13:01:52.656215 20134 solver.cpp:238]     Train net output #57: loss61 = 1119.68 (* 1 = 1119.68 loss)
I0728 13:01:52.656226 20134 solver.cpp:238]     Train net output #58: loss62 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656237 20134 solver.cpp:238]     Train net output #59: loss63 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656249 20134 solver.cpp:238]     Train net output #60: loss64 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656260 20134 solver.cpp:238]     Train net output #61: loss7 = 1150.35 (* 1 = 1150.35 loss)
I0728 13:01:52.656270 20134 solver.cpp:238]     Train net output #62: loss8 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656280 20134 solver.cpp:238]     Train net output #63: loss9 = 1129.56 (* 1 = 1129.56 loss)
I0728 13:01:52.656291 20134 sgd_solver.cpp:105] Iteration 108000, lr = 1e-09
I0728 13:10:43.708192 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:10:43.710554 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:10:44.094547 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_113400.caffemodel
I0728 13:10:44.307916 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_113400.solverstate
I0728 13:10:44.388221 20134 solver.cpp:331] Iteration 113400, Testing net (#0)
I0728 13:10:59.585256 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:10:59.597108 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:11:00.057754 20134 solver.cpp:398]     Test net output #0: mae = 75.5039 (* 1 = 75.5039 loss)
I0728 13:11:00.057776 20134 solver.cpp:398]     Test net output #1: mse = 12622.6 (* 1 = 12622.6 loss)
I0728 13:11:00.185299 20134 solver.cpp:219] Iteration 113400 (9.86266 iter/s, 547.519s/5400 iters), loss = 71543.8
I0728 13:11:00.185344 20134 solver.cpp:238]     Train net output #0: loss1 = 1117.3 (* 1 = 1117.3 loss)
I0728 13:11:00.185359 20134 solver.cpp:238]     Train net output #1: loss10 = 1100.21 (* 1 = 1100.21 loss)
I0728 13:11:00.185370 20134 solver.cpp:238]     Train net output #2: loss11 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185381 20134 solver.cpp:238]     Train net output #3: loss12 = 1127.83 (* 1 = 1127.83 loss)
I0728 13:11:00.185392 20134 solver.cpp:238]     Train net output #4: loss13 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185402 20134 solver.cpp:238]     Train net output #5: loss14 = 1115.49 (* 1 = 1115.49 loss)
I0728 13:11:00.185413 20134 solver.cpp:238]     Train net output #6: loss15 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185425 20134 solver.cpp:238]     Train net output #7: loss16 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185436 20134 solver.cpp:238]     Train net output #8: loss17 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185446 20134 solver.cpp:238]     Train net output #9: loss18 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185458 20134 solver.cpp:238]     Train net output #10: loss19 = 1140.37 (* 1 = 1140.37 loss)
I0728 13:11:00.185469 20134 solver.cpp:238]     Train net output #11: loss2 = 1108.84 (* 1 = 1108.84 loss)
I0728 13:11:00.185480 20134 solver.cpp:238]     Train net output #12: loss20 = 1108.2 (* 1 = 1108.2 loss)
I0728 13:11:00.185492 20134 solver.cpp:238]     Train net output #13: loss21 = 1103.37 (* 1 = 1103.37 loss)
I0728 13:11:00.185503 20134 solver.cpp:238]     Train net output #14: loss22 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185513 20134 solver.cpp:238]     Train net output #15: loss23 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185524 20134 solver.cpp:238]     Train net output #16: loss24 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185535 20134 solver.cpp:238]     Train net output #17: loss25 = 1123.22 (* 1 = 1123.22 loss)
I0728 13:11:00.185546 20134 solver.cpp:238]     Train net output #18: loss26 = 1118.15 (* 1 = 1118.15 loss)
I0728 13:11:00.185557 20134 solver.cpp:238]     Train net output #19: loss27 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185569 20134 solver.cpp:238]     Train net output #20: loss28 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185580 20134 solver.cpp:238]     Train net output #21: loss29 = 1137.21 (* 1 = 1137.21 loss)
I0728 13:11:00.185590 20134 solver.cpp:238]     Train net output #22: loss3 = 1124.57 (* 1 = 1124.57 loss)
I0728 13:11:00.185601 20134 solver.cpp:238]     Train net output #23: loss30 = 1131.03 (* 1 = 1131.03 loss)
I0728 13:11:00.185612 20134 solver.cpp:238]     Train net output #24: loss31 = 1119.03 (* 1 = 1119.03 loss)
I0728 13:11:00.185623 20134 solver.cpp:238]     Train net output #25: loss32 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185634 20134 solver.cpp:238]     Train net output #26: loss33 = 1118.52 (* 1 = 1118.52 loss)
I0728 13:11:00.185647 20134 solver.cpp:238]     Train net output #27: loss34 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185657 20134 solver.cpp:238]     Train net output #28: loss35 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185668 20134 solver.cpp:238]     Train net output #29: loss36 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185710 20134 solver.cpp:238]     Train net output #30: loss37 = 1124.44 (* 1 = 1124.44 loss)
I0728 13:11:00.185722 20134 solver.cpp:238]     Train net output #31: loss38 = 1136.56 (* 1 = 1136.56 loss)
I0728 13:11:00.185734 20134 solver.cpp:238]     Train net output #32: loss39 = 1123.16 (* 1 = 1123.16 loss)
I0728 13:11:00.185745 20134 solver.cpp:238]     Train net output #33: loss4 = 1113.34 (* 1 = 1113.34 loss)
I0728 13:11:00.185756 20134 solver.cpp:238]     Train net output #34: loss40 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185767 20134 solver.cpp:238]     Train net output #35: loss41 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185777 20134 solver.cpp:238]     Train net output #36: loss42 = 1109.79 (* 1 = 1109.79 loss)
I0728 13:11:00.185788 20134 solver.cpp:238]     Train net output #37: loss43 = 1119.28 (* 1 = 1119.28 loss)
I0728 13:11:00.185798 20134 solver.cpp:238]     Train net output #38: loss44 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185809 20134 solver.cpp:238]     Train net output #39: loss45 = 1119.86 (* 1 = 1119.86 loss)
I0728 13:11:00.185819 20134 solver.cpp:238]     Train net output #40: loss46 = 1136.92 (* 1 = 1136.92 loss)
I0728 13:11:00.185830 20134 solver.cpp:238]     Train net output #41: loss47 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185840 20134 solver.cpp:238]     Train net output #42: loss48 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185850 20134 solver.cpp:238]     Train net output #43: loss49 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185860 20134 solver.cpp:238]     Train net output #44: loss5 = 1126.26 (* 1 = 1126.26 loss)
I0728 13:11:00.185871 20134 solver.cpp:238]     Train net output #45: loss50 = 1115.71 (* 1 = 1115.71 loss)
I0728 13:11:00.185883 20134 solver.cpp:238]     Train net output #46: loss51 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185894 20134 solver.cpp:238]     Train net output #47: loss52 = 1132.95 (* 1 = 1132.95 loss)
I0728 13:11:00.185904 20134 solver.cpp:238]     Train net output #48: loss53 = 1129.13 (* 1 = 1129.13 loss)
I0728 13:11:00.185914 20134 solver.cpp:238]     Train net output #49: loss54 = 1124.32 (* 1 = 1124.32 loss)
I0728 13:11:00.185923 20134 solver.cpp:238]     Train net output #50: loss55 = 1113.16 (* 1 = 1113.16 loss)
I0728 13:11:00.185932 20134 solver.cpp:238]     Train net output #51: loss56 = 1122.67 (* 1 = 1122.67 loss)
I0728 13:11:00.185941 20134 solver.cpp:238]     Train net output #52: loss57 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185950 20134 solver.cpp:238]     Train net output #53: loss58 = 1123.51 (* 1 = 1123.51 loss)
I0728 13:11:00.185958 20134 solver.cpp:238]     Train net output #54: loss59 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.185967 20134 solver.cpp:238]     Train net output #55: loss6 = 1129.24 (* 1 = 1129.24 loss)
I0728 13:11:00.185976 20134 solver.cpp:238]     Train net output #56: loss60 = 1116.93 (* 1 = 1116.93 loss)
I0728 13:11:00.185984 20134 solver.cpp:238]     Train net output #57: loss61 = 1100.8 (* 1 = 1100.8 loss)
I0728 13:11:00.185993 20134 solver.cpp:238]     Train net output #58: loss62 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.186002 20134 solver.cpp:238]     Train net output #59: loss63 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.186010 20134 solver.cpp:238]     Train net output #60: loss64 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.186019 20134 solver.cpp:238]     Train net output #61: loss7 = 1130.85 (* 1 = 1130.85 loss)
I0728 13:11:00.186029 20134 solver.cpp:238]     Train net output #62: loss8 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.186040 20134 solver.cpp:238]     Train net output #63: loss9 = 1110.7 (* 1 = 1110.7 loss)
I0728 13:11:00.186050 20134 sgd_solver.cpp:105] Iteration 113400, lr = 1e-09
I0728 13:19:50.426875 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:19:50.427899 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:19:50.814091 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_118800.caffemodel
I0728 13:19:51.028802 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_118800.solverstate
I0728 13:19:51.109697 20134 solver.cpp:331] Iteration 118800, Testing net (#0)
I0728 13:20:06.322262 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:20:06.332116 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:20:06.787109 20134 solver.cpp:398]     Test net output #0: mae = 75.0806 (* 1 = 75.0806 loss)
I0728 13:20:06.787132 20134 solver.cpp:398]     Test net output #1: mse = 12582.4 (* 1 = 12582.4 loss)
I0728 13:20:06.911891 20134 solver.cpp:219] Iteration 118800 (9.87715 iter/s, 546.716s/5400 iters), loss = 70757.5
I0728 13:20:06.911942 20134 solver.cpp:238]     Train net output #0: loss1 = 1105.59 (* 1 = 1105.59 loss)
I0728 13:20:06.911950 20134 solver.cpp:238]     Train net output #1: loss10 = 1088 (* 1 = 1088 loss)
I0728 13:20:06.911957 20134 solver.cpp:238]     Train net output #2: loss11 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.911962 20134 solver.cpp:238]     Train net output #3: loss12 = 1115.25 (* 1 = 1115.25 loss)
I0728 13:20:06.911968 20134 solver.cpp:238]     Train net output #4: loss13 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.911974 20134 solver.cpp:238]     Train net output #5: loss14 = 1103.53 (* 1 = 1103.53 loss)
I0728 13:20:06.911980 20134 solver.cpp:238]     Train net output #6: loss15 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.911986 20134 solver.cpp:238]     Train net output #7: loss16 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.911993 20134 solver.cpp:238]     Train net output #8: loss17 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.911998 20134 solver.cpp:238]     Train net output #9: loss18 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912003 20134 solver.cpp:238]     Train net output #10: loss19 = 1126.43 (* 1 = 1126.43 loss)
I0728 13:20:06.912009 20134 solver.cpp:238]     Train net output #11: loss2 = 1096.57 (* 1 = 1096.57 loss)
I0728 13:20:06.912016 20134 solver.cpp:238]     Train net output #12: loss20 = 1095.63 (* 1 = 1095.63 loss)
I0728 13:20:06.912021 20134 solver.cpp:238]     Train net output #13: loss21 = 1091.6 (* 1 = 1091.6 loss)
I0728 13:20:06.912027 20134 solver.cpp:238]     Train net output #14: loss22 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912034 20134 solver.cpp:238]     Train net output #15: loss23 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912039 20134 solver.cpp:238]     Train net output #16: loss24 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912045 20134 solver.cpp:238]     Train net output #17: loss25 = 1110.82 (* 1 = 1110.82 loss)
I0728 13:20:06.912051 20134 solver.cpp:238]     Train net output #18: loss26 = 1105.68 (* 1 = 1105.68 loss)
I0728 13:20:06.912057 20134 solver.cpp:238]     Train net output #19: loss27 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912065 20134 solver.cpp:238]     Train net output #20: loss28 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912070 20134 solver.cpp:238]     Train net output #21: loss29 = 1123.34 (* 1 = 1123.34 loss)
I0728 13:20:06.912075 20134 solver.cpp:238]     Train net output #22: loss3 = 1111.62 (* 1 = 1111.62 loss)
I0728 13:20:06.912081 20134 solver.cpp:238]     Train net output #23: loss30 = 1118.36 (* 1 = 1118.36 loss)
I0728 13:20:06.912087 20134 solver.cpp:238]     Train net output #24: loss31 = 1106.74 (* 1 = 1106.74 loss)
I0728 13:20:06.912094 20134 solver.cpp:238]     Train net output #25: loss32 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912101 20134 solver.cpp:238]     Train net output #26: loss33 = 1106.11 (* 1 = 1106.11 loss)
I0728 13:20:06.912106 20134 solver.cpp:238]     Train net output #27: loss34 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912112 20134 solver.cpp:238]     Train net output #28: loss35 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912144 20134 solver.cpp:238]     Train net output #29: loss36 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912153 20134 solver.cpp:238]     Train net output #30: loss37 = 1112.13 (* 1 = 1112.13 loss)
I0728 13:20:06.912158 20134 solver.cpp:238]     Train net output #31: loss38 = 1123.54 (* 1 = 1123.54 loss)
I0728 13:20:06.912165 20134 solver.cpp:238]     Train net output #32: loss39 = 1110.41 (* 1 = 1110.41 loss)
I0728 13:20:06.912171 20134 solver.cpp:238]     Train net output #33: loss4 = 1101.19 (* 1 = 1101.19 loss)
I0728 13:20:06.912178 20134 solver.cpp:238]     Train net output #34: loss40 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912184 20134 solver.cpp:238]     Train net output #35: loss41 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912189 20134 solver.cpp:238]     Train net output #36: loss42 = 1097.51 (* 1 = 1097.51 loss)
I0728 13:20:06.912194 20134 solver.cpp:238]     Train net output #37: loss43 = 1107.15 (* 1 = 1107.15 loss)
I0728 13:20:06.912200 20134 solver.cpp:238]     Train net output #38: loss44 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912206 20134 solver.cpp:238]     Train net output #39: loss45 = 1107.76 (* 1 = 1107.76 loss)
I0728 13:20:06.912212 20134 solver.cpp:238]     Train net output #40: loss46 = 1123.11 (* 1 = 1123.11 loss)
I0728 13:20:06.912219 20134 solver.cpp:238]     Train net output #41: loss47 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912225 20134 solver.cpp:238]     Train net output #42: loss48 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912230 20134 solver.cpp:238]     Train net output #43: loss49 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912236 20134 solver.cpp:238]     Train net output #44: loss5 = 1114.01 (* 1 = 1114.01 loss)
I0728 13:20:06.912241 20134 solver.cpp:238]     Train net output #45: loss50 = 1103.48 (* 1 = 1103.48 loss)
I0728 13:20:06.912247 20134 solver.cpp:238]     Train net output #46: loss51 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912253 20134 solver.cpp:238]     Train net output #47: loss52 = 1121.14 (* 1 = 1121.14 loss)
I0728 13:20:06.912259 20134 solver.cpp:238]     Train net output #48: loss53 = 1116.17 (* 1 = 1116.17 loss)
I0728 13:20:06.912266 20134 solver.cpp:238]     Train net output #49: loss54 = 1111.62 (* 1 = 1111.62 loss)
I0728 13:20:06.912271 20134 solver.cpp:238]     Train net output #50: loss55 = 1101.05 (* 1 = 1101.05 loss)
I0728 13:20:06.912277 20134 solver.cpp:238]     Train net output #51: loss56 = 1109.81 (* 1 = 1109.81 loss)
I0728 13:20:06.912283 20134 solver.cpp:238]     Train net output #52: loss57 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912289 20134 solver.cpp:238]     Train net output #53: loss58 = 1110.83 (* 1 = 1110.83 loss)
I0728 13:20:06.912295 20134 solver.cpp:238]     Train net output #54: loss59 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912302 20134 solver.cpp:238]     Train net output #55: loss6 = 1116.42 (* 1 = 1116.42 loss)
I0728 13:20:06.912307 20134 solver.cpp:238]     Train net output #56: loss60 = 1104.43 (* 1 = 1104.43 loss)
I0728 13:20:06.912313 20134 solver.cpp:238]     Train net output #57: loss61 = 1088.57 (* 1 = 1088.57 loss)
I0728 13:20:06.912319 20134 solver.cpp:238]     Train net output #58: loss62 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912325 20134 solver.cpp:238]     Train net output #59: loss63 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912331 20134 solver.cpp:238]     Train net output #60: loss64 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912338 20134 solver.cpp:238]     Train net output #61: loss7 = 1118.14 (* 1 = 1118.14 loss)
I0728 13:20:06.912343 20134 solver.cpp:238]     Train net output #62: loss8 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912348 20134 solver.cpp:238]     Train net output #63: loss9 = 1098.55 (* 1 = 1098.55 loss)
I0728 13:20:06.912355 20134 sgd_solver.cpp:105] Iteration 118800, lr = 1e-09
I0728 13:28:56.537627 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:28:56.538650 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:28:56.929225 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_124200.caffemodel
I0728 13:28:57.139108 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_124200.solverstate
I0728 13:28:57.217301 20134 solver.cpp:331] Iteration 124200, Testing net (#0)
I0728 13:29:12.434123 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:29:12.454677 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:29:12.897616 20134 solver.cpp:398]     Test net output #0: mae = 74.7735 (* 1 = 74.7735 loss)
I0728 13:29:12.897639 20134 solver.cpp:398]     Test net output #1: mse = 12556.2 (* 1 = 12556.2 loss)
I0728 13:29:13.022620 20134 solver.cpp:219] Iteration 124200 (9.88828 iter/s, 546.101s/5400 iters), loss = 69808.2
I0728 13:29:13.022660 20134 solver.cpp:238]     Train net output #0: loss1 = 1090.9 (* 1 = 1090.9 loss)
I0728 13:29:13.022670 20134 solver.cpp:238]     Train net output #1: loss10 = 1073.1 (* 1 = 1073.1 loss)
I0728 13:29:13.022676 20134 solver.cpp:238]     Train net output #2: loss11 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022683 20134 solver.cpp:238]     Train net output #3: loss12 = 1100.16 (* 1 = 1100.16 loss)
I0728 13:29:13.022688 20134 solver.cpp:238]     Train net output #4: loss13 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022694 20134 solver.cpp:238]     Train net output #5: loss14 = 1088.73 (* 1 = 1088.73 loss)
I0728 13:29:13.022701 20134 solver.cpp:238]     Train net output #6: loss15 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022706 20134 solver.cpp:238]     Train net output #7: loss16 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022712 20134 solver.cpp:238]     Train net output #8: loss17 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022719 20134 solver.cpp:238]     Train net output #9: loss18 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022725 20134 solver.cpp:238]     Train net output #10: loss19 = 1109 (* 1 = 1109 loss)
I0728 13:29:13.022732 20134 solver.cpp:238]     Train net output #11: loss2 = 1081.59 (* 1 = 1081.59 loss)
I0728 13:29:13.022737 20134 solver.cpp:238]     Train net output #12: loss20 = 1080.02 (* 1 = 1080.02 loss)
I0728 13:29:13.022743 20134 solver.cpp:238]     Train net output #13: loss21 = 1077.09 (* 1 = 1077.09 loss)
I0728 13:29:13.022749 20134 solver.cpp:238]     Train net output #14: loss22 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022758 20134 solver.cpp:238]     Train net output #15: loss23 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022770 20134 solver.cpp:238]     Train net output #16: loss24 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022783 20134 solver.cpp:238]     Train net output #17: loss25 = 1095.69 (* 1 = 1095.69 loss)
I0728 13:29:13.022791 20134 solver.cpp:238]     Train net output #18: loss26 = 1090.52 (* 1 = 1090.52 loss)
I0728 13:29:13.022797 20134 solver.cpp:238]     Train net output #19: loss27 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022804 20134 solver.cpp:238]     Train net output #20: loss28 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022809 20134 solver.cpp:238]     Train net output #21: loss29 = 1107.19 (* 1 = 1107.19 loss)
I0728 13:29:13.022815 20134 solver.cpp:238]     Train net output #22: loss3 = 1096.15 (* 1 = 1096.15 loss)
I0728 13:29:13.022821 20134 solver.cpp:238]     Train net output #23: loss30 = 1103.04 (* 1 = 1103.04 loss)
I0728 13:29:13.022828 20134 solver.cpp:238]     Train net output #24: loss31 = 1091.64 (* 1 = 1091.64 loss)
I0728 13:29:13.022835 20134 solver.cpp:238]     Train net output #25: loss32 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022840 20134 solver.cpp:238]     Train net output #26: loss33 = 1090.94 (* 1 = 1090.94 loss)
I0728 13:29:13.022846 20134 solver.cpp:238]     Train net output #27: loss34 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022851 20134 solver.cpp:238]     Train net output #28: loss35 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022857 20134 solver.cpp:238]     Train net output #29: loss36 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022886 20134 solver.cpp:238]     Train net output #30: loss37 = 1096.92 (* 1 = 1096.92 loss)
I0728 13:29:13.022894 20134 solver.cpp:238]     Train net output #31: loss38 = 1107.95 (* 1 = 1107.95 loss)
I0728 13:29:13.022900 20134 solver.cpp:238]     Train net output #32: loss39 = 1095.05 (* 1 = 1095.05 loss)
I0728 13:29:13.022907 20134 solver.cpp:238]     Train net output #33: loss4 = 1086.29 (* 1 = 1086.29 loss)
I0728 13:29:13.022912 20134 solver.cpp:238]     Train net output #34: loss40 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022918 20134 solver.cpp:238]     Train net output #35: loss41 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022924 20134 solver.cpp:238]     Train net output #36: loss42 = 1082.54 (* 1 = 1082.54 loss)
I0728 13:29:13.022930 20134 solver.cpp:238]     Train net output #37: loss43 = 1092.37 (* 1 = 1092.37 loss)
I0728 13:29:13.022936 20134 solver.cpp:238]     Train net output #38: loss44 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022941 20134 solver.cpp:238]     Train net output #39: loss45 = 1092.89 (* 1 = 1092.89 loss)
I0728 13:29:13.022948 20134 solver.cpp:238]     Train net output #40: loss46 = 1106.39 (* 1 = 1106.39 loss)
I0728 13:29:13.022953 20134 solver.cpp:238]     Train net output #41: loss47 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022959 20134 solver.cpp:238]     Train net output #42: loss48 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022965 20134 solver.cpp:238]     Train net output #43: loss49 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022971 20134 solver.cpp:238]     Train net output #44: loss5 = 1099.19 (* 1 = 1099.19 loss)
I0728 13:29:13.022977 20134 solver.cpp:238]     Train net output #45: loss50 = 1088.65 (* 1 = 1088.65 loss)
I0728 13:29:13.022984 20134 solver.cpp:238]     Train net output #46: loss51 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.022990 20134 solver.cpp:238]     Train net output #47: loss52 = 1105.71 (* 1 = 1105.71 loss)
I0728 13:29:13.022996 20134 solver.cpp:238]     Train net output #48: loss53 = 1100.62 (* 1 = 1100.62 loss)
I0728 13:29:13.023002 20134 solver.cpp:238]     Train net output #49: loss54 = 1096.24 (* 1 = 1096.24 loss)
I0728 13:29:13.023008 20134 solver.cpp:238]     Train net output #50: loss55 = 1086.33 (* 1 = 1086.33 loss)
I0728 13:29:13.023015 20134 solver.cpp:238]     Train net output #51: loss56 = 1094.26 (* 1 = 1094.26 loss)
I0728 13:29:13.023020 20134 solver.cpp:238]     Train net output #52: loss57 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023026 20134 solver.cpp:238]     Train net output #53: loss58 = 1095.59 (* 1 = 1095.59 loss)
I0728 13:29:13.023031 20134 solver.cpp:238]     Train net output #54: loss59 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023042 20134 solver.cpp:238]     Train net output #55: loss6 = 1100.89 (* 1 = 1100.89 loss)
I0728 13:29:13.023048 20134 solver.cpp:238]     Train net output #56: loss60 = 1089.04 (* 1 = 1089.04 loss)
I0728 13:29:13.023054 20134 solver.cpp:238]     Train net output #57: loss61 = 1073.8 (* 1 = 1073.8 loss)
I0728 13:29:13.023061 20134 solver.cpp:238]     Train net output #58: loss62 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023066 20134 solver.cpp:238]     Train net output #59: loss63 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023072 20134 solver.cpp:238]     Train net output #60: loss64 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023080 20134 solver.cpp:238]     Train net output #61: loss7 = 1102.8 (* 1 = 1102.8 loss)
I0728 13:29:13.023092 20134 solver.cpp:238]     Train net output #62: loss8 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023099 20134 solver.cpp:238]     Train net output #63: loss9 = 1083.66 (* 1 = 1083.66 loss)
I0728 13:29:13.023106 20134 sgd_solver.cpp:105] Iteration 124200, lr = 1e-09
I0728 13:38:03.265460 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:38:03.269405 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:38:03.658113 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_129600.caffemodel
I0728 13:38:03.868783 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_129600.solverstate
I0728 13:38:03.947008 20134 solver.cpp:331] Iteration 129600, Testing net (#0)
I0728 13:38:19.148787 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:38:19.195855 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:38:19.612568 20134 solver.cpp:398]     Test net output #0: mae = 74.3529 (* 1 = 74.3529 loss)
I0728 13:38:19.612591 20134 solver.cpp:398]     Test net output #1: mse = 12500 (* 1 = 12500 loss)
I0728 13:38:19.737135 20134 solver.cpp:219] Iteration 129600 (9.87733 iter/s, 546.706s/5400 iters), loss = 69034.8
I0728 13:38:19.737175 20134 solver.cpp:238]     Train net output #0: loss1 = 1079.21 (* 1 = 1079.21 loss)
I0728 13:38:19.737185 20134 solver.cpp:238]     Train net output #1: loss10 = 1061.31 (* 1 = 1061.31 loss)
I0728 13:38:19.737190 20134 solver.cpp:238]     Train net output #2: loss11 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737196 20134 solver.cpp:238]     Train net output #3: loss12 = 1087.99 (* 1 = 1087.99 loss)
I0728 13:38:19.737202 20134 solver.cpp:238]     Train net output #4: loss13 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737208 20134 solver.cpp:238]     Train net output #5: loss14 = 1076.86 (* 1 = 1076.86 loss)
I0728 13:38:19.737215 20134 solver.cpp:238]     Train net output #6: loss15 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737221 20134 solver.cpp:238]     Train net output #7: loss16 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737226 20134 solver.cpp:238]     Train net output #8: loss17 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737231 20134 solver.cpp:238]     Train net output #9: loss18 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737238 20134 solver.cpp:238]     Train net output #10: loss19 = 1095.41 (* 1 = 1095.41 loss)
I0728 13:38:19.737244 20134 solver.cpp:238]     Train net output #11: loss2 = 1069.65 (* 1 = 1069.65 loss)
I0728 13:38:19.737251 20134 solver.cpp:238]     Train net output #12: loss20 = 1068.08 (* 1 = 1068.08 loss)
I0728 13:38:19.737260 20134 solver.cpp:238]     Train net output #13: loss21 = 1065.51 (* 1 = 1065.51 loss)
I0728 13:38:19.737270 20134 solver.cpp:238]     Train net output #14: loss22 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737277 20134 solver.cpp:238]     Train net output #15: loss23 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737283 20134 solver.cpp:238]     Train net output #16: loss24 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737289 20134 solver.cpp:238]     Train net output #17: loss25 = 1083.57 (* 1 = 1083.57 loss)
I0728 13:38:19.737295 20134 solver.cpp:238]     Train net output #18: loss26 = 1078.45 (* 1 = 1078.45 loss)
I0728 13:38:19.737301 20134 solver.cpp:238]     Train net output #19: loss27 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737313 20134 solver.cpp:238]     Train net output #20: loss28 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737319 20134 solver.cpp:238]     Train net output #21: loss29 = 1093.95 (* 1 = 1093.95 loss)
I0728 13:38:19.737325 20134 solver.cpp:238]     Train net output #22: loss3 = 1083.97 (* 1 = 1083.97 loss)
I0728 13:38:19.737331 20134 solver.cpp:238]     Train net output #23: loss30 = 1090.75 (* 1 = 1090.75 loss)
I0728 13:38:19.737337 20134 solver.cpp:238]     Train net output #24: loss31 = 1079.59 (* 1 = 1079.59 loss)
I0728 13:38:19.737344 20134 solver.cpp:238]     Train net output #25: loss32 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737349 20134 solver.cpp:238]     Train net output #26: loss33 = 1078.88 (* 1 = 1078.88 loss)
I0728 13:38:19.737356 20134 solver.cpp:238]     Train net output #27: loss34 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737362 20134 solver.cpp:238]     Train net output #28: loss35 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737390 20134 solver.cpp:238]     Train net output #29: loss36 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737398 20134 solver.cpp:238]     Train net output #30: loss37 = 1084.74 (* 1 = 1084.74 loss)
I0728 13:38:19.737404 20134 solver.cpp:238]     Train net output #31: loss38 = 1095.43 (* 1 = 1095.43 loss)
I0728 13:38:19.737411 20134 solver.cpp:238]     Train net output #32: loss39 = 1082.79 (* 1 = 1082.79 loss)
I0728 13:38:19.737419 20134 solver.cpp:238]     Train net output #33: loss4 = 1074.45 (* 1 = 1074.45 loss)
I0728 13:38:19.737428 20134 solver.cpp:238]     Train net output #34: loss40 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737437 20134 solver.cpp:238]     Train net output #35: loss41 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737447 20134 solver.cpp:238]     Train net output #36: loss42 = 1070.73 (* 1 = 1070.73 loss)
I0728 13:38:19.737457 20134 solver.cpp:238]     Train net output #37: loss43 = 1080.37 (* 1 = 1080.37 loss)
I0728 13:38:19.737465 20134 solver.cpp:238]     Train net output #38: loss44 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737475 20134 solver.cpp:238]     Train net output #39: loss45 = 1081.04 (* 1 = 1081.04 loss)
I0728 13:38:19.737485 20134 solver.cpp:238]     Train net output #40: loss46 = 1093.26 (* 1 = 1093.26 loss)
I0728 13:38:19.737495 20134 solver.cpp:238]     Train net output #41: loss47 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737505 20134 solver.cpp:238]     Train net output #42: loss48 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737515 20134 solver.cpp:238]     Train net output #43: loss49 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737525 20134 solver.cpp:238]     Train net output #44: loss5 = 1087.21 (* 1 = 1087.21 loss)
I0728 13:38:19.737535 20134 solver.cpp:238]     Train net output #45: loss50 = 1076.94 (* 1 = 1076.94 loss)
I0728 13:38:19.737545 20134 solver.cpp:238]     Train net output #46: loss51 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737555 20134 solver.cpp:238]     Train net output #47: loss52 = 1093.57 (* 1 = 1093.57 loss)
I0728 13:38:19.737566 20134 solver.cpp:238]     Train net output #48: loss53 = 1088.2 (* 1 = 1088.2 loss)
I0728 13:38:19.737573 20134 solver.cpp:238]     Train net output #49: loss54 = 1084.08 (* 1 = 1084.08 loss)
I0728 13:38:19.737581 20134 solver.cpp:238]     Train net output #50: loss55 = 1074.63 (* 1 = 1074.63 loss)
I0728 13:38:19.737592 20134 solver.cpp:238]     Train net output #51: loss56 = 1081.78 (* 1 = 1081.78 loss)
I0728 13:38:19.737601 20134 solver.cpp:238]     Train net output #52: loss57 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737607 20134 solver.cpp:238]     Train net output #53: loss58 = 1083.45 (* 1 = 1083.45 loss)
I0728 13:38:19.737612 20134 solver.cpp:238]     Train net output #54: loss59 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737618 20134 solver.cpp:238]     Train net output #55: loss6 = 1088.46 (* 1 = 1088.46 loss)
I0728 13:38:19.737624 20134 solver.cpp:238]     Train net output #56: loss60 = 1076.81 (* 1 = 1076.81 loss)
I0728 13:38:19.737630 20134 solver.cpp:238]     Train net output #57: loss61 = 1062.08 (* 1 = 1062.08 loss)
I0728 13:38:19.737637 20134 solver.cpp:238]     Train net output #58: loss62 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737643 20134 solver.cpp:238]     Train net output #59: loss63 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737648 20134 solver.cpp:238]     Train net output #60: loss64 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737653 20134 solver.cpp:238]     Train net output #61: loss7 = 1090.31 (* 1 = 1090.31 loss)
I0728 13:38:19.737659 20134 solver.cpp:238]     Train net output #62: loss8 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737665 20134 solver.cpp:238]     Train net output #63: loss9 = 1071.82 (* 1 = 1071.82 loss)
I0728 13:38:19.737671 20134 sgd_solver.cpp:105] Iteration 129600, lr = 1e-09
I0728 13:47:10.552103 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:47:10.555378 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:47:10.940070 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_135000.caffemodel
I0728 13:47:11.153606 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_135000.solverstate
I0728 13:47:11.233623 20134 solver.cpp:331] Iteration 135000, Testing net (#0)
I0728 13:47:26.425582 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:47:26.446112 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:47:26.889323 20134 solver.cpp:398]     Test net output #0: mae = 74.2648 (* 1 = 74.2648 loss)
I0728 13:47:26.889345 20134 solver.cpp:398]     Test net output #1: mse = 12500.4 (* 1 = 12500.4 loss)
I0728 13:47:27.013917 20134 solver.cpp:219] Iteration 135000 (9.86719 iter/s, 547.268s/5400 iters), loss = 68494.8
I0728 13:47:27.013957 20134 solver.cpp:238]     Train net output #0: loss1 = 1071.1 (* 1 = 1071.1 loss)
I0728 13:47:27.013967 20134 solver.cpp:238]     Train net output #1: loss10 = 1053.14 (* 1 = 1053.14 loss)
I0728 13:47:27.013972 20134 solver.cpp:238]     Train net output #2: loss11 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.013978 20134 solver.cpp:238]     Train net output #3: loss12 = 1079.67 (* 1 = 1079.67 loss)
I0728 13:47:27.013984 20134 solver.cpp:238]     Train net output #4: loss13 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.013990 20134 solver.cpp:238]     Train net output #5: loss14 = 1068.63 (* 1 = 1068.63 loss)
I0728 13:47:27.013996 20134 solver.cpp:238]     Train net output #6: loss15 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014003 20134 solver.cpp:238]     Train net output #7: loss16 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014008 20134 solver.cpp:238]     Train net output #8: loss17 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014012 20134 solver.cpp:238]     Train net output #9: loss18 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014016 20134 solver.cpp:238]     Train net output #10: loss19 = 1085.76 (* 1 = 1085.76 loss)
I0728 13:47:27.014024 20134 solver.cpp:238]     Train net output #11: loss2 = 1061.4 (* 1 = 1061.4 loss)
I0728 13:47:27.014029 20134 solver.cpp:238]     Train net output #12: loss20 = 1059.73 (* 1 = 1059.73 loss)
I0728 13:47:27.014034 20134 solver.cpp:238]     Train net output #13: loss21 = 1057.91 (* 1 = 1057.91 loss)
I0728 13:47:27.014040 20134 solver.cpp:238]     Train net output #14: loss22 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014046 20134 solver.cpp:238]     Train net output #15: loss23 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014052 20134 solver.cpp:238]     Train net output #16: loss24 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014058 20134 solver.cpp:238]     Train net output #17: loss25 = 1075.28 (* 1 = 1075.28 loss)
I0728 13:47:27.014065 20134 solver.cpp:238]     Train net output #18: loss26 = 1070.18 (* 1 = 1070.18 loss)
I0728 13:47:27.014070 20134 solver.cpp:238]     Train net output #19: loss27 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014076 20134 solver.cpp:238]     Train net output #20: loss28 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014082 20134 solver.cpp:238]     Train net output #21: loss29 = 1084.82 (* 1 = 1084.82 loss)
I0728 13:47:27.014088 20134 solver.cpp:238]     Train net output #22: loss3 = 1075.78 (* 1 = 1075.78 loss)
I0728 13:47:27.014096 20134 solver.cpp:238]     Train net output #23: loss30 = 1082.17 (* 1 = 1082.17 loss)
I0728 13:47:27.014101 20134 solver.cpp:238]     Train net output #24: loss31 = 1071.23 (* 1 = 1071.23 loss)
I0728 13:47:27.014106 20134 solver.cpp:238]     Train net output #25: loss32 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014113 20134 solver.cpp:238]     Train net output #26: loss33 = 1070.56 (* 1 = 1070.56 loss)
I0728 13:47:27.014119 20134 solver.cpp:238]     Train net output #27: loss34 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014125 20134 solver.cpp:238]     Train net output #28: loss35 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014164 20134 solver.cpp:238]     Train net output #29: loss36 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014175 20134 solver.cpp:238]     Train net output #30: loss37 = 1076.52 (* 1 = 1076.52 loss)
I0728 13:47:27.014184 20134 solver.cpp:238]     Train net output #31: loss38 = 1086.66 (* 1 = 1086.66 loss)
I0728 13:47:27.014195 20134 solver.cpp:238]     Train net output #32: loss39 = 1074.2 (* 1 = 1074.2 loss)
I0728 13:47:27.014204 20134 solver.cpp:238]     Train net output #33: loss4 = 1066.3 (* 1 = 1066.3 loss)
I0728 13:47:27.014209 20134 solver.cpp:238]     Train net output #34: loss40 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014215 20134 solver.cpp:238]     Train net output #35: loss41 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014221 20134 solver.cpp:238]     Train net output #36: loss42 = 1062.52 (* 1 = 1062.52 loss)
I0728 13:47:27.014228 20134 solver.cpp:238]     Train net output #37: loss43 = 1072.13 (* 1 = 1072.13 loss)
I0728 13:47:27.014233 20134 solver.cpp:238]     Train net output #38: loss44 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014240 20134 solver.cpp:238]     Train net output #39: loss45 = 1073.02 (* 1 = 1073.02 loss)
I0728 13:47:27.014245 20134 solver.cpp:238]     Train net output #40: loss46 = 1084 (* 1 = 1084 loss)
I0728 13:47:27.014252 20134 solver.cpp:238]     Train net output #41: loss47 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014258 20134 solver.cpp:238]     Train net output #42: loss48 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014263 20134 solver.cpp:238]     Train net output #43: loss49 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014269 20134 solver.cpp:238]     Train net output #44: loss5 = 1079.17 (* 1 = 1079.17 loss)
I0728 13:47:27.014276 20134 solver.cpp:238]     Train net output #45: loss50 = 1068.92 (* 1 = 1068.92 loss)
I0728 13:47:27.014281 20134 solver.cpp:238]     Train net output #46: loss51 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014287 20134 solver.cpp:238]     Train net output #47: loss52 = 1084.84 (* 1 = 1084.84 loss)
I0728 13:47:27.014293 20134 solver.cpp:238]     Train net output #48: loss53 = 1079.62 (* 1 = 1079.62 loss)
I0728 13:47:27.014299 20134 solver.cpp:238]     Train net output #49: loss54 = 1075.54 (* 1 = 1075.54 loss)
I0728 13:47:27.014305 20134 solver.cpp:238]     Train net output #50: loss55 = 1066.56 (* 1 = 1066.56 loss)
I0728 13:47:27.014312 20134 solver.cpp:238]     Train net output #51: loss56 = 1073.17 (* 1 = 1073.17 loss)
I0728 13:47:27.014317 20134 solver.cpp:238]     Train net output #52: loss57 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014323 20134 solver.cpp:238]     Train net output #53: loss58 = 1075.19 (* 1 = 1075.19 loss)
I0728 13:47:27.014329 20134 solver.cpp:238]     Train net output #54: loss59 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014335 20134 solver.cpp:238]     Train net output #55: loss6 = 1080.04 (* 1 = 1080.04 loss)
I0728 13:47:27.014340 20134 solver.cpp:238]     Train net output #56: loss60 = 1068.3 (* 1 = 1068.3 loss)
I0728 13:47:27.014346 20134 solver.cpp:238]     Train net output #57: loss61 = 1053.98 (* 1 = 1053.98 loss)
I0728 13:47:27.014353 20134 solver.cpp:238]     Train net output #58: loss62 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014358 20134 solver.cpp:238]     Train net output #59: loss63 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014365 20134 solver.cpp:238]     Train net output #60: loss64 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014371 20134 solver.cpp:238]     Train net output #61: loss7 = 1081.86 (* 1 = 1081.86 loss)
I0728 13:47:27.014377 20134 solver.cpp:238]     Train net output #62: loss8 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014384 20134 solver.cpp:238]     Train net output #63: loss9 = 1063.61 (* 1 = 1063.61 loss)
I0728 13:47:27.014390 20134 sgd_solver.cpp:105] Iteration 135000, lr = 1e-09
I0728 13:56:18.115183 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:56:18.116649 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:56:18.502583 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_140400.caffemodel
I0728 13:56:18.714956 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_140400.solverstate
I0728 13:56:18.795128 20134 solver.cpp:331] Iteration 140400, Testing net (#0)
I0728 13:56:34.029734 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:56:34.050894 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 13:56:34.494002 20134 solver.cpp:398]     Test net output #0: mae = 73.4568 (* 1 = 73.4568 loss)
I0728 13:56:34.494024 20134 solver.cpp:398]     Test net output #1: mse = 12604.1 (* 1 = 12604.1 loss)
I0728 13:56:34.618886 20134 solver.cpp:219] Iteration 140400 (9.86129 iter/s, 547.596s/5400 iters), loss = 67344.5
I0728 13:56:34.618930 20134 solver.cpp:238]     Train net output #0: loss1 = 1053.11 (* 1 = 1053.11 loss)
I0728 13:56:34.618939 20134 solver.cpp:238]     Train net output #1: loss10 = 1035.14 (* 1 = 1035.14 loss)
I0728 13:56:34.618947 20134 solver.cpp:238]     Train net output #2: loss11 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618952 20134 solver.cpp:238]     Train net output #3: loss12 = 1060.75 (* 1 = 1060.75 loss)
I0728 13:56:34.618959 20134 solver.cpp:238]     Train net output #4: loss13 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618964 20134 solver.cpp:238]     Train net output #5: loss14 = 1050.23 (* 1 = 1050.23 loss)
I0728 13:56:34.618970 20134 solver.cpp:238]     Train net output #6: loss15 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618976 20134 solver.cpp:238]     Train net output #7: loss16 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618983 20134 solver.cpp:238]     Train net output #8: loss17 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618988 20134 solver.cpp:238]     Train net output #9: loss18 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.618994 20134 solver.cpp:238]     Train net output #10: loss19 = 1065.61 (* 1 = 1065.61 loss)
I0728 13:56:34.619000 20134 solver.cpp:238]     Train net output #11: loss2 = 1043.36 (* 1 = 1043.36 loss)
I0728 13:56:34.619006 20134 solver.cpp:238]     Train net output #12: loss20 = 1040.03 (* 1 = 1040.03 loss)
I0728 13:56:34.619012 20134 solver.cpp:238]     Train net output #13: loss21 = 1040.4 (* 1 = 1040.4 loss)
I0728 13:56:34.619017 20134 solver.cpp:238]     Train net output #14: loss22 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619025 20134 solver.cpp:238]     Train net output #15: loss23 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619036 20134 solver.cpp:238]     Train net output #16: loss24 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619047 20134 solver.cpp:238]     Train net output #17: loss25 = 1056.25 (* 1 = 1056.25 loss)
I0728 13:56:34.619058 20134 solver.cpp:238]     Train net output #18: loss26 = 1051.77 (* 1 = 1051.77 loss)
I0728 13:56:34.619065 20134 solver.cpp:238]     Train net output #19: loss27 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619071 20134 solver.cpp:238]     Train net output #20: loss28 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619077 20134 solver.cpp:238]     Train net output #21: loss29 = 1064.65 (* 1 = 1064.65 loss)
I0728 13:56:34.619083 20134 solver.cpp:238]     Train net output #22: loss3 = 1056.39 (* 1 = 1056.39 loss)
I0728 13:56:34.619089 20134 solver.cpp:238]     Train net output #23: loss30 = 1063.03 (* 1 = 1063.03 loss)
I0728 13:56:34.619096 20134 solver.cpp:238]     Train net output #24: loss31 = 1052.81 (* 1 = 1052.81 loss)
I0728 13:56:34.619102 20134 solver.cpp:238]     Train net output #25: loss32 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619107 20134 solver.cpp:238]     Train net output #26: loss33 = 1052.5 (* 1 = 1052.5 loss)
I0728 13:56:34.619113 20134 solver.cpp:238]     Train net output #27: loss34 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619119 20134 solver.cpp:238]     Train net output #28: loss35 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619151 20134 solver.cpp:238]     Train net output #29: loss36 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619159 20134 solver.cpp:238]     Train net output #30: loss37 = 1057.41 (* 1 = 1057.41 loss)
I0728 13:56:34.619165 20134 solver.cpp:238]     Train net output #31: loss38 = 1067.74 (* 1 = 1067.74 loss)
I0728 13:56:34.619171 20134 solver.cpp:238]     Train net output #32: loss39 = 1055.5 (* 1 = 1055.5 loss)
I0728 13:56:34.619177 20134 solver.cpp:238]     Train net output #33: loss4 = 1048.33 (* 1 = 1048.33 loss)
I0728 13:56:34.619184 20134 solver.cpp:238]     Train net output #34: loss40 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619194 20134 solver.cpp:238]     Train net output #35: loss41 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619199 20134 solver.cpp:238]     Train net output #36: loss42 = 1044.54 (* 1 = 1044.54 loss)
I0728 13:56:34.619204 20134 solver.cpp:238]     Train net output #37: loss43 = 1053.92 (* 1 = 1053.92 loss)
I0728 13:56:34.619211 20134 solver.cpp:238]     Train net output #38: loss44 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619217 20134 solver.cpp:238]     Train net output #39: loss45 = 1054.41 (* 1 = 1054.41 loss)
I0728 13:56:34.619223 20134 solver.cpp:238]     Train net output #40: loss46 = 1063.91 (* 1 = 1063.91 loss)
I0728 13:56:34.619230 20134 solver.cpp:238]     Train net output #41: loss47 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619235 20134 solver.cpp:238]     Train net output #42: loss48 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619241 20134 solver.cpp:238]     Train net output #43: loss49 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619251 20134 solver.cpp:238]     Train net output #44: loss5 = 1060.24 (* 1 = 1060.24 loss)
I0728 13:56:34.619259 20134 solver.cpp:238]     Train net output #45: loss50 = 1051.01 (* 1 = 1051.01 loss)
I0728 13:56:34.619266 20134 solver.cpp:238]     Train net output #46: loss51 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619271 20134 solver.cpp:238]     Train net output #47: loss52 = 1066.22 (* 1 = 1066.22 loss)
I0728 13:56:34.619277 20134 solver.cpp:238]     Train net output #48: loss53 = 1060.94 (* 1 = 1060.94 loss)
I0728 13:56:34.619283 20134 solver.cpp:238]     Train net output #49: loss54 = 1057.11 (* 1 = 1057.11 loss)
I0728 13:56:34.619288 20134 solver.cpp:238]     Train net output #50: loss55 = 1048.45 (* 1 = 1048.45 loss)
I0728 13:56:34.619294 20134 solver.cpp:238]     Train net output #51: loss56 = 1054.41 (* 1 = 1054.41 loss)
I0728 13:56:34.619300 20134 solver.cpp:238]     Train net output #52: loss57 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619307 20134 solver.cpp:238]     Train net output #53: loss58 = 1056.32 (* 1 = 1056.32 loss)
I0728 13:56:34.619313 20134 solver.cpp:238]     Train net output #54: loss59 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619318 20134 solver.cpp:238]     Train net output #55: loss6 = 1061.21 (* 1 = 1061.21 loss)
I0728 13:56:34.619324 20134 solver.cpp:238]     Train net output #56: loss60 = 1049.57 (* 1 = 1049.57 loss)
I0728 13:56:34.619330 20134 solver.cpp:238]     Train net output #57: loss61 = 1036.25 (* 1 = 1036.25 loss)
I0728 13:56:34.619336 20134 solver.cpp:238]     Train net output #58: loss62 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619343 20134 solver.cpp:238]     Train net output #59: loss63 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619349 20134 solver.cpp:238]     Train net output #60: loss64 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619361 20134 solver.cpp:238]     Train net output #61: loss7 = 1062.42 (* 1 = 1062.42 loss)
I0728 13:56:34.619367 20134 solver.cpp:238]     Train net output #62: loss8 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619374 20134 solver.cpp:238]     Train net output #63: loss9 = 1045.67 (* 1 = 1045.67 loss)
I0728 13:56:34.619381 20134 sgd_solver.cpp:105] Iteration 140400, lr = 1e-09
I0728 14:05:25.189453 20141 data_layer.cpp:73] Restarting data prefetching from start.
I0728 14:05:25.192821 20140 data_layer.cpp:73] Restarting data prefetching from start.
I0728 14:05:25.575678 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_145800.caffemodel
I0728 14:05:26.044137 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_145800.solverstate
I0728 14:05:26.125007 20134 solver.cpp:331] Iteration 145800, Testing net (#0)
I0728 14:05:41.353545 20144 data_layer.cpp:73] Restarting data prefetching from start.
I0728 14:05:41.378859 20143 data_layer.cpp:73] Restarting data prefetching from start.
I0728 14:05:41.818132 20134 solver.cpp:398]     Test net output #0: mae = 73.6763 (* 1 = 73.6763 loss)
I0728 14:05:41.818156 20134 solver.cpp:398]     Test net output #1: mse = 12550.4 (* 1 = 12550.4 loss)
I0728 14:05:41.942695 20134 solver.cpp:219] Iteration 145800 (9.86636 iter/s, 547.314s/5400 iters), loss = 67043
I0728 14:05:41.942736 20134 solver.cpp:238]     Train net output #0: loss1 = 1048.83 (* 1 = 1048.83 loss)
I0728 14:05:41.942745 20134 solver.cpp:238]     Train net output #1: loss10 = 1030.82 (* 1 = 1030.82 loss)
I0728 14:05:41.942752 20134 solver.cpp:238]     Train net output #2: loss11 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942759 20134 solver.cpp:238]     Train net output #3: loss12 = 1056.52 (* 1 = 1056.52 loss)
I0728 14:05:41.942764 20134 solver.cpp:238]     Train net output #4: loss13 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942770 20134 solver.cpp:238]     Train net output #5: loss14 = 1045.91 (* 1 = 1045.91 loss)
I0728 14:05:41.942775 20134 solver.cpp:238]     Train net output #6: loss15 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942781 20134 solver.cpp:238]     Train net output #7: loss16 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942787 20134 solver.cpp:238]     Train net output #8: loss17 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942792 20134 solver.cpp:238]     Train net output #9: loss18 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942798 20134 solver.cpp:238]     Train net output #10: loss19 = 1060.5 (* 1 = 1060.5 loss)
I0728 14:05:41.942804 20134 solver.cpp:238]     Train net output #11: loss2 = 1038.92 (* 1 = 1038.92 loss)
I0728 14:05:41.942811 20134 solver.cpp:238]     Train net output #12: loss20 = 1035.32 (* 1 = 1035.32 loss)
I0728 14:05:41.942816 20134 solver.cpp:238]     Train net output #13: loss21 = 1036.67 (* 1 = 1036.67 loss)
I0728 14:05:41.942822 20134 solver.cpp:238]     Train net output #14: loss22 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942827 20134 solver.cpp:238]     Train net output #15: loss23 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942833 20134 solver.cpp:238]     Train net output #16: loss24 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942839 20134 solver.cpp:238]     Train net output #17: loss25 = 1052.15 (* 1 = 1052.15 loss)
I0728 14:05:41.942845 20134 solver.cpp:238]     Train net output #18: loss26 = 1047.35 (* 1 = 1047.35 loss)
I0728 14:05:41.942852 20134 solver.cpp:238]     Train net output #19: loss27 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942857 20134 solver.cpp:238]     Train net output #20: loss28 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942862 20134 solver.cpp:238]     Train net output #21: loss29 = 1059.64 (* 1 = 1059.64 loss)
I0728 14:05:41.942868 20134 solver.cpp:238]     Train net output #22: loss3 = 1052.35 (* 1 = 1052.35 loss)
I0728 14:05:41.942874 20134 solver.cpp:238]     Train net output #23: loss30 = 1058.32 (* 1 = 1058.32 loss)
I0728 14:05:41.942880 20134 solver.cpp:238]     Train net output #24: loss31 = 1048.36 (* 1 = 1048.36 loss)
I0728 14:05:41.942885 20134 solver.cpp:238]     Train net output #25: loss32 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942891 20134 solver.cpp:238]     Train net output #26: loss33 = 1047.96 (* 1 = 1047.96 loss)
I0728 14:05:41.942898 20134 solver.cpp:238]     Train net output #27: loss34 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942903 20134 solver.cpp:238]     Train net output #28: loss35 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942934 20134 solver.cpp:238]     Train net output #29: loss36 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942942 20134 solver.cpp:238]     Train net output #30: loss37 = 1052.9 (* 1 = 1052.9 loss)
I0728 14:05:41.942948 20134 solver.cpp:238]     Train net output #31: loss38 = 1063.01 (* 1 = 1063.01 loss)
I0728 14:05:41.942955 20134 solver.cpp:238]     Train net output #32: loss39 = 1050.99 (* 1 = 1050.99 loss)
I0728 14:05:41.942960 20134 solver.cpp:238]     Train net output #33: loss4 = 1044.03 (* 1 = 1044.03 loss)
I0728 14:05:41.942970 20134 solver.cpp:238]     Train net output #34: loss40 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942976 20134 solver.cpp:238]     Train net output #35: loss41 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942982 20134 solver.cpp:238]     Train net output #36: loss42 = 1040.22 (* 1 = 1040.22 loss)
I0728 14:05:41.942988 20134 solver.cpp:238]     Train net output #37: loss43 = 1049.54 (* 1 = 1049.54 loss)
I0728 14:05:41.942993 20134 solver.cpp:238]     Train net output #38: loss44 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.942999 20134 solver.cpp:238]     Train net output #39: loss45 = 1050.44 (* 1 = 1050.44 loss)
I0728 14:05:41.943006 20134 solver.cpp:238]     Train net output #40: loss46 = 1059.24 (* 1 = 1059.24 loss)
I0728 14:05:41.943011 20134 solver.cpp:238]     Train net output #41: loss47 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943017 20134 solver.cpp:238]     Train net output #42: loss48 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943023 20134 solver.cpp:238]     Train net output #43: loss49 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943028 20134 solver.cpp:238]     Train net output #44: loss5 = 1056.6 (* 1 = 1056.6 loss)
I0728 14:05:41.943034 20134 solver.cpp:238]     Train net output #45: loss50 = 1047.07 (* 1 = 1047.07 loss)
I0728 14:05:41.943040 20134 solver.cpp:238]     Train net output #46: loss51 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943047 20134 solver.cpp:238]     Train net output #47: loss52 = 1060.4 (* 1 = 1060.4 loss)
I0728 14:05:41.943053 20134 solver.cpp:238]     Train net output #48: loss53 = 1056.19 (* 1 = 1056.19 loss)
I0728 14:05:41.943058 20134 solver.cpp:238]     Train net output #49: loss54 = 1052.47 (* 1 = 1052.47 loss)
I0728 14:05:41.943064 20134 solver.cpp:238]     Train net output #50: loss55 = 1044.14 (* 1 = 1044.14 loss)
I0728 14:05:41.943070 20134 solver.cpp:238]     Train net output #51: loss56 = 1049.75 (* 1 = 1049.75 loss)
I0728 14:05:41.943076 20134 solver.cpp:238]     Train net output #52: loss57 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943083 20134 solver.cpp:238]     Train net output #53: loss58 = 1051.79 (* 1 = 1051.79 loss)
I0728 14:05:41.943089 20134 solver.cpp:238]     Train net output #54: loss59 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943094 20134 solver.cpp:238]     Train net output #55: loss6 = 1056.94 (* 1 = 1056.94 loss)
I0728 14:05:41.943100 20134 solver.cpp:238]     Train net output #56: loss60 = 1045.17 (* 1 = 1045.17 loss)
I0728 14:05:41.943105 20134 solver.cpp:238]     Train net output #57: loss61 = 1032.02 (* 1 = 1032.02 loss)
I0728 14:05:41.943111 20134 solver.cpp:238]     Train net output #58: loss62 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943117 20134 solver.cpp:238]     Train net output #59: loss63 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943123 20134 solver.cpp:238]     Train net output #60: loss64 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943128 20134 solver.cpp:238]     Train net output #61: loss7 = 1058.33 (* 1 = 1058.33 loss)
I0728 14:05:41.943135 20134 solver.cpp:238]     Train net output #62: loss8 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943140 20134 solver.cpp:238]     Train net output #63: loss9 = 1041.31 (* 1 = 1041.31 loss)
I0728 14:05:41.943146 20134 sgd_solver.cpp:105] Iteration 145800, lr = 1e-09
I0728 14:08:30.546684 20134 solver.cpp:448] Snapshotting to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_147528.caffemodel
I0728 14:08:31.078763 20134 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/crowd/code/shanghaiA/model/network_vgg_1.01_iter_147528.solverstate
I0728 14:08:31.161281 20134 solver.cpp:295] Optimization stopped early.
I0728 14:08:31.161300 20134 caffe.cpp:259] Optimization Done.
